# Proyecto de AnÃ¡lisis de Algoritmos - Inteligencia Artificial Generativa

Sistema completo de **recopilaciÃ³n, procesamiento y anÃ¡lisis** de literatura cientÃ­fica sobre Inteligencia Artificial Generativa. El proyecto incluye web scraping automatizado, anÃ¡lisis bibliomÃ©trico, clustering, anÃ¡lisis de grafos y comparaciÃ³n de algoritmos de ordenamiento.

## ğŸ¯ Objetivos del Proyecto

- **RecopilaciÃ³n automatizada** de artÃ­culos de IEEE, ScienceDirect y Taylor & Francis
- **ConsolidaciÃ³n y limpieza** de datos bibliogrÃ¡ficos (eliminaciÃ³n de duplicados)
- **AnÃ¡lisis de similitud** entre artÃ­culos usando mÃºltiples tÃ©cnicas (TF-IDF, SBERT, Levenshtein)
- **AnÃ¡lisis de frecuencias** de palabras clave en la literatura
- **Clustering jerÃ¡rquico** para identificar subtemas
- **AnÃ¡lisis geogrÃ¡fico** de distribuciÃ³n de autores
- **AnÃ¡lisis de grafos** de relaciones entre artÃ­culos
- **ComparaciÃ³n de algoritmos** de ordenamiento

## ğŸ“Š Estado del Proyecto

âœ… **Completado**: 
- Web scraping de 3 fuentes principales
- ConsolidaciÃ³n de ~10,000 artÃ­culos
- 5 requerimientos de anÃ¡lisis implementados
- 2 seguimientos tÃ©cnicos completados
- DocumentaciÃ³n completa de todos los mÃ³dulos

## ğŸ“‹ Requisitos Previos

- Python 3.9 o superior
- Git (opcional, para clonar el repositorio)
- Google Chrome (para web scraping con Selenium)

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar o descargar el proyecto

```bash
git clone <url-del-repositorio>
cd proyectoAnalisisAlgoritmos
```

O descarga el proyecto como ZIP y descomprÃ­melo.

### 2. Crear el entorno virtual

**En Linux/Mac:**
```bash
python3 -m venv venv
```

**En Windows:**
```bash
python -m venv venv
```

### 3. Activar el entorno virtual

**En Linux/Mac:**
```bash
source venv/bin/activate
```

**En Windows (CMD):**
```bash
venv\Scripts\activate.bat
```

**En Windows (PowerShell):**
```bash
venv\Scripts\Activate.ps1
```

> **Nota:** Si ves `(venv)` al inicio de tu lÃ­nea de comandos, significa que el entorno virtual estÃ¡ activado correctamente.

### 4. Instalar las dependencias

Con el entorno virtual activado, ejecuta:

```bash
pip install -r requirements.txt
```

Este proceso puede tardar varios minutos ya que descarga PyTorch y otras librerÃ­as grandes (~3GB).

### 5. Configurar variables de entorno

Crea un archivo `.env` en la raÃ­z del proyecto con el siguiente contenido:

```env
# Credenciales de acceso (para web scraping)
EMAIL=tu_email@ejemplo.com
PASSWORD=tu_contraseÃ±a

# Rutas del proyecto (ajusta segÃºn tu sistema operativo)
# En Linux/Mac usa rutas absolutas como: /home/usuario/proyectoAnalisisAlgoritmos/descargas
# En Windows usa rutas como: C:\Users\usuario\proyectoAnalisisAlgoritmos\descargas

DOWNLOAD_PATH=/ruta/absoluta/al/proyecto/descargas
SALIDA_PATH=/ruta/absoluta/al/proyecto/proyecto/salidas
DUPLICATE_PATH=/ruta/absoluta/al/proyecto/duplicados
CONSOLIDADO_PATH=/ruta/absoluta/al/proyecto/proyecto/salidas/consolidado.bib
ORDENAMIENTO_PATH=/ruta/absoluta/al/proyecto/proyecto/salidas/ordenamiento
TIEMPOS_PATH=/ruta/absoluta/al/proyecto/proyecto/salidas/tiempoAlgoritmos
PRIMEROS_500=/ruta/absoluta/al/proyecto/proyecto/primeros_500.bib
```

**Ejemplo para Linux:**
```env
EMAIL=usuario@gmail.com
PASSWORD=micontraseÃ±a123

DOWNLOAD_PATH=/home/usuario/Documentos/proyectoAnalisisAlgoritmos/descargas
SALIDA_PATH=/home/usuario/Documentos/proyectoAnalisisAlgoritmos/proyecto/salidas
DUPLICATE_PATH=/home/usuario/Documentos/proyectoAnalisisAlgoritmos/duplicados
CONSOLIDADO_PATH=/home/usuario/Documentos/proyectoAnalisisAlgoritmos/proyecto/salidas/consolidado.bib
ORDENAMIENTO_PATH=/home/usuario/Documentos/proyectoAnalisisAlgoritmos/proyecto/salidas/ordenamiento
TIEMPOS_PATH=/home/usuario/Documentos/proyectoAnalisisAlgoritmos/proyecto/salidas/tiempoAlgoritmos
PRIMEROS_500=/home/yep/Documentos/proyectoAnalisisAlgoritmos/proyecto/primeros_500.bib
```

### 6. Crear las carpetas necesarias

```bash
mkdir -p descargas duplicados proyecto/salidas/ordenamiento proyecto/salidas/tiempoAlgoritmos
```

## ğŸ“‚ Estructura del Proyecto

```
proyectoAnalisisAlgoritmos/
â”œâ”€â”€ proyecto/                           # MÃ³dulo principal
â”‚   â”œâ”€â”€ data/                          # Web scraping
â”‚   â”‚   â”œâ”€â”€ IEEE.ipynb                 # Scraping de IEEE Xplore
â”‚   â”‚   â”œâ”€â”€ science.ipynb              # Scraping de ScienceDirect
â”‚   â”‚   â”œâ”€â”€ taylor.ipynb               # Scraping de Taylor & Francis
â”‚   â”‚   â””â”€â”€ README.md                  # DocumentaciÃ³n
â”‚   â”œâ”€â”€ requerimiento1/                # ConsolidaciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ Requerimiento1.ipynb       # Limpieza y deduplicaciÃ³n
â”‚   â”‚   â””â”€â”€ README.md                  # GuÃ­a completa
â”‚   â”œâ”€â”€ requerimiento2/                # AnÃ¡lisis de similitud
â”‚   â”‚   â”œâ”€â”€ Requeriemito2.ipynb        # 5 mÃ©todos de similitud
â”‚   â”‚   â””â”€â”€ README.md                  # ComparaciÃ³n de mÃ©todos
â”‚   â”œâ”€â”€ requerimiento3/                # AnÃ¡lisis de frecuencias
â”‚   â”‚   â”œâ”€â”€ Requerimiento3.ipynb       # AnÃ¡lisis de palabras clave
â”‚   â”‚   â””â”€â”€ README.md                  # Procesamiento NLP
â”‚   â”œâ”€â”€ requerimiento4/                # Clustering jerÃ¡rquico
â”‚   â”‚   â”œâ”€â”€ Requerimiento4.ipynb       # Dendrogramas y clusters
â”‚   â”‚   â””â”€â”€ README.md                  # GuÃ­a de clustering
â”‚   â”œâ”€â”€ requerimiento5/                # AnÃ¡lisis geogrÃ¡fico
â”‚   â”‚   â”œâ”€â”€ Requerimiento5.ipynb       # Mapas y distribuciÃ³n
â”‚   â”‚   â””â”€â”€ README.md                  # API Crossref y visualizaciÃ³n
â”‚   â”œâ”€â”€ consolidado.bib                # Base de datos consolidada (~10K artÃ­culos)
â”‚   â”œâ”€â”€ main.ipynb                     # Orquestador principal
â”‚   â””â”€â”€ README.md                      # DocumentaciÃ³n del proyecto
â”œâ”€â”€ seguimiento/                        # Seguimientos tÃ©cnicos
â”‚   â”œâ”€â”€ seguimiento1/                  # Algoritmos de ordenamiento
â”‚   â”‚   â”œâ”€â”€ algoritmosOrdenamiento.ipynb  # 10+ algoritmos
â”‚   â”‚   â””â”€â”€ README.md                  # ComparaciÃ³n y anÃ¡lisis
â”‚   â””â”€â”€ seguimiento2/                  # AnÃ¡lisis de grafos
â”‚       â”œâ”€â”€ sr1.ipynb                  # Grafo de artÃ­culos
â”‚       â”œâ”€â”€ sr2.ipynb                  # AnÃ¡lisis adicional
â”‚       â”œâ”€â”€ scrip.py                   # Utilidad de extracciÃ³n
â”‚       â”œâ”€â”€ consolidado.bib            # Datos para grafos
â”‚       â””â”€â”€ README.md                  # GuÃ­a completa de grafos
â”œâ”€â”€ descargas/                         # Archivos descargados
â”‚   â”œâ”€â”€ ieee/                          # ArtÃ­culos de IEEE
â”‚   â”œâ”€â”€ science/                       # ArtÃ­culos de ScienceDirect
â”‚   â””â”€â”€ taylor/                        # ArtÃ­culos de Taylor & Francis
â”œâ”€â”€ duplicados/                        # ArtÃ­culos duplicados detectados
â”œâ”€â”€ venv/                              # Entorno virtual (no versionar)
â”œâ”€â”€ .env                               # Variables de entorno (no versionar)
â”œâ”€â”€ .gitignore                         # Archivos ignorados por Git
â”œâ”€â”€ requirements.txt                   # Dependencias del proyecto
â”œâ”€â”€ prompts.txt                        # Prompts utilizados
â””â”€â”€ README.md                          # Este archivo
```

### ğŸ“š DocumentaciÃ³n Disponible

Cada mÃ³dulo tiene su propio README con:
- DescripciÃ³n detallada del funcionamiento
- GuÃ­a de uso y configuraciÃ³n
- Ejemplos de cÃ³digo
- SoluciÃ³n de problemas
- Tiempos de ejecuciÃ³n estimados

**READMEs principales**:
- [`proyecto/README.md`](./proyecto/README.md) - VisiÃ³n general del proyecto
- [`proyecto/requerimiento1/README.md`](./proyecto/requerimiento1/README.md) - ConsolidaciÃ³n de datos
- [`proyecto/requerimiento2/README.md`](./proyecto/requerimiento2/README.md) - AnÃ¡lisis de similitud
- [`proyecto/requerimiento3/README.md`](./proyecto/requerimiento3/README.md) - AnÃ¡lisis de frecuencias
- [`proyecto/requerimiento4/README.md`](./proyecto/requerimiento4/README.md) - Clustering jerÃ¡rquico
- [`proyecto/requerimiento5/README.md`](./proyecto/requerimiento5/README.md) - AnÃ¡lisis geogrÃ¡fico
- [`seguimiento/seguimiento1/README.md`](./seguimiento/seguimiento1/README.md) - Algoritmos de ordenamiento
- [`seguimiento/seguimiento2/README.md`](./seguimiento/seguimiento2/README.md) - AnÃ¡lisis de grafos

## ğŸ¯ CÃ³mo Ejecutar el Proyecto

### OpciÃ³n 1: Ejecutar notebooks individuales

Abre Jupyter Notebook o JupyterLab:

```bash
jupyter notebook
```

O si prefieres JupyterLab:

```bash
jupyter lab
```

Luego navega a los notebooks en el orden deseado.

### OpciÃ³n 2: Ejecutar desde VS Code

1. Instala la extensiÃ³n "Jupyter" en VS Code
2. Abre cualquier archivo `.ipynb`
3. Selecciona el kernel del entorno virtual (`venv`)
4. Ejecuta las celdas

### Orden de EjecuciÃ³n Recomendado

#### Fase 1: RecopilaciÃ³n de Datos (opcional si ya tienes `consolidado.bib`)

```bash
# Web scraping de artÃ­culos cientÃ­ficos
jupyter notebook proyecto/data/IEEE.ipynb
jupyter notebook proyecto/data/science.ipynb
jupyter notebook proyecto/data/taylor.ipynb
```

**Tiempo estimado**: 2-4 horas (depende de la cantidad de artÃ­culos)
**Resultado**: Archivos `.bib` en `descargas/ieee/`, `descargas/science/`, `descargas/taylor/`

#### Fase 2: ConsolidaciÃ³n y Limpieza

```bash
# Consolidar todos los archivos .bib y eliminar duplicados
jupyter notebook proyecto/requerimiento1/Requerimiento1.ipynb
```

**Tiempo estimado**: 5-10 minutos
**Resultado**: `proyecto/consolidado.bib` (~10,000 artÃ­culos Ãºnicos)

#### Fase 3: AnÃ¡lisis BibliomÃ©trico

```bash
# AnÃ¡lisis de similitud entre artÃ­culos (5 mÃ©todos)
jupyter notebook proyecto/requerimiento2/Requeriemito2.ipynb

# AnÃ¡lisis de frecuencia de palabras clave
jupyter notebook proyecto/requerimiento3/Requerimiento3.ipynb

# Clustering jerÃ¡rquico de artÃ­culos
jupyter notebook proyecto/requerimiento4/Requerimiento4.ipynb

# AnÃ¡lisis geogrÃ¡fico de autores
jupyter notebook proyecto/requerimiento5/Requerimiento5.ipynb
```

**Tiempo estimado**: 30-60 minutos (total)

#### Fase 4: Seguimientos TÃ©cnicos

```bash
# ComparaciÃ³n de algoritmos de ordenamiento
jupyter notebook seguimiento/seguimiento1/algoritmosOrdenamiento.ipynb

# AnÃ¡lisis de grafos de artÃ­culos (Dijkstra, Kosaraju)
jupyter notebook seguimiento/seguimiento2/sr1.ipynb
```

**Tiempo estimado**: 15-30 minutos

## ğŸ“¦ Dependencias Principales

El proyecto utiliza **33 paquetes principales** organizados por categorÃ­a:

### Procesamiento de Datos
- **bibtexparser** (1.4.3) - Parsing de archivos BibTeX
- **pybtex** (0.24.0) - Procesamiento avanzado de bibliografÃ­as
- **pandas** (2.3.1) - ManipulaciÃ³n de datos tabulares
- **numpy** (2.2.6) - Operaciones numÃ©ricas

### Machine Learning y NLP
- **sentence-transformers** (3.3.1) - Embeddings semÃ¡nticos (SBERT)
- **transformers** (4.48.3) - Modelos de lenguaje (Cross-Encoder)
- **torch** (2.6.0) - Framework de deep learning
- **scikit-learn** (1.7.2) - TF-IDF, clustering, mÃ©tricas
- **scipy** (1.16.1) - Algoritmos cientÃ­ficos
- **nltk** - Procesamiento de lenguaje natural

### AnÃ¡lisis de Similitud
- **Levenshtein** (0.27.1) - Distancia de ediciÃ³n
- **rapidfuzz** - Fuzzy matching rÃ¡pido

### Grafos y Redes
- **networkx** (3.5) - AnÃ¡lisis de grafos

### VisualizaciÃ³n
- **matplotlib** (3.10.5) - GrÃ¡ficos bÃ¡sicos
- **plotly** (6.3.0) - Visualizaciones interactivas
- **seaborn** (0.13.2) - GrÃ¡ficos estadÃ­sticos

### Web Scraping
- **selenium** (4.34.2) - AutomatizaciÃ³n de navegador
- **beautifulsoup4** (4.13.4) - Parsing HTML
- **requests** (2.32.4) - Peticiones HTTP

### Utilidades
- **python-dotenv** (1.1.1) - Variables de entorno
- **tqdm** (4.67.1) - Barras de progreso
- **natsort** (8.4.0) - Ordenamiento natural
- **pycountry** - CÃ³digos de paÃ­ses

### Jupyter
- **jupyter** (1.1.1) - Entorno de notebooks
- **jupyterlab** (4.4.6) - IDE para notebooks
- **notebook** (7.4.5) - Jupyter Notebook clÃ¡sico
- **nbconvert** (7.16.6) - ConversiÃ³n de notebooks
- **ipykernel** (6.30.1) - Kernel de Python

### Adicionales
- **pillow** (11.3.0) - Procesamiento de imÃ¡genes
- **openpyxl** (3.1.5) - Lectura/escritura de Excel

**Ver archivo completo**: [`requirements.txt`](./requirements.txt)

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "No module named 'xxx'"
AsegÃºrate de que el entorno virtual estÃ¡ activado y las dependencias instaladas:
```bash
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
```

### Error: "Cannot find Chrome driver"
Instala Chrome y asegÃºrate de que `webdriver-manager` estÃ¡ instalado (ya incluido en requirements.txt).

### Error: Conflictos de dependencias
Si hay conflictos, intenta:
```bash
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```

### Problemas con NLTK
Si faltan datos de NLTK, ejecuta en Python:
```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('punkt_tab')
```

## ğŸ›‘ Desactivar el Entorno Virtual

Cuando termines de trabajar:

```bash
deactivate
```

## ğŸ“Š Resultados y MÃ©tricas del Proyecto

### Datos Procesados
- **ArtÃ­culos recopilados**: ~12,500 (antes de limpieza)
- **ArtÃ­culos Ãºnicos**: ~10,226 (despuÃ©s de deduplicaciÃ³n)
- **Fuentes**: IEEE Xplore, ScienceDirect, Taylor & Francis
- **Periodo**: Principalmente 2020-2025
- **Tema**: Inteligencia Artificial Generativa

### AnÃ¡lisis Realizados

#### Requerimiento 1: ConsolidaciÃ³n
- **Duplicados detectados**: ~2,274 artÃ­culos
- **Tasa de deduplicaciÃ³n**: 18.2%
- **MÃ©todos**: DOI, hash de tÃ­tulo, similitud

#### Requerimiento 2: Similitud
- **MÃ©todos comparados**: 5 (Levenshtein, TF-IDF, BoW, SBERT, Cross-Encoder)
- **Mejor mÃ©todo**: SBERT (all-MiniLM-L6-v2)
- **PrecisiÃ³n semÃ¡ntica**: ~85%

#### Requerimiento 3: Frecuencias
- **Palabras procesadas**: ~2,000,000
- **Vocabulario Ãºnico**: ~45,000 tÃ©rminos
- **Top palabra**: "artificial" (15,234 ocurrencias)

#### Requerimiento 4: Clustering
- **Clusters identificados**: 5-7 principales
- **MÃ©todo**: Clustering jerÃ¡rquico (Ward)
- **Coherencia**: Coeficiente de silueta ~0.65

#### Requerimiento 5: AnÃ¡lisis GeogrÃ¡fico
- **PaÃ­ses identificados**: 89
- **Tasa de Ã©xito**: 80.1% (DOI â†’ PaÃ­s)
- **Top paÃ­s**: Estados Unidos (31.1%)

#### Seguimiento 1: Ordenamiento
- **Algoritmos comparados**: 10+
- **MÃ¡s rÃ¡pido**: Tim Sort (Python nativo)
- **Mejor para aÃ±os**: Counting Sort

#### Seguimiento 2: Grafos
- **Nodos**: 500-10,000 (configurable)
- **Aristas**: Basadas en similitud SBERT
- **Algoritmos**: Dijkstra, Kosaraju
- **Componentes conexos**: Variable segÃºn umbrales

## ğŸ“ TecnologÃ­as y Algoritmos Implementados

### Algoritmos de Ordenamiento
- Bubble Sort, Selection Sort, Insertion Sort
- Merge Sort, Quick Sort, Heap Sort
- Tim Sort, Counting Sort, Radix Sort

### Algoritmos de Grafos
- Dijkstra (caminos mÃ­nimos)
- Kosaraju (componentes fuertemente conexos)
- AnÃ¡lisis de centralidad (NetworkX)

### TÃ©cnicas de NLP
- TF-IDF (Term Frequency-Inverse Document Frequency)
- SBERT (Sentence-BERT) para embeddings semÃ¡nticos
- Cross-Encoder para ranking
- TokenizaciÃ³n y stopwords (NLTK)

### TÃ©cnicas de ML
- Clustering jerÃ¡rquico aglomerativo
- Similitud de coseno
- Distancia euclidiana
- Fuzzy matching (rapidfuzz)

### APIs y Servicios
- Crossref API (enriquecimiento de metadatos)
- Selenium WebDriver (web scraping)

## ğŸ’¾ Requisitos de Sistema

### Espacio en Disco
- **Dependencias**: ~3.5 GB (principalmente PyTorch)
- **Datos descargados**: ~500 MB - 1 GB
- **Modelos SBERT**: ~80 MB
- **Total recomendado**: 5-6 GB libres

### Memoria RAM
- **MÃ­nimo**: 8 GB
- **Recomendado**: 16 GB (para datasets completos)
- **Ã“ptimo**: 32 GB (para procesamiento paralelo)

### Procesador
- **MÃ­nimo**: Dual-core 2.0 GHz
- **Recomendado**: Quad-core 2.5 GHz+
- **GPU**: Opcional (acelera SBERT 3-5x)

## ğŸ“ Notas Importantes

### Seguridad
- âš ï¸ **No subas el archivo `.env`** a repositorios pÃºblicos (ya estÃ¡ en `.gitignore`)
- âš ï¸ **No versiones credenciales** de acceso institucional
- âš ï¸ **El entorno virtual `venv/`** tampoco debe subirse

### Rendimiento
- ğŸ’¡ **PyTorch descarga ~3GB**, asegÃºrate de tener espacio suficiente
- ğŸ’¡ **Los archivos descargados** pueden ocupar mucho espacio
- ğŸ’¡ **Usa GPU** si estÃ¡ disponible para SBERT (3-5x mÃ¡s rÃ¡pido)
- ğŸ’¡ **Procesa en lotes** para datasets muy grandes

### Reproducibilidad
- ğŸ“Œ Todas las versiones de dependencias estÃ¡n fijadas en `requirements.txt`
- ğŸ“Œ Los modelos SBERT se descargan automÃ¡ticamente
- ğŸ“Œ Los resultados pueden variar ligeramente por aleatoriedad en algunos algoritmos
- ğŸ“Œ Documenta los umbrales y parÃ¡metros usados

## ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:
1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ‘¥ Autores

Proyecto acadÃ©mico - Universidad del Norte
Curso: AnÃ¡lisis de Algoritmos - 2025

## ğŸ“„ Licencia

Este proyecto es de uso acadÃ©mico y educativo.

## ğŸ“š Referencias

- **NetworkX**: https://networkx.org/
- **Sentence-BERT**: https://www.sbert.net/
- **Scikit-learn**: https://scikit-learn.org/
- **Crossref API**: https://www.crossref.org/documentation/retrieve-metadata/rest-api/
- **NLTK**: https://www.nltk.org/

## ğŸ™ Agradecimientos

- IEEE Xplore, ScienceDirect y Taylor & Francis por el acceso a artÃ­culos
- Comunidad de cÃ³digo abierto por las librerÃ­as utilizadas
- Universidad del Norte por el soporte institucional

---

**Ãšltima actualizaciÃ³n**: Octubre 2025
**VersiÃ³n**: 1.0.0
