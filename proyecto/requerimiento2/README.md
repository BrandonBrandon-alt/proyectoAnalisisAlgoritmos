# Requerimiento 2: An√°lisis de Similitud entre Art√≠culos

## Objetivo

Calcular y comparar la similitud entre pares de art√≠culos cient√≠ficos utilizando diferentes m√©tricas y algoritmos, desde m√©todos cl√°sicos hasta modelos de deep learning.

## Descripci√≥n General

Este m√≥dulo implementa **5 m√©todos diferentes** para medir similitud entre textos (abstracts de art√≠culos), permitiendo comparar su efectividad y precisi√≥n.

## M√©todos Implementados

### 1. Distancia de Levenshtein

**Descripci√≥n**: Mide el n√∫mero m√≠nimo de operaciones (inserci√≥n, eliminaci√≥n, sustituci√≥n) para transformar un texto en otro.

```python
from Levenshtein import distance

dist = distance(text1, text2)
similarity = 1 - (dist / max(len(text1), len(text2)))
```

**Caracter√≠sticas**:
- ‚úÖ Simple y r√°pido
- ‚úÖ Funciona a nivel de caracteres
- ‚ùå No considera sem√°ntica
- ‚ùå Sensible a orden de palabras

**Interpretaci√≥n**:
- `1.0` = Textos id√©nticos
- `0.8-0.9` = Muy similares
- `0.5-0.7` = Moderadamente similares
- `< 0.5` = Poco similares

### 2. TF-IDF + Similitud de Coseno

**Descripci√≥n**: Vectoriza textos usando TF-IDF y calcula el coseno del √°ngulo entre vectores.

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform([text1, text2])
similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
```

**Caracter√≠sticas**:
- ‚úÖ Considera importancia de palabras
- ‚úÖ Ignora palabras comunes (stopwords)
- ‚úÖ Independiente de longitud del texto
- ‚ùå No captura sin√≥nimos

**Interpretaci√≥n**:
- `> 0.8` = Muy similar (mismo tema)
- `0.5-0.8` = Similar (temas relacionados)
- `0.3-0.5` = Algo similar
- `< 0.3` = Diferentes

### 3. Bag of Words + Distancia Euclidiana

**Descripci√≥n**: Representa textos como vectores de frecuencia de palabras y calcula distancia euclidiana.

```python
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import euclidean_distances

vectorizer = CountVectorizer(stop_words='english')
bow_matrix = vectorizer.fit_transform([text1, text2])
distance = euclidean_distances(bow_matrix[0:1], bow_matrix[1:2])[0][0]
```

**Caracter√≠sticas**:
- ‚úÖ Simple de entender
- ‚úÖ R√°pido de calcular
- ‚ùå Sensible a longitud del texto
- ‚ùå No normalizado

**Interpretaci√≥n**:
- Valores m√°s bajos = Mayor similitud
- Depende de la longitud del texto

### 4. SBERT (Sentence-BERT)

**Descripci√≥n**: Usa modelos de transformers pre-entrenados para generar embeddings sem√°nticos.

```python
from sentence_transformers import SentenceTransformer, util

model = SentenceTransformer('all-MiniLM-L6-v2')
embeddings = model.encode([text1, text2], convert_to_tensor=True)
similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()
```

**Caracter√≠sticas**:
- ‚úÖ Captura significado sem√°ntico
- ‚úÖ Detecta sin√≥nimos y par√°frasis
- ‚úÖ Estado del arte en NLP
- ‚ùå M√°s lento que m√©todos cl√°sicos
- ‚ùå Requiere GPU para grandes vol√∫menes

**Interpretaci√≥n**:
- `> 0.7` = Muy similar sem√°nticamente
- `0.5-0.7` = Similar
- `0.3-0.5` = Algo relacionado
- `< 0.3` = Diferentes

**Modelo usado**: `all-MiniLM-L6-v2`
- Tama√±o: 80 MB
- Dimensiones: 384
- Velocidad: ~1000 oraciones/segundo (CPU)

### 5. Cross-Encoder

**Descripci√≥n**: Modelo que eval√∫a directamente pares de textos sin generar embeddings intermedios.

```python
from sentence_transformers import CrossEncoder

model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
score = model.predict([(text1, text2)])[0]
```

**Caracter√≠sticas**:
- ‚úÖ Mayor precisi√≥n que SBERT
- ‚úÖ Entrenado espec√≠ficamente para ranking
- ‚ùå M√°s lento (eval√∫a cada par)
- ‚ùå No genera embeddings reutilizables

**Interpretaci√≥n**:
- Valores m√°s altos = Mayor similitud
- Escala depende del modelo

## Estructura del C√≥digo

```python
# 1. Cargar datos
import bibtexparser
import pandas as pd

with open("consolidado.bib") as f:
    bib_database = bibtexparser.load(f)
abstracts = [entry.get('abstract', '') for entry in bib_database.entries]

# 2. Seleccionar pares de art√≠culos
pair1 = (abstracts[0], abstracts[1])
pair2 = (abstracts[0], abstracts[100])

# 3. Calcular similitudes con cada m√©todo
levenshtein_sim = calcular_levenshtein(pair1)
tfidf_sim = calcular_tfidf_cosine(pair1)
bow_dist = calcular_bow_euclidean(pair1)
sbert_sim = calcular_sbert(pair1)
cross_sim = calcular_cross_encoder(pair1)

# 4. Comparar resultados
comparar_metodos(resultados)
```

## Uso

### Ejecuci√≥n B√°sica

```bash
jupyter notebook Requeriemito2.ipynb
```

### Configuraci√≥n

```python
# Seleccionar art√≠culos a comparar
ARTICLE_INDEX_1 = 0
ARTICLE_INDEX_2 = 1

# Configurar modelos SBERT
SBERT_MODEL = 'all-MiniLM-L6-v2'
CROSS_ENCODER_MODEL = 'cross-encoder/ms-marco-MiniLM-L-6-v2'

# Configurar TF-IDF
TFIDF_MAX_FEATURES = 5000
TFIDF_NGRAM_RANGE = (1, 2)  # Unigramas y bigramas
```

## Resultados Esperados

### Tabla Comparativa

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¶‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë M√©todo                    ‚ïë Par 1     ‚ïë Par 2     ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï¨‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Levenshtein               ‚ïë 0.45      ‚ïë 0.12      ‚ïë
‚ïë TF-IDF + Coseno          ‚ïë 0.78      ‚ïë 0.23      ‚ïë
‚ïë BoW + Euclidiana         ‚ïë 45.2      ‚ïë 89.7      ‚ïë
‚ïë SBERT                     ‚ïë 0.82      ‚ïë 0.31      ‚ïë
‚ïë Cross-Encoder             ‚ïë 8.5       ‚ïë -2.3      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï©‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### Visualizaciones

El notebook genera:
- üìä Gr√°ficos de barras comparativos
- üìà Matrices de similitud (heatmaps)
- üìâ Distribuciones de scores

## Dependencias

```python
bibtexparser==1.4.3
pandas==2.3.1
Levenshtein==0.27.1
scikit-learn==1.7.2
sentence-transformers==3.3.1
numpy==2.2.6
matplotlib==3.10.5
```

## Casos de Uso

### 1. Detecci√≥n de Plagio
Usar SBERT o Cross-Encoder con umbral alto (> 0.8)

### 2. Recomendaci√≥n de Art√≠culos
Usar SBERT para encontrar art√≠culos similares

### 3. Clustering
Usar TF-IDF + Coseno para agrupar documentos

### 4. Deduplicaci√≥n
Combinar Levenshtein + SBERT

## Comparaci√≥n de M√©todos

| Criterio | Levenshtein | TF-IDF | BoW | SBERT | Cross-Encoder |
|----------|-------------|--------|-----|-------|---------------|
| Velocidad | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚ö°‚ö° | ‚ö° |
| Precisi√≥n | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Sem√°ntica | ‚ùå | ‚ö†Ô∏è | ‚ùå | ‚úÖ | ‚úÖ |
| Escalabilidad | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ùå |

## Problemas Comunes

### Error: "Model not found"
```bash
# Descargar modelos manualmente
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')"
```

### Warning: "CUDA not available"
- Normal en CPU
- Para usar GPU: instalar `torch` con soporte CUDA

### Memoria insuficiente
```python
# Procesar en lotes
BATCH_SIZE = 32
for batch in chunks(texts, BATCH_SIZE):
    embeddings = model.encode(batch)
```

## Tiempo de Ejecuci√≥n

| M√©todo | 100 pares | 1000 pares | 10000 pares |
|--------|-----------|------------|-------------|
| Levenshtein | 1s | 10s | 2min |
| TF-IDF | 2s | 15s | 3min |
| SBERT | 5s | 45s | 8min |
| Cross-Encoder | 15s | 2.5min | 25min |

## Recomendaciones

‚úÖ **Para an√°lisis exploratorio**: TF-IDF + Coseno
‚úÖ **Para m√°xima precisi√≥n**: SBERT o Cross-Encoder
‚úÖ **Para grandes vol√∫menes**: TF-IDF
‚úÖ **Para detecci√≥n de plagio**: Combinar m√∫ltiples m√©todos

## Pr√≥ximos Pasos

Los resultados de similitud pueden usarse en:
- **Requerimiento 4**: Clustering jer√°rquico
- Sistemas de recomendaci√≥n
- Detecci√≥n de duplicados
- An√°lisis de tendencias
