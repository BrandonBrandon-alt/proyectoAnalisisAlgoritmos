{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271a3161",
   "metadata": {},
   "source": [
    "## Requerimiento 1: Consolidaci√≥n y Limpieza de Datos BibTeX\n",
    "\n",
    "Este notebook implementa un **sistema robusto de consolidaci√≥n** de archivos BibTeX de m√∫ltiples fuentes, con detecci√≥n de duplicados y manejo de errores.\n",
    "\n",
    "### Objetivos:\n",
    "1. **Buscar recursivamente** archivos `.bib` en directorios\n",
    "2. **Verificar unicidad** de archivos por contenido (hash MD5)\n",
    "3. **Detectar duplicados** por t√≠tulo normalizado\n",
    "4. **Consolidar** entradas √∫nicas en un solo archivo\n",
    "5. **Exportar duplicados** para auditor√≠a\n",
    "6. **Manejo robusto de errores** en parsing\n",
    "\n",
    "### Flujo del Proceso:\n",
    "```\n",
    "B√∫squeda Recursiva ‚Üí Verificaci√≥n de Hash ‚Üí Ordenamiento Natural ‚Üí \n",
    "Parsing con Entorno Limpio ‚Üí Normalizaci√≥n de T√≠tulos ‚Üí \n",
    "Detecci√≥n de Duplicados ‚Üí Consolidaci√≥n ‚Üí Exportaci√≥n\n",
    "```\n",
    "\n",
    "### Caracter√≠sticas Principales:\n",
    "\n",
    "#### üîç Detecci√≥n de Duplicados:\n",
    "- **Por contenido**: Hash MD5 de archivos\n",
    "- **Por t√≠tulo**: Normalizaci√≥n inteligente (sin puntuaci√≥n, min√∫sculas)\n",
    "- **Registro detallado**: Origen de cada duplicado\n",
    "\n",
    "#### üõ°Ô∏è Manejo de Errores:\n",
    "- **Entorno limpio**: Directorio temporal por archivo\n",
    "- **Try-catch**: Captura errores de parsing\n",
    "- **Continuaci√≥n**: Procesa archivos restantes si uno falla\n",
    "\n",
    "#### üìä Estad√≠sticas:\n",
    "- Archivos procesados\n",
    "- Entradas √∫nicas consolidadas\n",
    "- Duplicados detectados\n",
    "- Errores encontrados\n",
    "\n",
    "### Tecnolog√≠as Utilizadas:\n",
    "- **pybtex**: Parsing y escritura de BibTeX\n",
    "- **hashlib**: C√°lculo de hash MD5\n",
    "- **natsort**: Ordenamiento natural de archivos\n",
    "- **tempfile**: Directorios temporales\n",
    "- **re**: Normalizaci√≥n con regex\n",
    "\n",
    "### üìÅ Estructura de Datos:\n",
    "\n",
    "#### Entrada:\n",
    "```\n",
    "descargas/\n",
    "‚îú‚îÄ‚îÄ ieee/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ieee_generative_ai_page_1.bib\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ ieee_generative_ai_page_2.bib\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îú‚îÄ‚îÄ sciencedirect/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ sciencedirect_page_1.bib\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
    "‚îî‚îÄ‚îÄ springer/\n",
    "    ‚îî‚îÄ‚îÄ springer_page_1.bib\n",
    "```\n",
    "\n",
    "#### Salida:\n",
    "```\n",
    "proyecto/salidas/consolidado.bib    # Archivo consolidado\n",
    "duplicados/duplicados.bib            # Duplicados detectados\n",
    "```\n",
    "\n",
    "### Variables de Entorno:\n",
    "```python\n",
    "DOWNLOAD_PATH   # Ruta de archivos .bib a procesar\n",
    "SALIDA_PATH     # Ruta del archivo consolidado\n",
    "DUPLICATE_PATH  # Ruta del archivo de duplicados\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425e0d9d",
   "metadata": {},
   "source": [
    "### Implementaci√≥n del Sistema de Consolidaci√≥n\n",
    "\n",
    "Este script implementa 4 funciones principales para consolidar archivos Bi bTeX de forma robusta.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Funci√≥n 1: `process_bibtex_file_with_clean_environment(file_path)`\n",
    "\n",
    "### Prop√≥sito:\n",
    "Procesa un archivo BibTeX en un **entorno aislado** para evitar problemas de cach√© del parser.\n",
    "\n",
    "### Problema que Resuelve:\n",
    "```python\n",
    "# Sin entorno limpio:\n",
    "parser = bibtex_input.Parser()\n",
    "bib1 = parser.parse_file(\"file1.bib\")  # OK\n",
    "bib2 = parser.parse_file(\"file2.bib\")  # ‚ùå Puede usar cach√© de file1\n",
    "```\n",
    "\n",
    "### Soluci√≥n:\n",
    "```python\n",
    "# Con entorno limpio:\n",
    "temp_dir = tempfile.mkdtemp()           # Directorio temporal √∫nico\n",
    "temp_file = os.path.join(temp_dir, \"temp_file.bib\")\n",
    "shutil.copy2(file_path, temp_file)      # Copia a temp\n",
    "parser = bibtex_input.Parser()          # Parser nuevo\n",
    "bib_data = parser.parse_file(temp_file) # Parsing limpio\n",
    "shutil.rmtree(temp_dir)                 # Limpieza\n",
    "```\n",
    "\n",
    "### Ventajas:\n",
    "- ‚úÖ Evita conflictos de cach√©\n",
    "- ‚úÖ Cada archivo se procesa independientemente\n",
    "- ‚úÖ Limpieza autom√°tica con `finally`\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Funci√≥n 2: `normalize_title(title)`\n",
    "\n",
    "### Prop√≥sito:\n",
    "Normaliza t√≠tulos para **comparaci√≥n robusta** de duplicados.\n",
    "\n",
    "### Transformaciones:\n",
    "\n",
    "#### 1. Eliminaci√≥n de Caracteres Especiales:\n",
    "```python\n",
    "re.sub(r'[^\\w\\s]', '', title.lower())\n",
    "```\n",
    "**Ejemplo**:\n",
    "```\n",
    "\"Machine Learning: A Survey (2024)\" \n",
    "‚Üí \"machine learning a survey 2024\"\n",
    "```\n",
    "\n",
    "#### 2. Eliminaci√≥n de Espacios M√∫ltiples:\n",
    "```python\n",
    "re.sub(r'\\s+', ' ', normalized).strip()\n",
    "```\n",
    "**Ejemplo**:\n",
    "```\n",
    "\"machine    learning   survey\"\n",
    "‚Üí \"machine learning survey\"\n",
    "```\n",
    "\n",
    "#### 3. Conversi√≥n a Min√∫sculas:\n",
    "```python\n",
    ".lower()\n",
    "```\n",
    "**Ejemplo**:\n",
    "```\n",
    "\"Machine Learning\" ‚Üí \"machine learning\"\n",
    "```\n",
    "\n",
    "### Casos de Uso:\n",
    "\n",
    "| T√≠tulo Original 1 | T√≠tulo Original 2 | Normalizado | ¬øDuplicado? |\n",
    "|-------------------|-------------------|-------------|-------------|\n",
    "| \"AI: A Survey\" | \"AI - A Survey\" | \"ai a survey\" | ‚úÖ S√≠ |\n",
    "| \"Machine Learning\" | \"Machine  Learning\" | \"machine learning\" | ‚úÖ S√≠ |\n",
    "| \"Deep Learning\" | \"Deep Learning.\" | \"deep learning\" | ‚úÖ S√≠ |\n",
    "| \"AI Survey\" | \"ML Survey\" | diferentes | ‚ùå No |\n",
    "\n",
    "### Limitaciones:\n",
    "- No detecta sin√≥nimos (\"car\" vs \"automobile\")\n",
    "- No detecta variaciones (\"Part I\" vs \"Part II\")\n",
    "- Sensible a palabras adicionales\n",
    "\n",
    "---\n",
    "\n",
    "## üîÄ Funci√≥n 3: `merge_bibtex_files(file_paths, output_path, duplicates_path)`\n",
    "\n",
    "### Prop√≥sito:\n",
    "Funci√≥n principal que **consolida** m√∫ltiples archivos BibTeX.\n",
    "\n",
    "### Algoritmo:\n",
    "\n",
    "#### Paso 1: Inicializaci√≥n\n",
    "```python\n",
    "merged_db = BibliographyData()      # Base de datos consolidada\n",
    "processed_titles = {}                # Diccionario de t√≠tulos vistos\n",
    "duplicate_entries = set()            # Set de IDs duplicados\n",
    "```\n",
    "\n",
    "#### Paso 2: Procesamiento por Archivo\n",
    "```python\n",
    "for file_path in file_paths:\n",
    "    bib_data = process_bibtex_file_with_clean_environment(file_path)\n",
    "```\n",
    "\n",
    "#### Paso 3: Procesamiento por Entrada\n",
    "```python\n",
    "for entry_id, entry in bib_data.entries.items():\n",
    "    # 1. Verificar si tiene t√≠tulo\n",
    "    if 'title' not in entry.fields:\n",
    "        merged_db.add_entry(entry_id, entry)  # Agregar sin verificar\n",
    "        continue\n",
    "    \n",
    "    # 2. Normalizar t√≠tulo\n",
    "    title = entry.fields['title']\n",
    "    normalized_title = normalize_title(title)\n",
    "    \n",
    "    # 3. Verificar duplicados\n",
    "    if normalized_title in processed_titles:\n",
    "        # Es duplicado ‚Üí guardar en lista\n",
    "        duplicate_entries.add(entry_id)\n",
    "        duplicates_list.append(entry_text)\n",
    "    else:\n",
    "        # Es √∫nico ‚Üí agregar a consolidado\n",
    "        merged_db.add_entry(entry_id, entry)\n",
    "        processed_titles[normalized_title] = (entry_id, file_path)\n",
    "```\n",
    "\n",
    "#### Paso 4: Exportaci√≥n\n",
    "```python\n",
    "writer = bibtex_output.Writer()\n",
    "writer.write_file(merged_db, output_path)           # Consolidado\n",
    "with open(duplicates_path, \"w\") as f:\n",
    "    f.writelines(duplicates_list)                    # Duplicados\n",
    "```\n",
    "\n",
    "### Manejo de Errores:\n",
    "```python\n",
    "try:\n",
    "    bib_data = process_bibtex_file_with_clean_environment(file_path)\n",
    "    # ... procesamiento ...\n",
    "except Exception as e:\n",
    "    print(f\"Error al procesar {file_path}: {e}\")\n",
    "    # Contin√∫a con el siguiente archivo\n",
    "```\n",
    "\n",
    "**Errores comunes**:\n",
    "- `repeated bibliography entry`: Entrada duplicada dentro del mismo archivo\n",
    "- `syntax error`: Formato BibTeX inv√°lido\n",
    "- `FileNotFoundError`: Archivo no existe\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Funci√≥n 4: `main()`\n",
    "\n",
    "### Prop√≥sito:\n",
    "Funci√≥n principal que **orquesta** todo el proceso.\n",
    "\n",
    "### Flujo Detallado:\n",
    "\n",
    "#### 1. B√∫squeda Recursiva de Archivos:\n",
    "```python\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.bib'):\n",
    "            bibtex_files.append(os.path.join(root, file))\n",
    "```\n",
    "\n",
    "**Resultado**: Lista de rutas absolutas a todos los `.bib`\n",
    "\n",
    "#### 2. Ordenamiento Natural:\n",
    "```python\n",
    "bibtex_files = natsorted(bibtex_files)\n",
    "```\n",
    "\n",
    "**Diferencia**:\n",
    "```\n",
    "# Ordenamiento est√°ndar:\n",
    "['page_1.bib', 'page_10.bib', 'page_2.bib']\n",
    "\n",
    "# Ordenamiento natural (natsorted):\n",
    "['page_1.bib', 'page_2.bib', 'page_10.bib']\n",
    "```\n",
    "\n",
    "#### 3. Verificaci√≥n de Unicidad por Hash:\n",
    "```python\n",
    "file_hash = hashlib.md5()\n",
    "with open(file_path, 'rb') as f:\n",
    "    for chunk in iter(lambda: f.read(4096), b''):\n",
    "        file_hash.update(chunk)\n",
    "digest = file_hash.hexdigest()\n",
    "```\n",
    "\n",
    "**Ventajas del hash MD5**:\n",
    "- ‚úÖ Detecta archivos id√©nticos con nombres diferentes\n",
    "- ‚úÖ R√°pido (lectura por chunks de 4KB)\n",
    "- ‚úÖ √önico por contenido\n",
    "\n",
    "**Ejemplo**:\n",
    "```\n",
    "ieee_page_1.bib (hash: abc123...)\n",
    "ieee_page_1_copy.bib (hash: abc123...)  ‚Üê Duplicado detectado\n",
    "```\n",
    "\n",
    "#### 4. Consolidaci√≥n:\n",
    "```python\n",
    "unique_count, duplicate_count = merge_bibtex_files(\n",
    "    unique_files, \n",
    "    output_path, \n",
    "    duplicates_path\n",
    ")\n",
    "```\n",
    "\n",
    "#### 5. Resumen:\n",
    "```python\n",
    "print(f\"Archivos procesados: {len(bibtex_files)}\")\n",
    "print(f\"Entradas √∫nicas: {unique_count}\")\n",
    "print(f\"Entradas duplicadas: {duplicate_count}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Resultados Esperados (Ejemplo Real):\n",
    "\n",
    "```\n",
    "Orden de procesamiento de archivos:\n",
    "1. ieee/ieee_generative_ai_page_1.bib\n",
    "2. ieee/ieee_generative_ai_page_2.bib\n",
    "...\n",
    "41. springer/springer_page_1.bib\n",
    "\n",
    "Verificando unicidad de archivos...\n",
    "Total de archivos encontrados: 41\n",
    "Archivos √∫nicos por contenido: 41\n",
    "\n",
    "Procesando: ieee/ieee_generative_ai_page_1.bib\n",
    "  Advertencia: Entrada 10280429 sin t√≠tulo, se agregar√° como √∫nica\n",
    "\n",
    "Procesando: ieee/ieee_generative_ai_page_2.bib\n",
    "  Duplicado encontrado por t√≠tulo: Trusted Artificial Intelligence...\n",
    "  Original ID: 9724346 en: page_1.bib\n",
    "  Duplicado ID: 9599411 en: page_2.bib\n",
    "\n",
    "...\n",
    "\n",
    "Resumen:\n",
    "  Archivos procesados: 41\n",
    "  Entradas √∫nicas: 3,602\n",
    "  Entradas duplicadas: 52\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ An√°lisis de Resultados:\n",
    "\n",
    "### Tasa de Duplicaci√≥n:\n",
    "```\n",
    "52 / (3602 + 52) = 1.42%\n",
    "```\n",
    "**Interpretaci√≥n**: Muy baja, indica buena calidad de datos\n",
    "\n",
    "### Causas de Duplicados:\n",
    "1. **M√∫ltiples fuentes**: Mismo art√≠culo en IEEE y ScienceDirect\n",
    "2. **Paginaci√≥n**: Art√≠culo aparece en m√∫ltiples p√°ginas de resultados\n",
    "3. **Errores de scraping**: Descarga repetida\n",
    "\n",
    "### Errores Comunes:\n",
    "- **`repeated bibliography entry`**: Archivo con entradas duplicadas internamente\n",
    "- **`syntax error`**: Formato BibTeX malformado\n",
    "- **Entradas sin t√≠tulo**: ~0.2% de casos\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Mejoras Posibles:\n",
    "\n",
    "### 1. Detecci√≥n de Duplicados por DOI:\n",
    "```python\n",
    "if 'doi' in entry.fields:\n",
    "    doi = entry.fields['doi']\n",
    "    if doi in processed_dois:\n",
    "        # Duplicado por DOI (m√°s confiable que t√≠tulo)\n",
    "```\n",
    "\n",
    "### 2. Fuzzy Matching de T√≠tulos:\n",
    "```python\n",
    "from rapidfuzz import fuzz\n",
    "similarity = fuzz.ratio(title1, title2)\n",
    "if similarity > 90:  # 90% similar\n",
    "    # Posible duplicado\n",
    "```\n",
    "\n",
    "### 3. Logging Estructurado:\n",
    "```python\n",
    "import logging\n",
    "logging.basicConfig(filename='consolidation.log', level=logging.INFO)\n",
    "logging.info(f\"Procesando: {file_path}\")\n",
    "```\n",
    "\n",
    "### 4. Progreso Visual:\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "for file_path in tqdm(bibtex_files, desc=\"Procesando archivos\"):\n",
    "    # ...\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3fb6d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yep/Documentos/proyectoAnalisisAlgoritmos/venv/lib64/python3.13/site-packages/pybtex/plugin/__init__.py:26: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orden de procesamiento de archivos:\n",
      "1. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_1.bib\n",
      "2. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_2.bib\n",
      "3. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_3.bib\n",
      "4. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_4.bib\n",
      "5. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_5.bib\n",
      "6. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_6.bib\n",
      "7. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_7.bib\n",
      "8. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_8.bib\n",
      "9. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_9.bib\n",
      "10. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_10.bib\n",
      "11. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_11.bib\n",
      "12. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_12.bib\n",
      "13. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_13.bib\n",
      "14. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_14.bib\n",
      "15. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_15.bib\n",
      "16. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_16.bib\n",
      "17. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_17.bib\n",
      "18. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_18.bib\n",
      "19. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_19.bib\n",
      "20. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_20.bib\n",
      "21. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_1.bib\n",
      "22. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_2.bib\n",
      "23. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_3.bib\n",
      "24. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_4.bib\n",
      "25. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_5.bib\n",
      "26. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_6.bib\n",
      "27. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_7.bib\n",
      "28. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_8.bib\n",
      "29. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_9.bib\n",
      "30. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib\n",
      "31. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_11.bib\n",
      "32. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "33. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "34. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_14.bib\n",
      "35. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_15.bib\n",
      "36. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_16.bib\n",
      "37. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "38. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "39. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "40. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "41. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_1.bib\n",
      "42. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_2.bib\n",
      "43. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_3.bib\n",
      "44. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_4.bib\n",
      "45. /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_5.bib\n",
      "\n",
      "Verificando unicidad de archivos...\n",
      "Total de archivos encontrados: 45\n",
      "Archivos √∫nicos por contenido: 45\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_1.bib\n",
      "  Advertencia: Entrada 10280429 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_1.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_2.bib\n",
      "  Duplicado encontrado por t√≠tulo: Trusted Artificial Intelligence: Technique Requirements and Best Practices\n",
      "  Original ID: 9724346 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_1.bib\n",
      "  Duplicado ID: 9599411 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_2.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_3.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_4.bib\n",
      "  Advertencia: Entrada 10522548 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_4.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_5.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_6.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_7.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_8.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_9.bib\n",
      "  Advertencia: Entrada 10769228 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_9.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_10.bib\n",
      "  Duplicado encontrado por t√≠tulo: A Brief History of AI\n",
      "  Original ID: 10950937 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_7.bib\n",
      "  Duplicado ID: 10982332 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_10.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_11.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_12.bib\n",
      "  Duplicado encontrado por t√≠tulo: Introduction\n",
      "  Original ID: 10933933 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_8.bib\n",
      "  Duplicado ID: 11178277 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_12.bib\n",
      "  Duplicado encontrado por t√≠tulo: Cybersecurity Education in the Age of Artificial Intelligence: A Novel Proactive and Collaborative Learning Paradigm\n",
      "  Original ID: 9962643 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_6.bib\n",
      "  Duplicado ID: 10367784 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_12.bib\n",
      "  Advertencia: Entrada 10251313 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_12.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_13.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_14.bib\n",
      "  Advertencia: Entrada 11130815 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_14.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_15.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_16.bib\n",
      "  Advertencia: Entrada 11099027 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_16.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_17.bib\n",
      "  Advertencia: Entrada 10769388 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_17.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_18.bib\n",
      "  Advertencia: Entrada 10769100 sin t√≠tulo en /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_18.bib, se agregar√° como √∫nica\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Chapter 1: The Generative AI Landscape\n",
      "  Original ID: 11164583 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_19.bib\n",
      "  Duplicado ID: 11164828 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_19.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_20.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_1.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_2.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_3.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_4.bib\n",
      "  Duplicado encontrado por t√≠tulo: Assessing Laterality Errors in Radiology: Comparing Generative Artificial Intelligence and Natural Language Processing\n",
      "  Original ID: KATHAIT20241575 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_3.bib\n",
      "  Duplicado ID: KATHAIT20241575 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_4.bib\n",
      "  Duplicado encontrado por t√≠tulo: Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping\n",
      "  Original ID: SINGH2024100531 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_3.bib\n",
      "  Duplicado ID: SINGH2024100531 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_4.bib\n",
      "  Duplicado encontrado por t√≠tulo: Generative artificial intelligence: A hot topic to face with\n",
      "  Original ID: COSCI2025112113 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_3.bib\n",
      "  Duplicado ID: COSCI2025112113 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_4.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_5.bib\n",
      "  Duplicado encontrado por t√≠tulo: Generative Artificial Intelligence\n",
      "  Original ID: 10952786 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/ieee/ieee_generative_ai_page_4.bib\n",
      "  Duplicado ID: LEE20241318 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_5.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_6.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_7.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_7.bib: repeated bibliograhpy entry: LIU2025\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_8.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_8.bib: repeated bibliograhpy entry: LI2025\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_9.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib: repeated bibliograhpy entry: LI2025\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_11.bib\n",
      "  Duplicado encontrado por t√≠tulo: FDA-approved artificial intelligence products in abdominal imaging: A comprehensive review\n",
      "  Original ID: AJMERA2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib\n",
      "  Duplicado ID: AJMERA2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_11.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial Intelligence Solutions to Improve Emergency Department Wait Times: Living Systematic Review\n",
      "  Original ID: AHMADZADEH2025174 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib\n",
      "  Duplicado ID: AHMADZADEH2025174 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_11.bib\n",
      "  Duplicado encontrado por t√≠tulo: Review of artificial intelligence-based applications for money laundering detection\n",
      "  Original ID: MOUSAVIAN2025200572 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib\n",
      "  Duplicado ID: MOUSAVIAN2025200572 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_11.bib\n",
      "  Duplicado encontrado por t√≠tulo: A Revised Framework for Evaluating the Quality of Mental Health Artificial Intelligence-Based Chatbots\n",
      "  Original ID: DESAGE20243 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_10.bib\n",
      "  Duplicado ID: DESAGE20243 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_11.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib: repeated bibliograhpy entry: YANG2025\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence and robotics in education: Advances, challenges, and future perspectives\n",
      "  Original ID: FOMBONA2025101533 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "  Duplicado ID: FOMBONA2025101533 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "  Duplicado encontrado por t√≠tulo: Effectiveness of artificial intelligence in classification of connective tissue diseases in patients with anti-nuclear antibody (ANA) positivity\n",
      "  Original ID: BOSNALI2026108679 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "  Duplicado ID: BOSNALI2026108679 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "  Duplicado encontrado por t√≠tulo: Foresee the unseen: Evaluating the impact of artificial intelligence on international trade\n",
      "  Original ID: JAKUBIK2025842 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "  Duplicado ID: JAKUBIK2025842 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence in predicting personalized nanocarrier formulations for herbal drugs: Bridging phytomedicine and precision nanotechnology\n",
      "  Original ID: SRIDHAR2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "  Duplicado ID: SRIDHAR2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "  Duplicado encontrado por t√≠tulo: Generative Semantic Communication: Architectures, Technologies, and Applications\n",
      "  Original ID: REN2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_12.bib\n",
      "  Duplicado ID: REN2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_13.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_14.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_14.bib: repeated bibliograhpy entry: LEE2025\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_15.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_16.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial Intelligence (AI) and the Journal of Pediatric and Adolescent Gynecology (JPAG)\n",
      "  Original ID: HILLARD2025301 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_14.bib\n",
      "  Duplicado ID: HILLARD2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Impact of ChatGPT and generative AI on lifelong learning and upskilling learners in higher education: unveiling the challenges and opportunities globally\n",
      "  Original ID: ASAD2024507 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: ASAD2024507 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial Intelligence for Radiation Treatment Planning: Bridging Gaps From Retrospective Promise to Clinical Reality\n",
      "  Original ID: CONROY2025103630 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: CONROY2025103630 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence for predicting urban heat island effect and optimising land use/land cover for mitigation: Prospects and recent advancements\n",
      "  Original ID: MOHAMED2024101976 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: MOHAMED2024101976 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: On the implications of artificial intelligence methods for feature engineering in reliability sector\n",
      "  Original ID: GUO2025463 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: GUO2025463 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence in open innovation project management: A systematic literature review on technologies, applications, and integration requirements\n",
      "  Original ID: PRASETYO2025100445 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: PRASETYO2025100445 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial INtelligence to Support Informed DEcision-making (INSIDE) for Improved Literature Analysis in Oncology\n",
      "  Original ID: STENZL20241011 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: STENZL20241011 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: The good, the bad, and the algorithm: The impact of generative AI on cybersecurity\n",
      "  Original ID: COPPOLINO2025129406 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: COPPOLINO2025129406 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Exploratory literature review and scientometric analysis of artificial intelligence applied to geopolymeric materials\n",
      "  Original ID: CARVALHO2025110210 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: CARVALHO2025110210 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Harnessing artificial intelligence and machine learning for fraud detection and prevention in Nigeria\n",
      "  Original ID: ODUFISAN2025100127 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: ODUFISAN2025100127 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: What are artificial intelligence literacy and competency? A comprehensive framework to support them\n",
      "  Original ID: CHIU2024100171 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: CHIU2024100171 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: From Artificial intelligence (AI) to Artificial General Intelligence (AGI) ‚Äì the road ahead\n",
      "  Original ID: KRISHNAN20251 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: KRISHNAN20251 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Health Care Social Robots in the Age of Generative AI: Protocol for a Scoping Review\n",
      "  Original ID: LEMPE2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: LEMPE2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence in medical imaging education: Recommendations for undergraduate curriculum development\n",
      "  Original ID: CROTTY202467 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: CROTTY202467 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence in echocardiography: Applications and future directions\n",
      "  Original ID: JIANG2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_17.bib\n",
      "  Duplicado ID: JIANG2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Beauty or the Borg: Agentic artificial intelligence organizational socialization in synergistic Hybrid Transformative Dynamic Flows\n",
      "  Original ID: STYLOS2025105205 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: STYLOS2025105205 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence adoption in urban planning governance: A systematic review of advancements in decision-making, and policy making\n",
      "  Original ID: LARTEY2025105337 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: LARTEY2025105337 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Beyond the horizon: A comprehensive analysis of artificial intelligence-based weather forecasting models\n",
      "  Original ID: HAJIAGHAJANY2025112335 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: HAJIAGHAJANY2025112335 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Influential factors driving artificial intelligence revolution in building industry with regional focus on East Asia\n",
      "  Original ID: KIM2025113661 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: KIM2025113661 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence in metabolomics: a current review\n",
      "  Original ID: CHI2024117852 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: CHI2024117852 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: A review of artificial intelligence in dam engineering\n",
      "  Original ID: CAO2025100122 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: CAO2025100122 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Future of outcomes research in plastic surgery: Artificial intelligence generated synthetic data and predictive models\n",
      "  Original ID: OZMEN202438 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: OZMEN202438 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: GPT-4 Artificial Intelligence Model Outperforms ChatGPT, Medical Students, and Neurosurgery Residents on Neurosurgery Written Board-Like Questions\n",
      "  Original ID: GUERRA2023e160 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: GUERRA2023e160 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: From Internet to Artificial Intelligence (Al) Bots: Symbiotic Evolutions of Digital Technologies and e-Patients\n",
      "  Original ID: SANDS2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: SANDS2025 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Perspectives on navigating the use of artificial intelligence by patients for their surgical care management\n",
      "  Original ID: SHENOY2025116540 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: SHENOY2025116540 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: How to cope with potential malfeasance using artificial intelligence: Call to action\n",
      "  Original ID: LAMBERT2024230 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: LAMBERT2024230 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence as-a-service in agriculture: sketching a scalable platform for multipurpose decision support\n",
      "  Original ID: ADAO2025156 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: ADAO2025156 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Governance efficiency and upgrade pathways of international generative AI policies and regulations\n",
      "  Original ID: WANG2026103082 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: WANG2026103082 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado encontrado por t√≠tulo: Integrating Critical thinking and embracing Artificial Intelligence: Dual Pillars for advancing dental education\n",
      "  Original ID: SHARAB20241660 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_18.bib\n",
      "  Duplicado ID: SHARAB20241660 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence and the electrocardiogram: A modern renaissance\n",
      "  Original ID: PALERMI2025106329 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado ID: PALERMI2025106329 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "  Duplicado encontrado por t√≠tulo: Artificial intelligence in therapeutic management of hyperlipidemic ocular pathology\n",
      "  Original ID: INOUYE2024109954 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado ID: INOUYE2024109954 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "  Duplicado encontrado por t√≠tulo: Responsible artificial intelligence governance: A review and research framework\n",
      "  Original ID: PAPAGIANNIDIS2025101885 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado ID: PAPAGIANNIDIS2025101885 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "  Duplicado encontrado por t√≠tulo: Chapter 7 - Artificial general intelligence and misinformation: balancing innovation and ethical challenges\n",
      "  Original ID: SHIN2026173 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado ID: SHIN2026173 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "  Duplicado encontrado por t√≠tulo: How artificial intelligence could transform emergency care\n",
      "  Original ID: KACHMAN202440 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_19.bib\n",
      "  Duplicado ID: KACHMAN202440 en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/sciencedirect/sciencedirect_page_20.bib: repeated bibliograhpy entry: GUO2025\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_1.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_1.bib: syntax error in line 140: '=' expected\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_2.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_3.bib\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_4.bib\n",
      "Error al procesar /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_4.bib: syntax error in line 227: '=' expected\n",
      "\n",
      "Procesando: /home/yep/Documentos/proyectoAnalisisAlgoritmos/descargas/springer/springer_page_5.bib\n",
      "Archivo consolidado guardado en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/proyecto/salidas/consolidado.bib\n",
      "Duplicados guardados en: /home/yep/Documentos/proyectoAnalisisAlgoritmos/duplicados/duplicados.bib\n",
      "\n",
      "Resumen:\n",
      "  Archivos procesados: 45\n",
      "  Entradas √∫nicas: 3632\n",
      "  Entradas duplicadas: 52\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import tempfile\n",
    "import shutil\n",
    "import re\n",
    "from pybtex.database.input import bibtex as bibtex_input\n",
    "from pybtex.database.output import bibtex as bibtex_output\n",
    "from pybtex.database import BibliographyData\n",
    "from natsort import natsorted\n",
    "\n",
    "def process_bibtex_file_with_clean_environment(file_path):\n",
    "    \"\"\"Procesa un archivo BibTeX con un entorno limpio para evitar problemas de cach√©.\"\"\"\n",
    "    # Crear directorio temporal\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    try:\n",
    "        # Copiar el archivo a un directorio temporal con un nombre √∫nico\n",
    "        temp_file = os.path.join(temp_dir, f\"temp_{os.path.basename(file_path)}\")\n",
    "        shutil.copy2(file_path, temp_file)\n",
    "        \n",
    "        # Usar un nuevo parser para cada archivo\n",
    "        parser = bibtex_input.Parser()\n",
    "        bib_data = parser.parse_file(temp_file)\n",
    "        \n",
    "        return bib_data\n",
    "    finally:\n",
    "        # Limpiar el directorio temporal\n",
    "        shutil.rmtree(temp_dir)\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"Normaliza un t√≠tulo para facilitar la comparaci√≥n.\n",
    "    Elimina espacios extra, signos de puntuaci√≥n y convierte a min√∫sculas.\"\"\"\n",
    "    if not title:\n",
    "        return \"\"\n",
    "    # Eliminar caracteres especiales y convertir a min√∫sculas\n",
    "    normalized = re.sub(r'[^\\w\\s]', '', title.lower())\n",
    "    # Eliminar espacios m√∫ltiples y convertir a min√∫sculas\n",
    "    normalized = re.sub(r'\\s+', ' ', normalized).strip().lower()\n",
    "    return normalized\n",
    "\n",
    "def merge_bibtex_files(file_paths, output_path, duplicates_path):\n",
    "    merged_db = BibliographyData()\n",
    "    duplicates_list = []\n",
    "    processed_titles = {}  # Cambiado de processed_ids a processed_titles\n",
    "    duplicate_entries = set()  # Para contar entradas duplicadas √∫nicas\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            print(f\"\\nProcesando: {file_path}\")\n",
    "            bib_data = process_bibtex_file_with_clean_environment(file_path)\n",
    "\n",
    "            for entry_id, entry in bib_data.entries.items():\n",
    "                # Verificar si el entry tiene un campo de t√≠tulo\n",
    "                if 'title' not in entry.fields:\n",
    "                    print(f\"  Advertencia: Entrada {entry_id} sin t√≠tulo en {file_path}, se agregar√° como √∫nica\")\n",
    "                    merged_db.add_entry(entry_id, entry)\n",
    "                    continue\n",
    "                \n",
    "                # Normalizar el t√≠tulo para comparaci√≥n\n",
    "                title = entry.fields['title']\n",
    "                normalized_title = normalize_title(title)\n",
    "                \n",
    "                if normalized_title in processed_titles:\n",
    "                    # Encontramos un t√≠tulo duplicado\n",
    "                    original_entry_id, original_file = processed_titles[normalized_title]\n",
    "                    print(f\"  Duplicado encontrado por t√≠tulo: {title}\")\n",
    "                    print(f\"  Original ID: {original_entry_id} en: {original_file}\")\n",
    "                    print(f\"  Duplicado ID: {entry_id} en: {file_path}\")\n",
    "                    \n",
    "                    # Agregar el ID a la lista de duplicados √∫nicos\n",
    "                    duplicate_entries.add(entry_id)\n",
    "\n",
    "                    # Guardar duplicado como texto en la lista\n",
    "                    duplicates_list.append(f\"@{entry.type}{{{entry_id},\\n\")\n",
    "                    duplicates_list.append(f\"  title = {{{title}}},\\n\")\n",
    "                    for field, value in entry.fields.items():\n",
    "                        if field != 'title':  # Ya agregamos el t√≠tulo\n",
    "                            duplicates_list.append(f\"  {field} = {{{value}}},\\n\")\n",
    "                    duplicates_list.append(\"}\\n\\n\")\n",
    "                    \n",
    "                else:\n",
    "                    # Es un t√≠tulo nuevo, lo agregamos\n",
    "                    merged_db.add_entry(entry_id, entry)\n",
    "                    processed_titles[normalized_title] = (entry_id, file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar {file_path}: {e}\")\n",
    "\n",
    "    # Crear directorios de salida si no existen\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(duplicates_path), exist_ok=True)\n",
    "    \n",
    "    # Guardar el archivo consolidado\n",
    "    writer = bibtex_output.Writer()\n",
    "    writer.write_file(merged_db, output_path)\n",
    "    print(f\"Archivo consolidado guardado en: {output_path}\")\n",
    "\n",
    "    # Guardar el archivo de duplicados manualmente\n",
    "    if duplicates_list:\n",
    "        with open(duplicates_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(duplicates_list)\n",
    "        print(f\"Duplicados guardados en: {duplicates_path}\")\n",
    "    else:\n",
    "        print(\"No se encontraron duplicados.\")\n",
    "    \n",
    "    return len(merged_db.entries), len(duplicate_entries)\n",
    "\n",
    "def main():\n",
    "    folder_path = os.getenv(\"DOWNLOAD_PATH\") \n",
    "\n",
    "    # Buscar archivos .bib recursivamente en todas las subcarpetas\n",
    "    bibtex_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.bib'):\n",
    "                full_path = os.path.join(root, file)\n",
    "                bibtex_files.append(full_path)\n",
    "    \n",
    "    # Ordenamos usando natsorted para lograr un \"orden natural\"\n",
    "    bibtex_files = natsorted(bibtex_files)\n",
    "\n",
    "    # Verificar en que orden se procesaran los archivos\n",
    "    print(\"Orden de procesamiento de archivos:\")\n",
    "    for i, f in enumerate(bibtex_files):\n",
    "        print(f\"{i+1}. {f}\")\n",
    "\n",
    "    # Verificar que los archivos sean √∫nicos\n",
    "    print(\"\\nVerificando unicidad de archivos...\")\n",
    "    file_hashes = {}\n",
    "    unique_files = []\n",
    "    \n",
    "    for file_path in bibtex_files:\n",
    "        # Calcular hash del archivo\n",
    "        file_hash = hashlib.md5()\n",
    "        with open(file_path, 'rb') as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b''):\n",
    "                file_hash.update(chunk)\n",
    "        \n",
    "        # Verificar si ya hemos visto este hash\n",
    "        digest = file_hash.hexdigest()\n",
    "        if digest in file_hashes:\n",
    "            print(f\"¬°ADVERTENCIA! Archivo duplicado detectado:\")\n",
    "            print(f\"  - {file_path}\")\n",
    "            print(f\"  - {file_hashes[digest]}\")\n",
    "            print(f\"  Ambos tienen el mismo hash: {digest}\")\n",
    "        else:\n",
    "            file_hashes[digest] = file_path\n",
    "            unique_files.append(file_path)\n",
    "    \n",
    "    print(f\"Total de archivos encontrados: {len(bibtex_files)}\")\n",
    "    print(f\"Archivos √∫nicos por contenido: {len(unique_files)}\")\n",
    "    \n",
    "    # Proceder solo con archivos √∫nicos\n",
    "    bibtex_files = unique_files\n",
    "\n",
    "    # Rutas para archivos de salida\n",
    "    output_path = os.path.join( os.getenv(\"SALIDA_PATH\") , \"consolidado.bib\")\n",
    "    duplicates_path = os.path.join( os.getenv(\"DUPLICATE_PATH\"), \"duplicados.bib\")\n",
    "    \n",
    "    unique_count, duplicate_count = merge_bibtex_files(bibtex_files, output_path, duplicates_path)\n",
    "    \n",
    "    print(f\"\\nResumen:\")\n",
    "    print(f\"  Archivos procesados: {len(bibtex_files)}\")\n",
    "    print(f\"  Entradas √∫nicas: {unique_count}\")\n",
    "    print(f\"  Entradas duplicadas: {duplicate_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a7cc2",
   "metadata": {},
   "source": [
    "## üéì Conclusi√≥n:\n",
    "\n",
    "Este sistema de consolidaci√≥n es **robusto y escalable**, capaz de procesar miles de archivos BibTeX de m√∫ltiples fuentes, detectando duplicados de forma inteligente y manejando errores gracefully.\n",
    "\n",
    "**Caracter√≠sticas clave**:\n",
    "- ‚úÖ Entorno limpio por archivo\n",
    "- ‚úÖ Normalizaci√≥n inteligente de t√≠tulos\n",
    "- ‚úÖ Detecci√≥n de duplicados por contenido y t√≠tulo\n",
    "- ‚úÖ Manejo de errores sin interrumpir el proceso\n",
    "- ‚úÖ Estad√≠sticas detalladas\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
