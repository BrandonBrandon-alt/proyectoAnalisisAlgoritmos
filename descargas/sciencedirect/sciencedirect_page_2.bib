@article{HUNG2025103005,
title = {Factors driving user behavior and value creation with text-to-image generative artificial intelligence (AI): A systems theory perspective},
journal = {Technology in Society},
volume = {83},
pages = {103005},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103005},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25001952},
author = {Chih-Lung Hung and Jen-Her Wu and Po-Chuen Chiang and Qi Li and Yi-Cheng Chen},
keywords = {Text-to-image generative AI, Systems theory, Compatibility, Synergy, User value},
abstract = {The rise of image-generative AI has made it a crucial tool for image creators, gaining popularity in fields such as cartography, design, and photography. As users increasingly rely on AI for image creation, understanding the factors that drive user value becomes essential. Drawing on systems theory, this study proposes a conceptual framework to examine the relationships among integration effort, compatibility, synergy, and value creation. Data from 531 AI image creators supported our hypotheses, revealing that: (1) integration effort significantly enhances both compatibility and synergy; (2) compatibility positively influences synergy; (3) synergy directly and positively impacts user value creation; and (4) synergy serves as a critical mediator in the relationships between the two enablers—compatibility and integration effort—and user value creation, with compatibility also partially mediating the link between integration effort and synergy. These results extend systems theory by integrating it more deeply with the resource-based view and highlighting synergy as a pivotal factor that not only directly drives user value creation but also mediates the effects of compatibility and integration effort. Furthermore, the study empirically confirms that user value can be conceptualized through three key constructs: efficiency, effectiveness, and innovation.}
}
@article{WHITE2025452,
title = {Generative artificial intelligence tools in journal article preparation: A preliminary catalog of ethical considerations, opportunities, and pitfalls*},
journal = {JDS Communications},
volume = {6},
number = {3},
pages = {452-457},
year = {2025},
issn = {2666-9102},
doi = {https://doi.org/10.3168/jdsc.2024-0707},
url = {https://www.sciencedirect.com/science/article/pii/S2666910224002011},
author = {Robin R. White},
abstract = {The launch of generative artificial intelligence (GenAI) tools has catalyzed considerable discussion about the potential impacts of these systems within the scientific article preparation process. This symposium paper seeks to summarize current recommendations on the use of GenAI tools in scientific article preparation, and to provide speculations about the future challenges and opportunities of GenAI use in scientific publishing. Due to the dynamic nature of these tools and the rapid advancement of their sophistication, the most important recommendation is that ongoing engagement and discussion within the scientific community about these issues is critical. When using GenAI tools in scientific article preparation, humans are ultimately accountable and responsible for products produced. Given that accountability, an expert panel convened by the National Academies of Science, Engineering, and Medicine recently proposed principles of GenAI use in science communication, including (1) transparent disclosure and attribution; (2) verification of AI-generated content and analyses; (3) documentation of artificial intelligence (AI)-generated data; (4) a focus on ethics and equity; and (5) continuous monitoring, oversight, and public engagement. In addition to the importance of human accountability, many publishers have established consistent policies suggesting that GenAI tools should not be used for peer reviewing, figure generation or manipulation, or assigned authorship on scientific articles. Along with the potential ethical challenges associated with GenAI use in scientific publishing, there are numerous potential benefits. Herein we summarize example conversations demonstrating the capacity of GenAI tools to support the article preparation process, and an example standard operating procedure for human-AI interaction in article preparation. Finally, diverse broader questions about the impact of GenAI tools on communication, knowledge, and advancement of science are raised for rumination.}
}
@article{ZHANG2026104392,
title = {The double-edged impact of generative artificial intelligence dependence on service innovation in the hospitality industry: A self-regulation perspective},
journal = {International Journal of Hospitality Management},
volume = {132},
pages = {104392},
year = {2026},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2025.104392},
url = {https://www.sciencedirect.com/science/article/pii/S0278431925003202},
author = {Zhenduo Zhang and Yanyu Dai and Jianing Guo and Haonan Zhang and Yifei Shen and Huan Xiao},
keywords = {Generative artificial intelligence dependence, Problem-solving pondering, Affective rumination, Service innovation, Conscientiousness, Neuroticism},
abstract = {To date, studies on the relationship between generative artificial intelligence (GenAI) dependence and service innovation have yielded inconsistent results. Drawing on self-regulation theory, we examine how and when GenAI dependence promotes or inhibits service innovation in the hospitality industry. Three studies were conducted to examine how GenAI is used in hospitality management and test the conceptual model: a three-wave questionnaire survey (N = 333), a quasi-field experiment (N = 227), and an in-depth interview (N = 11). The results indicate that GenAI dependence promotes service innovation by decreasing affective rumination, and this beneficial indirect path is amplified by employees’ neuroticism. Meanwhile, GenAI dependence inhibits service innovation by decreasing problem-solving pondering, and this unfavourable indirect path is weakened by employees’ conscientiousness. This exploration of when and how the use of GenAI either promotes or inhibits service innovation broadens our understanding of the consequences of GenAI dependence in the hospitality management field.}
}
@article{RAHMAN20243,
title = {Generative artificial intelligence: opportunities, challenges and future avenues for organizational learning},
journal = {Development and Learning in Organizations: An International Journal},
volume = {39},
number = {2},
pages = {3-7},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-04-2024-0101},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000534},
author = {Hanfia Rahman and Tripti Singh},
keywords = {Generative artificial intelligence, Organizational learning, Systematic literature review},
abstract = {Purpose
This study provides a comprehensive investigation of the opportunities and challenges associated with generative artificial intelligence (GAI) use in development and learning in organizations. Additionally, it highlights the future avenues in GAI research and provides practical recommendations for policymakers.
Design/methodology/approach
Data for the review was collected from the Web of Science database using the search criteria (“Generative artificial intelligence” OR “artificial intelligence”) AND (“human resource management” OR “human resource development” OR “workplace learning” OR “organizational learning” OR “organizational development” OR “learning organization”) on March 6th, 2024. Filtering results to Management and Business categories yielded 71 articles. After abstract review, 6 unrelated articles were excluded, leaving 65 articles for final analysis.
Findings
The study presents several opportunities of GAI such as applications in personal learning and content generation. Moreover, it unravels several potential challenges of GAI such as quality and accuracy issues and elucidates several future research directions.
Originality/value
Our study is the first literature review that provides and a comprehensive overview of generative artificial intelligence in the context of organizational learning.}
}
@article{LIN2025,
title = {Applications, Challenges, and Prospects of Generative Artificial Intelligence Empowering Medical Education: Scoping Review},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/71125},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225001394},
author = {Yuhang Lin and Zhiheng Luo and Zicheng Ye and Nuoxi Zhong and Lijian Zhao and Long Zhang and Xiaolan Li and Zetao Chen and Yijia Chen},
keywords = {generative artificial intelligence, GAI, large language model, ChatGPT, medical education, human-machine symbiosis},
abstract = {Background
Nowadays, generative artificial intelligence (GAI) drives medical education toward enhanced intelligence, personalization, and interactivity. With its vast generative abilities and diverse applications, GAI redefines how educational resources are accessed, teaching methods are implemented, and assessments are conducted.
Objective
This study aimed to review the current applications of GAI in medical education; analyze its opportunities and challenges; identify its strengths and potential issues in educational methods, assessments, and resources; and capture GAI’s rapid evolution and multidimensional applications in medical education, thereby providing a theoretical foundation for future practice.
Methods
This scoping review used PubMed, Web of Science, and Scopus to analyze literature from January 2023 to October 2024, focusing on GAI applications in medical education. Following PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines, 5991 articles were retrieved, with 1304 duplicates removed. The 2-stage screening (title or abstract and full-text review) excluded 4564 articles and a supplementary search included 8 articles, yielding 131 studies for final synthesis. We included (1) studies addressing GAI’s applications, challenges, or future directions in medical education, (2) empirical research, systematic reviews, and meta-analyses, and (3) English-language articles. We excluded commentaries, editorials, viewpoints, perspectives, short reports, or communications with low levels of evidence, non-GAI technologies, and studies centered on other fields of medical education (eg, nursing). We integrated quantitative analysis of publication trends and Human Development Index (HDI) with thematic analysis of applications, technical limitations, and ethical implications.
Results
Analysis of 131 articles revealed that 74.0% (n=97) originated from countries or regions with very high HDI, with the United States contributing the most (n=33); 14.5% (n=19) were from high HDI countries, 5.3% (n=7) from medium HDI countries, and 2.2% (n=3) from low HDI countries, with 3.8% (n=5) involving cross-HDI collaborations. ChatGPT was the most studied GAI model (n=119), followed by Gemini (n=22), Copilot (n=11), Claude (n=6), and LLaMA (n=4). Thematic analysis indicated that GAI applications in medical education mainly embody the diversification of educational methods, scientific evaluation of educational assessments, and dynamic optimization of educational resources. However, it also highlighted current limitations and potential future challenges, including insufficient scene adaptability, data quality and information bias, overreliance, and ethical controversies.
Conclusion
GAI application in medical education exhibits significant regional disparities in development, and model research statistics reflect researchers’ certain usage preferences. GAI holds potential for empowering medical education, but widespread adoption requires overcoming complex technical and ethical challenges. Grounded in symbiotic agency theory, we advocate establishing the resource-method-assessment tripartite model, developing specialized models and constructing an integrated system of general large language models incorporating specialized ones, promoting resource sharing, refining ethical governance, and building an educational ecosystem fostering human-machine symbiosis, enabling deep tech-humanism integration and advancing medical education toward greater efficiency and human-centeredness.}
}
@article{CHEN2025S169,
title = {344 - Shaping an Generative Artificial Intelligence Model for Enhancing Early Recognition of Out-of-hospital Cardiac Arrest by Emergency Medical Dispatch Audios and Performance Measurement},
journal = {Resuscitation},
volume = {215},
pages = {S169},
year = {2025},
note = {RESUSCITATION Official Journal of the European Resuscitation Council Abstracts of Resuscitation 2025},
issn = {0300-9572},
doi = {https://doi.org/10.1016/S0300-9572(25)00694-X},
url = {https://www.sciencedirect.com/science/article/pii/S030095722500694X},
author = {Tai-Yuan Chen and Kent You-Shuo Chen and Kah-Meng Chong and Mei-Fen Yang and Zhen-Yi Chen and Chien-Xing Lin and Patrick Chow-In Ko}
}
@article{SIMMS2025106544,
title = {Generative artificial intelligence (AI) literacy in nursing education: A crucial call to action},
journal = {Nurse Education Today},
volume = {146},
pages = {106544},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2024.106544},
url = {https://www.sciencedirect.com/science/article/pii/S0260691724004544},
author = {Rachel C. Simms},
keywords = {Artificial intelligence, Nursing education, Educational technology, Ethics, Nursing},
abstract = {Introduction
Generative artificial intelligence (AI) is revolutionizing healthcare, necessitating corresponding advancements in nursing education to ensure that future nurses are equipped for a technologically driven environment. This article explores the imperative integration of generative AI literacy in nursing education.
Implications for nurse educators
The article delves into the practical challenges and opportunities presented by generative AI in nursing. It underscores the need for educators to adapt curricula and teaching methods to effectively incorporate generative AI learning, ensuring students are proficient in generative AI technologies and aware of their ethical implications.
Generative AI literacy
Defined as a core educational requirement, this section highlights the skills and knowledge that nurse educators must impart. It encompasses the ability to critically assess AI-generated content, understand the underlying technologies, and responsibly apply this knowledge in clinical settings.
Conclusion
The article concludes by emphasizing the urgency of integrating generative AI literacy into nursing education. It advocates for a proactive approach to curriculum development and calls for global collaboration and standardization in AI education to address the diverse and evolving needs of healthcare.}
}
@article{SUN2025103806,
title = {Enhancing critical language awareness in EAL writing education amid the rise of generative artificial intelligence},
journal = {System},
volume = {134},
pages = {103806},
year = {2025},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2025.103806},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X25002167},
author = {Yachao Sun and Ge Lan},
keywords = {Generative artificial intelligence, Critical language awareness, English as an additional language, Writing education, Critical AI literacy, Digital literacies},
abstract = {The emergence of generative artificial intelligence (GenAI) tools has presented both opportunities and challenges in English as an Additional Language (EAL) writing education. This mixed-methods exploratory study investigated how Chinese EAL students perceived and used GenAI, and how these attitudes and behaviors reflected their Critical Language Awareness (CLA). Survey data were collected from 320 Chinese undergraduate and graduate students studying in China and abroad, supplemented by in-depth semi-structured interviews with five volunteers. Quantitative findings revealed that, while participants valued GenAI for reducing language barriers and enhancing writing mechanics, they remained wary of issues related to originality, transparency, and ethical accountability. Qualitative analysis further illuminated participants' emerging CLA, evident in their negotiations of power (managing overreliance and misinformation), ideology (navigating dominant academic norms), and social justice (acknowledging cultural biases encoded in GenAI training data). Although students were primarily motivated by pragmatic benefits, such as improved grammar, structure, and efficiency, they also recognized GenAI's potential to perpetuate monolingual, Western-centric perspectives. These results underscore the need to embed CLA principles in GenAI-assisted pedagogy. By encouraging students to critically interrogate GenAI outputs, question linguistic hierarchies, and reflect on sociocultural contexts, educators can better leverage GenAI's affordances while fostering ethical, culturally responsive, and equitable writing practices.}
}
@article{LUO2025,
title = {Generative Artificial Intelligence Tools in Medical Research (GAMER): Protocol for a Scoping Review and Development of Reporting Guidelines},
journal = {JMIR Research Protocols},
volume = {14},
year = {2025},
issn = {1929-0748},
doi = {https://doi.org/10.2196/64640},
url = {https://www.sciencedirect.com/science/article/pii/S1929074825005001},
author = {Xufei Luo and Yih Chung Tham and Mohammad Daher and Zhaoxiang Bian and Yaolong Chen and Janne Estill},
keywords = {generative AI, chatbots, reporting guidelines, transparency, Delphi method, large language models, ChatGPT},
abstract = {Background
The integration of artificial intelligence (AI) has revolutionized medical research, offering innovative solutions for data collection, patient engagement, and information dissemination. Powerful generative AI (GenAI) tools and other similar chatbots have emerged, facilitating user interactions with virtual conversational agents. However, the increasing use of GenAI tools in medical research presents challenges, including ethical concerns, data privacy issues, and the potential for generating false content. These issues necessitate standardization of reporting to ensure transparency and scientific rigor.
Objective
The development of the Generative Artificial Intelligence Tools in Medical Research (GAMER) reporting guidelines aims to establish comprehensive, standardized guidelines for reporting the use of GenAI tools in medical research.
Methods
The GAMER guidelines are being developed following the methodology recommended by the Enhancing the Quality and Transparency of Health Research (EQUATOR) Network, involving a scoping review and expert Delphi consensus. The scoping review searched PubMed, Web of Science, Embase, CINAHL, PsycINFO, and Google Scholar (for the first 200 results) using keywords like “generative AI” and “medical research” to identify reporting elements in GenAI-related studies. The Delphi process involves 30-50 experts with ≥3 years of experience in AI applications or medical research, selected based on publication records and expertise across disciplines (eg, clinicians and data scientists) and regions (eg, Asia and Europe). A 7-point-scale survey will establish consensus on checklist items. The testing phase invites authors to apply the GAMER checklist to GenAI-related manuscripts and provide feedback via a questionnaire, while experts assess reliability (κ statistic) and usability (time taken, 7-point Likert scale). The study has been approved by the Ethics Committee of the Institute of Health Data Science at Lanzhou University (HDS-202406-01).
Results
The GAMER project was launched in July 2023 by the Evidence-Based Medicine Center of Lanzhou University and the WHO Collaborating Centre for Guideline Implementation and Knowledge Translation, and it concluded in July 2024. The scoping review was completed in November 2023. The Delphi process was conducted from October 2023 to April 2024. The testing phase began in March 2025 and is ongoing. The expected outcome of the GAMER project is a reporting checklist accompanied by relevant terminology, examples, and explanations to guide stakeholders in better reporting the use of GenAI tools.
Conclusions
GAMER aims to guide researchers, reviewers, and editors in the transparent and scientific application of GenAI tools in medical research. By providing a standardized reporting checklist, GAMER seeks to enhance the clarity, completeness, and integrity of research involving GenAI tools, thereby promoting collaboration, comparability, and cumulative knowledge generation in AI-driven health care technologies.
International Registered Report Identifier (IRRID)
DERR1-10.2196/64640}
}
@article{VISSAK2025436,
title = {Applying generative artificial intelligence applications for academic research on firms’ nonlinear internationalization},
journal = {Review of International Business and Strategy},
volume = {35},
number = {4},
pages = {436-484},
year = {2025},
issn = {2059-6014},
doi = {https://doi.org/10.1108/RIBS-10-2024-0120},
url = {https://www.sciencedirect.com/science/article/pii/S2059601425000037},
author = {Tiia Vissak and Lasse Torkkeli},
keywords = {Nonlinear internationalization, De-internationalization, Re-internationalization, Internationalization, Generative artificial intelligence (GenAI) tools, GenAI tools in research},
abstract = {Purpose
This study aims to critically evaluate the applicability of generative artificial intelligence (GenAI) tools for academic research in international business (IB), specifically focusing on the topic of firms’ nonlinear internationalization. It assesses these tools’ key performance dimensions: correctness, hallucinations and thoroughness.
Design/methodology/approach
This research adopts an exploratory approach, examining a comprehensive set of GenAI tools: eight chatbots and four AI-driven applications designed for academic purposes. The evaluation focuses on the capabilities and limitations of these tools in generating accurate research-related content for IB scholars.
Findings
This study finds that while GenAI tools capture some aspects of nonlinear internationalization, they often produce partially accurate and/or biased results. Common issues include providing fictitious sources, incorrect publication data and vague or incorrect answers. Thus, substantial development is still needed for GenAI tools to become reliable for scientific research.
Practical implications
Researchers should use GenAI tools with caution, verifying the accuracy of generated content and citations independently. A cautious approach is crucial to maintain the integrity and quality of academic research.
Social implications
This study raises awareness about ethical and practical challenges of using AI in academia, including issues related to plagiarism and misinformation. It underscores the importance of critical evaluation when using GenAI tools for research.
Originality/value
This paper contributes to the emerging literature on the role of GenAI in academic research by providing a critical assessment of the usability and limitations of current tools in studying complex IB phenomena. By using nonlinear internationalization as an example, it demonstrates how GenAI may support or hinder IB scholarship.}
}
@article{VALLEE2026101714,
title = {Generative artificial intelligence in otorhinolaryngology: From innovation to public health transformation},
journal = {Brazilian Journal of Otorhinolaryngology},
volume = {92},
number = {1},
pages = {101714},
year = {2026},
issn = {1808-8694},
doi = {https://doi.org/10.1016/j.bjorl.2025.101714},
url = {https://www.sciencedirect.com/science/article/pii/S1808869425001582},
author = {Alexandre Vallée}
}
@article{HASAN2025874,
title = {Ethical Application of Generative Artificial Intelligence in Medicine},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {4},
pages = {874-885},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S074980632401048X},
author = {Sayyida S. Hasan and Matthew S. Fury and Joshua J. Woo and Kyle N. Kunze and Prem N. Ramkumar},
abstract = {Generative artificial intelligence (AI) may revolutionize health care, providing solutions that range from enhancing diagnostic accuracy to personalizing treatment plans. However, its rapid and largely unregulated integration into medicine raises ethical concerns related to data integrity, patient safety, and appropriate oversight. One of the primary ethical challenges lies in generative AI’s potential to produce misleading or fabricated information, posing risks of misdiagnosis or inappropriate treatment recommendations, which underscore the necessity for robust physician oversight. Transparency also remains a critical concern, as the closed-source nature of many large-language models prevents both patients and health care providers from understanding the reasoning behind AI-generated outputs, potentially eroding trust. The lack of regulatory approval for AI as a medical device, combined with concerns around the security of patient-derived data and AI-generated synthetic data, further complicates its safe integration into clinical workflows. Furthermore, synthetic datasets generated by AI, although valuable for augmenting research in areas with scarce data, complicate questions of data ownership, patient consent, and scientific validity. In addition, generative AI’s ability to streamline administrative tasks risks depersonalizing care, further distancing providers from patients. These challenges compound the deeper issues plaguing the health care system, including the emphasis of volume and speed over value and expertise. The use of generative AI in medicine brings about mass scaling of synthetic information, thereby necessitating careful adoption to protect patient care and medical advancement. Given these considerations, generative AI applications warrant regulatory and critical scrutiny. Key starting points include establishing strict standards for data security and transparency, implementing oversight akin to institutional review boards to govern data usage, and developing interdisciplinary guidelines that involve developers, clinicians, and ethicists. By addressing these concerns, we can better align generative AI adoption with the core foundations of humanistic health care, preserving patient safety, autonomy, and trust while harnessing AI’s transformative potential.
Level of Evidence
Level V, expert opinion.}
}
@article{KUMAR2025115160,
title = {Generative artificial intelligence (GenAI) revolution: A deep dive into GenAI adoption},
journal = {Journal of Business Research},
volume = {189},
pages = {115160},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.115160},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324006647},
author = {Aman Kumar and Amit Shankar and Linda D. Hollebeek and Abhishek Behl and Weng Marc Lim},
keywords = {Artificial intelligence, Generative artificial intelligence, Generative AI, GenAI, Adoption, Behavioral reasoning theory, Mixed methods},
abstract = {This study examines key reasons (for and against) that influence business-to-business (B2B) managers’ intention to adopt generative artificial intelligence (GenAI). We also investigate how GenAI adoption influences firm performance, along with the moderating effect of ethical leadership. Study 1 undertakes a series of in-depth interviews, yielding a set of hypotheses that are tested in Study 2. A total of 277 responses was collected from respondents in the USA, the UK, Canada, India, Australia, Malaysia, and Japan to test the proposed model using structural equation modeling. The findings highlight that need for uniqueness, information completeness, convenience, and deceptiveness significantly impact GenAI adoption. The results also highlight that GenAI adoption boosts firm performance. Finally, ethical leadership was found to moderate the effect of GenAI adoption on firm performance. This study enriches the GenAI, technology adoption, and behavioral reasoning theory literatures while also providing pertinent insights for firms intending to adopt GenAI.}
}
@article{SCHULZEBALHORN2025109121,
title = {Graph-to-SFILES: Control structure prediction from process topologies using generative artificial intelligence},
journal = {Computers & Chemical Engineering},
volume = {199},
pages = {109121},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2025.109121},
url = {https://www.sciencedirect.com/science/article/pii/S0098135425001255},
author = {Lukas {Schulze Balhorn} and Kevin Degens and Artur M. Schweidtmann},
keywords = {Control structure prediction, Graph-to-sequence, Process graph, SFILES 2.0, Generative artificial intelligence},
abstract = {Control structure design is an important but tedious step in P&ID development. Generative artificial intelligence (AI) promises to reduce P&ID development time by supporting engineers. Previous research on generative AI in chemical process design mainly represented processes by sequences. However, graphs offer a promising alternative because of their permutation invariance. We propose the Graph-to-SFILES model, a generative AI method to predict control structures from flowsheet topologies. The Graph-to-SFILES model takes the flowsheet topology as a graph input and returns a control-extended flowsheet as a sequence in the SFILES 2.0 notation. We compare four different graph encoder architectures, one of them being a graph neural network (GNN) proposed in this work. The Graph-to-SFILES model achieves a top-5 accuracy of 73.2% when trained on 10,000 flowsheet topologies. In addition, the proposed GNN performs best among the encoder architectures. Compared to a purely sequence-based approach, the Graph-to-SFILES model improves the top-5 accuracy for a relatively small training dataset of 1,000 flowsheets from 0.9% to 28.4%. However, the sequence-based approach performs better on a large-scale dataset of 100,000 flowsheets. These results highlight the potential of graph-based AI models to accelerate P&ID development in small-data regimes but their effectiveness on industry relevant case studies still needs to be investigated.}
}
@article{YIN2025100227,
title = {A systematic examination of generative artificial intelligence (GenAI) use guidelines in applied linguistics journals},
journal = {Research Methods in Applied Linguistics},
volume = {4},
number = {3},
pages = {100227},
year = {2025},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2025.100227},
url = {https://www.sciencedirect.com/science/article/pii/S2772766125000485},
author = {Shuhui Yin and Carol A. Chapelle},
keywords = {GenAI literacy for research, GenAI use guidelines, Applied linguistics journals, Scholarly publishing},
abstract = {The unannounced appearance of GenAI in 2022 and the speed of its adoption by researchers have left many questions unanswered about its accepted ethical use, with no apparent consensus among applied linguists. In this context, it’s essential for researchers to develop their GenAI literacy for research to engage with GenAI effectively and responsibly. This study contributes to identifying key components of this literacy through examining accepted GenAI uses in research practices. Based on a systematically sampled collection of 170 high-impact journals in applied linguistics, we investigated the scope and nature of GenAI use guidelines provided by 76 journals intended to guide authors. A checklist including four items regarding general statements and 17 items regarding three categories of specific aspects that GenAI guidelines target (authorship, uses, and human responsibility) was identified. Our findings reveal that (1) less than half of the journals provided GenAI use guidelines to guide authors, (2) the number of specific aspects varied across journals, with most falling short of comprehensive coverage, and (3) disagreements were observed about whether AI can be cited and used for manuscript drafting, idea generating, image generating, data generation, data collection, and data analysis and interpretation. Additionally, journals varied in their guidance on how to disclose GenAI uses. We propose recommendations for journals in improving their AI guidelines. Importantly, we introduce and conceptualize the new construct GenAI literacy for research article writing (GenAI-LR) that is important for authors to develop. We provide actionable recommendations accordingly based on our findings.}
}
@article{ALFONZETTI2025e492,
title = {Transforming the Landscape of Clinical Information Retrieval Using Generative Artificial Intelligence: An Application in Machine Fault Analysis},
journal = {Practical Radiation Oncology},
volume = {15},
number = {5},
pages = {e492-e499},
year = {2025},
issn = {1879-8500},
doi = {https://doi.org/10.1016/j.prro.2025.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S187985002500058X},
author = {Tyler Alfonzetti and Junyi Xia},
abstract = {In a radiation oncology clinic, machine downtime can be a serious burden to the entire department. This study investigates using increasingly popular generative artificial intelligence (AI) techniques to assist medical physicists in troubleshooting linear accelerator issues. Google's NotebookLM, supplemented with background information on linear accelerator issues/solutions, was used as a machine troubleshooting assistant for this purpose. Two board-certified medical physicists evaluated the large language model's responses based on hallucination, relevancy, correctness, and completeness. Results indicated that responses improved with increasing source data context and more specific prompt construction. Keeping risk mitigation and the inherent limitations of AI in mind, this work offers a viable, low-risk method to improve efficiency in radiation oncology. This work uses a “Machine Troubleshooting Assistance” application to provide an adaptable example of how radiation oncology clinics can begin using generative AI to enhance clinical efficiency.}
}
@article{METZGER2025103313,
title = {Generative artificial intelligence augmenting SME financial management},
journal = {Technovation},
volume = {147},
pages = {103313},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103313},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225001452},
author = {Michael Metzger and Seán O'Reilly and Ciarán {Mac an Bhaird}},
keywords = {Financial management, SMEs, Artificial intelligence, Digital technologies, Predictive modelling, Going concern},
abstract = {This study investigates the potential for entrepreneurs to leverage advances in technological innovation, specifically generative Artificial Intelligence (AI), to build management capability to mitigate business and financial risks. Drawing on theories of Technology Affordances and Constraints and the Resource-Based View (RBV) of the firm, recognising that small and medium-sized enterprises (SMEs) are inherently resource-constrained. We examine how AI-generated financial diagnostics can empower SMEs by generating accessible, real-time analysis and insights, thus bolstering the management function and increasing chances of survival and growth. Using a dataset of 1,150 UK SMEs spanning eight years of financial statements, we test a large language model (LLM) prediction assessment and analyse the potential for SMEs to utilise the technology, notwithstanding enterprise-specific constraints. We conclude that AI may be a very effective tool for smaller enterprises to augment the financial management function, although its efficacy hinges on organisational readiness, competence in interpreting data, and the will to act on automated red-flag alerts. These findings offer practical guidance for SMEs seeking to enhance their financial management processes in today's digital era.}
}
@article{HUANG2025445,
title = {Ophthalmology Journals’ Guidelines on Generative Artificial Intelligence: A Comprehensive Analysis},
journal = {American Journal of Ophthalmology},
volume = {271},
pages = {445-454},
year = {2025},
issn = {0002-9394},
doi = {https://doi.org/10.1016/j.ajo.2024.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002939424005889},
author = {Wenqiao Huang and Yating Liang and Xianghui Wei and Yi Du},
abstract = {Purpose
The integration of generative artificial intelligence (GAI) into scientific research and academic writing has generated considerable controversy. Currently, standards for using GAI in academic medicine remain undefined. This study aims to conduct a comprehensive analysis of the guidance provided for authors regarding the use of GAI in ophthalmology scientific journals.
Design
Cross-sectional bibliometric analysis.
Participants
A total of 140 ophthalmology journals listed in the Scimago Journal and Country Rankings, regardless of language or origin.
Methods
We systematically searched and screened the 140 ophthalmology journals’ websites on October 19 and 20, 2024, and conducted updates on November 19 and 20, 2024.
Main Outcome Measures
The content of GAI guidelines from the websites of the 140 ophthalmology journals.
Results
Of 140 journals reviewed, 96 (69%) provide explicit guidelines for authors regarding the use of GAI. Among these, nearly all journals agree on 3 key points: (1) 94 journals (98%) have established specific guidelines prohibiting GAI from being listed as an author; (2) 94 journals (98%) emphasize that human authors are responsible for the outputs generated by GAI tools; and (3) all 96 journals require authors to disclose any use of GAI. In addition, 20 journals (21%) specify that their guidelines pertain solely to the writing process with GAI. Furthermore, 92 journals (66%) have developed guidelines concerning GAI-generated images, with 63 journals (68%) permitting their use and 29 (32%) prohibiting them. Among those that prohibit GAI images, 27 journals (93%) allow their use under specific conditions.
Conclusion
Although there is considerable ethical consensus among ophthalmology journals regarding the use of GAI, notable variations exist in terms of permissible use and disclosure practices. Establishing standardized guidelines is essential to safeguard the originality and integrity of scientific research. Researchers must uphold high standards of academic ethics and integrity when using GAI.}
}
@article{ZHU2025102434,
title = {SpectroGen: A physically informed generative artificial intelligence for accelerated cross-modality spectroscopic materials characterization},
journal = {Matter},
pages = {102434},
year = {2025},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2025.102434},
url = {https://www.sciencedirect.com/science/article/pii/S2590238525004771},
author = {Yanmin Zhu and Loza F. Tadesse},
keywords = {spectral transfer, generative neural network, materials characterization, Raman spectroscopy, infrared spectroscopy, X-ray diffraction},
abstract = {Summary
Artificial intelligence (AI)-driven materials discovery offers rapid design of novel material compositions, yet synthesis and characterization lag behind. Characterization, in particular, remains bottlenecked by labor-intensive experiments using expert-operated instruments that typically rely on electromagnetic spectroscopy. We introduce SpectroGen, a generative AI model for transmodality spectral generation, designed to accelerate materials characterization. SpectroGen generates high-resolution, high-signal-to-noise ratio spectra with 99% correlation to ground truth and a root-mean-square error of 0.01 a.u. Its performance is driven by two key innovations: (1) a novel distribution-based physical prior and (2) a variational autoencoder (VAE) architecture. The prior simplifies complex structural inputs into interpretable Gaussian or Lorentzian distributions, while the VAE maps them into a physically grounded latent space for accurate spectral transformation. SpectroGen generalizes across spectral domains and promises rapid, accurate spectral predictions, potentially transforming high-throughput discovery in domains such as battery materials, catalysts, superconductors, and pharmaceuticals.}
}
@article{SEXTON2024606,
title = {Assessments of Generative Artificial Intelligence as Clinical Decision Support Ought to be Incorporated Into Randomized Controlled Trials of Electronic Alerts for Acute Kidney Injury},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {2},
number = {4},
pages = {606-610},
year = {2024},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S2949761224001019},
author = {Donal J. Sexton and Conor Judge}
}
@article{LI2025,
title = {Comparative Analysis of Generative Artificial Intelligence Systems in Solving Clinical Pharmacy Problems: Mixed Methods Study},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/76128},
url = {https://www.sciencedirect.com/science/article/pii/S2291969425001401},
author = {Lulu Li and Pengqiang Du and Xiaojing Huang and Hongwei Zhao and Ming Ni and Meng Yan and Aifeng Wang},
keywords = {artificial intelligence, DeepSeek-R1, clinical pharmacy, comparative analysis, generative AI},
abstract = {Background
Generative artificial intelligence (AI) systems are increasingly deployed in clinical pharmacy; yet, systematic evaluation of their efficacy, limitations, and risks across diverse practice scenarios remains limited.
Objective
This study aims to quantitatively evaluate and compare the performance of 8 mainstream generative AI systems across 4 core clinical pharmacy scenarios—medication consultation, medication education, prescription review, and case analysis with pharmaceutical care—using a multidimensional framework.
Methods
Forty-eight clinically validated questions were selected via stratified sampling from real-world sources (eg, hospital consultations, clinical case banks, and national pharmacist training databases). Three researchers simultaneously tested 8 different generative AI systems (ERNIE Bot, Doubao, Kimi, Qwen, GPT-4o, Gemini-1.5-Pro, Claude-3.5-Sonnet, and DeepSeek-R1) using standardized prompts within a single day (February 20, 2025). A double-blind scoring design was used, with 6 experienced clinical pharmacists (≥5 years experience) evaluating the AI responses across 6 dimensions: accuracy, rigor, applicability, logical coherence, conciseness, and universality, scored 0‐10 per predefined criteria (eg, −3 for inaccuracy and −2 for incomplete rigor). Statistical analysis used one-way ANOVA with Tukey Honestly Significant Difference (HSD) post hoc testing and intraclass correlation coefficients (ICC) for interrater reliability (2-way random model). Qualitative thematic analysis identified recurrent errors and limitations.
Results
DeepSeek-R1 (DeepSeek) achieved the highest overall performance (mean composite score: medication consultation 9.4, SD 1.0; case analysis 9.3, SD 1.0), significantly outperforming others in complex tasks (P<.05). Critical limitations were observed across models, including high-risk decision errors—75% omitted critical contraindications (eg, ethambutol in optic neuritis) and a lack of localization—90% erroneously recommended macrolides for drug-resistant Mycoplasma pneumoniae (China’s high-resistance setting), while only DeepSeek-R1 aligned with updated American Academy of Pediatrics (AAP) guidelines for pediatric doxycycline. Complex reasoning deficits: only Claude-3.5-Sonnet detected a gender-diagnosis contradiction (prostatic hyperplasia in female); no model identified diazepam’s 7-day prescription limit. Interrater consistency was lowest for conciseness in case analysis (ICC=0.70), reflecting evaluator disagreement on complex outputs. ERNIE Bot (Baidu) consistently underperformed (case analysis: 6.8, SD 1.5; P<.001 vs DeepSeek-R1).
Conclusions
While generative AI shows promise as a pharmacist assistance tool, significant limitations—including high-risk errors (eg, contraindication omissions), inadequate localization, and complex reasoning gaps—preclude autonomous clinical decision-making. Performance stratification highlights DeepSeek-R1’s current advantage, but all systems require optimization in dynamic knowledge updating, complex scenario reasoning, and output interpretability. Future deployment must prioritize human oversight (human-AI co-review), ethical safeguards, and continuous evaluation frameworks.}
}
@article{PAN2025110175,
title = {Enhanced feedback analysis of vertical load reliability parameters for airplane landing gear using an improved generative adversarial network and explainable artificial intelligence techniques},
journal = {Engineering Applications of Artificial Intelligence},
volume = {145},
pages = {110175},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110175},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625001757},
author = {Weihuang Pan and Yunwen Feng and Cheng Lu and Jiaqi Liu and Jingcui Liang},
keywords = {Landing gear vertical load, Operation reliability, Improved generative adversarial Network, Explainable artificial intelligence, Feedback analysis, Shapley Additive explanations, Data generation},
abstract = {Effective feedback analysis of critical equipment data is essential for improving performance and optimizing design parameters in aviation systems. This study presents a novel framework that integrates an improved generative adversarial network (GAN) with explainable artificial intelligence techniques (XAI) to evaluate the reliability of the vertical load for airplane landing gear. By utilizing limited data from the Quick Access Recorder (QAR), the improved GAN generates extensive synthetic data to expand the dataset and strengthen the analysis. Each parameter's importance and influence on vertical load reliability are then evaluated through the Shapley Additive Explanations (SHAP) method, a key approach in XAI. Validation using landing gear data from a typical civil airplane demonstrates the effectiveness of this method and confirms the viability of explainable artificial intelligence for parametric feedback analysis. The results highlight the impact of each parameter on vertical load reliability, providing valuable insights to support enhanced design and operational efficiency of landing gear.}
}
@article{TAIWO2025100316,
title = {Making waves: Generative artificial intelligence in water distribution networks: Opportunities and challenges},
journal = {Water Research X},
volume = {28},
pages = {100316},
year = {2025},
issn = {2589-9147},
doi = {https://doi.org/10.1016/j.wroa.2025.100316},
url = {https://www.sciencedirect.com/science/article/pii/S2589914725000155},
author = {Ridwan Taiwo and Abdul-Mugis Yussif and Tarek Zayed},
keywords = {Digital water systems, Generative artificial intelligence, Smart water distribution networks, Retrieval-augmented generation, ChatGPT, Reclaimed WDNs, RAG, Multimodal AI},
abstract = {Water distribution networks (WDNs) face increasing challenges from aging infrastructure, population growth, and climate change, necessitating innovative technological solutions. This study examines the integration of Generative Artificial Intelligence (GenAI) in WDNs, including both conventional and reclaimed water systems. Through a comprehensive analysis of current literature and emerging applications, the study identifies key opportunities in near-future applications focusing on enhancing information retrieval through advanced document processing, improving water quality management via real-time monitoring and visualization, implementing predictive maintenance strategies through pattern recognition, and optimizing real-time operational control through adaptive algorithms. Results also demonstrate that GenAI can transform WDN operations through advanced visualization, scenario generation, and adaptive optimization capabilities, particularly in far-future applications such as demand forecasting, emergency response, and network design optimization. The analysis reveals significant challenges, including data quality and availability issues, particularly in non-English speaking regions, scalability constraints in large-scale networks, the critical need for water professionals with hybrid expertise in both traditional engineering and AI systems, and complex regulatory requirements that vary significantly across the globe. The study also explores unique applications in reclaimed WDNs, particularly in quality control, treatment optimization, and stakeholder engagement. These findings provide water utilities, policymakers, and researchers with valuable insights for implementing GenAI technologies while balancing technological advancement with human expertise and social responsibility.}
}
@article{KHOSO2025100627,
title = {Empowering creativity and engagement: The impact of generative artificial intelligence usage on Chines EFL students' language learning experience},
journal = {Computers in Human Behavior Reports},
volume = {18},
pages = {100627},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100627},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825000429},
author = {Abdul Khalique Khoso and Wang Honggang and Mansoor Ali Darazi},
keywords = {Generative artificial intelligence, Use of ChatGPT, Language learning engagement, EFL student' creativity, EFL students' self-efficacy and tertiary education},
abstract = {Present study examines the impact of Generative Artificial Intelligence (GAI) like Use of ChatGPT on Language Learning Engagement and EFL Students Creativity among Chinese EFL students at the tertiary level in China. Present study aims to investigates the direct effects of Use of ChatGPT on Language Learning Engagement, impact of engagement on EFL students' creativity and the mediating role of engagement between Use of ChatGPT and EFL student ‘creativity thereby, the moderating effect of creative self-efficacy on Language learning engagement and EFL students’ creativity is also investigated. Present study uses quantitative empirical research design and the data were collected from n = 370 EFL students at Yangzhou University of China through a structured survey. Moreover, the analysis for present study was conducted using SPSS and PLS-SEM. The Findings reveal that ChatGPT use positively influences language engagement, enhancing creativity. Language Learning Engagement mediates the relationship between Use of ChatGPT and EFL student’s creativity, while creative self-efficacy significantly moderates the engagement and creativity. These results align with existing research, underscoring the importance of engagement in driving creativity and highlighting the role of self-efficacy in amplifying this effect. The study’s implications suggest that integrating Use of ChatGPT into EFL education can foster both engagement and creative outcomes, providing valuable insights for educators and policy-makers aiming to enhance language learning experiences. Future research could explore additional factors influencing the AI-engagement-creativity dynamic.}
}
@article{YOUNG2025200,
title = {A Hands-Free Approach With Voice to Text and Generative Artificial Intelligence: Streamlining Radiology Reporting},
journal = {Journal of the American College of Radiology},
volume = {22},
number = {2},
pages = {200-203},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400838X},
author = {Austin Young and Katherine E. Wang and Michael X. Jin and Kian Avilla and Kevin Gilotra and Pamela Nguyen and Pablo R. Ros}
}
@article{DORTAGONZALEZ2024102187,
title = {Generative artificial intelligence usage by researchers at work: Effects of gender, career stage, type of workplace, and perceived barriers},
journal = {Telematics and Informatics},
volume = {94},
pages = {102187},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102187},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000911},
author = {Pablo Dorta-González and Alexis Jorge López-Puig and María Isabel Dorta-González and Sara M. González-Betancor},
keywords = {Artificial intelligence, Use of AI by researchers in the workplace, Challenges in implementing AI, Gender imbalance},
abstract = {The integration of generative artificial intelligence technology into research environments has become increasingly common in recent years, representing a significant shift in the way researchers approach their work. This paper seeks to explore the factors underlying the frequency of use of generative AI amongst researchers in their professional environments. As survey data may be influenced by a bias towards scientists interested in AI, potentially skewing the results towards the perspectives of these researchers, this study uses a regression model to isolate the impact of specific factors such as gender, career stage, type of workplace, and perceived barriers to using AI technology on the frequency of use of generative AI. It also controls for other relevant variables such as direct involvement in AI research or development, collaboration with AI companies, geographic location, and scientific discipline. Our results show that researchers who face barriers to AI adoption experience an 11 % increase in tool use, while those who cite insufficient training resources experience an 8 % decrease. Female researchers experience a 7 % decrease in AI tool usage compared to men, while advanced career researchers experience a significant 19 % decrease. Researchers associated with government advisory groups are 45 % more likely to use AI tools frequently than those in government roles. Researchers in for-profit companies show an increase of 19 %, while those in medical research institutions and hospitals show an increase of 16 % and 15 %, respectively. This paper contributes to a deeper understanding of the mechanisms driving the use of generative AI tools amongst researchers, with valuable implications for both academia and industry.}
}
@article{ZHANG2025100040,
title = {Generative artificial intelligence (AI) in built environment design and planning – A state-of-the-art review},
journal = {Progress in Engineering Science},
volume = {2},
number = {1},
pages = {100040},
year = {2025},
issn = {2950-4252},
doi = {https://doi.org/10.1016/j.pes.2024.100040},
url = {https://www.sciencedirect.com/science/article/pii/S2950425224000409},
author = {Haolan Zhang and Ruichuan Zhang},
keywords = {Generative artificial intelligence (AI), Built environment design, Deep learning, Data-driven design, Benchmarking},
abstract = {Despite numerous studies on adopting, implementing, and developing generative design approaches within the architectural, engineering, and construction (AEC) sectors, there remains a limited understanding of the capabilities and constraints of generative artificial intelligence (AI) in specific applications for built environment design and planning. This review paper aims to bridge this gap by providing a systematic review guided by a framework encompassing three main related application areas in building development – site layout, interior, and exterior design, and three main categories of generative AI algorithms – rule-based AI and expert systems, optimization and metaheuristics, and machine learning algorithms, with a focus on state-of-the-art deep learning algorithms. We collected, reviewed, and analyzed 179 state-of-the-art studies in the past decade, consolidating siloed knowledge of user-centric design constraints and objectives, hybrid generative AI methods, data sources for development and testing, as well as benchmarking methods and metrics for assessing design performance, thereby providing a comprehensive understanding of the efficacy of generative AI technologies across diverse design contexts.}
}
@article{ZHOU2025103953,
title = {Government adoption of generative artificial intelligence and ambidextrous innovation},
journal = {International Review of Economics & Finance},
volume = {98},
pages = {103953},
year = {2025},
issn = {1059-0560},
doi = {https://doi.org/10.1016/j.iref.2025.103953},
url = {https://www.sciencedirect.com/science/article/pii/S1059056025001169},
author = {Zhikai Zhou and Dewen Liu and Zhongjie Chen and Martin Pancho},
keywords = {Generative artificial intelligence, TOE framework, Technology adoption, Organizational ambidextrous innovation},
abstract = {Every information technological revolution has brought about new possibilities for governmental organizational innovation, and the rapid development of Generative artificial intelligence (Gen-AI) is poised to profoundly impact government governance models and public service supply methods. Understanding the factors influencing government adoption of Gen-AI, and analyzing the impact of such adoption on governmental organizational innovation behavior, have emerged as urgent and cutting-edge topics. Based on the Technology-Organization-Environment (TOE) framework and the ambidextrous organization theory, this study systematically analyzes the three-layered driving factors that influence government organizations' adoption of Gen-AI, and examines the impact of Gen-AI on exploratory and exploitative innovation within government organizations. Furthermore, it delves into the influence mechanisms of technology adoption on different innovation behaviors from the meso-institutional and micro-implementation perspectives. At the theoretical level, this study constructs a conceptual framework for understanding the adoption of Gen-AI technology, extends the application scope of the TOE theory and enhances its explanatory power, while also providing new insights into the complexity of technology-enabled organizational innovation. At the practical level, it offers a more strategic perspective and profound implications for government organizations to maintain innovative vitality and achieve sustainable development amidst the wave of intelligent transformation.}
}
@article{DING2025100866,
title = {Tracking the carbon footprint of global generative artificial intelligence},
journal = {The Innovation},
volume = {6},
number = {5},
pages = {100866},
year = {2025},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2025.100866},
url = {https://www.sciencedirect.com/science/article/pii/S2666675825000694},
author = {Zhaohao Ding and Jianxiao Wang and Yiyang Song and Xiaokang Zheng and Guannan He and Xiupeng Chen and Tiance Zhang and Wei-Jen Lee and Jie Song}
}
@article{TRIPATHI2025,
title = {Toward Pediatric Patient–Friendly Education Material Using Generative Artificial Intelligence},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025004041},
author = {Satvik Tripathi and Dana Alkhulaifat and Hansel J. Otero and Tessa S. Cook}
}
@article{ROBINSON2025212,
title = {Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {307},
pages = {212-220},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2024.12.059},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425000216},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines},
keywords = {AI, Artificial intelligence, ChatGPT, Generative AI, Large language models},
abstract = {Artificial intelligence (AI) is rapidly being used in medicine due to its advanced capabilities in image and video recognition, clinical decision support, surgical education, and administrative task automation. Large language models such as OpenAI’s Generative Pretrained Transformer (GPT)-4 and Google’s Bard have particularly revolutionized text generation, offering substantial benefits for the academic surgeon, including aiding in manuscript and grant writing. However, integrating AI into academic surgery necessitates addressing ethical concerns such as bias, transparency, and intellectual property. This paper provides guidelines and recommendations based on current literature around the opportunities and ethical challenges of AI in academic surgery. We discuss the underlying mechanisms of large language models, their potential biases, and the importance of responsible usage. Furthermore, we explore the ethical implications of AI in clinical documentation, highlighting improved efficiency and necessary privacy concerns. This review also addresses the critical issue of intellectual property dilemmas posed by AI-generated innovations in university settings. Finally, we propose guidelines for the responsible adoption of AI in academic and clinical environments, stressing the need for transparency, ethical training, and robust governance frameworks to ensure AI enhances, rather than undermines, academic integrity and patient care.}
}
@article{WANG2024102744,
title = {Green entrepreneurship success in the age of generative artificial intelligence: The interplay of technology adoption, knowledge management, and government support},
journal = {Technology in Society},
volume = {79},
pages = {102744},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102744},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002926},
author = {Shaofeng Wang and Hao Zhang},
keywords = {Generative artificial intelligence, Green entrepreneurship, Knowledge management, Green innovation, Government support, Resource orchestration theory},
abstract = {This study investigates the integral role of generative artificial intelligence (GAI) in enhancing green entrepreneurship success, focusing on the interconnected dynamics of GAI adoption, green knowledge management, innovation, and government support. Despite the growing interest in GAI, existing research lacks an understanding of how GAI fosters green entrepreneurship success, particularly in green knowledge management and innovation pathways. Utilizing a robust theoretical framework grounded in resource orchestration and knowledge management theories, we examine the influence of GAI on acquiring and applying green knowledge and its subsequent impact on fostering green innovation. The study examines how government funding moderates these correlations. Employing PLS-SEM and fsQCA, the research elucidates complex interrelationships and causal paths. The findings reveal that GAI significantly enhances green knowledge management capabilities, which drives green innovation and entrepreneurship success. Additionally, government support plays a crucial role in amplifying these effects. This study contributes to technological change and social transformation discourse, offering practical insights for decision-makers and stakeholders in green entrepreneurship and policy-making.}
}
@article{YANG2025,
title = {Reinforcement learning-based generative artificial intelligence for novel pesticide design},
journal = {Journal of Advanced Research},
year = {2025},
issn = {2090-1232},
doi = {https://doi.org/10.1016/j.jare.2025.02.030},
url = {https://www.sciencedirect.com/science/article/pii/S2090123225001286},
author = {Ruoqi Yang and Biao Li and Jin Dong and Zhuomei Cai and Hongyan Lin and Fan Wang and Guangfu Yang},
keywords = {Generative model, Reinforcement learning, Pesticide design, 4-hydroxyphenylpyruvate dioxygenase},
abstract = {Introduction
Pesticides play a pivotal role in ensuring food security, and the development of green pesticides is an inevitable trend in global agricultural progress. Although deep learning-based generative models have revolutionized de novo drug design in pharmaceutical research, their application in pesticide research and development remains unexplored.
Objectives
This study aims to pioneer the application of generative artificial intelligence to pesticide design by proposing a reinforcement learning-based framework for obtaining pesticide-like molecules with high binding affinity.
Methods
This framework comprises two key components: PestiGen-G, which systematically explores the pesticide-like chemical space using a character-based generative model coupled with the REINFORCE algorithm; and PestiGen-S, which combines a fragment-based generative model with the Monte Carlo Tree Search algorithm to generate molecules that stably bind to the specific target protein.
Results
Experimental results show that the molecules generated by PestiGen have superior pesticide-likeness and binding affinity compared to those generated by existing methods. In addition, we employ an active learning strategy to reduce the false-positive rate of the generated molecules. Finally, through collaboration with domain experts, we successfully designed a novel 4-hydroxyphenylpyruvate dioxygenase inhibitor (YH23768) with favorable enzyme inhibition and herbicidal potency.
Conclusion
This proof-of-concept study highlights the utility of PestiGen as a valuable tool for pesticide design. The web server based on the model is freely available at https://dpai.ccnu.edu.cn/PestiGen/.}
}
@article{LIU2025114513,
title = {A friend or a foe? The effect of generative artificial intelligence on creator contributions on original work sharing platforms},
journal = {Decision Support Systems},
volume = {197},
pages = {114513},
year = {2025},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2025.114513},
url = {https://www.sciencedirect.com/science/article/pii/S0167923625001149},
author = {Shan Liu and Wenxuan Hu and Baojun Gao},
keywords = {Generative artificial intelligence, Copyright infringement, Original work sharing platform, Crowding out, Protective motivation theory},
abstract = {While generative artificial intelligence (GAI) is increasingly used to create content, it is often criticized for collecting and training private data and induces potential copy infringement issue. This dilemma leaves a question of whether GAI increases or decreases creators' work sharing. Drawn on protection motivation theory, this study examines how the launch of a GAI system affects creators' contributions on an original work sharing platform. We discover that GAI poses a threat to drawing-category creators, leading to a significant crowding-out effect on their contributions. Specifically, compared with that of non-drawing-category creators, the work sharing of drawing-category creators decreases by 19.64 % and 14.29 % within a short period after the launch and removal of the GAI system, respectively. We discover that creators' protective behavior is driven by GAI-related copyright infringement. Compared with creators without copyright protection, those with copyright protection are more inclined to cease contributions or even leave the platform. We further find that among copyright-protected creators, top creators, evidenced by their acquisition of a large number of supporters or platform honor titles, exhibit more pronounced responses to protect their works due to their higher coping efficacy. Notably, this threat reduces creators' sharing behavior or even lead to their exit from the platform. Nevertheless, such reduction is likely to gradually recover once the threat subsides. Overall, our findings have important implications for whether and how platform managers adopt GAI systems, especially in an original work sharing context.}
}
@article{RODLER20241496,
title = {Generative artificial intelligence in surgery},
journal = {Surgery},
volume = {175},
number = {6},
pages = {1496-1502},
year = {2024},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2024.02.019},
url = {https://www.sciencedirect.com/science/article/pii/S0039606024001193},
author = {Severin Rodler and Conner Ganjavi and Pieter {De Backer} and Vasileios Magoulianitis and Lorenzo Storino Ramacciotti and Andre Luis {De Castro Abreu} and Inderbir S. Gill and Giovanni E. Cacciamani},
abstract = {Generative artificial intelligence is able to collect, extract, digest, and generate information in an understandable way for humans. As the first surgical applications of generative artificial intelligence are applied, this perspective paper aims to provide a comprehensive overview of current applications and future perspectives for the application of generative artificial intelligence in surgery, from preoperative planning to training. Generative artificial intelligence can be used before surgery for planning and decision support by extracting patient information and providing patients with information and simulation regarding the procedure. Intraoperatively, generative artificial intelligence can document data that is normally not captured as intraoperative adverse events or provide information to help decision-making. Postoperatively, GAIs can help with patient discharge and follow-up. The ability to provide real-time feedback and store it for later review is an important capability of GAIs. GAI applications are emerging as highly specialized, task-specific tools for tasks such as data extraction, synthesis, presentation, and communication within the realm of surgery. GAIs have the potential to play a pivotal role in facilitating interaction between surgeons and artificial intelligence.}
}
@article{SHAHRIAR2025101787,
title = {The role of generative artificial intelligence in digital agri-food},
journal = {Journal of Agriculture and Food Research},
volume = {20},
pages = {101787},
year = {2025},
issn = {2666-1543},
doi = {https://doi.org/10.1016/j.jafr.2025.101787},
url = {https://www.sciencedirect.com/science/article/pii/S2666154325001589},
author = {Sakib Shahriar and Maria G. Corradini and Shayan Sharif and Medhat Moussa and Rozita Dara},
keywords = {Generative artificial intelligence, Agri-food, Digital agriculture, Smart food, Food security, Food quality, Food safety, Food authenticity, Sustainable agriculture},
abstract = {The agriculture and food (agri-food) sector faces rising global concerns about its sustainability and resilience to climate events. Thus, new solutions are needed to ensure environmental and food security. Artificial Intelligence (AI) offers inventive solutions to improve agricultural and food production practices. Generative AI methods, such as generative adversarial networks (GANs), variational autoencoders, and large language models (LLMs), add to the transformative process initiated by AI and expert systems in agricultural and food-related practices to enhance productivity, sustainability, and resilience. This study categorizes generative AI approaches and their capabilities in agri-food systems and provides a comprehensive review of the current landscape of generative AI applications in the sector. It discusses the impact of these technologies on enhancing agricultural productivity, food quality, and safety, as well as sustainability, presenting potential use cases like combatting climate change and foodborne disease modeling that highlight the practical applications and benefits of generative AI in agri-food. Furthermore, it addresses the ethical implications of deploying generative AI, including privacy, security, reliability, and unbiased decision-making.}
}
@article{HERZBERG2025102363,
title = {Assessing the standard-essentiality of 5G technology patents by means of generative artificial intelligence},
journal = {World Patent Information},
volume = {81},
pages = {102363},
year = {2025},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2025.102363},
url = {https://www.sciencedirect.com/science/article/pii/S0172219025000304},
author = {Andre Herzberg},
abstract = {In telecommunication technology, identifying standard-essential patents (SEPs) plays a crucial role in the management of intellectual property. This technology is regulated by technical standards that are largely based on the content of SEPs. These patents are declared standard-essential by their owners because they contain elements of a technical standard. The declaration process leaves room for over- and under-declaration, which entails risks for organizations. This paper focuses on the question of how generative artificial intelligence can be used to assess the standard-essentiality of 5G technology patents. For this purpose, the standard-essentiality is assessed using different prompts with four Large Language Models (LLMs) in two variants. In the first variant, the LLM results are generated by a rather simple prompt and compared with an approach based on unsupervised and supervised machine learning. The result shows that large LLMs are capable of assessing the standard-essentiality. In the second variant, the best-performing LLM is selected and the prompt is expanded to include selected parts of a technical standard. While the assessment results remain largely the same, the LLM is now able to explain in which detail a patent is part of a standard. This has several implications for patent evaluation, licensing and litigation strategies.}
}
@article{KOKABI2025100619,
title = {Ionic Cell Microscopy: A new modality for visualizing cells using microfluidic impedance cytometry and generative artificial intelligence},
journal = {Biosensors and Bioelectronics: X},
volume = {24},
pages = {100619},
year = {2025},
issn = {2590-1370},
doi = {https://doi.org/10.1016/j.biosx.2025.100619},
url = {https://www.sciencedirect.com/science/article/pii/S2590137025000469},
author = {Mahtab Kokabi and Gulam M. Rather and Mehdi Javanmard},
keywords = {Cancer imaging, Impedance cytometry, Microfluidic device, Label-free diagnostics, Generative AI},
abstract = {This study introduces a novel approach to cancer cell imaging by integrating microfluidic sensor technology with artificial intelligence (AI). We developed a custom microfluidic device with polydimethylsiloxane (PDMS) microchannels and integrated electrodes to capture electrical impedance data. The device was fabricated using photolithography, electron beam evaporation, and lift-off techniques. Instead of traditional imaging methods, electrical impedance signals were used to reconstruct cell images. A generative AI model with eight hidden layers processed 191 impedance values to accurately reconstruct the shapes of cancer cells and control beads. Our approach successfully reconstructed images of MDA-MB-231 breast cancer cells, HeLa cells, and beads, achieving 91 % accuracy on the test dataset. Validation using the Structural Similarity Index (SSI) and Mean Structural Similarity Index (MSSIM) produced scores of 0.97 for breast cancer cells and 0.93 for beads, confirming the high precision of this method. This label-free, impedance-based imaging offers a promising solution for cancer diagnostics by accurately reconstructing cell shapes and distinguishing cell types, particularly in point-of-care applications.}
}
@article{ZHAO2025103055,
title = {Unlocking ancient wisdom with modern tools: A new approach to the revitalization of ancient texts based on generative artificial intelligence},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {3},
pages = {103055},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103055},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000515},
author = {YueYan Zhao and WenJie Zhou},
keywords = {Generative artificial intelligence, Chinese classics, Multi-granularity knowledge deconstruction, Knowledge services},
abstract = {In the fields of library science and information science, the gap between the obscure language of ancient texts and the cognitive abilities of the average reader is the primary obstacle to the widespread dissemination of the rich wisdom in traditional cultural heritage. The rapid development of generative artificial intelligence technology has provided the conditions for researchers to transition from sequential organization of bibliographic references to the deconstruction and reorganization of knowledge elements. This study, reveals the intrinsic relationship patterns between multi-granularity knowledge in ancient texts from perspectives such as logical relationships, frame semantic associations, hierarchical structures, and feature associations, and constructs a multidimensional knowledge representation model for ancient texts. Furthermore, a YAML prompt template was designed by integrating large language models with the deconstruction of multi-granularity knowledge elements from ancient texts, and experiments were conducted using the Chinese classic “Records of the Grand Historian: Biographies.” The results indicate that the method developed in this study for the deconstruction and reorganization of knowledge elements in ancient texts exhibits notable characteristics such as multi-granularity, cross-document application, refinement, multiple perspectives, efficiency improvement, and scalability, demonstrating potential for application in the field of knowledge services for ancient texts.}
}
@article{ECKHARDT2025100987,
title = {Livestock behaviour forecasting via generative artificial intelligence},
journal = {Smart Agricultural Technology},
volume = {11},
pages = {100987},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525002205},
author = {Regina Eckhardt and Reza Arablouei and Aaron Ingham and Kieren McCosker and Heinz Bernhardt},
keywords = {Accelerometer data, Cattle behaviour, Data imputation, Generative AI, Precision agriculture},
abstract = {Recent advancements in sensor technology and generative artificial intelligence (AI) are transforming precision livestock farming by enhancing behaviour monitoring and predictive analytics. This study examines the effectiveness of Transformer-type generative AI models in predicting cattle behaviour profiles and imputing missing data from collar accelerometer readings collected during two trials in Queensland, Australia, in 2022 and 2023, alongside climatic data. Each trial involved 60 cattle equipped with collars that classified six core behaviours: grazing, ruminating, walking, resting, drinking, and other over five-second time windows. Hourly behaviour profiles were constructed for each animal and experiment day by aggregating the behaviour predictions over every calendar hour, representing the time spent on each behaviour within each hour. Subsequently, four Transformer-type models (i.e., standard Transformer, Informer, Reformer, and Autoformer) were trained on the hourly behaviour profile data to predict behaviour profiles of the next 24 hours for each animal. Among the considered models, Autoformer showed the highest predictive accuracy when including climate data, achieving a mean absolute error (MAE) of <5.5 min, while the next best model had an MAE of approximately 6 min. For imputing missing data, the standard Transformer outperformed traditional imputation methods, with an MAE of <30 min over 24 hours, compared to 40 to 70 min for traditional methods (mean, median, and linear interpolation). These results highlight the potential of generative AI, particularly Autoformer and Transformer, to enhance predictive accuracy and data imputation in livestock management, thereby supporting regulatory guidance for data-driven decision-making and improved farming practices.}
}
@article{NGUYEN2025491,
title = {Guidelines for learning design and assessment for generative artificial intelligence-integrated education: a unified view},
journal = {Information and Learning Sciences},
volume = {126},
number = {78},
pages = {491-512},
year = {2025},
issn = {2398-5348},
doi = {https://doi.org/10.1108/ILS-11-2024-0148},
url = {https://www.sciencedirect.com/science/article/pii/S239853482500004X},
author = {Andy Nguyen and Anh Thi Duong and Diep Thi Bich Nguyen and Van Thi Thanh Lai and Belle Dang},
keywords = {Artificial intelligence, Generative AI, AIED, Ethics, Policies, Learning design, Assessment},
abstract = {Purpose
The rapid advancement and widespread adoption of generative artificial intelligence (GenAI) in education have significantly impacted learning, teaching and assessment practices. This development has raised critical questions about necessary changes to learning design and traditional assessment methods for a society where GenAI becomes embedded in both learning and work environments. This paper aims to investigate the extent of global consensus on learning design and assessment for GenAI-integrated learning environments.
Design/methodology/approach
This study’s policy analysis approach follows Nguyen et al. (2023) by mapping and analysing current policies and guidelines from intergovernmental organisations. This study conducts a comprehensive review of policies and guidelines relevant to learning design and assessment for GenAI-integrated education, highlighting key competencies, ethical principles and implementation guidelines.
Findings
This paper presents an integrated perspective on the key skills and competencies needed for learning with GenAI, alongside strategies for designing effective GenAI-integrated learning experiences. The study findings highlight the need to rethink conventional assessment goals and methods to capture the full range of learning gains enabled by GenAI.
Originality/value
While recent guidelines have begun to address GenAI’s role in education, there remains ongoing debate over the foundational principles needed to design meaningful learning and assessment in this new context. The proposed integrated framework offers practical guidance for educators and policymakers while also laying the groundwork for future research on the pedagogical and systemic impacts of GenAI integration.}
}
@article{HAMADA2025174,
title = {In silico design of smaller size enzymatic protein by generative artificial intelligence (ProtGPT2)},
journal = {Journal of Bioscience and Bioengineering},
volume = {140},
number = {3},
pages = {174-179},
year = {2025},
issn = {1389-1723},
doi = {https://doi.org/10.1016/j.jbiosc.2025.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389172325001598},
author = {Hiroyuki Hamada and Tamon Matsuzawa and Taizo Hanai},
keywords = {Generative artificial intelligence, Protein language model, ProtGPT2, Amino acid sequence design, Smaller size protein, Malate dehydrogenase},
abstract = {The construction of small proteins by removing amino acid subsequences that are not involved in function, activity, or structure is crucial for bioprocessing and drug development. Traditional design methods often focus on reconstructing functional motifs, but they face challenges in stabilizing structure and reproducing function. In this study, we aimed to develop a design method for small proteins using ProtGPT2, a model that generates protein sequences based on function and structure. First, amino acid sequence data of malate dehydrogenase (MDH) was collected, and ProtGPT2 was fine-tuned (ProtGPT2 for MDH). The chain length and perplexity (ppl) of the generated sequences were evaluated, producing shorter sequences than the natural ones. The validity of the generated sequences was assessed using both population and individual analyses. Population analysis, including multiple sequence alignment (MSA) and t-distributed stochastic neighbor embedding (tSNE), revealed that ProtGPT2 for MDH identified functional motifs of MDH and incorporated them into the generated sequences. Additionally, tSNE showed that the generated sequences were highly similar to natural MDH sequences. In individual analysis, 10 randomly selected sequences were evaluated using BLAST, AlphaFold2, and InterPro. BLAST indicated that 9 sequences were novel MDH variants. AlphaFold2 confirmed that their 3D structures were highly similar to known MDH structures. InterPro identified domains and active sites in 2 sequences, suggesting that they were novel, small MDH variants. In conclusion, ProtGPT2 for MDH has the potential to design amino acid sequence candidates for small MDHs. The validity and utility of the model will be established through future experimental efforts.}
}
@article{BIRKUN2025110680,
title = {Generative artificial intelligence-mediated counselling on first aid for seizures: The performance of publicly available chatbot versus its customised version},
journal = {Epilepsy & Behavior},
volume = {171},
pages = {110680},
year = {2025},
issn = {1525-5050},
doi = {https://doi.org/10.1016/j.yebeh.2025.110680},
url = {https://www.sciencedirect.com/science/article/pii/S1525505025004202},
author = {Alexei A. Birkun and Yekaterina Kosova and Anton Rudenko},
keywords = {Cardiopulmonary resuscitation, Epilepsy, First aid, Generative Artificial Intelligence, Large language models, Natural language processing, Seizures},
abstract = {Background
The potential application of cutting-edge generative artificial intelligence chatbots in the capacity of emergency consultants is gaining growing attention. This study aimed to analyse the quality of advice on first aid for seizures generated by a commercially developed chatbot in comparison with its customised version.
Methods
The baseline version of ChatGPT (model GPT-4o) and the same chatbot customised using a specialised knowledge base and prompt engineering were tested in four scenarios mimicking bystander requests for instructions on how to help a victim with seizures. The scenarios included ongoing seizures and postictal states, with or without consciousness and breathing. A checklist-based evaluation was conducted.
Results
In total, 120 user-to-chatbot dialogues were generated (2 chatbots × 15 dialogues × 4 scenarios). The baseline chatbot always failed to consider the victim’s state, including whether the seizures are continuing, or if the victim in the postictal period is conscious and breathing normally. Its advice was non-selective and inaccurate, with frequent omissions of key recommendations on first aid and suggestions of inadequate measures. The customised chatbot-generated guidance was consistently tailored to the victim’s condition, significantly more precise and completely safe. Depending on the scenario, the mean percentage of chatbot responses that fulfilled the checklist items was 14–49 % for the baseline chatbot and 77–92 % for the customised version (p ≤ 0.039).
Conclusions
Whereas the publicly available version of the chatbot is not acceptable for first aid counselling, its expert-informed customisation ensures high accuracy and safety of generated advice. Further research in this field is advisable.}
}
@article{BAHARMAND20251486,
title = {Leveraging Generative Artificial Intelligence to Address Data Management Challenges in Humanitarian Operations},
journal = {IFAC-PapersOnLine},
volume = {59},
number = {10},
pages = {1486-1491},
year = {2025},
note = {11th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2025},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2025.09.250},
url = {https://www.sciencedirect.com/science/article/pii/S2405896325010110},
author = {Hossein Baharmand},
keywords = {Generative AI, humanitarian operations, decision-making, resource allocation, case study},
abstract = {Integrating generative artificial intelligence (Gen-AI) into humanitarian operations presents a transformative opportunity to enhance decision-making and resource allocation. This paper explores how Gen-AI can address data management challenges in humanitarian contexts, thereby supporting decision-making and resource allocation in humanitarian operations. We examine the practical benefits and challenges of implementing this technology by studying three pilot projects: the Humanitarian Data Insights Project, the UNHCR and Arm partnership, and the WFP’s voice-to-text project. The findings highlight the potential of Gen-AI to streamline data processes, enhance accuracy, and facilitate real-time insights while also addressing concerns related to bias, data privacy, and accountability. The paper concludes with recommendations for humanitarian organizations to effectively leverage Gen-AI, emphasizing the importance of relevant data governance, AI literacy, and cross-sector collaboration. This study contributes to the growing body of knowledge on applying advanced technologies in humanitarian operations, offering insights for future research and practical implementation.}
}
@article{SALARI2025100652,
title = {Impacts of generative artificial intelligence on the future of labor market: A systematic review},
journal = {Computers in Human Behavior Reports},
volume = {18},
pages = {100652},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100652},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825000673},
author = {Nader Salari and Mahan Beiromvand and Amin Hosseinian-Far and Javad Habibi and Fateme Babajani and Masoud Mohammadi},
keywords = {Job market, AI, ChatGPT, Labor market, GenAI},
abstract = {Background
Generative AI (GenAI) has the ability to autonomously collect and process data to generate contents, inform decisions, solve problems, and perform tasks that typically require human reasoning. This Systematic Review is conducted to examine the impacts of GenAI on the future of employment, focusing on concerns about rising unemployment, and the positive and negative perspectives outlined within exiting studies. The findings from this review can help identify research gaps, guide organizational planning, and improve AI governance frameworks and policies.
Methods
To identify relevant studies, the PubMed, Scopus, Web of Science, Embase, ScienceDirect and Google Scholar databases and repositories were systematically searched using the keywords: ‘Future of work’, ‘Job market’, ‘Generative AI’, ‘Generative AI’, and ‘ChatGPT’. Additionally, the reference lists of the identified related articles were reviewed for grey literature.
Results
Following the PRISMA guidelines, a total of 14 articles were selected for analysis. Selected studies have examined the positive and negative viewpoints on GenAI, together with pertinent challenges and opportunities. Accordingly, GenAI, when compliant with security and ethical issues, has the potential to increase efficiency whilst reducing costs and time.
Conclusion
Considering the rapid growth and adoption of AI technologies, examining the impacts of GenAI on the future of labor market is crucial. GenAI is likely to create new roles in some sectors yet reduce opportunities in others. A nuanced assessment of the impacts, and ongoing monitoring are vital for effective preparation and adaptation to the evolving work landscape in the presence of advanced AI technologies.}
}
@article{TONG2025103629,
title = {A rapidly structured aircraft concept design method based on generative artificial intelligence},
journal = {Chinese Journal of Aeronautics},
volume = {38},
number = {10},
pages = {103629},
year = {2025},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2025.103629},
url = {https://www.sciencedirect.com/science/article/pii/S1000936125002353},
author = {Yao TONG and Mingqiang LUO and Shangqing REN and Zheng ZHANG and Chenguang XING and Ziliang DU},
keywords = {Aircraft, Conceptual design, Generative artificial intelligence, Large language model, Prompt engineering},
abstract = {Aircraft conceptual design is a critical step in the development and research of aircraft, involving complex processes and multiple disciplines. Improving the efficiency of aircraft conceptual design while ensuring quality is an important challenge. Intelligent technologies such as neural networks have played significant roles in areas like aerodynamics and structural analysis. However, due to issues such as high data demands and difficulties in transfer learning, their application in the conceptual design phase has been limited. The rise of generative artificial intelligence, exemplified by Large Language Model (LLM), offers a new approach to this problem. Therefore, this study proposes a methodology for generating aircraft conceptual design solutions based on LLMs and develops a prototype system. First, four of the current best-performing general-purpose LLMs are selected for deployment as foundational models. Then, based on the general prompt framework of LLMs, schema for aircraft conceptual design solutions, and real-world design cases, task prompts for generating aircraft conceptual design solutions are crafted, resulting in three types of prompts: Full-Instruction, 1-Shot, and 5-Shot. Finally, the prototype system is utilized to design conceptual solutions, and the model-generated solutions are compared with those designed by engineers from both objective and subjective perspectives. The experimental results indicate that LLMs demonstrate conceptual design capabilities comparable to those of engineers, exhibiting strong generalization ability and potential for innovative design.}
}
@article{RONKSLEYPAVIA2025100437,
title = {A scoping literature review of generative artificial intelligence for supporting neurodivergent school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100437},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100437},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000773},
author = {Michelle Ronksley-Pavia and Lan Nguyen and Elizabeth Wheeley and Judy Rose and Michelle M. Neumann and Chris Bigum and David L. Neumann},
keywords = {Artificial intelligence, Generative AI, GenAI, Neurodiversity, School, Personalized learning, Teachers},
abstract = {While Generative Artificial Intelligence (GenAI) platforms like ChatGPT have gained significant traction in education, their specific applications for neurodivergent learners remain largely unmapped. Through systematic searching of academic databases and grey literature between 2020 and 2024, this scoping literature review examined the emerging landscape of GenAI applications in supporting neurodivergent students (e.g., those with ADHD, autism, dyslexia, gifted, twice-exceptional) within K-12 educational contexts. Twenty-one relevant sources were identified, discussing GenAI usage with neurodivergent students, the analysis revealed discussion of several predominant applications, including personalized learning, administrative assistance for educators, and development of individualized education plans. The review identified both promising approaches and significant concerns. Benefits included GenAI's potential to provide real-time, personalized support for students as well as reducing administrative burdens for educators. However, notable concerns emerged regarding information accuracy, over-reliance on AI, privacy considerations, and the need for human oversight. The limited empirical evidence base was particularly striking, with only nine studies providing original research data. The review identified critical gaps in current understanding, particularly regarding GenAI's effectiveness across different neurodivergent conditions and curriculum areas, and little evidence of approaches detailed in ways that educators could use. This scoping review demonstrates the need for robust empirical research examining GenAI usage in learning for neurodivergent students. These insights are timely and crucial for educators, researchers, and policymakers working to harness GenAI's potential in supporting neurodivergent learners within inclusive educational environments.}
}
@article{EHMKE2025222,
title = {Self-perceived knowledge, skills, and attitude of nursing faculty on generative artificial intelligence in nursing education: A descriptive, cross-sectional study},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {222-227},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000447},
author = {Sabrina D. Ehmke and Jenny Bridges and Sarah E. Patel},
keywords = {Artificial intelligence, Nursing education, Nursing faculty},
abstract = {Background
AI is transforming health and education, offering innovative solutions to workflow and curriculum challenges. However, faculty members lack familiarity with AI, limiting their ability to prepare students for AI-driven healthcare.
Aim
Our study investigated nursing faculty's knowledge, skills, and attitudes toward integrating Artificial Intelligence (AI) into education, examining differences by degree type and the influence of policies or syllabi on AI integration.
Methods
A descriptive, cross-sectional study assessed faculty's self-perceptions of knowledge, skills, and attitudes regarding AI in education. Data were gathered via a survey of nursing faculty from diverse institutions.
Results
Findings revealed gaps in AI knowledge and skills linked to educational level and institutional policy development. Doctorly prepared-faculty reported higher perceived knowledge and skills, while BS-prepared faculty had higher attitudes toward AI. Faculty involved in AI policy or syllabus development perceived greater knowledge, skills, and attitudes.
Conclusion
Faculty education and policy support are critical for integrating AI into education. Institutions should invest in faculty development and ethical AI adoption, using case studies, simulation, and decision-support tools to enhance curriculum and healthcare outcomes.}
}
@article{BARROSO2025501667,
title = {Application of generative artificial intelligence chatbots in the field of anesthesia},
journal = {Revista Española de Anestesiología y Reanimación (English Edition)},
volume = {72},
number = {6},
pages = {501667},
year = {2025},
issn = {2341-1929},
doi = {https://doi.org/10.1016/j.redare.2025.501667},
url = {https://www.sciencedirect.com/science/article/pii/S2341192925001179},
author = {A. Barroso and R. Casans}
}
@article{TEO2024100091,
title = {Cybersecurity in the generative artificial intelligence era},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100091},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100091},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000926},
author = {Zhen Ling Teo and Chrystie Wan Ning Quek and Joy Le Yi Wong and Daniel Shu Wei Ting},
keywords = {Generative Artificial Intelligence, ChatGPT, Cybersecurity, Privacy risks, Large language model},
abstract = {Generative Artificial Intelligence (GenAI) are algorithms capable of generating original content. The ability of GenAI to learn and generate novel outputs alike human cognition has taken the world by storm and ushered in a new era. In this review, we explore the role of GenAI in healthcare, including clinical, operational, and research applications, and delve into the cybersecurity risks of this technology. We discuss risks such as data privacy risks, data poisoning attacks, the propagation of bias, and hallucinations. In this review, we recommend risk mitigation strategies to enhance cybersecurity in GenAI technologies and further explore the use of GenAI as a tool in itself to enhance cybersecurity across the various AI algorithms. GenAI is emerging as a pivotal catalyst across various industries including the healthcare domain. Comprehending the intricacies of this technology and its potential risks will be imperative for us to fully capitalise on the benefits that GenAI can bring.}
}
@article{ZHAO2025102299,
title = {From interface to inference: mapping the impact of generative artificial intelligence affordances on user risk perception},
journal = {Telematics and Informatics},
volume = {101},
pages = {102299},
year = {2025},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2025.102299},
url = {https://www.sciencedirect.com/science/article/pii/S0736585325000619},
author = {Haoyu Zhao and Zhengbiao Han and Shuqi Yin and Nan yang and Preben Hansen},
keywords = {Perceived affordances, User risk perception, Generative artificial intelligence, Human-computer interaction},
abstract = {A deep understanding of Generative Artificial Intelligence (GAI) is crucial not only for technological development but also for formulating effective risk response strategies. However, previous studies have mainly focused on how individual factors affect GAI risk perception while the technical functions and features that are the root causes of user concerns regarding GAI remain unclear. To address this gap, the current study, grounded in affordance theory, explored how perceived affordances of GAI influenced user risk perceptions across six dimensions: information, security, technical, social, ethical, and legal. A hierarchical regression analysis was conducted on a survey of 1,031 GAI users to examine the impact of interactivity, agency, and security affordances on these risk dimensions. The results indicate that higher perceptions of affordances such as bandwidth, synchrony, and transparency are significantly associated with lower risk perceptions across all dimensions. Notably, women reported higher perceived risks than men in most categories, whereas age and GAI usage experience did not significantly affect these perceptions. These findings highlight the importance of enhancing user control, transparency, and privacy protections in GAI system design to effectively mitigate perceived risks. This study contributes to the literature by providing a multidimensional analysis of risk perception in the context of GAI, offering practical insights for the development of inclusive, transparent, and user-centered artificial intelligence systems.}
}
@article{PALLOTTINO2025109919,
title = {Applications and perspectives of Generative Artificial Intelligence in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {230},
pages = {109919},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.109919},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925000250},
author = {Federico Pallottino and Simona Violino and Simone Figorilli and Catello Pane and Jacopo Aguzzi and Giacomo Colle and Eugenio {Nerio Nemmi} and Alessandro Montaghi and Damianos Chatzievangelou and Francesca Antonucci and Lavinia Moscovini and Alessandro Mei and Corrado Costa and Luciano Ortenzi},
keywords = {GAI, GAN, NLP, LLMs, ChatGPT, Microsoft Copilot},
abstract = {Artificial Intelligence (AI) applications related to agriculture have recently gained in use and attention. They are indeed valuable tools for interpreting data, improving production chains, and optimizing the use of natural resources. Among AI models, the most recent and promising area is represented by Generative Artificial Intelligence (GAI). After an initial description of its general model architectures, this work aims to review its practical uses and potentials in the following individual sectors: agriculture, precision farming, and animal farming, as well as interdisciplinary applications. The literature search was carried out using the SCOPUS, Google Scholar, and Web of Science databases. GAI holds immense potential for revolutionizing agriculture, offering solutions ranging from precision farming to pest management and supply chain optimization. Though some applications can extend beyond efficiency gains, and hallucinations occurrence i.e. false output information presented as fact, remains an open issue, GAI can be decisive for tasks like improving training datasets, refining models, and facilitating time series analysis. This review extensively describes the vital importance of these tasks for agriculture, precision and animal farming, caused by the rise of new technologies. As a result, by embracing and responsibly implementing GAI applications, it is possible to create a more sustainable and resilient future for agriculture and precision farming. GAI have the capacity to extract specific information from big data systems, offering huge potential to meet a growing global population demand and consequent environmental challenges for the future.}
}
@article{CHENG2025104194,
title = {From emotion to reflection: leveraging EmotionPrompt strategy to empower self-determination in decision-making with generative artificial intelligence},
journal = {Information & Management},
volume = {62},
number = {7},
pages = {104194},
year = {2025},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2025.104194},
url = {https://www.sciencedirect.com/science/article/pii/S0378720625000977},
author = {Xusen Cheng and Lu Gao and Xin (Robert) Luo},
keywords = {Human–AI interaction, EmotionPrompt, Regulatory focus theory, Cognitive reappraisal, Psychological empowerment},
abstract = {Communication and reflection abilities are critical in managing strategic cooperation between humans and Generative Artificial Intelligence (GAI), especially when facing conflict in decision-making. This study introduces two variations of EmotionPrompt strategies, drawing on regulatory focus theory, to explore both individuals' perceptions of GAI ability and their empowerment in self-competence when handling disagreements. An experiment between humans and GAI chatbots in determining product promotion strategy showed that emotional prompts impact individuals' reappraisals of both chatbots and their own performance profoundly, cultivating self-determination in the final decision. Importantly, EmotionPrompt with promotion orientation can increase the perceived flexibility of chatbot decision-makers, facilitating individual self-enhancement and trust in GAI competence. In contrast, the prevention-oriented EmotionPrompt appears to constrain individuals' judgments and decision-making processes, as evidenced by the increased occurrence of inhibit words and anxiety emotions in their reflections. These findings provide novel perspectives on implementing specific regulatory-oriented EmotionPrompt strategies in GAI to address opinion conflicts in decision-making with humans.}
}
@article{BOSCO2025,
title = {Designing a Multimodal and Culturally Relevant Alzheimer Disease and Related Dementia Generative Artificial Intelligence Tool for Black American Informal Caregivers: Cognitive Walk-Through Usability Study},
journal = {JMIR Aging},
volume = {8},
year = {2025},
issn = {2561-7605},
doi = {https://doi.org/10.2196/60566},
url = {https://www.sciencedirect.com/science/article/pii/S2561760525000027},
author = {Cristina Bosco and Ege Otenen and John {Osorio Torres} and Vivian Nguyen and Darshil Chheda and Xinran Peng and Nenette M Jessup and Anna K Himes and Bianca Cureton and Yvonne Lu and Carl V Hill and Hugh C Hendrie and Priscilla A Barnes and Patrick C Shih},
keywords = {multimodality, artificial intelligence, AI, generative AI, usability, black, African American, cultural, Alzheimer's, dementia, caregivers, mobile app, interaction, cognition, user opinion, geriatrics, smartphone, mHealth, digital health, aging},
abstract = {Background
Many members of Black American communities, faced with the high prevalence of Alzheimer disease and related dementias (ADRD) within their demographic, find themselves taking on the role of informal caregivers. Despite being the primary individuals responsible for the care of individuals with ADRD, these caregivers often lack sufficient knowledge about ADRD-related health literacy and feel ill-prepared for their caregiving responsibilities. Generative AI has become a new promising technological innovation in the health care domain, particularly for improving health literacy; however, some generative AI developments might lead to increased bias and potential harm toward Black American communities. Therefore, rigorous development of generative AI tools to support the Black American community is needed.
Objective
The goal of this study is to test Lola, a multimodal mobile app, which, by relying on generative AI, facilitates access to ADRD-related health information by enabling speech and text as inputs and providing auditory, textual, and visual outputs.
Methods
To test our mobile app, we used the cognitive walk-through methodology, and we recruited 15 informal ADRD caregivers who were older than 50 years and part of the Black American community living within the region. We asked them to perform 3 tasks on the mobile app (ie, searching for an article on brain health, searching for local events, and finally, searching for opportunities to participate in scientific research in their area), then we recorded their opinions and impressions. The main aspects to be evaluated were the mobile app’s usability, accessibility, cultural relevance, and adoption.
Results
Our findings highlight the users’ need for a system that enables interaction with different modalities, the need for a system that can provide personalized and culturally and contextually relevant information, and the role of community and physical spaces in increasing the use of Lola.
Conclusions
Our study shows that, when designing for Black American older adults, a multimodal interaction with the generative AI system can allow individuals to choose their own interaction way and style based upon their interaction preferences and external constraints. This flexibility of interaction modes can guarantee an inclusive and engaging generative AI experience.}
}
@article{JIN2025100467,
title = {Mechanisms of enhancing learning with unequal preparation: An experimental study on generative artificial intelligence use and proficiency in programming learning},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100467},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100467},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25001079},
author = {Yuan Jin and Wei He and Jun Shen and Jingyun Hu},
keywords = {Generative artificial intelligence (GenAI), Learning preparation, GenAI proficiency, Learning outcomes, Experimental study},
abstract = {Prior learning preparation, encompassing learners' prior knowledge, resources, and readiness for learning new material, plays a critical role in a new learning process. Unequal learning preparation commonly exists among learners with varying socioeconomic and academic backgrounds, and can further exacerbate the educational divide. By reducing learning cost and providing less prepared learners with personalized delivery of information and knowledge, Generative Artificial Intelligence (GenAI) may help mitigate disparities in learning preparation. In this study, we investigate the roles of learners' use of GenAI in their learning processes, considering varying levels of learners’ prior learning preparation and proficiency in GenAI use. Specifically, we examine the effects of the use of GenAI tools on learning outcomes through its impacts on perceived informational benefit, learning cost, and knowledge fit in the focal learning process, moderated by learning preparation and GenAI proficiency of learners. Based on an experiment in a programming learning context, we find that although GenAI use significantly reduces learning cost, especially for less prepared learners, the cost reduction effect has not been translated into improved learning outcomes. We find no significant moderating effects of learning preparation on how GenAI use affects informational benefit and knowledge fit, further showing that GenAI tools have not yet been effectively utilized to help less prepared learners or reduce the educational divide. As indicated by the significant moderating roles of GenAI proficiency, to fully leverage the power of GenAI, improving GenAI proficiency can be crucial to ensure learning effectiveness for learners with different levels of learning preparation.}
}
@article{MABWE2025820,
title = {Generative artificial intelligence chatbots in investment decision-making: a phantom menace or a new hope?},
journal = {Foresight},
volume = {27},
number = {4},
pages = {820-863},
year = {2025},
issn = {1463-6689},
doi = {https://doi.org/10.1108/FS-06-2024-0122},
url = {https://www.sciencedirect.com/science/article/pii/S1463668925000082},
author = {Kumbirai Mabwe and Nasir Aminu and Stanislav Hristov Ivanov and Diyan Dimov},
keywords = {Generative AI, ChatGPT, Bard, Gemini, Bing, Large language models, Chatbots, Investment recommendations},
abstract = {Purpose
This study aims to investigate the relevance, accuracy, specificity and justification of investment recommendations of generative artificial intelligence (GenAI) chatbots for different investment capitals and countries (UK and Bulgaria).
Design/methodology/approach
A two-stage mixed methods approach was used. Prompts were queried into OpenAI’s ChatGPT, Microsoft Bing and Google Bard (now Gemini). Finance and investment practitioners and finance and investment lecturers assessed the chatbots’ recommendations through an online questionnaire using a five-point Likert scale. The Chi-squared test, Wilcoxon-signed ranks test, Mann–Whitney U test and Friedman test were used for data analysis to compare GenAIs’ recommendations for the UK and Bulgaria across different amounts of investment capital and to assess the consistency of the chatbots.
Findings
GenAI chatbots’ responses were found to perform medium-to-high in terms of relevance, accuracy, specificity and justification. For the UK sample, the amount of investment had a marginal effect but prompt timing had an interesting impact. Unlike the British sample, the GenAI application, prompt timing and investment amount did not significantly influence the Bulgarian respondents’ evaluations. While the mean responses of the British sample were slightly higher, these differences were not statistically significant, indicating that ChatGPT, Bing and Bard performed similarly in both the UK and Bulgaria.
Originality/value
The study assesses the relevance, accuracy, specificity and justification of GenAI chatbots’ investment recommendations for two different periods, investment amounts and countries.}
}
@article{YE2024102851,
title = {Privacy and personal data risk governance for generative artificial intelligence: A Chinese perspective},
journal = {Telecommunications Policy},
volume = {48},
number = {10},
pages = {102851},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102851},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124001484},
author = {Xiongbiao Ye and Yuhong Yan and Jia Li and Bo Jiang},
keywords = {Generative AI, Privacy and personal data protection, Risk governance, Chinese law},
abstract = {The rapid development of generative artificial intelligence (AI) has attracted global attention and posed challenges to existing data governance frameworks. The increased technical complexity and expanded scale of data usage not only make it more difficult to regulate AI but also present challenges for the current legal system. This article, which takes ChatGPT's training data and working principles as a starting point, examines specific privacy risks, data leakage risks, and personal data risks posed by generative AI. It also analyzes the latest practices in privacy and personal data protection in China. This article finds that while China's governance on privacy and personal data protection takes a macro-micro integration approach and a private-and-public law integration approach, there are shortcomings in the legal system. Given that the current personal data protection system centered on individual control is unsuitable for the modes of data processing by generative AI, and that private law is insufficient in safeguarding data privacy, urgent institutional innovation is needed to achieve the objective of “trustworthy AI.”}
}
@article{JIN2025105248,
title = {High heels, compass, spider-man, or drug? Metaphor analysis of generative artificial intelligence in academic writing},
journal = {Computers & Education},
volume = {228},
pages = {105248},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105248},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000168},
author = {Fangzhou Jin and Lanfang Sun and Yunqiu Pan and Chin-Hsi Lin},
keywords = {Artificial intelligence, Writing, Metaphor analysis, Cross-cultural skills, Interdisciplinary knowledge},
abstract = {This research employed metaphor analysis to explore 277 postgraduate students' perceptions of the role of generative artificial intelligence (GenAI) in academic writing. All participants were international students, from a total of 14 countries and regions, studying in the United Kingdom. Data collection was carried out in two phases. The first was a survey comprising demographic and metaphor-related questions, and the second involved metaphor checking, in which participants provided screenshots of their interactions with GenAI. The data, which were analyzed both qualitatively and quantitatively, yielded 53 unique metaphors for the concept of GenAI in academic writing. We divided these into four conceptual categories in what we term the 4T Pyramid Model: Technical Support (representative metaphor: high-heeled shoes), Text Development (compass), Transformative Potential (Spider-Man), and Threat (drug). The respondents' academic disciplines influenced their perceptions of GenAI, but overall, the results suggest that most viewed it as transformative, i.e., more than just a writing tool. This study's innovative methodology integrating metaphor analysis with real user interactions offers a framework, aligned with Bloom's Taxonomy, that reveals the multi-level benefits and potential risks of GenAI. It also provides actionable insights for AI literacy education, including strategies for effective prompt design.}
}
@article{CRUMBLY2025103129,
title = {A classification framework for generative artificial intelligence for social good},
journal = {Technovation},
volume = {139},
pages = {103129},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103129},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001792},
author = {Jack Crumbly and Raktim Pal and Nezih Altay},
keywords = {Artificial intelligence (AI), Generative artificial intelligence (GenAI), Social good, Classification},
abstract = {Many policy makers and corporate leaders are adjusting their strategies to harness the power of GenAI. There are numerous debates on how GenAI would fundamentally change existing business models. However, there is not much discussion on roles of generative AI in the domain of social good. Broader views covering potential opportunities of GenAI to enable diverse initiatives in the social good space are largely missing. We intend to reduce the gap by developing a classification framework that should allow researchers gauge the potential impact of GenAI for social good initiatives. Through case analysis, we assess how value-added abilities of GenAI may influence various social good initiatives. We adopt/develop two loosely connected classification frameworks that are grounded in task-technology fit (TTF) theory. Subsequently, we investigate how our analyses of GenAI initiatives utilizing different dimensions of these two frameworks may be synthesized to provide appropriate explanation for potential success of GenAI for social good. We develop five propositions that will provide guidance to practitioners and researchers. The theoretically grounded analysis of 21 GenAI for social good use cases based on the two classification frameworks, and the resulting propositions are the original contributions of this paper to the AI for social good literature.}
}
@article{NING2024e848,
title = {Generative artificial intelligence and ethical considerations in health care: a scoping review and ethics checklist},
journal = {The Lancet Digital Health},
volume = {6},
number = {11},
pages = {e848-e856},
year = {2024},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(24)00143-2},
url = {https://www.sciencedirect.com/science/article/pii/S2589750024001432},
author = {Yilin Ning and Salinelat Teixayavong and Yuqing Shang and Julian Savulescu and Vaishaanth Nagaraj and Di Miao and Mayli Mertens and Daniel Shu Wei Ting and Jasmine Chiat Ling Ong and Mingxuan Liu and Jiuwen Cao and Michael Dunn and Roger Vaughan and Marcus Eng Hock Ong and Joseph Jao-Yiu Sung and Eric J Topol and Nan Liu},
abstract = {Summary
The widespread use of Chat Generative Pre-trained Transformer (known as ChatGPT) and other emerging technology that is powered by generative artificial intelligence (GenAI) has drawn attention to the potential ethical issues they can cause, especially in high-stakes applications such as health care, but ethical discussions have not yet been translated into operationalisable solutions. Furthermore, ongoing ethical discussions often neglect other types of GenAI that have been used to synthesise data (eg, images) for research and practical purposes, which resolve some ethical issues and expose others. We did a scoping review of the ethical discussions on GenAI in health care to comprehensively analyse gaps in the research. To reduce the gaps, we have developed a checklist for comprehensive assessment and evaluation of ethical discussions in GenAI research. The checklist can be integrated into peer review and publication systems to enhance GenAI research and might be useful for ethics-related disclosures for GenAI-powered products and health-care applications of such products and beyond.}
}
@article{SUPPAN2025,
title = {Performance of 3 Conversational Generative Artificial Intelligence Models for Computing Maximum Safe Doses of Local Anesthetics: Comparative Analysis},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/66796},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000419},
author = {Mélanie Suppan and Pietro Elias Fubini and Alexandra Stefani and Mia Gisselbaek and Caroline Flora Samer and Georges Louis Savoldelli},
keywords = {local anesthetic, dose calculation, toxicity, performance, conversational generative artificial intelligence, artificial intelligence, anesthesiology, comparative analysis, anesthetics, LA, generative artificial intelligence, ChatGPT, Copilot, Gemini, artificial intelligence models, machine learning, neural network, LLM, NLP, natural language processing, large language model, AI, ML},
abstract = {Background
Generative artificial intelligence (AI) is showing great promise as a tool to optimize decision-making across various fields, including medicine. In anesthesiology, accurately calculating maximum safe doses of local anesthetics (LAs) is crucial to prevent complications such as local anesthetic systemic toxicity (LAST). Current methods for determining LA dosage are largely based on empirical guidelines and clinician experience, which can result in significant variability and dosing errors. AI models may offer a solution, by processing multiple parameters simultaneously to suggest adequate LA doses.
Objective
This study aimed to evaluate the efficacy and safety of 3 generative AI models, ChatGPT (OpenAI), Copilot (Microsoft Corporation), and Gemini (Google LLC), in calculating maximum safe LA doses, with the goal of determining their potential use in clinical practice.
Methods
A comparative analysis was conducted using a 51-item questionnaire designed to assess LA dose calculation across 10 simulated clinical vignettes. The responses generated by ChatGPT, Copilot, and Gemini were compared with reference doses calculated using a scientifically validated set of rules. Quantitative evaluations involved comparing AI-generated doses to these reference doses, while qualitative assessments were conducted by independent reviewers using a 5-point Likert scale.
Results
All 3 AI models (Gemini, ChatGPT, and Copilot) completed the questionnaire and generated responses aligned with LA dose calculation principles, but their performance in providing safe doses varied significantly. Gemini frequently avoided proposing any specific dose, instead recommending consultation with a specialist. When it did provide dose ranges, they often exceeded safe limits by 140% (SD 103%) in cases involving mixtures. ChatGPT provided unsafe doses in 90% (9/10) of cases, exceeding safe limits by 198% (SD 196%). Copilot’s recommendations were unsafe in 67% (6/9) of cases, exceeding limits by 217% (SD 239%). Qualitative assessments rated Gemini as “fair” and both ChatGPT and Copilot as “poor.”
Conclusions
Generative AI models like Gemini, ChatGPT, and Copilot currently lack the accuracy and reliability needed for safe LA dose calculation. Their poor performance suggests that they should not be used as decision-making tools for this purpose. Until more reliable AI-driven solutions are developed and validated, clinicians should rely on their expertise, experience, and a careful assessment of individual patient factors to guide LA dosing and ensure patient safety.}
}
@article{SILALAHI2025102995,
title = {Can generative artificial intelligence drive sustainable behavior? A consumer-adoption model for AI-driven sustainability recommendations},
journal = {Technology in Society},
volume = {83},
pages = {102995},
year = {2025},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.102995},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X2500185X},
author = {Andri Dayarana K. Silalahi},
keywords = {Generative AI, Sustainable behavior, User trust, Elaboration likelihood model, Cognitive engagement, Pro-environmental adoption},
abstract = {Generative AI (GAI) has the potential to promote sustainable behavior through personalized recommendations; yet its effectiveness hinges on user trust—an issue that remains under-explored in the literature. Existing studies often focus on specific domains without addressing broader trust-building mechanisms or the cognitive and motivational factors needed for sustained engagement. This study investigates how trust shapes the adoption of GAI-driven sustainability recommendations by integrating the Elaboration Likelihood Model (ELM) and Expectancy-Value Theory (EVT) into a single framework. Using data from sustainability-oriented users, we examine how central route constructs-perceived information quality and utility-peripheral route constructs-anthropomorphism and interaction quality-enhance trust, while perceived information complexity and perceived risk moderate these relationships. Our findings indicate that high-quality, useful information enhances trust through cognitive engagement, whereas anthropomorphic design and interaction quality reinforce trust via the heuristic route. However, excessive complexity and privacy concerns undermine trust, highlighting the need for clearer communication and data transparency. This study broadens theoretical understanding by extending ELM and EVT to the context of GAI-driven sustainability efforts, providing an integrated framework that encompasses cognitive and motivational trust drivers. These insights fill gaps in technology adoption research and offer practical guidance for developing GAI platforms that effectively support pro-environmental behavior change.}
}
@article{HUANG2025100526,
title = {Generative spatial artificial intelligence for sustainable smart cities: A pioneering large flow model for urban digital twin},
journal = {Environmental Science and Ecotechnology},
volume = {24},
pages = {100526},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2025.100526},
url = {https://www.sciencedirect.com/science/article/pii/S2666498425000043},
author = {Jeffrey Huang and Simon Elias Bibri and Paul Keel},
keywords = {Sustainable smart cities, Generative artificial intelligence, Generative spatial artificial intelligence, Foundation models, Large flow model, Urban digital twin, Urban planning and design},
abstract = {Rapid urbanization, alongside escalating resource depletion and ecological degradation, underscores the critical need for innovative urban development solutions. In response, sustainable smart cities are increasingly turning to cutting-edge technologies—such as Generative Artificial Intelligence (GenAI), Foundation Models (FMs), and Urban Digital Twin (UDT) frameworks—to transform urban planning and design practices. These transformative tools provide advanced capabilities to analyze complex urban systems, optimize resource management, and enable evidence-based decision-making. Despite recent progress, research on integrating GenAI and FMs into UDT frameworks remains scant, leaving gaps in our ability to capture complex urban flows and multimodal dynamics essential to achieving environmental sustainability goals. Moreover, the lack of a robust theoretical foundation and real-world operationalization of these tools hampers comprehensive modeling and practical adoption. This study introduces a pioneering Large Flow Model (LFM), grounded in a robust foundational framework and designed with GenAI capabilities. It is specifically tailored for integration into UDT systems to enhance predictive analytics, adaptive learning, and complex data management functionalities. To validate its applicability and relevance, the Blue City Project in Lausanne City is examined as a case study, showcasing the ability of the LFM to effectively model and analyze urban flows—namely mobility, goods, energy, waste, materials, and biodiversity—critical to advancing environmental sustainability. This study highlights how the LFM addresses the spatial challenges inherent in current UDT frameworks. The LFM demonstrates its novelty in comprehensive urban modeling and analysis by completing impartial city data, estimating flow data in new locations, predicting the evolution of flow data, and offering a holistic understanding of urban dynamics and their interconnections. The model enhances decision-making processes, supports evidence-based planning and design, fosters integrated development strategies, and enables the development of more efficient, resilient, and sustainable urban environments. This research advances both the theoretical and practical dimensions of AI-driven, environmentally sustainable urban development by operationalizing GenAI and FMs within UDT frameworks. It provides sophisticated tools and valuable insights for urban planners, designers, policymakers, and researchers to address the complexities of modern cities and accelerate the transition towards sustainable urban futures.}
}
@article{LEE2025104317,
title = {Readability, quality and accuracy of generative artificial intelligence chatbots for commonly asked questions about labor epidurals: a comparison of ChatGPT and Bard},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104317},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104317},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003297},
author = {D. Lee and M. Brown and J. Hammond and M. Zakowski},
keywords = {Labor analgesia, Epidural, Pregnancy, Generative Artificial Intelligence, Patient educational materials},
abstract = {Introduction
Over 90% of pregnant women and 76% expectant fathers search for pregnancy health information. We examined readability, accuracy and quality of answers to common obstetric anesthesia questions from the popular generative artificial intelligence (AI) chatbots ChatGPT and Bard.
Methods
Twenty questions for generative AI chatbots were derived from frequently asked questions based on professional society, hospital and consumer websites. ChatGPT and Bard were queried in November 2023. Answers were graded for accuracy by four obstetric anesthesiologists. Quality was measured using Patient Education Materials Assessment Tool for Print (PEMAT). Readability was measured using six readability indices. Accuracy, quality and readability were compared using independent t-test.
Results
Bard readability scores were high school level, significantly easier than ChatGPT’s college level by all scoring metrics (P <0.001). Bard had significantly longer answers (P <0.001), yet with similar accuracy of Bard (85% ± 10) and ChatGPT (87% ± 14) (P=0.5). PEMAT understandability scores were no statistically significantly different (P=0.06). Actionability by PEMAT scores for Bard was significantly higher (22% vs. 9%) than ChatGPT (P=0.007)
Conclusion
Answers to questions about “labor epidurals” should be accurate, high quality, and easy to read. Bard at high school reading level, was well above the goal 4th to 6th grade level suggested for patient materials. Consumers, health care providers, hospitals and governmental agencies should be aware of the quality of information generated by chatbots. Chatbots should meet the standards for readability and understandability of health-related questions, to aid public understanding and enhance shared decision-making.}
}
@article{WHEATLEY2024102942,
title = {Comparing generative artificial intelligence tools to voice assistants using reference interactions},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {5},
pages = {102942},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102942},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324001034},
author = {Amanda Wheatley and Sandy Hervieux},
keywords = {Artificial intelligence, Voice assistants, Generative AI, Reference},
abstract = {This study investigates the ability of voice assistants and generative AI tools to respond to reference questions traditionally received by academic librarians. The authors created a sample of 25 questions based on queries received on the virtual reference service at their institution. They then created a rubric to evaluate the quality of the answers that the AI powered tools provided. The authors determined that the tools understand reference questions well and provide relevant answers but that the quality of the references provided, and the accuracy of the answers can be lacking. They suggest that more research needs to be done to understand the place of AI powered tools in reference services.}
}
@article{SHEN2025102045,
title = {Fostering Undergraduates’ Critical Thinking in Digital Multimodal Composition with Generative Artificial Intelligence},
journal = {Thinking Skills and Creativity},
pages = {102045},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.102045},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125002937},
author = {Yanan Shen and Yanyan Han},
keywords = {Critical thinking, Generative artificial intelligence, Digital multimodal composition, Instructional design, Higher education},
abstract = {Fostering critical thinking (CT) in higher education has become increasingly pertinent and challenging in the era of generative artificial intelligence (GenAI). However, empirical studies on CT skill cultivation in GenAI-assisted learning are limited, especially in prevalent multimodal contexts. Integrating the CT skill framework and visual grammar, this qualitative case study developed a teaching module to foster undergraduates’ CT skills in GenAI-assisted digital multimodal composing (DMC), focusing on non-proficient AI users. It further explored four groups’ learning experiences in the classroom through students’ GenAI-assisted PowerPoint products, reflective writings, interviews, and design process observation. The findings revealed students’ more thoughtful scrutiny, comprehensive evaluation, and selective adoption of multimodal AIGC to achieve communicative purposes, with group variations and limitations in each dimension. This progress was facilitated by collaborative, revision-based DMC classwork with specifically defined, multi-dimensional requirements, systematic framework teaching, and real-time scaffolding. In conclusion, collaborative GenAI-assisted DMC practice with systematic instructional support can significantly foster students’ CT skill cultivation. These findings illuminate future pedagogical innovations to encourage deep learning and higher-order cognitive skills among a broader range of students in GenAI-assisted multimodal contexts.}
}
@article{MOTOKI2025106904,
title = {Assessing political bias and value misalignment in generative artificial intelligence},
journal = {Journal of Economic Behavior & Organization},
volume = {234},
pages = {106904},
year = {2025},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2025.106904},
url = {https://www.sciencedirect.com/science/article/pii/S0167268125000241},
author = {Fabio Y.S. Motoki and Valdemar {Pinho Neto} and Victor Rangel},
keywords = {Generative AI, Societal values, Large language models, Multimodal, AI governance},
abstract = {Our analysis reveals a concerning misalignment of values between ChatGPT and the average American. We also show that ChatGPT displays political leanings when generating text and images, but the degree and direction of skew depend on the theme. Notably, ChatGPT repeatedly refused to generate content representing certain mainstream perspectives, citing concerns over misinformation and bias. As generative AI systems like ChatGPT become ubiquitous, such misalignment with societal norms poses risks of distorting public discourse. Without proper safeguards, these systems threaten to exacerbate societal divides and depart from principles that underpin free societies.}
}
@article{BUI2025101392,
title = {Exploring value co-creation and co-destruction between consumers & generative artificial intelligence (GAI) in travel},
journal = {Tourism Management Perspectives},
volume = {58},
pages = {101392},
year = {2025},
issn = {2211-9736},
doi = {https://doi.org/10.1016/j.tmp.2025.101392},
url = {https://www.sciencedirect.com/science/article/pii/S2211973625000571},
author = {Hien Thu Bui and Viachaslau Filimonau and Hakan Sezerel},
keywords = {Emerging technology, Generative artificial intelligence, Travel assistance, Value co-creation, Value co-destruction, ChatGPT},
abstract = {Little is known about the (dis)benefits of using generative artificial intelligence (GAI) with travel-related purposes, which hinders an understanding of the value co-created and co-destructed in the process of its use by tourists. This mixed methods study explored and examined the key factors in value co-creation and co-destruction when using a popular GAI's conversational interface, ChatGPT, in tourism. The results indicate that the key perceived utility of ChatGPT is in travel planning and time saving, and the main perceived shortcomings are its limited knowledge and inaccurate responses. The study pinpoints the importance of refining and developing GAI collaboratively by all tourism stakeholders given that perceived value co-creation outweighs value co-destruction.}
}
@article{KAPLAN2025106080,
title = {New generative artificial intelligence model: ScholarGPT’s performance on dental avulsion},
journal = {International Journal of Medical Informatics},
volume = {204},
pages = {106080},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106080},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625002977},
author = {Taibe Tokgöz Kaplan},
keywords = {Artificial intelligence, ChatGPT, Dental avulsion, Gemini, Large Language Models, ScholarGPT},
abstract = {Background
This study aims to evaluate the performance of ScholarGPT, a Large Language Model (LLM) developed for academic purposes, on questions related to dental avulsion. In addition, to analyze and compare it with the results of the previous study evaluating the performance of ChatGPT and Gemini.
Method
A total of 22 technical questions (11 multiple-choice questions (MCQs), 11 true/false (T/F)) were posed to the ScholarGPT. ScholarGPT responses were assessed using a modified Global Quality Scale (GQS). Responses were randomized using an online randomizer (www.randomizer.org) before scoring. A single researcher carried out the assessments at three different times, two weeks apart, and a new randomization was performed before each scoring.
Results
When the answers given by ScholarGPT according to the question groups were analyzed by the Mann-Whitney U test, the mean value was found to be 4.64 for MCQ questions and 4.82 for T/F questions. ScholarGPT provided similarly high-quality and consistent answers in both question types (p = 0.590). When the performance of ScholarGPT was compared with Gemini and ChatGPT via the Friedman test, the mean score of ScholarGPT responses was significantly higher than both ChatGPT and Gemini (mean difference with Gemini = 0.75; mean difference with ChatGPT = 1.62, p < 0.001). ScholarGPT produced statistically significantly more consistent and higher-quality responses than ChatGPT and Gemini.
Conclusion
ScholarGPT showed high performance on technical questions related to dental avulsion and produced more consistent and higher-quality answers than ChatGPT and Gemini. According to the findings, LLMs based on academic databases can provide more accurate and reliable information. In the future, through the development of LLMs specific to the branches of dentistry, artificial intelligence systems can produce higher quality and consistent information.}
}
@article{CHEN2024104593,
title = {The revolution of generative artificial intelligence in psychology: The interweaving of behavior, consciousness, and ethics},
journal = {Acta Psychologica},
volume = {251},
pages = {104593},
year = {2024},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2024.104593},
url = {https://www.sciencedirect.com/science/article/pii/S0001691824004712},
author = {Dian Chen and Ying Liu and Yiting Guo and Yulin Zhang},
keywords = {Generative artificial intelligence, ChatGPT, Psychology, Natural language processing, Ethics},
abstract = {In recent years, there have been unparalleled prospects for psychological study due to the swift advancement of generative artificial intelligence (AI) in natural language processing, shown by ChatGPT. This review article looks into the uses and effects of generative artificial intelligence in psychology. We employed a systematic selection process, encompassing papers published between 2015 and 2024 from databases such as Google Scholar, PubMed, and IEEE Xplore, using keywords like “Generative AI in psychology” “ChatGPT and behavior modeling” and “AI in mental health”. First, the paper goes over the fundamental ideas of generative AI and lists its uses in data analysis, behavior modeling, and social interaction simulation. A detailed comparison table has been added to contrast conventional research methodologies with GenAI-based approaches in psychology studies. Next, analyzing the theoretical and ethical issues that generative AI raises for psychological research, it highlights how crucial it is to develop a coherent theoretical framework. This study illustrates the benefits of generative AI in handling vast amounts of data and increasing research efficiency by contrasting traditional research methods with AI-driven methodologies. Regarding particular uses, the study explores how generative AI might be used to simulate social interactions, analyze massive amounts of text, and learn about cognitive processes. Section 5 has been expanded to include discussions on political biases, geographic biases, and other biases. In conclusion, the paper looks forward to the future development of generative AI in psychology research and suggests techniques for improving it. We have included methodological solutions such as the Retrieval Augmented Generation (RAG) approach and human-in-the-loop systems, as well as data privacy solutions like open-source local LLMs. In summary, generative AI has the potential to revolutionize psychological research, but in order to maintain the moral and scientific integrity of the field, ethical and theoretical concerns must be carefully considered before applying the technology.}
}
@article{CAMPELLONE2025,
title = {Safety and User Experience of a Generative Artificial Intelligence Digital Mental Health Intervention: Exploratory Randomized Controlled Trial},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67365},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125007381},
author = {Timothy R Campellone and Megan Flom and Robert M Montgomery and Lauren Bullard and Maddison C Pirner and Aaron Pavez and Michelle Morales and Devin Harper and Catherine Oddy and Tom O'Connor and Jade Daniels and Stephanie Eaneff and Valerie L Forman-Hoffman and Casey Sackett and Alison Darcy},
keywords = {generative AI, digital mental health intervention, user experience, RCT, randomized, controlled trials, randomized controlled trial, chatbots, artificial intelligence, AI, user relationship, user satisfaction, user safety, user, exploratory, relationship, satisfaction, safety, generative, DMHI, mental health, digital health},
abstract = {Background
General awareness and exposure to generative artificial intelligence (AI) have increased recently. This transformative technology has the potential to create a more dynamic and engaging user experience in digital mental health interventions (DMHIs). However, if not appropriately used and controlled, it can introduce risks to users that may result in harm and erode trust. At the time of conducting this trial, there had not been a rigorous evaluation of an approach to safely implementing generative AI in a DMHI.
Objective
This study aims to explore the user relationship, experience, safety, and technical guardrails of a DMHI using generative AI compared with a rules-based intervention.
Methods
We conducted a 2-week exploratory randomized controlled trial (RCT) with 160 adult participants randomized to receive a generative AI (n=81) or rules-based (n=79) version of a conversation-based DMHI. Self-report measures of the user relationship (client satisfaction, working alliance bond, and accuracy of empathic listening and reflection) and experience (engagement metrics, adverse events, and technical guardrail success) were collected. Descriptions and validation of technical guardrails for handling user inputs (eg, detecting potentially concerning language and off-topic responses) and model outputs (eg, not providing medical advice and not providing a diagnosis) are provided, along with examples to illustrate how they worked. Safety monitoring was conducted throughout the trial for adverse events, and the success of technical guardrails created for the generative arm was assessed post trial.
Results
In general, the majority of measures of user relationship and experience appeared to be similar in both the generative and rules-based arms. The generative arm appeared to be more accurate at detecting and responding to user statements with empathy (98% accuracy vs 69%). There were no serious or device-related adverse events, and technical guardrails were shown to be 100% successful in posttrial review of generated statements. A majority of participants in both groups reported an increase in positive sentiment (62% and 66%) about AI at the end of the trial.
Conclusions
This trial provides initial evidence that, with the right guardrails and process, generative AI can be successfully used in a digital mental health intervention (DMHI) while maintaining the user experience and relationship. It also provides an initial blueprint for approaches to technical and conversational guardrails that can be replicated to build a safe DMHI.
Trial Registration
ClinicalTrials.gov NCT05948670; https://clinicaltrials.gov/study/NCT05948670}
}
@article{NG2025101222,
title = {Prompt engineering for generative artificial intelligence chatbots in health research: A practical guide for traditional, complementary, and integrative medicine researchers},
journal = {Integrative Medicine Research},
volume = {14},
number = {4},
pages = {101222},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101222},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025001027},
author = {Jeremy Y. Ng},
keywords = {AI chatbots, Prompt engineering, Large language models, Generative artificial intelligence},
abstract = {Generative artificial intelligence (GenAI) chatbots powered by large language models (LLMs) are increasingly used in health research to support a range of academic and clinical activities. While increasingly adopted in biomedical research, their application in traditional, complementary, and integrative medicine (TCIM) remains underexplored. TCIM presents unique challenges, including complex interventions, culturally embedded practices, and variable terminology. This article provides a practical, evidence-informed guide to help TCIM researchers engage responsibly with GenAI chatbots through prompt engineering, the design of clear, structured, and purposeful prompts to improve output relevance and accuracy. The guide outlines strategies to tailor GenAI chatbot interactions to the methodological and epistemological diversity of TCIM. It presents use cases across the research process, including research question development, study design, literature searches, selection of reporting guidelines and appraisal tools, quantitative and qualitative analysis, writing and dissemination, and implementation planning. For each stage, the guide offers examples and best practices while emphasizing that AI-generated content should always serve as a starting point, not a final product, and must be reviewed and verified using credible sources. Potential risks such as hallucinated outputs, embedded bias, and ethical challenges are discussed, particularly in culturally sensitive contexts. Transparency in GenAI chatbot use and researcher accountability are emphasized as essential principles. While GenAI chatbots can expand access to research support and foster innovation in TCIM, they cannot substitute for critical thinking, methodological rigour, or domain-specific expertise. Used responsibly, GenAI chatbots can augment human judgment and contribute meaningfully to the evolution of TCIM scholarship.}
}
@article{BARAKCORREN2025102242,
title = {From Text to Data: Automatically Extracting Data From Catheterization Reports Using Generative Artificial Intelligence},
journal = {Journal of the Society for Cardiovascular Angiography & Interventions},
volume = {4},
number = {3, Part B},
pages = {102242},
year = {2025},
note = {The Role of Artificial Intelligence in Cardiovascular Interventions},
issn = {2772-9303},
doi = {https://doi.org/10.1016/j.jscai.2024.102242},
url = {https://www.sciencedirect.com/science/article/pii/S2772930324016247},
author = {Yuval Barak-Corren and Mudit Gupta and Jessica Tang and Christopher L. Smith and Ryan Callahan and Yoav Dori and Jonathan J. Rome and Matthew J. Gillespie and Michael L. O’Byrne},
keywords = {artificial intelligence, generative artificial intelligence, health informatics, interventional cardiology, natural language processing, pediatric cardiology}
}
@article{SOLORZANOREQUEJO2024102157,
title = {Fostering creativity in engineering design through constructive dialogues with generative artificial intelligence},
journal = {Cell Reports Physical Science},
volume = {5},
number = {9},
pages = {102157},
year = {2024},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2024.102157},
url = {https://www.sciencedirect.com/science/article/pii/S2666386424004429},
author = {William {Solórzano Requejo} and Francisco {Franco Martínez} and Carlos {Aguilar Vega} and Rodrigo {Zapata Martínez} and Adrián {Martínez Cendrero} and Andrés {Díaz Lantada}},
keywords = {artificial intelligence, engineering design, creativity promotion, biohybrid materials, medical devices, product design, architected materials: architectural structures},
abstract = {Summary
Artificial intelligence (AI) is progressively reshaping the way that researchers design and study highly complex systems. In this perspective, we introduce an engineering design methodology aimed at fostering creativity through “constructive dialogues with a generative AI” and exemplify its potential through a set of methodically developed case studies. This creativity promotion approach starts with computer-aided design (CAD) models of lattices, metamaterials, and architected materials, which are provided as initial inputs to a generative AI through a chat. Then, the conversation starts with researchers asking the generative AI to modify the provided CAD model images by incorporating new elements, placing them in quasi-real-life environments, or adapting the provided designs to the structures of new products. To illustrate the methodology, a varied set of selected case studies of constructive dialogues leading to highly innovative designs are provided, bridging the gap between tissue engineering scaffolds and building architectures, biohybrid materials and product design, and innovative structures and medical devices, to cite a few.}
}
@article{MESSER2025100108,
title = {How do people react to political bias in generative artificial intelligence (AI)?},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100108},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100108},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000689},
author = {Uwe Messer},
keywords = {Artificial intelligence, Alignment, Political orientation, Bias, Acceptance, Large language model},
abstract = {Generative Artificial Intelligence (GAI) such as Large Language Models (LLMs) have a concerning tendency to generate politically biased content. This is a challenge, as the emergence of GAI meets politically polarized societies. Therefore, this research investigates how people react to biased GAI-content based on their pre-existing political beliefs and how this influences the acceptance of GAI. In three experiments (N = 513), it was found that perceived alignment between user's political orientation and bias in generated content (in text and images) increases acceptance and reliance on GAI. Participants who perceived alignment were more likely to grant GAI access to sensitive smartphone functions and to endorse the use in critical domains (e.g., loan approval; social media moderation). Because users see GAI as a social actor, they consider perceived alignment as a sign of greater objectivity, thus granting aligned GAI access to more sensitive areas.}
}
@article{CURRIE2025103,
title = {Gender bias in text-to-image generative artificial intelligence depiction of Australian paramedics and first responders},
journal = {Australasian Emergency Care},
volume = {28},
number = {2},
pages = {103-109},
year = {2025},
issn = {2588-994X},
doi = {https://doi.org/10.1016/j.auec.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S2588994X24000757},
author = {Geoffrey Currie and Johnathan Hewis and Phillip Ebbs},
keywords = {First responder, Generative artificial intelligence, Diversity, Inclusivity},
abstract = {Introduction
In Australia, almost 50 % of paramedics are female yet they remain under-represented in stereotypical depictions of the profession. The potentially transformative value of generative artificial intelligence (AI) may be limited by stereotypical errors, misrepresentations and bias. Increasing use of text-to-image generative AI, like DALL-E 3, could reinforce gender and ethnicity biases and, therefore, is important to objectively evaluate.
Method
In March 2024, DALL-E 3 was utilised via GPT-4 to generate a series of individual and group images of Australian paramedics, ambulance officers, police officers and firefighters. In total, 82 images were produced including 60 individual-character images, and 22 multiple-character group images. All 326 depicted characters were independently analysed by three reviewers for apparent gender, age, skin tone and ethnicity.
Results
Among first responders, 90.8 % (N = 296) were depicted as male, 90.5 % (N = 295) as Caucasian, 95.7 % (N = 312) as a light skin tone, and 94.8 % (N = 309) as under 55 years of age. For paramedics and police the gender distribution was a statistically significant variation from that of actual Australian workforce data (all p < 0.001). Among the images of individual paramedics and ambulance officers (N = 32), DALL-E 3 depicted 100 % as male, 100 % as Caucasian and 100 % with light skin tone.
Conclusion
Gender and ethnicity bias is a significant limitation for text-to-image generative AI using DALL-E 3 among Australian first responders. Generated images have a disproportionately high misrepresentation of males, Caucasians and light skin tones that are not representative of the diversity of paramedics in Australia today.}
}
@article{GARCIAMORENO2025113415,
title = {Artificial intelligence-aided generative design of non-imaging secondary reflector for linear Fresnel concentrating collector},
journal = {Solar Energy},
volume = {292},
pages = {113415},
year = {2025},
issn = {0038-092X},
doi = {https://doi.org/10.1016/j.solener.2025.113415},
url = {https://www.sciencedirect.com/science/article/pii/S0038092X25001781},
author = {Jorge Moreno García-Moreno and Alaric Christian Montenon and Mihalis A. Nicolaou and Wojciech Lipiński and Kypros Milidonis},
keywords = {Concentrated solar thermal, Non-imaging optics, Linear Fresnel reflector, Artificial intelligence, Generative design, NSGA-II},
abstract = {In this article, an AI-aided generative design workflow is presented for the geometrical optimisation of secondary reflectors of linear Fresnel concentrating collectors. The geometry of the secondary reflector is based on principles of non-imaging optics, for which the exact analytical solution is derived for a specific linear Fresnel system acting as a validation test case. The artificial intelligence-aided generative design workflow is then applied on the same system and the optimal geometry generated is compared against the analytical solution. It is shown that the secondary reflector geometry obtained from the artificial intelligence-aided generative design workflow approaches the shape of the one obtained using the analytical solution and can outperform the latter with respect to the magnitude of radiative power intercepted by the receiver and radiative flux distribution at the receiver aperture.}
}
@article{COHEN2025111646,
title = {Generative artificial intelligence and academic writing: friend or foe?},
journal = {Journal of Clinical Epidemiology},
volume = {179},
pages = {111646},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111646},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624004025},
author = {Jérémie F. Cohen and David Moher},
keywords = {Artificial Intelligence, Large language models, Medical writing, Publication ethics, Research ethics, Research integrity},
abstract = {This viewpoint examines the use of generative AI models in medical writing, discusses the opportunities and threats they represent, and highlights avenues for improvement and future research.}
}
@article{HIROSAWA2025,
title = {Utility of Generative Artificial Intelligence for Japanese Medical Interview Training: Randomized Crossover Pilot Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/77332},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000996},
author = {Takanobu Hirosawa and Masashi Yokose and Tetsu Sakamoto and Yukinori Harada and Kazuki Tokumasu and Kazuya Mizuta and Taro Shimizu},
keywords = {artificial intelligence, generative artificial intelligence, medical interview training, mock patient, simulation education},
abstract = {Background
The medical interview remains a cornerstone of clinical training. There is growing interest in applying generative artificial intelligence (AI) in medical education, including medical interview training. However, its utility in culturally and linguistically specific contexts, including Japanese, remains underexplored. This study investigated the utility of generative AI for Japanese medical interview training.
Objective
This pilot study aimed to evaluate the utility of generative AI as a tool for medical interview training by comparing its performance with that of traditional face-to-face training methods using a simulated patient.
Methods
We conducted a randomized crossover pilot study involving 20 postgraduate year 1‐2 physicians from a university hospital. Participants were randomly allocated into 2 groups. Group A began with an AI-based station on a case involving abdominal pain, followed by a traditional station with a standardized patient presenting chest pain. Group B followed the reverse order, starting with the traditional station for abdominal pain and subsequently within the AI-based station for the chest pain scenario. In the AI-based stations, participants interacted with a GPT-configured platform that simulated patient behaviors. GPTs are customizable versions of ChatGPT adapted for specific purposes. The traditional stations involved face-to-face interviews with a simulated patient. Both groups used identical, standardized case scenarios to ensure uniformity. Two independent evaluators, blinded to the study conditions, assessed participants’ performances using 6 defined metrics: patient care and communication, history taking, physical examination, accuracy and clarity of transcription, clinical reasoning, and patient management. A 6-point Likert scale was used for scoring. The discrepancy between the evaluators was resolved through discussion. To ensure cultural and linguistic authenticity, all interviews and evaluations were conducted in Japanese.
Results
AI-based stations scored lower across most categories, particularly in patient care and communication, than traditional stations (4.48 vs 4.95; P=.009). However, AI-based stations demonstrated comparable performance in clinical reasoning, with a nonsignificant difference (4.43 vs 4.85; P=.10).
Conclusions
The comparable performance of generative AI in clinical reasoning highlights its potential as a complementary tool in medical interview training. One of its main advantages lies in enabling self-learning, allowing trainees to independently practice interviews without the need for simulated patients. Nonetheless, the lower scores in patient care and communication underline the importance of maintaining traditional methods that capture the nuances of human interaction. These findings support the adoption of hybrid training models that combine generative AI with conventional approaches to enhance the overall effectiveness of medical interview training in Japan.
Trial Registration
UMIN-CTR UMIN000053747; https://center6.umin.ac.jp/cgi-open-bin/ctr_e/ctr_view.cgi?recptno=R000061336}
}
@article{REASON2025,
title = {The “Artificial Intelligence Statistician”: Utilizing Generative Artificial Intelligence to Select an Appropriate Model and Execute Network Meta-Analyses},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525025112},
author = {Tim Reason and Yunchou Wu and Cheryl Jones and Emma Benbow and Kasper Johannesen and Bill Malcolm},
keywords = {automated analysis, health technology assessment (HTA), joint clinical assessments (JCAs), large language models (LLMs), network meta-analysis (NMA)},
abstract = {Objectives
This exploratory study aimed to develop a large language model (LLM)-based process to automate components of network meta-analysis (NMA), including model selection, analysis, output evaluation, and results interpretation. Automating these tasks with LLMs can enhance efficiency, consistency, and scalability in health economics and outcomes research, while ensuring that analyses adhere to established guidelines required by health technology assessment agencies. Improvements in efficiency and scalability may potentially become relevant as the European Union Health Technology Assessment Regulation comes into force, given anticipated analysis requirements and timelines.
Methods
Using Claude 3.5 Sonnet (V2), a process was designed to automate statistical model selection, NMA output evaluation, and results interpretation based on an “analysis-ready” data set. Validation was assessed by replicating examples from the National Institute for Health and Care Excellence Technical Support Document (TSD2), replicating results of non-Decision Support Unit-published NMAs, and generating comprehensive outputs (eg, heterogeneity, inconsistency, and convergence).
Results
The automated LLM-based process produced accurate results. Compared with TSD2 examples, differences were minimal, within expectations (given differences in sampling frameworks used), and comparable to those observed between estimates produced by the R vignettes against TSD2. Similar consistency was noted for non-Decision Support Unit-published NMA examples. Additionally, the LLM process generated and interpreted comprehensive NMA outputs.
Conclusions
This exploratory study demonstrates the feasibility of LLMs to automate key components of NMAs, determining the requisite NMA framework based only on input data. Further exploring these capabilities could clarify their role in streamlining NMA workflows.}
}
@article{KIM2025125873,
title = {A physics-driven generative model to accelerate artificial intelligence development for lithium-ion battery diagnostics},
journal = {Applied Energy},
volume = {391},
pages = {125873},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2025.125873},
url = {https://www.sciencedirect.com/science/article/pii/S0306261925006038},
author = {Joonhee Kim and Hyosik Moon and Kwanwoong Yoon and Huiyong Chun and Myeongjae Lee and Jeongsik Ko and Soohee Han},
keywords = {Artificial intelligence, Battery diagnosis, Data augmentation, Electrochemical model, Generative model, Lithium-ion battery, Synthetic data},
abstract = {Recent advancements in artificial intelligence (AI) have highlighted the potential of extensive battery cycle data for diagnosing performance degradation in lithium-ion batteries (LIBs). Therefore, related generative models have been developed to rapidly generate a variety of battery data from a small number of real-world experimental measurements. This study proposes a physics-driven generative model (PGM) to produce realistic battery cycle data by reasonably sampling electrochemical parameters in a stochastic manner. PGM captured the fundamental principles of LIBs as electrochemical parameter distributions and then generated the corresponding virtual LIBs, even under conditions that have not been previously applied. This superior generalizable capability was validated by showing that PGM was very effective in detecting the internal short circuits (ISCs) of LIBs. Synthetic data with different ISC degree effects were generated using PGM based only on ISC-free LIBs. The results showed that a neural network trained on the generated synthetic data achieved a detection accuracy of 97.39 % for real physical ISCs, which was comparable to the detection results of a neural network trained using approximately 25 times more real data, including experimental results with ISCs. The proposed PGM is expected to contribute significantly to the rapid advancement of AI-based LIB diagnostics by generating physically meaningful data based on internal electrochemical principles.}
}
@article{RASHIDI2025100687,
title = {Generative Artificial Intelligence in Pathology and Medicine: A Deeper Dive},
journal = {Modern Pathology},
volume = {38},
number = {4},
pages = {100687},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100687},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002679},
author = {Hooman H. Rashidi and Joshua Pantanowitz and Alireza Chamanzar and Brandon Fennell and Yanshan Wang and Rama R. Gullapalli and Ahmad Tafti and Mustafa Deebajah and Samer Albahra and Eric Glassy and Matthew G. Hanna and Liron Pantanowitz},
keywords = {ChatGPT, diffusion, generative adversarial network, generative artificial intelligence, generative pretrained transformer, multiagent},
abstract = {This review article builds upon the introductory piece in our 7-part series, delving deeper into the transformative potential of generative artificial intelligence (Gen AI) in pathology and medicine. The article explores the applications of Gen AI models in pathology and medicine, including the use of custom chatbots for diagnostic report generation, synthetic image synthesis for training new models, data set augmentation, hypothetical scenario generation for educational purposes, and the use of multimodal along with multiagent models. This article also provides an overview of the common categories within Gen AI models, discussing open-source and closed-source models, as well as specific examples of popular models such as GPT-4, Llama, Mistral, DALL-E, Stable Diffusion, and their associated frameworks (eg, transformers, generative adversarial networks, diffusion-based neural networks), along with their limitations and challenges, especially within the medical domain. We also review common libraries and tools that are currently deemed necessary to build and integrate such models. Finally, we look to the future, discussing the potential impact of Gen AI on health care, including benefits, challenges, and concerns related to privacy, bias, ethics, application programming interface costs, and security measures.}
}
@article{KHANIFAR2025100069,
title = {Generative artificial intelligence in soil science},
journal = {Soil Advances},
volume = {4},
pages = {100069},
year = {2025},
issn = {2950-2896},
doi = {https://doi.org/10.1016/j.soilad.2025.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2950289625000375},
author = {Javad Khanifar}
}
@article{DUAN2025103719,
title = {The transformative roles of generative artificial intelligence in vision techniques for structural health monitoring: A state-of-the-art review},
journal = {Advanced Engineering Informatics},
volume = {68},
pages = {103719},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103719},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625006123},
author = {Shundi Duan and Xiao Tan and Pengwei Guo and Yurong Guo and Yi Bao},
keywords = {Generative artificial intelligence, Structural health monitoring, Image restoration, Data augmentation, Multi-modal generative AI, Large language model},
abstract = {As urbanization accelerates, aging infrastructure demands more advanced inspection methods for structural health monitoring. The growing integration of artificial intelligence (AI) and computer vision technologies has significantly enhanced damage detection accuracy while simultaneously reducing inspection time and operational costs. Despite these advantages, the adoption of AI-based technologies in infrastructure maintenance remains limited due to challenges related to data. One major issue is the lack of comprehensive, task-specific annotated datasets. Another is the poor quality of images captured by drones or mobile devices, which are often affected by noise, blurring, and inconsistent lighting. Although recent advances in generative AI offer promising support for structural health monitoring, it remains unclear which models are best suited for specific tasks. This study examines the use of generative AI in structural health monitoring, focusing on key challenges such as limited datasets and low-quality image restoration. The review covers a range of generative AI technologies, outlining their principles, strengths, limitations, and representative applications to support the selection of appropriate tools for specific tasks. Generative AI models enable accurate image segmentation and structural anomaly detection using limited training data. The paper also explores new opportunities for integrating multi-modal generative AI to enhance human–computer interaction in support of structural health monitoring. A framework is proposed to streamline the use of generative AI technologies for data augmentation, image restoration, damage inspection, and human–computer interaction in structural health monitoring.}
}
@article{FLEURENCE2025175,
title = {Generative Artificial Intelligence for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations: An ISPOR Working Group Report},
journal = {Value in Health},
volume = {28},
number = {2},
pages = {175-183},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.3846},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524067548},
author = {Rachael L. Fleurence and Jiang Bian and Xiaoyan Wang and Hua Xu and Dalia Dawoud and Mitchell Higashi and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic modeling methods, generative AI, large language models, real world evidence, systematic reviews},
abstract = {Objectives
To provide an introduction to the uses of generative artificial intelligence (AI) and foundation models, including large language models, in the field of health technology assessment (HTA).
Methods
We reviewed applications of generative AI in 3 areas: systematic literature reviews, real-world evidence, and health economic modeling.
Results
(1) Literature reviews: generative AI has the potential to assist in automating aspects of systematic literature reviews by proposing search terms, screening abstracts, extracting data, and generating code for meta-analyses; (2) real-world evidence: generative AI can facilitate automating processes and analyze large collections of real-world data, including unstructured clinical notes and imaging; (3) health economic modeling: generative AI can aid in the development of health economic models, from conceptualization to validation. Limitations in the use of foundation models and large language models include challenges surrounding their scientific rigor and reliability, the potential for bias, implications for equity, as well as nontrivial concerns regarding adherence to regulatory and ethical standards, particularly in terms of data privacy and security. Additionally, we survey the current policy landscape and provide suggestions for HTA agencies on responsibly integrating generative AI into their workflows, emphasizing the importance of human oversight and the fast-evolving nature of these tools.
Conclusions
Although generative AI technology holds promise with respect to HTA applications, it is still undergoing rapid developments and improvements. Continued careful evaluation of their applications to HTA is required. Both developers and users of research incorporating these tools, should familiarize themselves with their current capabilities and limitations.}
}
@article{TADOKORO2025663,
title = {On the effective co-creation of CAD models by leveraging generative artificial intelligence},
journal = {Procedia CIRP},
volume = {134},
pages = {663-668},
year = {2025},
note = {58th CIRP Conference on Manufacturing Systems 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.02.181},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125005608},
author = {Fuwa Tadokoro and Angkush Kumar Ghosh and Sharifu Ura},
keywords = {Computer-Aided Design, Generative Artificial Intelligence, Co-creation, Prompt Tuning, Modular Decomposition, Information, Complexity},
abstract = {Collaboration between humans and generative artificial intelligence (GenAI) can result in effective problem-solving methods for smart manufacturing. From this point of view, this study presents how to solve computer-aided design (CAD) problems using GenAI-human collaboration, where a GenAI tool generates structured code (syntax) for CAD while a designer articulates the design intent (semantics). The focus is to see how the information type, model complexity, and prompt structure collectively affect the collaboration. A set of case studies demonstrate that a modular modeling approach with low-level information improves prompt efficiency and modeling accuracy, especially in complex scenarios. This strategy also enables novice and expert users to collaborate with GenAI in solving challenging real-world CAD tasks effectively. The findings support the development of advanced human-AI co-creation systems and encourage future research in areas such as reverse engineering, multi-part assemblies, and collaborative CAD workflows coupled with complex design constraints.}
}
@article{CHENG2025101497,
title = {Online reviews generated by generative artificial intelligence versus human: A study of perceived differences and user adoption behavior},
journal = {Electronic Commerce Research and Applications},
volume = {71},
pages = {101497},
year = {2025},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2025.101497},
url = {https://www.sciencedirect.com/science/article/pii/S1567422325000225},
author = {Xusen Cheng and Ang Zeng and Bo Yang and Yu Liu and Xiaoping Zhang},
keywords = {generative artificial intelligence (GAI), GAI-generated reviews, human-generated reviews, willingness to use GAI},
abstract = {Companies in various industries are attempting to integrate Generative Artificial Intelligence (GAI) into their existing businesses. In the e-commerce domain, GAI has shown tremendous potential in generating online reviews. However, existing literature has paid less attention to how consumers respond to GAI-generated reviews versus human-generated reviews. Moreover, little research has explored whether and why consumers are willing to use GAI to generate online reviews. By conducting two experiments, this study investigates how consumers respond differently to GAI-generated reviews versus human-generated reviews and identifies potential factors that influence consumers’ willingness to use GAI to generate reviews. Findings indicate that although there is no significant difference in consumers’ perceptions between human-generated and GAI-generated reviews in terms of review credibility, review richness, and review usefulness, only half of the participants are willing to use GAI to generate reviews. Further analysis results suggest that individuals who consider GAI unethical tend to avoid using GAI. Those with high personal innovativeness are more willing to use GAI to generate online reviews. Our findings deepen the understanding of consumer attitudes toward GAI-generated reviews and provide implications for the deployment of GAI in the online review system.}
}
@article{DEEB20241724,
title = {The emerging role of generative artificial intelligence in transplant medicine},
journal = {American Journal of Transplantation},
volume = {24},
number = {10},
pages = {1724-1730},
year = {2024},
issn = {1600-6135},
doi = {https://doi.org/10.1016/j.ajt.2024.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1600613524003824},
author = {Maya Deeb and Anirudh Gangadhar and Madhumitha Rabindranath and Khyathi Rao and Michael Brudno and Aman Sidhu and Bo Wang and Mamatha Bhat},
keywords = {artificial intelligence, deep learning, generative adversarial networks, large language models, machine learning, natural language processing, variational autoencoders},
abstract = {Generative artificial intelligence (AI), a subset of machine learning that creates new content based on training data, has witnessed tremendous advances in recent years. Practical applications have been identified in health care in general, and there is significant opportunity in transplant medicine for generative AI to simplify tasks in research, medical education, and clinical practice. In addition, patients stand to benefit from patient education that is more readily provided by generative AI applications. This review aims to catalyze the development and adoption of generative AI in transplantation by introducing basic AI and generative AI concepts to the transplant clinician and summarizing its current and potential applications within the field. We provide an overview of applications to the clinician, researcher, educator, and patient. We also highlight the challenges involved in bringing these applications to the bedside and need for ongoing refinement of generative AI applications to sustainably augment the transplantation field.}
}
@article{GAO2024173,
title = {Adoption and impact of generative artificial intelligence on blockchain-enabled supply chain efficiency},
journal = {Journal of Systems and Information Technology},
volume = {27},
number = {2},
pages = {173-196},
year = {2024},
issn = {1328-7265},
doi = {https://doi.org/10.1108/JSIT-04-2024-0143},
url = {https://www.sciencedirect.com/science/article/pii/S1328726524000053},
author = {Cong Gao and Kay-Hooi Keoy and Ai-Fen Lim},
keywords = {Generative artificial intelligence, Blockchain, Supply chain efficiency, Innovation diffusion theory, Sustainability development goals, SDG 9 – Industrial growth and industrial diversification},
abstract = {Purpose
The purpose of this study is to investigate the primary determinants influencing the acceptance of generative artificial intelligence (GAI) adoption within Blockchain-enabled environments. Further research will examine the impact of GAI adoption on supply chain efficiency (SCE) through the enhancement of Blockchain.
Design/methodology/approach
Drawing on innovation diffusion theory (IDT), this study used partial least square structural equation modelling (PLS-SEM) to look into the hypotheses. The data were gathered via online questionnaires from employers of Chinese supply chain enterprises that have already integrated Blockchain.
Findings
The findings of this study demonstrate that relative advantages (RAs), compatibility, trialability and observability have a significant positive effect on GAI adoption, while complexity harms GAI adoption. Above all, the GAI adoption has significantly enhanced Blockchain, thus effectively improving SCE.
Practical implications
The outcomes from this study furnish enterprises and organizations with valuable insights to proficiently integrate GAI and Blockchain capability, optimize supply chain management and bolster market competitiveness. Also, this study will help accelerate the successful integration of business processes and attain Sustainability Development Goals 9, industrial growth and industrial diversification.
Originality/value
To the extent of the author’s knowledge, the current status of the GAI study remains largely exploratory, and there is limited empirical evidence on integrating Blockchain capability and GAI. This research bridges the knowledge gap by fully revealing the optimal integration of these two transformative technologies to leverage their potential advantages in supply chain management.}
}
@article{PARK2024428,
title = {Generative artificial intelligence in nursing: A scoping review},
journal = {Collegian},
volume = {31},
number = {6},
pages = {428-436},
year = {2024},
issn = {1322-7696},
doi = {https://doi.org/10.1016/j.colegn.2024.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1322769624000696},
author = {Ga Eun Park and Hyeryeon Kim and U Ri Go},
keywords = {Generative artificial intelligence, Artificial intelligence, ChatGPT, Nursing, Nurses, Healthcare, Machine learning},
abstract = {ABSTRACT
Background
Generative artificial intelligence (AI) is rapidly transforming multiple sectors, with significant potential to revolutionise nursing through advancements in education, practice, and research. However, the application of generative AI in nursing remains underexplored, highlighting the need for a comprehensive review of its current impact and future implications.
Aim
To investigate the current state and implications of generative AI in nursing education, practice, and research.
Methods
This scoping review was conducted following the methodological frameworks of Arksey and O’Malley, refined by Levac and colleagues. The databases searched for articles published between January 2020 and April 2024 included PubMed, Embase, CINAHL, PsycINFO, Cochrane Library, and IEEE Xplore.
Findings
A total of 4858 articles were identified, with 23 included in this review. Most of the selected studies were published in 2024 (n = 19/23), primarily conducted in the United States (n = 8/23), and largely consisted of quantitative descriptive studies (n = 14/22). ChatGPT was the most frequently used tool, appearing in 95.7% of the studies (n = 22/23). The articles addressed various nursing domains, including nursing education (n = 12/23), practice (n = 10/23), and research (n = 1/23). Both the benefits and concerns associated with this technology were identified.
Discussion
Generative AI shows great promise for transforming nursing education, practice, and research; however, its integration is still in the early stages.
Conclusion
To fully leverage the benefits of generative AI, nursing professionals must address the challenges associated with AI and lead its ethical adoption. Rigorous research and proactive leadership are crucial to realising the potential of generative AI in nursing.}
}
@article{ALBUSAIDI2024100630,
title = {Redefining boundaries in innovation and knowledge domains: Investigating the impact of generative artificial intelligence on copyright and intellectual property rights},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {4},
pages = {100630},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100630},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24001690},
author = {Adil S. Al-Busaidi and Raghu Raman and Laurie Hughes and Mousa Ahmed Albashrawi and Tegwen Malik and Yogesh K. Dwivedi and Thuraiya {Al- Alawi} and Mohammed AlRizeiqi and Gareth Davies and Mark Fenwick and Parul Gupta and Shashikala Gurpur and Apeksha Hooda and Paulius Jurcys and Daryl Lim and Nicola Lucchi and Tanvi Misra and Ramakrishnan Raman and Anuragini Shirish and Paul Walton},
keywords = {ChatGPT, Generative artificial intelligence, GenAI, Generative scholar, Innovation, Intellectual property (IP) Risks, Large language models (LLMs), Misuse case analysis, Personality rights},
abstract = {The rapid integration of generative AI (GenAI) into industries and society has prompted a re-evaluation of copyright and intellectual property rights (IPR) frameworks. GenAI's ability to produce original content using data from human-created sources raises critical ethical and legal concerns. Current copyright and IPR frameworks, designed around human authorship, are insufficient to address these challenges. This study, using a multi-perspective approach, explores GenAI's disruptive potential in replicating or transforming copyrighted materials, challenging established IPR norms. Findings highlight gaps in legislation and the opacity of GenAI platforms. To address these issues, this study presents a Dynamic Ethical Framework linked to a future global fair use policy, aiming to guide responsible GenAI development and use. By incorporating insights from domain experts, this study contextualizes emerging challenges and potential solutions within broader societal and technological trends. That said, this study calls for international collaboration and further research to reform IPR related laws and frameworks, ensuring they remain relevant and equitable in a GenAI-driven era.}
}
@incollection{CHOUDHURY202665,
title = {Chapter 4 - Applications of artificial intelligence and generative artificial intelligence in digital healthcare ecosystem},
editor = {Alex Khang},
booktitle = {Revolutionizing Digital Healthcare Through Artificial Intelligence and Automation},
publisher = {Academic Press},
pages = {65-82},
year = {2026},
isbn = {978-0-443-36434-1},
doi = {https://doi.org/10.1016/B978-0-443-36434-1.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443364341000082},
author = {Rajashri Roy Choudhury and Piyal Roy},
keywords = {Blockchain, Data ownership, Electronic health records, GAN, Generative AI, Internet of things, Large language models, Virtual AI},
abstract = {There have been some significant advancements in communication and information technologies that have contributed to the rapid proliferation of this digital health ecosystem. One of the primary drivers behind this push for ultralow-power is Artificial Intelligence (AI) because it essentially supports autonomous decision-making capabilities for healthcare devices, outside the control of humans. This chapter reveals the synergy of AI in elderly care with examples from Asia, deliberates on technology as an enabler of healthcare solutions and via these freshness air examines ways to cater to age-related problems contributing toward a sustainable inclusive healthcare system. This chapter examines implications of data ownership and AI integration within digital healthcare, commenting on commercialization and privacy ethics. While AI has promise in using data to improve the diagnosis and treatment of patients, issues related to bias and algorithmic transparency must be addressed. Although illustrations as, for example, discriminatory effects demonstrated by the use of generative adversarial networks in medical imaging highlight that AI is more than useful, there are fair outcomes in health still to be achieved. We also take a look at the role that generative AI and large language models (GenAI, LLMs) can have on healthcare. Yet, as innovations capable of transformation continue to develop; so, does the concern around ethics and security. This chapter describes the ever-nascent applications of GenAI LLMs on bettering healthcare delivery and accessibility. This covers use cases in medical imaging, drug discovery and personalized care: alongside challenges such as data bias and integration difficulty.}
}
@article{LIU20251202,
title = {Environmental Assessment and Improvement of Factory Building Designs based on Generative Artificial Intelligence},
journal = {Procedia CIRP},
volume = {135},
pages = {1202-1207},
year = {2025},
note = {32nd CIRP Conference on Life Cycle Engineering (LCE2025)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.12.119},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125004184},
author = {Shengyu Liu and Sipke Hoekstra and Sebastian Thiede},
keywords = {Generative Artificial Intelligence, Life Cycle Assessment, Factory},
abstract = {The paper explores an innovative approach to evaluate the environmental impact of factory buildings at early design stages. Generative design, a cutting-edge computational technique, is employed to generate multiple factory building design alternatives based on user and case specific boundary conditions, e.g. related to material flow and space restrictions. This paper aims to integrate generative design principles with environmental assessment metrics to improve factory buildings for minimal environmental footprint, e.g. driven through energy demand. Thus, a framework that combines the generative factory design approach with key environmental assessment parameters is introduced. The effectiveness of generative design in enhancing the environmental performance of factory buildings is demonstrated with a case study. A comparative analysis of different designs highlights main influencing factors, as well as trade-offs and synergies between different manufacturing system performances and environmental oriented objectives. With that, the paper underlines the value of generative design as a transformative tool in sustainable factory design and provides actionable insights for architects, engineers, and policymakers aiming to develop greener industrial facilities.}
}
@article{LIEBSCHER2025e106,
title = {Testing the Implementation and Acceptance of Generative Artificial Intelligence to Augment Vascular Surgery Journal Club},
journal = {Journal of Vascular Surgery},
volume = {82},
number = {4},
pages = {e106},
year = {2025},
issn = {0741-5214},
doi = {https://doi.org/10.1016/j.jvs.2025.06.096},
url = {https://www.sciencedirect.com/science/article/pii/S0741521425014764},
author = {Sean Liebscher and Rhea Puthumana and Mead Ferris and Daniel Bertges}
}
@article{KONG2024100328,
title = {Examining teachers’ behavioural intention of using generative artificial intelligence tools for teaching and learning based on the extended technology acceptance model},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100328},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100328},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001310},
author = {Siu Cheung Kong and Yin Yang and Chunyu Hou},
keywords = {Artificial intelligence literacy, Generative artificial intelligence tools, Teacher development, Teaching and learning, Extended technology acceptance model},
abstract = {The rapid development of generative artificial intelligence (GenAI) tools has given rise to a growing discussion of the potential challenges and benefits that the use of these technologies may present in the field of education. This study examines the acceptance of the use of GenAI tools for teaching and learning among primary and secondary school teachers in Hong Kong. It uses an extension of the technology acceptance model (TAM) with a modified framework that incorporates two key factors: self-efficacy and subjective norm. Data were collected from a sample of 367 primary and secondary school teachers in Hong Kong using questionnaires containing items for six constructs: self-efficacy, perceived usefulness, perceived ease of use, attitude towards using, subjective norm, and behavioural intention. The results show that fostering teachers' self-efficacy, perceived usefulness, and attitude is essential for successfully increasing their behavioural intention to use GenAI tools. Subjective norm was also found to influence teachers' behavioural intention. To enhance teachers' effective use of GenAI for teaching, teacher development programmes should focus on equipping teachers with comprehensive conceptual knowledge and skills and an understanding of the application of these tools to teaching and learning. Policy support to create a conducive environment for the use of GenAI in teaching and learning would also be beneficial. The study has theoretical implications in its extension of the TAM model as well as implications for enhancing teachers’ AI literacy and developing pedagogies for the meaningful use of GenAI tools for teaching and learning in K–12 settings.}
}
@article{RASHIDI2025100663,
title = {Statistics of Generative Artificial Intelligence and Nongenerative Predictive Analytics Machine Learning in Medicine},
journal = {Modern Pathology},
volume = {38},
number = {3},
pages = {100663},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100663},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002436},
author = {Hooman H. Rashidi and Bo Hu and Joshua Pantanowitz and Nam Tran and Silvia Liu and Alireza Chamanzar and Mert Gur and Chung-Chou H. Chang and Yanshan Wang and Ahmad Tafti and Liron Pantanowitz and Matthew G. Hanna},
keywords = {BiLingual Evaluation Understudy, accuracy, precision, F1 score, receiver operating characteristic area under the curve, perplexity},
abstract = {The rapidly evolving landscape of artificial intelligence (AI) and machine learning (ML) in medicine has prompted medical professionals to increasingly familiarize themselves with related topics. This also demands grasping the underlying statistical principles that govern their design, validation, and reproducibility. Uniquely, the practice of pathology and medicine produces vast amount of data that can be exploited by AI/ML. The emergence of generative AI, especially in the area of large language models and multimodal frameworks, represents approaches that are starting to transform medicine. Fundamentally, generative and traditional (eg, nongenerative predictive analytics) ML techniques rely on certain common statistical measures to function. However, unique to generative AI are metrics such as, but not limited to, perplexity and BiLingual Evaluation Understudy score that provide a means to determine the quality of generated samples that are typically unfamiliar to most medical practitioners. In contrast, nongenerative predictive analytics ML often uses more familiar metrics tailored to specific tasks as seen in the typical classification (ie, confusion metrics measures, such as accuracy, sensitivity, F1 score, and receiver operating characteristic area under the curve) or regression studies (ie, root mean square error and R2). To this end, the goal of this review article (as part 4 of our AI review series) is to provide an overview and a comparative measure of statistical measures and methodologies used in both generative AI and traditional (ie, nongenerative predictive analytics) ML fields along with their strengths and known limitations. By understanding their similarities and differences along with their respective applications, we will become better stewards of this transformative space, which ultimately enables us to better address our current and future needs and challenges in a more responsible and scientifically sound manner.}
}
@article{JANG2024102175,
title = {When, What, and how should generative artificial intelligence explain to Users?},
journal = {Telematics and Informatics},
volume = {93},
pages = {102175},
year = {2024},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2024.102175},
url = {https://www.sciencedirect.com/science/article/pii/S0736585324000790},
author = {Soobin Jang and Haeyoon Lee and Yujin Kim and Daeho Lee and Jungwoo Shin and Jungwoo Nam},
keywords = {Generative AI, Conversational user interface, Explainable AI, Conjoint analysis},
abstract = {With the commercialization of ChatGPT, generative artificial intelligence (AI) has been applied almost everywhere in our lives. However, even though generative AI has become a daily technology that anyone can use, most non-majors need to know the process and reason for the results because it can be misused due to lack of sufficient knowledge and misunderstanding. Therefore, this study investigated users’ preferences for when, what, and how generative AI should provide explanations about the process of generating and the reasoning behind the results, using conjoint method and mixed logit analysis. The results show that users are most sensitive to the timing of providing eXplainable AI (XAI), and that users want additional information only when they ask for explanations during the process of using generative AI. The results of this study will help shape the XAI design of future generative AI from a user perspective and improve usability.}
}
@article{ICHIKAWA2025,
title = {Generative Artificial Intelligence in Medical Education—Policies and Training at US Osteopathic Medical Schools: Descriptive Cross-Sectional Survey},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/58766},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000236},
author = {Tsunagu Ichikawa and Elizabeth Olsen and Arathi Vinod and Noah Glenn and Karim Hanna and Gregg C Lund and Stacey Pierce-Talsma},
keywords = {artificial intelligence, medical education, faculty development, policy, AI, training, United States, school, university, college, institution, osteopathic, osteopathy, curriculum, student, faculty, administrator, survey, cross-sectional},
abstract = {Background
Interest has recently increased in generative artificial intelligence (GenAI), a subset of artificial intelligence that can create new content. Although the publicly available GenAI tools are not specifically trained in the medical domain, they have demonstrated proficiency in a wide range of medical assessments. The future integration of GenAI in medicine remains unknown. However, the rapid availability of GenAI with a chat interface and the potential risks and benefits are the focus of great interest. As with any significant medical advancement or change, medical schools must adapt their curricula to equip students with the skills necessary to become successful physicians. Furthermore, medical schools must ensure that faculty members have the skills to harness these new opportunities to increase their effectiveness as educators. How medical schools currently fulfill their responsibilities is unclear. Colleges of Osteopathic Medicine (COMs) in the United States currently train a significant proportion of the total number of medical students. These COMs are in academic settings ranging from large public research universities to small private institutions. Therefore, studying COMs will offer a representative sample of the current GenAI integration in medical education.
Objective
This study aims to describe the policies and training regarding the specific aspect of GenAI in US COMs, targeting students, faculty, and administrators.
Methods
Web-based surveys were sent to deans and Student Government Association (SGA) presidents of the main campuses of fully accredited US COMs. The dean survey included questions regarding current and planned policies and training related to GenAI for students, faculty, and administrators. The SGA president survey included only those questions related to current student policies and training.
Results
Responses were received from 81% (26/32) of COMs surveyed. This included 47% (15/32) of the deans and 50% (16/32) of the SGA presidents (with 5 COMs represented by both the deans and the SGA presidents). Most COMs did not have a policy on the student use of GenAI, as reported by the dean (14/15, 93%) and the SGA president (14/16, 88%). Of the COMs with no policy, 79% (11/14) had no formal plans for policy development. Only 1 COM had training for students, which focused entirely on the ethics of using GenAI. Most COMs had no formal plans to provide mandatory (11/14, 79%) or elective (11/15, 73%) training. No COM had GenAI policies for faculty or administrators. Eighty percent had no formal plans for policy development. Furthermore, 33.3% (5/15) of COMs had faculty or administrator GenAI training. Except for examination question development, there was no training to increase faculty or administrator capabilities and efficiency or to decrease their workload.
Conclusions
The survey revealed that most COMs lack GenAI policies and training for students, faculty, and administrators. The few institutions with policies or training were extremely limited in scope. Most institutions without current training or policies had no formal plans for development. The lack of current policies and training initiatives suggests inadequate preparedness for integrating GenAI into the medical school environment, therefore, relegating the responsibility for ethical guidance and training to the individual COM member.}
}
@article{RIANTO2025104427,
title = {Generative artificial intelligence for fire scenario analysis in complex building design layouts},
journal = {Fire Safety Journal},
volume = {155},
pages = {104427},
year = {2025},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2025.104427},
url = {https://www.sciencedirect.com/science/article/pii/S0379711225000918},
author = {Shandy Rianto and Yanfu Zeng and Xinyan Huang and Xinzheng Lu},
keywords = {Intelligent design, Fire safety engineering, Generative AI, Building fire simulation, Computational fluid dynamics},
abstract = {Performance-based fire safety design requires thoroughly evaluating building fire scenarios to ensure comprehensive fire safety. However, conventional Computational Fluid Dynamics (CFD) fire simulations are computationally intensive and time-consuming, limiting the number of scenarios that can be practically analyzed. This study addresses these challenges by using generative artificial intelligence (AI) to predict fire scenes in realistic multi-room building layouts, characterized by complex shapes and intricate wall partitions. Three generative AI models for image generation are employed for this purpose: GAN-based pix2pix and pix2pixHD, as well as the diffusion model. These models were trained on an extensive dataset of CFD fire simulations to generate near-ceiling smoke movement and temperature distribution outcomes. When tested on new unseen building layouts, these models demonstrated remarkable accuracy and provided near real-time assessments. The diffusion model achieved the highest accuracy (>94 %) while requiring the more computational time. The high performance of these models highlights the potential of using generative AI to enhance fire safety engineering by enabling faster and more comprehensive fire risk assessments.}
}
@article{MONZON2025,
title = {Leveraging Generative Artificial Intelligence to Improve Motivation and Retrieval in Higher Education Learners},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/59210},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000352},
author = {Noahlana Monzon and Franklin Alan Hays},
keywords = {educational technology, retrieval practice, flipped classroom, cognitive engagement, personalized learning, generative artificial intelligence, higher education, university education, learners, instructors, curriculum structure, learning, technologies, innovation, academic misconduct, gamification, self-directed, socio-economic disparities, interactive approach, medical education, chatGPT, machine learning, AI, large language models},
abstract = {Generative artificial intelligence (GenAI) presents novel approaches to enhance motivation, curriculum structure and development, and learning and retrieval processes for both learners and instructors. Though a focus for this emerging technology is academic misconduct, we sought to leverage GenAI in curriculum structure to facilitate educational outcomes. For instructors, GenAI offers new opportunities in course design and management while reducing time requirements to evaluate outcomes and personalizing learner feedback. These include innovative instructional designs such as flipped classrooms and gamification, enriching teaching methodologies with focused and interactive approaches, and team-based exercise development among others. For learners, GenAI offers unprecedented self-directed learning opportunities, improved cognitive engagement, and effective retrieval practices, leading to enhanced autonomy, motivation, and knowledge retention. Though empowering, this evolving landscape has integration challenges and ethical considerations, including accuracy, technological evolution, loss of learner’s voice, and socioeconomic disparities. Our experience demonstrates that the responsible application of GenAI’s in educational settings will revolutionize learning practices, making education more accessible and tailored, producing positive motivational outcomes for both learners and instructors. Thus, we argue that leveraging GenAI in educational settings will improve outcomes with implications extending from primary through higher and continuing education paradigms.}
}