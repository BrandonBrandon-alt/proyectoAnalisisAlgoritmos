@article{YEUNG2025103082,
title = {University students' perceptions on how generative artificial intelligence shape learning and research practices: A case study in Hong Kong},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {5},
pages = {103082},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103082},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000783},
author = {Renee Sze Kei Yeung and Ruwen Tian and Dickson K.W. Chiu and Samuel Ping-Man Choi},
keywords = {Generative artificial intelligence, Academic libraries, Student learning, Student research, Quantitative study},
abstract = {The launch of chat-based Generative Artificial Intelligence (GenAI) in November 2022 has garnered significant attention and adoption across various sectors, particularly the academic community. Considering the potential transformative impact of GenAI on university students' learning and research practices, this research examines the patterns of use, perceived benefits, and drawbacks of GenAI among undergraduates and postgraduates at universities in Hong Kong. This research employs the 5E instructional model to systematically investigate the effectiveness of GenAI tools in supporting learning and research among local university students. The 170 valid responses revealed generally positive perceptions of the benefits of using GenAI in learning and research-related activities. However, they also acknowledged its potential drawbacks on ethical issues such as plagiarism and academic dishonesty. In addition, respondents agreed that GenAI could effectively support their learning and research activities despite concerns about potential skill deficits, such as diminished critical thinking and analytical abilities caused by the excessive use of GenAI. These findings highlight the increasingly critical role that academic communities like libraries could play in promoting ethical, effective, and literate use of GenAI technologies through targeted training, tool curation, and research support services.}
}
@article{FINI2025102568,
title = {Application of generative artificial intelligence in the aquacultural sector},
journal = {Aquacultural Engineering},
volume = {111},
pages = {102568},
year = {2025},
issn = {0144-8609},
doi = {https://doi.org/10.1016/j.aquaeng.2025.102568},
url = {https://www.sciencedirect.com/science/article/pii/S0144860925000573},
author = {Chiara Fini and Simone Gaetano Amato and Daniela Scutaru and Sara Biancardi and Francesca Antonucci and Simona Violino and Luciano Ortenzi and Eugenio Nerio Nemmi and Alessandro Mei and Federico Pallottino and Simone Figorilli and Corrado Costa},
keywords = {Smart aquaculture, GAI, Feed optimization, Fish monitoring, Seafood security, Seafood traceability, Animal welfare},
abstract = {Artificial Intelligence (AI) applications in aquaculture have recently attracted growing attention, as these technologies are becoming vital for data analysis, improving production processes, and optimizing the use of natural resources. Among the different AI approaches, Generative Artificial Intelligence (GAI) emerges as one of the most innovative and promising.This paper explores the use of Generative Artificial Intelligence (GAI) in aquaculture, evaluating its advantages and challenges within the industry's unique context. It begins with an overview of generative model architectures, then delves into their potential contributions to aquatic resource management, the improvement of farming practices, and the promotion of environmental sustainability.To obtain the most up-to-date insights, research was carried out using database such as SCOPUS, Google Scholar, and Web of Science databases. GAI holds significant promise for aquaculture, with applications that include enhanced water quality management, fish stock health prediction, and automated feeding supervision. When applied responsibly, GAI can streamline routine operations while contributing to a more resilient and sustainable future for the aquaculture industry. With its ability to extract valuable insights from big data, GAI proves to be a powerful tool for tackling future challenges, ensuring food production that meets the demands of a growing global population while addressing increasingly urgent environmental concerns.}
}
@article{VOLPATO2025100195,
title = {Trusting emotional support from generative artificial intelligence: a conceptual review},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100195},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100195},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000799},
author = {Riccardo Volpato and Lisa DeBruine and Simone Stumpf},
keywords = {Trust, Generative AI, Theory, Emotional support, Multidisciplinary},
abstract = {People are increasingly using generative artificial intelligence (AI) for emotional support, creating trust-based interactions with limited predictability and transparency. We address the fragmented nature of research on trust in AI through a multidisciplinary conceptual review, examining theoretical foundations for understanding trust in the emerging context of emotional support from generative AI. Through an in-depth literature search across human-computer interaction, computer-mediated communication, social psychology, mental health, economics, sociology, philosophy, and science and technology studies, we developed two principal contributions. First, we summarise relevant definitions of trust across disciplines. Second, based on our first contribution, we define trust in the context of emotional support provided by AI and present a categorisation of relevant concepts that recur across well-established research areas. Our work equips researchers with a map for navigating the literature and formulating hypotheses about AI-based mental health support, as well as important theoretical, methodological, and practical implications for advancing research in this area.}
}
@article{PANDAYSHUKLA2025105088,
title = {Exploring generative artificial intelligence in teacher education},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105088},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105088},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25001659},
author = {Priya Panday-Shukla},
keywords = {Generative artificial intelligence (GenAI), Artificial intelligence (AI), Diffusion of Innovation (DOI), Teacher educators, Pre-service teachers},
abstract = {Generative artificial intelligence (GenAI) has the potential to be a powerful tool for educators. However, understanding the key attributes that can influence pre-service teachers and teacher educators’ adoption of GenAI tools remains limited. This collective exploratory case study investigated the perceptions and experiences of 52 pre-service teachers and 21 teacher educators at a U.S. Pacific Northwest university through surveys and focus groups. Findings provide teacher educators and administrators with a deeper understanding of the perceived barriers and facilitators to diffusion and adoption of these tools. The recommendations outline practical approaches to improve key attributes and prepare educators and future teachers.}
}
@article{KARAOGLANYILMAZ2025100187,
title = {Exploring the role of cognitive flexibility, digital competencies, and self-regulation skills on students' generative artificial intelligence anxiety},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100187},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100187},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000714},
author = {Fatma Gizem {Karaoglan Yilmaz} and Ramazan Yilmaz and Ahmet Berk Ustun and Hatice Uzun},
keywords = {Generative artificial intelligence, Artificial intelligence anxiety, University students, Cognitive flexibility, Digital competencies, Self-regulation skills},
abstract = {The purpose of the study is to examine the role of cognitive flexibility, digital competencies and self-regulation skills in reducing university students' artificial intelligence (AI) anxiety. The study proposes that it isn't possible to harness the potential benefits of AI technologies unless students' concerns about these technologies are suitably addressed. Although the number of potential benefits specifically related to the use of AI in education is enormous, addressing students' concerns about AI is essential to ensure the effective use of these technologies in education. The correlational survey model was used in this study. Four well-established instruments were employed to collect data from students who studied in different public university faculties in Turkey. Participants were selected from students who had been using AI tools for educational purposes for at least six months. The findings showed that cognitive flexibility, digital competencies and self-regulation skills impact on AI anxiety. Students with high cognitive flexibility had lower AI anxiety, while students with high digital competencies were better able to comprehend and use AI technologies. In addition, students with high self-regulation skills were able to manage their own learning processes more effectively and experienced less anxiety in using AI. As a result, increasing university students' digital competencies and self-regulation skills can be influential in reducing their AI anxiety. Accordingly, educational institutions could offer programs to develop students' digital competencies and AI literacy. These programs can help them adapt to AI technologies more easily and reduce their anxiety about these technologies by teaching students how to use AI technologies effectively and efficiently.}
}
@article{FLEURENCE2025,
title = {A Taxonomy of Generative Artificial Intelligence in Health Economics and Outcomes Research: An ISPOR Working Group Report},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.2167},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525023356},
author = {Rachael L. Fleurence and Xiaoyan Wang and Jiang Bian and Mitchell K. Higashi and Turgay Ayer and Hua Xu and Dalia Dawoud and Jagpreet Chhatwal},
keywords = {artificial intelligence, economic models, generative AI, large language models, systematic reviews},
abstract = {Objectives
This article presents a taxonomy of generative artificial intelligence (AI) for health economics and outcomes research (HEOR), explores emerging applications, outlines methods to improve the accuracy and reliability of AI-generated outputs, and describes current limitations.
Methods
Foundational generative AI concepts are defined, and current HEOR applications are highlighted, including for systematic literature reviews, health economic modeling, real-world evidence generation, and dossier development. Techniques such as prompt engineering (eg, zero-shot, few-shot, chain-of-thought, and persona pattern prompting), retrieval-augmented generation, model fine-tuning, domain-specific models, and the use of agents are introduced to enhance AI performance. Limitations associated with the use of generative AI foundation models are described.
Results
Generative AI demonstrates significant potential in HEOR, offering enhanced efficiency, productivity, and innovative solutions to complex challenges. Although foundation models show promise in automating complex tasks, challenges persist in scientific accuracy and reproducibility, bias and fairness, and operational deployment. Strategies to address these issues and improve AI accuracy are discussed.
Conclusions
Generative AI has the potential to transform HEOR by improving efficiency and accuracy across diverse applications. However, realizing this potential requires building HEOR expertise and addressing the limitations of current AI technologies. Ongoing research and innovation will be key to shaping AI’s future role in our field.}
}
@article{ROBISON2025101822,
title = {Development of a prompt template to support simulation design: Maximizing the potential of generative artificial intelligence},
journal = {Clinical Simulation in Nursing},
volume = {108},
pages = {101822},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101822},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001380},
author = {Elizabeth Robison and Theresa Cooney and Tammy Schwaab and Sami Rahman},
keywords = {Artificial intelligence, Healthcare simulation, Nursing education, Prompt engineering, Scenario design},
abstract = {Background
Generative AI tools like ChatGPT are rapidly changing academia and healthcare, particularly in nursing education through their ability to assist in creating clinical simulation scenarios. The key to effectively using these tools lies in prompt engineering, the careful crafting of inputs to guide AI outputs.
Aim
An initiative by nurse educators explored how prompt engineering, aligned with established simulation standards, could streamline scenario design.
Findings
The findings revealed variations in output quality and focus among different AI platforms (ChatGPT, CoPilot, Claude), highlighting the need for careful selection and human oversight to ensure accuracy and relevance in AI-generated simulation content.
Conclusions
This iterative process of prompt refinement holds significant promise for creating more engaging and effective learning experiences, but AI serves as a tool that augments, not replaces, the expertise of nursing simulationists.}
}
@article{MUNIR2025102439,
title = {Pharmacy meets AI: Effect of a drug information activity on student perceptions of generative artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {10},
pages = {102439},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102439},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725001601},
author = {Faria Munir and Heather Ipema and Rahul Nohria and Divita Singh},
keywords = {ChatGPT, Artificial intelligence, Drug information, Student perceptions, Generative artificial intelligence, Large language model, Health professional student, Health professional education},
abstract = {Objective
The current study assessed pharmacy students' perceptions about generative AI before and after participation in a ChatGPT-based drug information activity.
Methods
In 2024, students at three colleges of pharmacy completed a baseline and post-activity survey on their perceptions of ChatGPT including its reliability, usefulness, and impact on academic performance and critical thinking. The survey was modified from the TAME-ChatGPT assessment and used a 5-point Likert scale. After the baseline survey, students answered clinically relevant drug information questions on their own using primary or tertiary resources and compared their answers with ChatGPT responses. Independent t-test samples were used to compare baseline and post-activity surveys.
Results
A total of 227 students completed the pre-survey and 203 students completed the post-survey. Students' concerns about the reliability of ChatGPT increased after completing the drug information activity (pre-survey: 3.57 ± 0.96; post-survey: 3.88 ± 1.11; p = 0.002). Students' concerns about reliance on ChatGPT and prevention of critical thinking increased (pre-survey: 3.30 ± 1.34; post-survey: 3.57 ± 1.21; p = 0.031). The following areas decreased after the activity: enthusiasm about ChatGPT as learning and research tool (pre-survey: 3.60 ± 1.02; post-survey: 3.32 ± 1.18; p = 0.008), viewing ChatGPT as an important tool for academic success (pre-survey: 3.40 ± 1.13; post-survey: 3.12 ± 1.23; p = 0.015), and concern regarding being accused of plagiarism when using ChatGPT(pre-survey: 4.12 ± 0.96; post-survey: 3.91 ± 1.10; p = 0.031). Open-ended responses revealed that students largely perceived ChatGPT as unreliable for drug information, citing concerns about accuracy and outdated content. However, some students noted its potential usefulness for non-clinical tasks such as generating ideas, organizing content, or providing general overviews.
Conclusion
After a hands-on ChatGPT-based drug information activity, pharmacy students reported increased concerns about reliability and over-reliance on artificial intelligence-based technology. The results of this study may encourage pharmacy educators to implement classroom activities for active exploration of the benefits and challenges of generative AI.
Contribution to literature
Limited published data describes pharmacy student perceptions of artificial intelligence platforms as a drug information source. There is even less literature with pre- and post-data after implementing an activity in which students gain hands-on experience critiquing an artificial intelligence platform response. Therefore, this study was conducted to evaluate student perceptions after using ChatGPT in the classroom and comparing its performance to their own responses based on information from primary and tertiary literature. The results demonstrate that despite enthusiasm before using ChatGPT, concerns for reliability and hindering thinking increased after a observing the limitations of its performance in answering drug information questions.}
}
@article{ZAMORA2025103161,
title = {Generative artificial intelligence, large language models and ChatGPT in musculoskeletal Oncology: Current applications and future potential},
journal = {Journal of Clinical Orthopaedics and Trauma},
volume = {69},
pages = {103161},
year = {2025},
issn = {0976-5662},
doi = {https://doi.org/10.1016/j.jcot.2025.103161},
url = {https://www.sciencedirect.com/science/article/pii/S0976566225002590},
author = {Tomas Zamora and Paulina Salas and Sebastian Zuñiga and Eduardo Botello and Marcelo E. Andia},
keywords = {Musculoskeletal neoplasms, Artificial intelligence, Natural language processing, Machine learning, Decision support systems, Clinical, Medical informatics},
abstract = {Generative artificial intelligence (AI), particularly large language models (LLMs), has emerged as a transformative technology across all medical specialties, including musculoskeletal (MSK) oncology. These models, such as ChatGPT and others, can process natural language, synthesize vast amounts of information, and generate contextually relevant outputs that resemble human communication. In orthopedic oncology, LLMs show promise in facilitating literature reviews, enhancing patient education, and supporting clinical decision-making by analyzing multidimensional data while providing improved logic-based reasoning. Additionally, they can assist in radiological and pathological workflows by interpreting imaging reports and drafting diagnostic summaries, thereby increasing efficiency and accuracy. In the near future, they are expected to aid in real-time patient follow-up and counseling, information transfer, efficient diagnostics, and even continuous surgical education and assistance. Despite their potential, challenges such as the risk of inaccuracies and biases, as well as the necessity for continuous supervision, warrant a cautious and responsible integration into clinical practice. This narrative review examines the current applications of LLMs in MSK oncology, their limitations, and their future potential in shaping precision medicine and equitable healthcare delivery.}
}
@article{FOOTE2025101593,
title = {Embracing Generative Artificial Intelligence in Clinical Research and Beyond: Opportunities, Challenges, and Solutions},
journal = {JACC: Advances},
volume = {4},
number = {3},
pages = {101593},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.101593},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25000109},
author = {Henry P. Foote and Chuan Hong and Mohd Anwar and Maria Borentain and Kevin Bugin and Nancy Dreyer and Josh Fessel and Nitender Goyal and Morgan Hanger and Adrian F. Hernandez and Christoph P. Hornik and Jennifer G. Jackman and Alistair C. Lindsay and Michael E. Matheny and Kerem Ozer and Jan Seidel and Norman Stockbridge and Peter J. Embi and Christopher J. Lindsell},
keywords = {artificial intelligence, clinical research, generative AI, participant engagement, research ethics},
abstract = {To explore threats and opportunities and to chart a path for safely navigating the rapid changes that generative artificial intelligence (AI) will bring to clinical research, the Duke Clinical Research Institute convened a multidisciplinary think tank in January 2024. Leading experts from academia, industry, nonprofits, and government agencies highlighted the potential opportunities of generative AI in automation of documentation, strengthening of participant and community engagement, and improvement of trial accuracy and efficiency. Challenges include technical hurdles, ethical dilemmas, and regulatory uncertainties. Success is expected to require establishing rigorous data management and security protocols, fostering integrity and trust among stakeholders, and sharing information about the safety and effectiveness of AI applications. Meeting insights point towards a future where, through collaboration and transparency, generative AI will help to shorten the translational pipeline and increase the inclusivity and equitability of clinical research.}
}
@article{SERRASIMON2025103033,
title = {Generative artificial intelligence in advertising. Field applications in Rio de Janeiro and Catalonia},
journal = {Telecommunications Policy},
volume = {49},
number = {8},
pages = {103033},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103033},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001302},
author = {Jordi Serra-Simón and Mònica Puntí-Brun and Sílvia Espinosa-Mirabet and Maria Alice {de Faria Nogueira} and Ramón Martín-Guart and Sandro {Tôrres de Azevedo}},
keywords = {AI, GenAI, Advertising agencies, Creativity, Digital media, Rio de Janeiro, Catalonia},
abstract = {The emergence of Artificial Intelligence has revolutionized industries in various productive sectors on an international level. Advertising agencies are not immune to this reality and have also experienced the effects of AI through the advent and widespread use of technologies that enable the design, creation, editing, and writing of content for the advertising industry. This article allows us to measure the impact of the arrival of AI in several advertising agencies, independent and holding companies (such as McCann and Havas Media) in Rio de Janeiro and Catalonia. The research analyses the use and integration of these programs in creative and productive processes based on 25 in-depth interviews with 13 directors and 12 creatives in both regions. The results show that agencies are using generative AI tools, but for different purposes, and that in some cases, AI is related to the advertising creation process, while in others, it is used for tasks related to the design of strategic communication plans or even the design of prototypes and models. Although there is unanimous agreement on the benefits of AI, there are concerns about ethical issues and its use in the finalists' work. This article allows us to glimpse new lines of research related to the implementation of generative AI tools in advertising creativity, customer relationship management, and advertising production.}
}
@article{WU2025102588,
title = {A generative artificial intelligence approach to tracking mainland China's housing market sentiment using social media data},
journal = {China Economic Review},
pages = {102588},
year = {2025},
issn = {1043-951X},
doi = {https://doi.org/10.1016/j.chieco.2025.102588},
url = {https://www.sciencedirect.com/science/article/pii/S1043951X25002469},
author = {Zhang Wu and Michael Cheng and Philip Ng and Alice Wang},
keywords = {Generative artificial intelligence, Property market sentiment, Granular sentiment indices, Mainland China},
abstract = {This paper develops a daily housing market sentiment index that leverages Chinese social media data and generative Artificial Intelligence (GenAI). We adopt a human-in-the-loop methodology and find that the GenAI assessments align closely with human evaluations. Compared to conventional methods, GenAI also offers methodological advantages and arguably provides a more reliable measurement of sentiment. Our empirical analysis demonstrates that the GenAI-driven sentiment index effectively captures public sentiment trends and robustly drives property sales. Furthermore, we utilise GenAI's strong comprehension abilities to identify cities mentioned in microblogs, thereby creating more granular sentiment indices at the city level. These city-level sentiment indices prove useful in predicting local property sales and revealing significant sentiment spillovers from major to smaller cities. Our research offers policymakers enhanced tools for timely market monitoring and underscores the transformative potential of GenAI in research and macroeconomic surveillance, enabling the analysis of previously unmanageable big and unstructured data.}
}
@article{LUO2025111903,
title = {Lack of methodological rigor and limited coverage of generative artificial intelligence in existing artificial intelligence reporting guidelines: a scoping review},
journal = {Journal of Clinical Epidemiology},
volume = {186},
pages = {111903},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2025.111903},
url = {https://www.sciencedirect.com/science/article/pii/S0895435625002367},
author = {Xufei Luo and Bingyi Wang and Qianling Shi and Zijun Wang and Honghao Lai and Hui Liu and Yishan Qin and Fengxian Chen and Xuping Song and Long Ge and Lu Zhang and Zhaoxiang Bian and Yaolong Chen and Hongfeng He and Ye Wang and Haodong Li and Huayu Zhang and Di Zhu and Yuanyuan Yao and Dongrui Peng and Zhewei Li and Jie Zhang and Yishan Qin and Fan Wang and Zhenyu Tang and Yueyan Li and Hanxiang Liu and Jungang Zhao},
keywords = {Reporting guidelines, Artificial intelligence, Scoping review, Generative artificial intelligence, Large language models, Methodological quality},
abstract = {Objectives
This study aimed to systematically map the development methods, scope, and limitations of existing artificial intelligence (AI) reporting guidelines in medicine and to explore their applicability to generative AI (GAI) tools, such as large language models (LLMs).
Study Design and Setting
We reported a scoping review adhering to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. Five information sources were searched, including MEDLINE (via PubMed), Enhancing the QUAlity and Transparency Of health Research (EQUATOR) Network, China National Knowledge Infrastructure, FAIRsharing, and Google Scholar, from inception to December 31, 2024. Two reviewers independently screened records and extracted data using a predefined Excel template. Data included guideline characteristics (eg, development methods, target audience, AI domain), adherence to EQUATOR Network recommendations, and consensus methodologies. Discrepancies were resolved by a third reviewer.
Results
Sixty-eight AI reporting guidelines were included; 48.5% focused on general AI, whereas only 7.4% addressed GAI/LLMs. Methodological rigor was limited; 39.7% described development processes, 42.6% involved multidisciplinary experts, and 33.8% followed EQUATOR recommendations. Significant overlap existed, particularly in medical imaging (20.6% of guidelines). GAI-specific guidelines (14.7%) lacked comprehensive coverage and methodological transparency.
Conclusion
Existing AI reporting guidelines in medicine have suboptimal methodological rigor, redundancy, and insufficient coverage of GAI applications. Future and updated guidelines should prioritize standardized development processes, multidisciplinary collaboration, and expanded focus on emerging AI technologies like LLMs.}
}
@article{SONG2025105157,
title = {A case study of teachers’ generative artificial intelligence integration processes and factors influencing them},
journal = {Teaching and Teacher Education},
volume = {165},
pages = {105157},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2025.105157},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X25002343},
author = {Zicong Song and Jingjing Qin and Fangzhou Jin and Wai Ming Cheung and Chin-Hsi Lin},
keywords = {Teacher, Generative artificial intelligence, Integration, Factors, Transformation},
abstract = {How schoolteachers integrate generative artificial intelligence (GenAI) into their teaching remains underexplored. This case study of 22 teachers from Guangdong delineates four GenAI user types, i.e., cautious adapters, efficiency enhancers, technology enthusiasts, and pedagogical innovators; groups teachers’ GenAI integration into five levels, from low to high; and examines how transformation of GenAI integration is influenced by individual, technological, and environmental factors. These findings extend the Substitution, Augmentation, Modification, and Redefinition (SAMR) model into PSAMR – the “P” stands for “Prohibition” – emphasizing GenAI’s dynamic, controversial nature. They also indicate that, during integration, educators should focus more on human factors than on tools’ functionalities.}
}
@article{KUNZE2025,
title = {Commercial Products Using Generative Artificial Intelligence Include Ambient Scribes, Automated Documentation and Scheduling, Revenue Cycle Management, Patient Engagement and Education, and Prior Authorization Platforms},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2025.05.021},
url = {https://www.sciencedirect.com/science/article/pii/S0749806325003974},
author = {Kyle N. Kunze and Jennifer Bepple and Asheesh Bedi and Prem N. Ramkumar and Christian A. Pean},
abstract = {The integration of artificial intelligence into clinical practice is rapidly transforming health care workflows. At the forefront are large language models (LLMs), embedded within commercial and enterprise platforms to optimize documentation, streamline administration, and personalize patient engagement. The evolution of LLMs in health care has been driven by rapid advancements in natural language processing and deep learning. Emerging commercial products include ambient scribes, automated documentation and scheduling, revenue cycle management, patient engagement and education assistants, and prior authorization platforms. Ambient scribes remain the leading commercial generative artificial intelligence product, with approximately 90 platforms in existence to date. Emerging applications may improve provider efficiency and payer-provider alignment by automating the prior authorization process to reduce the manual labor burden placed on clinicians and staff. Current limitations include (1) lack of regulatory oversight, (2) existing biases, (3) inconsistent interoperability with electronic health records, and (4) lack of physician and stakeholder buy-in due to lack of confidence in LLM outputs. Looking forward requires discussion of ethical, clinical, and operational considerations.}
}
@article{GMITEREK2025103043,
title = {Generative artificial intelligence in the activities of academic libraries of public universities in Poland},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {3},
pages = {103043},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103043},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000394},
author = {Grzegorz Gmiterek and Sebastian D. Kotuła},
keywords = {Generative artificial intelligence, Artificial intelligence, Academic libraries},
abstract = {The article presents the results of a study conducted, using both survey and content analysis (of the websites and fan pages) of all the libraries of the public universities in Poland to establish their use of generative artificial intelligence. The general findings showed that not all libraries were active in promoting artificial intelligence solutions. Most (57 %) of the libraries supported the inclusion of GAI in the repertoire of library tools, although only 39.3 % dealt with GAI issues. 46 % actively used them despite 50 % of the libraries creating conditions favorable for the use of GAI. Interestingly, 43 % of libraries indicated that they did not think there was a need to use GAI tools with the main reasons given including a lack of staff competencies and the appropriate regulations in the area. For those libraries using GAI or AI, 47 % of them had information about this published on their home pages and 39 % on their fan pages. The most common information found was about the promotion of AI tools, the resources available in the library, organized events (49,67 % of all information) and documents on the subject (36,77 % of the published information).}
}
@article{CHEN2025100737,
title = {Effect of Generative Artificial Intelligence on University Students Learning Outcomes: A Systematic Review and Meta-Analysis},
journal = {Educational Research Review},
pages = {100737},
year = {2025},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2025.100737},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X25000740},
author = {Shuzhen Chen and Alan C.K. Cheung},
keywords = {Artificial intelligence, ChatGPT, Academic performance, Meta-analysis, Experimental studies, Higher education},
abstract = {Generative artificial intelligence (Gen-AI) is transforming higher education by enhancing students’ learning outcomes. Noteworthy, the magnitude of effect sizes has not reached consensus, reflecting substantial variability arising from contextual conditions and methodological approaches. To bridge this gap, grounded in activity theory-mobile computer-supported collaborative learning (AT-MCSCL) framework, this meta-analysis comprehensively synthesized 57 studies and 97 estimations and confirmed that Gen-AI had large effect size on university students’ learning outcomes (g+ = 0.804), particularly in language skills (g+ = 2.331), academic achievement (g+ = 0.633), affective-motivational status (g+ = 0.617), and higher-order thinking (g+ = 0.580), except for a lack of statistically significant effect on metacognition (g+ = 0.078). Meanwhile, this study revealed moderators related to learner, tool, roles, rules and contextual features: (a) freshmen and language learners benefited the most; (b) outcomes measured by tests, studies with medium-sized samples (40-100), medium (4-12 weeks) intervention, and published in journals yielded the higher effect sizes; (c) studies conducted in classroom settings, Middle East, low ICT levels, low socioeconomic status, and higher power distance produced higher effect sizes. This study provides more robust evidence to effectiveness of Gen-AI in higher education and elucidates contextual heterogeneity comprehensively, offering reliable insights for Gen-AI integration in diverse learning environments.}
}
@article{HAQUE2026108611,
title = {Generative artificial intelligence and large language models in smart healthcare applications: Current status and future perspectives},
journal = {Computational Biology and Chemistry},
volume = {120},
pages = {108611},
year = {2026},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2025.108611},
url = {https://www.sciencedirect.com/science/article/pii/S1476927125002725},
author = {Md. Asraful Haque and Hifzur R. Siddique},
keywords = {Generative AI, LLM, Healthcare applications, Ethical concern, Bias in AI models},
abstract = {With climate change, habitat destruction, and increased population ages, the incidence of both communicable and non-communicable diseases is rising, and managing these has become a growing concern. In recent years, generative artificial intelligence (AI) and large language models (LLMs) have ushered in a transformative era for smart healthcare applications. These models, built on advanced ML architectures like Generative Pre-trained Transformers (GPT) and Bidirectional Encoder Representations from Transformers (BERT), have demonstrated significant capabilities in various medical tasks. This review aims to provide an overview of the potential benefits of generative AI and LLMs in smart healthcare applications, as well as challenges and ethical considerations. A systematic literature review was conducted to identify relevant research papers published in peer-reviewed journals. Databases such as PubMed, PMC, Cochrane Library, Google Scholar, and Web of Science were searched using keywords related to generative AI, LLMs, and healthcare applications. The relevant papers were analyzed to extract key findings and contributions. Generative AI and LLMs are powerful tools that can process and analyze massive amounts of data. Researchers are actively exploring their potential to transform healthcare-powering intelligent virtual health assistants, crafting personalized patient care plans, and facilitating early detection and intervention for medical conditions. With ongoing research and development, the future of generative AI and LLMs in healthcare is promising; however, issues such as bias in AI models, lack of explainability, ethical concerns, and integration difficulties must be addressed.}
}
@article{HOURI2025102040,
title = {Evaluating Knowledge Gaps in Cardio-Obstetrics: A Comparative Analysis of Cardiologists, Obstetricians, and Generative Artificial Intelligence},
journal = {JACC: Advances},
volume = {4},
number = {8},
pages = {102040},
year = {2025},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2025.102040},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X25004648},
author = {Ohad Houri and Nili {Schamroth Pravda}}
}
@article{XIA2026105465,
title = {A systematic literature review on designing self-regulated learning using generative artificial intelligence and its future research directions},
journal = {Computers & Education},
volume = {240},
pages = {105465},
year = {2026},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105465},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525002337},
author = {Qi Xia and Qian Liu and Ahmed Tlili and Thomas K.F. Chiu},
keywords = {Generative artificial intelligence, Self-regulated learning, Forethought, Performance, Self-reflection, Systematic review},
abstract = {A growing body of research suggests that generative AI (GenAI) can significantly enhance self-regulated learning (SRL) through its immediacy and interactivity. Nevertheless, challenges remain, including the lack of clarity regarding the mechanisms by which generative AI influences SRL, as well as the difficulties teachers encounter when trying to incorporate it into their classrooms. This systematic review study investigates how to design SRL activities using GenAI. We examined 73 articles published over the past five years, drawn from four databases: Web of Science, ProQuest, ERIC, and Scopus. This study has three major empirical findings. First, six pedagogical affordances from GenAI across the three phases of SRL—forethought, Performance, and self-reflection—are (i) creating personalized learning objectives; (ii) searching for, analyzing, and integrating resources; (iii) monitoring and evaluating progress; (iv) recommending learning strategies; (v) recording progress and providing feedback; and (vi) generating new ideas and examples. Second, popular student learning activities using GenAI in each phase are information searching in the forethought; strategies for problem-solving in the performance, and obtaining feedback and conducting self-assessments in the self-reflection. Third, two major dimensions influencing student engagement in SRL using GenAI are individual and environmental. Finally, we visualize how the three empirical findings relate to each other. Our findings help us understand how AI as a human-machine collaborative tool affects the SRL process. This study provides practical recommendations for facilitating SRL in GenAI-enhanced environments and offers guidance for the design and development of personalized GenAI learning tools.}
}
@article{OSTICK2025e1296,
title = {The use of generative artificial intelligence (AI) in nursing education},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {4},
pages = {e1296-e1301},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725001799},
author = {Mollie Ostick and Bette Mariani and Catherine Lovecchio},
keywords = {AI literacy, Artificial intelligence (AI), Ethical implications, Generative chatbots, Nursing education, Personalized learning},
abstract = {Background
Generative artificial intelligence (AI) tools such as ChatGPT and Gemini are increasingly used in higher education, including nursing, with the potential to transform content delivery and student engagement. However, their use and broader implications in nursing education remain underexplored.
Innovation
This paper synthesizes current literature on generative AI in nursing education, focusing on applications such as AI-generated NCLEX-style questions, automated feedback on assignments, and simulation scenario development. It highlights AI’s potential to support personalized learning, enhance efficiency, and assist faculty, while also identifying key research gaps and ethical concerns.
Implications
By outlining benefits and challenges, this paper offers a foundation for responsible integration and emphasizes the need to prepare faculty and students for its ethical and effective use.
Conclusions
As AI becomes more embedded in nursing education, ongoing evaluation is essential to ensure it enhances learning, supports faculty, and aligns with nursing’s professional values.}
}
@article{SHEN2026119,
title = {Prevalence and Characteristics of Generative Artificial Intelligence Policies in Vascular Surgery Journals: A Cross-Sectional Review},
journal = {Annals of Vascular Surgery},
volume = {123},
pages = {119-129},
year = {2026},
issn = {0890-5096},
doi = {https://doi.org/10.1016/j.avsg.2025.09.056},
url = {https://www.sciencedirect.com/science/article/pii/S0890509625006624},
author = {Fanru Shen and Victor F.A. Almeida and John Y. Ha and Berk B. Ozmen and Eliana F.R. Duraes},
abstract = {Background
The integration of generative artificial intelligence (GenAI) into academic publishing presents new opportunities and ethical challenges. Transparent editorial oversight is essential, yet the extent of GenAI policy adoption among vascular surgery journals remains unclear.
Methods
We conducted a cross-sectional review of vascular surgery journals indexed in the 2024 Scimago Journal Rank and Google Scholar Metrics. Eligible journals were active, peer-reviewed titles regularly publishing vascular surgery research. As of June 12, 2025, 2 independent reviewers assessed author instructions, journal websites, and publisher policies for GenAI-related guidance. Extracted variables included permitted GenAI applications (e.g., language editing, image generation), disclosure requirements, authorship restrictions, naming of specific tools, and human accountability clauses. Journal characteristics—geographic origin, Scimago Journal Rank quartile, and H-index—were also recorded. Descriptive statistics and Welch's t-tests were used for analysis.
Results
Of 25 journals evaluated, 18 (72%) had explicit GenAI editorial policies. All prohibited attributing authorship to artificial intelligence (AI) tools and emphasized human responsibility. Nineteen journals (76%) required disclosure of GenAI use, but only 14 (56%) specified disclosure location. Thirteen (52%) addressed AI-generated images. Journals permitting GenAI-assisted language editing had significantly higher H-indices (70.2 vs. 20.7; P = 0.0167). Scimago Journal Rank Q1/Q2 journals demonstrated more comprehensive policies than lower-tier journals (6.8 vs. 4.0 elements; P = 0.0094). US- and UK-based journals led in policy specificity.
Conclusion
While GenAI policies are increasingly present in vascular surgery journals, inconsistencies persist. Standardized, enforceable editorial guidance is needed to ensure ethical and transparent integration of GenAI into scholarly publishing.}
}
@article{CHAN2025101795,
title = {Strategies to incorporate generative artificial intelligence in simulation-based education among undergraduate students of healthcare professions: A scoping review},
journal = {Clinical Simulation in Nursing},
volume = {106},
pages = {101795},
year = {2025},
issn = {1876-1399},
doi = {https://doi.org/10.1016/j.ecns.2025.101795},
url = {https://www.sciencedirect.com/science/article/pii/S1876139925001124},
author = {Jackie Hoi Man Chan and Ken Hok Man Ho and Jacqueline Maria Dias},
keywords = {Generative artificial intelligence, Integration, Review, Simulation, Strategies, Undergraduate},
abstract = {Background
Complex prompting and unreadiness among faculty and students are some of the reported challenges when incorporating generative artificial intelligence (GenAI) into simulation-based education (SBE) in undergraduate healthcare programmes. However, strategies for incorporating GenAI into SBE are unclear. This scoping review identified current evidence on GenAI technology, its role, study outcomes, and strategies to incorporate GenAI into the SBE of undergraduate healthcare programmes.
Methods
The Joanna Briggs Institute methodology for scoping reviews was adopted. Eight electronic databases were searched from inception to January 21, 2025. Two authors independently screened and extracted data. The PAGER framework collated, critiqued, and reported the results.
Results
Eight studies were included. ChatGPT was the most frequently employed GenAI technology in SBE of undergraduate healthcare programmes, to enhance the students’ cognitive and affective learning. Study outcomes focused on usability. Five core strategies were synthesized: (a) establish guidelines on GenAI use; (b) enhance GenAI literacy; (c) enhance competency in GenAI prompting in simulation; (d) ensure pedagogical alignment; and (e) conduct pilot tests.
Conclusions
The findings provide insights into GenAI integration in SBE in undergraduate healthcare programmes. Further studies on the benefits of GenAI when applied to SBE are needed to demonstrate its impact on student learning.}
}
@article{SIAH202645,
title = {Authenticity and academic integrity in Generative Artificial Intelligence (GenAI) use among undergraduate nursing students},
journal = {Journal of Professional Nursing},
volume = {62},
pages = {45-51},
year = {2026},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2025.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S8755722325001668},
author = {Chiew-Jiat Rosalind Siah and Junwei Vincent Lim and Meng Meng Lyu and Tracy Levett-Jones and Ihsan Mattar},
keywords = {Ethics, Generative Artificial Intelligence (GenAI), Education, Students, Nursing},
abstract = {Background
The use of large Generative Artificial Intelligence (GenAI) in higher education is reshaping how students learn. While GenAI offers significant benefits and the potential to improve education, it also poses ethical challenges and may affect students' ability to identify learning gaps and engage with course content.
Purpose
This study aims to explore students' experiences with GenAI related to academic integrity and the authenticity of work, including their awareness and attitudes toward acceptable use.
Method
This study employed a qualitative descriptive approach. The participants were recruited from the Bachelor of Science (Nursing) program in an academic university during the period October 2024 to January 2025.
Results
Fourteen undergraduates in their second- and third-year of study participated in group interviews. The qualitative data analysis revealed five key themes: 1) integration with learning, 2) trust and credibility of GenAI information, 3) ethical considerations, 4) addressing academic integrity, and 5) guidance on using GenAI.
Conclusion
These five key themes underscore the need to better understand the role of GenAI in higher education, particularly in self-directed learning and managing learning activities. With regards to academic integrity, clear guidelines must be put in place for educators to guide the use of GenAI, emphasizing its use as an instrument to augment, and not replace original work.}
}
@article{LI2025100820,
title = {Elevating entrepreneurship with generative artificial intelligence},
journal = {Journal of Innovation & Knowledge},
volume = {10},
number = {6},
pages = {100820},
year = {2025},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2025.100820},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X25001659},
author = {Yaojie Li and John Kirk Ring and Dan Jin and Saleh Bajaba},
keywords = {Entrepreneurship, Information gathering, Information foraging, Generative artificial intelligence, Prompt engineering},
abstract = {Generative artificial intelligence (GenAI) transforms the entrepreneurial landscape by providing contextual information, identifying viable opportunities, and facilitating entrepreneurial decision-making. Despite the growing acknowledgment of its use in entrepreneurial activities, this field lacks a robust theoretical framework and practical implementation. This study seeks to fill this gap by drawing on information behavior literature to explore the effect of GenAI across the entrepreneurial spectrum. By leveraging large language models and prompt engineering patterns, we examined how GenAI could generate accurate, relevant, and inspiring content through various interaction scenarios. Our findings suggest that GenAI significantly mitigates early-stage entrepreneurial information asymmetry and supports sophisticated problem-solving when coupled with appropriate domain knowledge and prompt engineering techniques. However, GenAI’s task complexity limits its use in late-stage entrepreneurial exploitation activities. Finally, this study provides insight into research avenues and practical applications.}
}