@article{STIDHAM2025432,
title = {Artificial Intelligence–Enabled Clinical Trials in Inflammatory Bowel Disease: Automating and Enhancing Disease Assessment and Study Management},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {432-443},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.02.039},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525005414},
author = {Ryan W. Stidham and Louis R. Ghanem and Joel G. Fletcher and David H. Bruining},
keywords = {Artificial Intelligence, Inflammatory Bowel Disease, Crohn's Disease, Ulcerative Colitis, Computer Vision, Automation, Large Language Models, Natural Language Processing, Digital Twin},
abstract = {Artificial intelligence (AI) will fundamentally improve how we perform clinical trials by addressing issues of standardizing disease scoring, improving the sensitivity and precision of activity and phenotype assessments, and automating laborious and time-consuming study functions. Progress in AI image analysis is quickly proving to replicate expert judgment in endoscopy, histology, and cross-sectional imaging with speed, reproducibility, and reduced bias. However, AI analytics offer the ability to quantify disease characteristics with more detail and precision than human experts. Large language models and generative AI are automating the collection of high-quality data from electronic records and improving our ability to predict patient outcomes. This narrative review will focus on AI tools available today, their expected implementation, and future-facing opportunities for AI to reimagine inflammatory bowel disease clinical trials.}
}
@article{LIU2025682,
title = {Interactive Design of Dynamic Visual Communication Driven by Artificial Intelligence Algorithms},
journal = {Procedia Computer Science},
volume = {261},
pages = {682-690},
year = {2025},
note = {The 5th International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy (SPIoT2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.321},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925014231},
author = {Shen Liu and Li Ding},
keywords = {Dynamic visual communication design, artificial intelligence algorithm, spatial attention mechanism, channel attention mechanism, generative adversarial network},
abstract = {Dynamic visual communication design usually needs to process multimodal information. How to effectively integrate these multi-dimensional features and establish stable associations between different modalities remains a technical challenge. To this end, this article explores the application of artificial intelligence algorithms, especially spatial attention and channel attention mechanisms, in dynamic image and video generation to achieve more accurate semantic consistency between text and images. This article introduces a spatial attention mechanism, which dynamically focuses on the spatial area related to the text description by calculating the similarity between text and image features; at the same time, the channel attention mechanism further optimizes the match with the text description by adjusting the channel weights in the image feature map. In addition, the study introduces user interaction design, and users can influence the generation target of the generator through real-time feedback and adjustment, making it more personalized and in line with needs. The optimization process of the generator and the discriminator further improves the realism and quality of dynamic image and video generation through GAN (Generative Adversarial Network). Experiments show that the proposed method can effectively enhance the semantic consistency in the image generation process and provide new technical support for dynamic visual communication design.}
}
@article{LIU2026124387,
title = {How does artificial intelligence adoption shape employee performance? A novel exploration of mimetic artificial intelligence performance through a hybrid approach based on PLS-SEM and ANN},
journal = {Technological Forecasting and Social Change},
volume = {222},
pages = {124387},
year = {2026},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124387},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525004184},
author = {Shengmin Liu and Yu Mei},
keywords = {Artificial intelligence adoption at work, Employee problem-solving efficacy, Employee learning from artificial intelligence, Adaptive performance, Mimetic artificial intelligence performance, ANN},
abstract = {Within the context of Industry 5.0 and digital transformation, the rapid advancement of information technology has rendered artificial intelligence ubiquitous, presenting significant challenges and opportunities for the workforce. This study employs a hybrid Partial Least Squares Structural Equation Modeling (PLS-SEM) and Artificial Neural Network (ANN) approach to investigate employee performance within artificial intelligence-adoption work environments. Utilizing a three-wave experience sampling methodology, we collected 308 valid questionnaires from employees in Chinese internet companies. Our findings demonstrate that artificial intelligence adoption at work positively associated with employees' problem-solving efficacy, which in turn influences adaptive performance. Furthermore, stronger artificial intelligence adoption at work is associated with an increased employees' mimetic artificial intelligence performance through employee learning from artificial intelligence. Task-oriented leadership amplifies the effects of artificial intelligence adoption at work on both problem-solving efficacy and adaptive performance. Conversely, knowledge-oriented leadership strengthens the relationship between artificial intelligence adoption at work and employee learning from artificial intelligence, thereby developping mimetic artificial intelligence performance. This research contributes by introducing and measuring the novel concept of “mimetic artificial intelligence performance,” extending the application of social comparison, learning and influence theories. The study offers valuable theoretical insights and practical implications for understanding and optimizing employee performance in artificial intelligence-driven workplaces.}
}
@article{GUNTUKA2025215,
title = {Generative AI in minimizing cyber-attacks: Developing the Vehicular Threat Intelligence Flowchart},
journal = {Procedia Computer Science},
volume = {257},
pages = {215-224},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925007665},
author = {Sony Guntuka and Elhadi Shakshuki and Haroon Malik},
keywords = {Cyber attacks, GenAI, Vehicular Networks, Cybersecurity, Threat Detection},
abstract = {This paper delves into the innovative applications of Generative Artificial Intelligence (GenAI) in enhancing the cybersecurity of vehicular networks, a critical area given the increasing integration of intelligent transport systems and autonomous vehicles. As vehicular networks become more sophisticated, they also become more susceptible to cyber-attacks that can compromise vehicle control systems, endangering public safety and personal privacy. GenAI offers advanced capabilities for automating defences, improving threat intelligence, and creating dynamic security frameworks that can adapt to emerging threats. This research is a comprehensive overview of the current state of GenAI in the context of vehicular network cybersecurity, highlighting the development and implementation of the Vehicular Threat Intelligence Flowchart (VTIF). The VTIF features a threat detection rule algorithm that automates the identification of cyber threats, significantly improving detection accuracy. While the integration of GenAI presents substantial benefits, it also introduces new risks, necessitating robust ethical, legal, and technical oversight. This paper outlines the potential advantages and challenges of employing GenAI in vehicular cybersecurity and proposes future research directions aimed at developing resilient and ethical cybersecurity mechanisms.}
}
@article{ACAMPORA2026100807,
title = {Quantum artificial intelligence: A survey},
journal = {Computer Science Review},
volume = {59},
pages = {100807},
year = {2026},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100807},
url = {https://www.sciencedirect.com/science/article/pii/S1574013725000838},
author = {Giovanni Acampora and Angela Chiatto and Roberto Schiattarella and Autilia Vitiello},
keywords = {Artificial intelligence, Quantum computing, Quantum artificial intelligence},
abstract = {Quantum computing and artificial intelligence are two highly topical fields of research that can benefit from each other’s discoveries by opening a completely new scenario in computation, that of quantum artificial intelligence. Indeed, on the one hand, artificial intelligence algorithms can be made computationally more efficient due to the potential speedup enabled by quantum phenomena; on the other hand, the complex development of quantum computing technologies and methodologies can be properly supported by the use of classical artificial intelligence approaches. The “entanglement” of these two disciplines is opening up completely new directions in computer science research, and this survey aims to provide a systematic and taxonomic overview of the work that has already been done and that which will begin in the near future.}
}
@article{YAO2025100100,
title = {Artificial Intelligence for Sustainable Architectural Design},
journal = {Nexus},
pages = {100100},
year = {2025},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2025.100100},
url = {https://www.sciencedirect.com/science/article/pii/S2950160125000476},
author = {Jiawei Yao and Yixin Jian and Chenyu Huang and Liang Yuan and Jiahong Ye and Zewei Shi and John Kaiser Calautit and Shen Wei and Xi Deng and Tim Broyd and Qingrui Minyag Jiang and Philip F. Yuan},
keywords = {Artificial Intelligence, Sustainable Building, Architectural Design, Systematic Review},
abstract = {Amid global challenges of resource depletion, climate risk, and urban health inequality, Artificial Intelligence for Sustainable Architectural Design (AI4SAD) has become a key driver of the shift from experience-based to intelligence-driven design. Drawing on a systematic review of 408 studies, this work is the first to map the global spatiotemporal profile of AI4SAD across design stages, sustainability goals, and algorithmic applications. The findings indicate a significant transparency deficit: only a few studies disclose data sources, model parameters, or performance gains. This gap constrains reproducibility, cross-scenario transfer, and cumulative knowledge. We propose a three-stage development framework and identify an ongoing transition from Level 2 (specialized models) to Level 3 (foundation models). Furthermore, a roadmap is established to guide future advancements in generalizability, autonomy, and interpretability, promoting the responsible application of AI in sustainable architectural design.}
}
@article{PUCHADES202523,
title = {Artificial intelligence in clinical practice: Quality and evidence},
journal = {Revista Clínica Española (English Edition)},
volume = {225},
number = {1},
pages = {23-27},
year = {2025},
issn = {2254-8874},
doi = {https://doi.org/10.1016/j.rceng.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2254887424001425},
author = {R. Puchades and L. Ramos-Ruperto},
keywords = {Artificial intelligence, Quality, Evidence, Inteligencia artificial, Calidad, Evidencia},
abstract = {A revolution is taking place within the field of artificial intelligence (AI) with the emergence of generative AI. Although we are in an early phase at the clinical level, there is an exponential increase in the number of scientific articles that use AI (discriminative and generative) in their methodology. According to the current situation, we may be in an “AI bubble” stage; requiring filters and tools to evaluate its application, based on the quality and evidence provided. In this sense, initiatives have been developed to determine standards and guidelines for the use of discriminative AI (CONSORT AI, STARD AI and others), and more recently for generative AI (the CHART collaborative). As a new technology, AI requires scientific regulation to guarantee the efficacy and safety of its applications, while maintaining the quality of care; an evidence-based AI (IABE).
Resumen
Dentro del campo de la inteligencia artificial (IA) se está produciendo una revolución con la aparición de la IA generativa. Si bien estamos en una fase precoz a nivel clínico, se observa un incremento exponencial del número de artículos científicos que utilizan la IA (discriminativa y generativa) en su metodología. De acuerdo con la situación actual, tal vez nos encontremos en una etapa de «burbuja de la IA»; precisando filtros y herramientas para evaluar su aplicación, en base a la calidad y evidencia aportada. En este sentido, se han desarrollado iniciativas para determinar estándares y guías para el uso de IA discriminativa (CONSORT AI, STARD AI y otras), y más recientemente para la IA generativa (the CHART collaborative). Como nueva tecnología, la IA requiere una regulación científica para garantizar la eficacia y seguridad en sus aplicaciones, manteniendo la calidad de la atención; una IA basada en la evidencia (IABE).}
}
@article{SCHWENDICKE2025315,
title = {Artificial Intelligence in Prosthodontics},
journal = {Dental Clinics of North America},
volume = {69},
number = {2},
pages = {315-326},
year = {2025},
note = {Updates in Prosthodontics},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2024.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0011853224000958},
author = {Falk Schwendicke and Hossein {Mohammad Rahimi} and Antonin Tichy},
keywords = {AI, Computer vision, Deep learning, Intraoral scan, Image analysis, Prosthesis}
}
@article{UKWANDU2025103616,
title = {The future of teaching and learning in the context of emerging artificial intelligence technologies},
journal = {Futures},
volume = {171},
pages = {103616},
year = {2025},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2025.103616},
url = {https://www.sciencedirect.com/science/article/pii/S0016328725000783},
author = {Elochukwu Ukwandu and Omobolanle Omisade and Karl Jones and Simon Thorne and Mike Castle},
keywords = {Generative artificial intelligence, Prompt technologies, Artificial intelligence, ChatGPT, AI-Agents, Future of teaching and learning, Emerging AI disruptive technologies},
abstract = {In the context of emerging artificial intelligence technologies (AI) such as AI-Bots (ChatGPT) and AI-Agents, it is imperative that adequate adjustment be made, and also seen to be made. However, this has to be done from an informed positions. There is no doubt that these disruptive technologies are changing the way we live, conduct our day-to-day businesses, teach, learn and conduct research. There are also emerging concerns that these dynamics may result in a paradigm shift from student-teacher relationship to student-AI-Tutor-based relationship within the academic circle. Besides, there are foreseeable dangers of compromising academic integrity through high-technology plagiarism and the potentials of students avoiding learning through AI deployment and utilisation in their academic pursuits. But something worth considering is how applying these tools in education will potentially change the entire classroom experience of students, their knowledge and skills outcomes that are relevant in this AI era. This position paper is an effort to put into context what the authors of this paper forecast as the future of teaching and learning in the context of these inevitable disruptions to education activities and its subsectors as we currently know it. The authors found it necessary to take these positions to help bring to fore some practical use cases of AI in education; recent developments and theoretical frameworks in literature, technical reports, as well as experts opinions that can help assuage stakeholder’s concerns despite some obvious existing challenges. It is our view that this paper will be found useful by educators, stakeholders and administrators in the areas of curriculum design, classroom administration and entire academic planning and reviews.}
}
@article{MATOS2025100571,
title = {A systematic review of artificial intelligence applications in education: Emerging trends and challenges},
journal = {Decision Analytics Journal},
volume = {15},
pages = {100571},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100571},
url = {https://www.sciencedirect.com/science/article/pii/S277266222500027X},
author = {Tomás Matos and Walter Santos and Eftim Zdravevski and Paulo Jorge Coelho and Ivan Miguel Pires and Filipe Madeira},
keywords = {Artificial intelligence, ChatGPT, Educational technology, Machine learning, Adaptive learning, Systematic review},
abstract = {The academic world is becoming increasingly interested in the applications of Artificial Intelligence technology in education. A systematic review examines AI applications in education, focusing on their effectiveness, challenges, and implications. A comprehensive analysis of studies published between 2011 and 2024 encompassed 45 research articles from major databases, such as PubMed Central, IEEE Xplore, Elsevier, Springer, MDPI, ACM, and PMC. The findings highlight the predominant use of generative AI tools like ChatGPT (30%), followed by other advanced technologies, such as GPT-4, machine learning, and virtual reality. Research across global regions, particularly in Canada (18%), the United States (12%), and China (8%), highlights the multifaceted applications of AI in enhancing personalized learning, fostering critical thinking, and supporting professional education. Tools such as ChatGPT have demonstrated strong performance in theoretical knowledge delivery and medical education, while augmented and virtual reality excels in practical skill development. Despite these advances, challenges such as data privacy concerns, algorithmic bias, and the need for specialized educator training remain critical.}
}
@article{LI2025100023,
title = {A review of data science and artificial intelligence applications in air transportation systems},
journal = {Artificial Intelligence for Transportation},
volume = {2},
pages = {100023},
year = {2025},
issn = {3050-8606},
doi = {https://doi.org/10.1016/j.ait.2025.100023},
url = {https://www.sciencedirect.com/science/article/pii/S3050860625000237},
author = {Lishuai Li},
keywords = {Artificial intelligence, Data science, Air transportation, Air traffic management, Airline operations, Airport management, Aviation safety, Sustainability},
abstract = {The air transportation system is a critical component of global infrastructure, moving passengers and cargo worldwide. Rising traffic volumes and operational complexity have driven the evolution of analytical methods in aviation: from early rule-based automation through mechanism-based models (simulations, digital twins), operations research (optimization, statistics) and data-driven approaches (machine learning, deep learning) to emerging autonomous systems (generative AI, agentic AI). This review examines data science and artificial intelligence (AI) applications that address specific aviation challenges and demonstrate measurable operational improvements. We analyze implementations in airline management, airport operations and air traffic management, identifying performance gains that include reduced delays, improved aircraft utilization, lower maintenance costs, and improved safety metrics. However, AI deployment faces technical barriers including legacy system integration and data standardization, along with regulatory and ethical challenges that include certification processes, data privacy, and liability frameworks for automated decision making. Future research priorities could focus on developing robust AI systems that meet aviation’s stringent safety and reliability standards, advancing AI-enabled sustainability through integrated design and operational optimization, and establishing frameworks for novel air transportation systems, including urban air mobility and autonomous flight operations.}
}
@article{KOX2025105817,
title = {Perceptions, hopes, and concerns regarding the possibilities of artificial intelligence in weather warning contexts},
journal = {International Journal of Disaster Risk Reduction},
volume = {130},
pages = {105817},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2025.105817},
url = {https://www.sciencedirect.com/science/article/pii/S2212420925006417},
author = {Thomas Kox and Sara Harrison and Ferdinand Ziegler and Lars Gerhold},
keywords = {Human-AI collaboration, Delphi, Risk communication, Weather forecasting, Warning systems},
abstract = {Artificial intelligence (AI) is increasingly used in disaster risk reduction, including early warning systems (EWS) for weather hazards. While AI promises faster data processing and improved forecast accuracy, concerns remain about automation bias, reduced human oversight, or accountability, and erosion of professional judgment. Despite rapid technological advances, the perceptions of the weather warning community remain underrepresented in current research. To address this, we conducted an Argumentative Delphi study with experts from the 2024 WMO HIWeather Final Conference. Participants assessed AI's impact on 13 key aspects of weather warnings – including quality, interpretability, accountability, and social bias – and shared hopes and concerns. Overall, participants expressed cautious optimism. AI is expected to improve the goodness of warnings, potentially cascading into broader dimensions of warning efficacy, public trust, and institutional responsibility. However, concerns include over-reliance on AI, erosion of human involvement, and challenges in maintaining a single authoritative voice in warning communication. Rather than viewing AI as replacement for human decision-making, it is seen as decision-support tool that augments professional expertise. Tailored warnings and multilingual communication emerged as promising areas for AI application, though issues of data bias and accessibility remain. Thus, ethical implementation is vital to ensure inclusiveness and alignment global disaster risk reduction goals. Finally, the introduction of AI touches the ‘professional core’ of weather warning as an occupation and prompts experts to define their evolving roles and core competencies in the face of technological advancements. Future research should explore how generative AI may reshape forecasting and the profession itself.}
}
@article{LEITE2025124115,
title = {Artificial intelligence in higher education: Research notes from a longitudinal study},
journal = {Technological Forecasting and Social Change},
volume = {215},
pages = {124115},
year = {2025},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2025.124115},
url = {https://www.sciencedirect.com/science/article/pii/S0040162525001465},
author = {Higor Leite},
keywords = {Generative artificial intelligence, Higher education, Innovation, Technology, Transformative service research},
abstract = {Generative artificial intelligence (GenAI) has disrupted traditional educational approaches. Students are applying GenAI tools to access and create new content. However, the emergence of GenAI in higher education comes with caveats and academics and university administrators are learning to navigate this uncharted territory. GenAI is treated as a double-edged sword, with several benefits, such as innovation and productivity, but also drawbacks regarding ethics and academic misconduct. Therefore, our study aims to understand the impact of GenAI on students' experiences in the higher education ecosystem as students move to a new AI-enhanced job market. This research note article presents preliminary results from a 12-month longitudinal study with students interacting with GenAI. We conducted 35 semi-structured interviews and collected private diary entries (n = 108). Our results show six meaningful themes: Harnessing AI for Enhanced Academic Performance, AI Ethics and Trust Impact on Learning, GenAI as a Supplement to Human Work, Integration and Versatility of GenAI Tools, Balancing GenAI Limitations, and Navigating the AI Adoption Journey. The study also uses the transformative service research lens to present the transformative impact of GenAI in higher education. To contribute to practice and policymakers, we designed a research agenda to inform future studies on GenAI.}
}
@article{SPIEGLER2026103109,
title = {Images of AI: How AI practitioners view the impact of Artificial Intelligence on society, now and in the future},
journal = {Technology in Society},
volume = {84},
pages = {103109},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103109},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002994},
author = {Simone Spiegler and Rashina Hoda and Aastha Pant},
keywords = {Artificial intelligence, AI, Societal impact, Human control, Future, Responsible AI, Large language models, LLMs, AI practitioners, Images, AI psychosis, Generative AI, Agentic AI},
abstract = {Despite unprecedented technological advancement, intense commercial investment, international agreements, and growing societal concerns with Artificial Intelligence (AI), there is little insight into how those driving the field – the everyday AI practitioners – perceive AI and its impact on society, now and in the future. We address this critical gap by conducting a broad-based survey with 100 AI practitioners, followed by in-depth interviews with 20 AI practitioners, including developers, managers, and consultants. Using socio-technical grounded theory (STGT) for data analysis, we inductively identified six images of AI which capture six ways in which AI practitioners view AI, now and in the future, and their implications for impact on society and human control: Parrot captures AI that mimics human behaviour, including biases; Companion surrounds humans in daily life and supports decision making with empathy-like traits; Wolf in Sheep’s Clothing highlights AI misused by humans, causing societal harms; Saviour envisions AI solving complex problems beyond human capacity; Wizard portrays AI as powerful, yet, unpredictable and inexplicable; and Pinocchio imagines AI as gaining free will, learning from mistakes, and possibly harming humans. These images of AI provide a novel framework for understanding how AI practitioners perceive and shape AI solutions. Our findings and recommendations will assist AI practitioners, companies, and users with a shared vocabulary and understanding to explicitly and critically examine the intended and unintended impacts of AI solutions on human society, contributing to more responsible and human controlled AI design and use.}
}
@article{ARADYA20251749,
title = {Artificial intelligence for maxillofacial prosthodontics: A technological shift in craniofacial rehabilitation- a scoping review},
journal = {Journal of Oral Biology and Craniofacial Research},
volume = {15},
number = {6},
pages = {1749-1766},
year = {2025},
issn = {2212-4268},
doi = {https://doi.org/10.1016/j.jobcr.2025.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S2212426825002490},
author = {Anupama Aradya and Koduru Sravani and M.B. Ravi and K.N. {Raghavendra Swamy} and S. Ganesh and K. {Pradeep Chandra} and H.K. Sowmya and B.V. Jayashankar and Nisarga {Vinod Kumar} and K.M. Sangeeta},
keywords = {Artificial intelligence, Maxillofacial prosthesis, CAD/CAM, Deep learning, Digital dentistry, Facial rehabilitation},
abstract = {Introduction
Artificial intelligence (AI) transforms dentistry and holds considerable promise for maxillofacial prosthodontics (MFP). Applications in imaging, computer-aided design and manufacturing (CAD/CAM), and additive manufacturing are improving diagnosis, treatment planning, and prosthetic rehabilitation for patients with craniofacial abnormalities. Despite advances in materials and digital workflows, challenges remain in achieving optimal accuracy, efficiency, and customisation in prosthetic design. The integration of AI in maxillofacial prosthodontics is still in its early stages. Currently, there is no review detailing the scope, trends, potential, and limitations of AI in this field. A scoping review is therefore necessary to consolidate existing evidence, identify knowledge gaps, and suggest directions for future research and clinical application. This review objective is to systematically map and analyse the current literature on AI in maxillofacial prosthodontics, focusing on its role in craniofacial rehabilitation.
Methods
This scoping review adhered to the methodological framework of Arksey and O'Malley (2005) and was guided by the Joanna Briggs Institute (JBI) Manual for Evidence Synthesis (2020). Reporting complied with PRISMA-ScR (Preferred Reporting Items for Systematic reviews and Meta-Analyses extension for Scoping Reviews) guidelines to ensure clarity and reproducibility. The review was registered with the Open Science Framework (registration number: www.osf.io/3b9jr). Electronic databases, including Medline via PubMed, Scopus, Cochrane Database, Science Direct, Google Scholar, and Semantic Scholar, were searched up to 7 June 2025. Full-text English articles containing the keywords “Artificial Intelligence and Maxillofacial Prosthodontics” and related terms were included.
Results
This scoping review included 35 articles from diverse geographic regions. The studies addressed several specific applications of AI in maxillofacial prosthodontics, including the production of implant-supported auricular prostheses, coloration of maxillofacial prostheses, evaluation of facial attractiveness in patients with clefts, capture of 3D impressions of cleft palates, identification of hypernasality, assessment of lip symmetry, and detection of teeth in cleft lip and palate cases.
Conclusion
Artificial intelligence offers significant opportunities for maxillofacial prosthodontics, especially in imaging, digital design, and prosthesis production. Progress in this area requires interdisciplinary teamwork, large-scale clinical trials, and the development of standardized validation methods to ensure safe and effective clinical application.}
}
@article{OZTURK2025216,
title = {Artificial intelligence as author: Can scientific reviewers recognize GPT-4o-generated manuscripts?},
journal = {The American Journal of Emergency Medicine},
volume = {97},
pages = {216-219},
year = {2025},
issn = {0735-6757},
doi = {https://doi.org/10.1016/j.ajem.2025.07.034},
url = {https://www.sciencedirect.com/science/article/pii/S0735675725004954},
author = {Ahmet Öztürk and Anılcan Tahsin Karahan and Serkan Günay and Abdul Samed Erdal and Seval Komut and Erdal Komut and Yavuz Yiğit},
keywords = {ChatGPT, Artificial intelligence, Journal, Editor, Reviewer},
abstract = {Introduction
Chat Generative Pre-Trained Transformer (ChatGPT) is a natural language processing model. It can be argued that ChatGPT has recently begun to assume the role of a technological assistant capable of supporting academics in the process of scientific writing. ChatGPT may contribute to the spread of incorrect or incomplete information within academic literature, leading to conceptual confusion and potential academic misconduct. The aim of this study is to determine whether a scientific article entirely generated by an AI application such as ChatGPT can be detected by an academic journal editor or peer reviewer.
Methods
This study was conducted between November 1, 2024, and December 1, 2024. GPT-4o, was utilized in this study. ChatGPT was instructed to write a scientific article focused on predicting mortality and return of spontaneous circulation (ROSC) in OHCA cases. The manuscript written by ChatGPT-4o was sent to 14 different reviewers who had previously served as reviewers or editors. The reviewers were asked to evaluate the manuscript as if they were an SCI-E journal editor or peer reviewer. The reviewers were informed that the article had been written by ChatGPT and were asked whether they had identified this during their review.
Results
Among the reviewers, 42.9 % (n = 6) decided to reject the manuscript at the editorial stage, whereas another 42.9 % (n = 6) opted to forward it to a peer reviewer. During the peer review stage, 42.9 % (n = 6) of the reviewers recommended rejection, while 28.6 % (n = 4) suggested major revisions. 78.6 % (n = 11) of the reviewers did not realize that the manuscript had been generated by an artificial intelligence model.
Conclusion
The findings of our study highlight the necessity for journal editors and peer reviewers to be well-informed about ChatGPT and to develop systems capable of identifying whether a manuscript has been written by a human or generated by artificial intelligence.}
}
@article{KING2025,
title = {The Promise and Perils of Artificial Intelligence in Advancing Participatory Science and Health Equity in Public Health},
journal = {JMIR Public Health and Surveillance},
volume = {11},
year = {2025},
issn = {2369-2960},
doi = {https://doi.org/10.2196/65699},
url = {https://www.sciencedirect.com/science/article/pii/S2369296025000365},
author = {Abby C King and Zakaria N Doueiri and Ankita Kaulberg and Lisa {Goldman Rosas}},
keywords = {digital health, artificial intelligence, community-based participatory research, citizen science, health equity, societal trends, public health, viewpoint, policy makers, public participation, information technology, micro-level data, macro-level data, LLM, natural language processing, machine learning, language model, Our Voice},
abstract = {Current societal trends reflect an increased mistrust in science and a lowered civic engagement that threaten to impair research that is foundational for ensuring public health and advancing health equity. One effective countermeasure to these trends lies in community-facing citizen science applications to increase public participation in scientific research, making this field an important target for artificial intelligence (AI) exploration. We highlight potentially promising citizen science AI applications that extend beyond individual use to the community level, including conversational large language models, text-to-image generative AI tools, descriptive analytics for analyzing integrated macro- and micro-level data, and predictive analytics. The novel adaptations of AI technologies for community-engaged participatory research also bring an array of potential risks. We highlight possible negative externalities and mitigations for some of the potential ethical and societal challenges in this field.}
}
@article{ABBAS2025101551,
title = {Management accounting and artificial intelligence: A comprehensive literature review and recommendations for future research},
journal = {The British Accounting Review},
pages = {101551},
year = {2025},
issn = {0890-8389},
doi = {https://doi.org/10.1016/j.bar.2025.101551},
url = {https://www.sciencedirect.com/science/article/pii/S0890838925000010},
author = {Khalid Abbas},
keywords = {Artificial intelligence, Machine learning, Explainable AI, Management accounting, Large language models, Digitalization},
abstract = {Digitalization and artificial intelligence (AI) technologies have the potential to disrupt and transform the management accounting domain and the role of accountants. The study systematically reviews 91 articles, synthesizing scholarly work on digitalization, AI, machine learning (ML), deep learning (DL), explainable AI, generative AI, and large language models (LLMs) in management accounting. In this context, the value of the paper is multi-fold. First, we argue that these technologies transform accounting information and organizational structures, affecting the accounting function's relationship with other organizational functions. Second, they present new challenges for management accountants, including data privacy, confidentiality, security and ethical concerns. Third, digital technologies automate basic accounting tasks and decision-making processes, potentially reshaping management accountants' roles and skills in terms of job elimination, upskilling, deskilling and reskilling. Fourth, these technologies create new opportunities for multidisciplinary collaboration and redefine professional boundaries. This paper contributes by discussing the impact of digitalization and the latest AI technologies on management accounting, illustrating how they can create business value, and highlighting associated challenges and risks for the profession. It proposes research agendas and potential research questions for future studies, providing insight into the potential impacts and implications for the accounting profession and the role of accountants.}
}
@article{JOBSTREIBIZER2025372,
title = {The impact of artificial intelligence on business models: a bibliometric-systematic literature review},
journal = {Management Decision},
volume = {63},
number = {13},
pages = {372-396},
year = {2025},
issn = {0025-1747},
doi = {https://doi.org/10.1108/MD-10-2024-2309},
url = {https://www.sciencedirect.com/science/article/pii/S0025174725000084},
author = {Joshua Jobstreibizer and Tatiana Beliaeva and Marcos Ferasso and Sascha Kraus and Andreas Kallmuenzer},
keywords = {Artificial intelligence, AI, Business models, Bibliometric-systematic literature review, Network analysis},
abstract = {Purpose
This study aims to conduct a bibliometric-Systematic Literature Review’ (B-SLR) to trace the impact of artificial intelligence (AI) on business models (BM). It explores the intellectual structure, key thematic clusters and the evolution of this emerging field, with the aim of identifying current trends and future research directions.
Design/methodology/approach
The analysis covers 87 journal articles retrieved from the Scopus database. It follows the guidelines of a multi-method literature review, combining a bibliometric analysis and a systematic literature review. Co-citation, co-occurrence and timeline analyses were performed to uncover intellectual foundations, map key research areas and track recent developments.
Findings
The study highlights the central role of AI in reshaping BM, particularly in areas such as customer engagement, innovation, sustainability, Industry 4.0 and digitalization. Recent developments emphasize AI’s applications in narrow fields, circular BM and the growing influence of generative AI. A framework of AI adoption in BM is developed, suggesting promising directions for future research.
Research limitations/implications
This study suggests that future research should explore AI’s role in BM more deeply by integrating interdisciplinary perspectives. It highlights the need for more empirical studies on AI-driven innovation and its long-term effects on business strategies, particularly in emerging areas such as generative AI and circular economy models.
Practical implications
This review provides managers with insights into how AI can drive BM innovation and highlights emerging areas of AI applications. It offers a roadmap for integrating AI technologies into BM to gain competitive advantages.
Originality/value
This study provides an up-to-date, comprehensive analysis of AI’s impact on BM, contributing to both academic literature and practical business strategies by synthesizing recent developments and suggesting future research directions.}
}
@article{JEONG2025110855,
title = {Application of Explainable Artificial Intelligence for personalized childhood weight management using IoT data},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110855},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110855},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525012065},
author = {Jaemin Jeong and Ji-Hoon Jeong and Gee-Myung Moon and Young-Duk Seo and Euijong Lee},
keywords = {Healthcare, Shapley additive explanation (SHAP), Tabnet, Explainable artificial intelligence (XAI), Generative adversarial networks (GAN)},
abstract = {Childhood obesity is a growing global health concern as it is correlated with an increased risk of adult-onset and chronic diseases. Recent advances in digital healthcare technologies have enhanced the efficiency of health data analysis and diagnosis, leading to increased interest in artificial intelligence (AI) applications in childhood obesity research; however, several challenges remain, such as data limitations, class-imbalance issues, and difficulties in model interpretability. This study addresses these challenges through a comprehensive framework that utilizes wearable devices for real-time lifestyle data collection and employs Wasserstein generative adversarial networks (WGANs) to address data imbalance concerns. The proposed framework incorporates an explainable model architecture combining tabular attention network (TabNet) with eXtreme Gradient Boosting (XGBoost), complemented by SHapley Additive exPlanations (SHAP) analysis for enhanced interpretability. The framework was validated using data collected from 362 elementary school students over six months, with an additional external validation set of 82 students. The results demonstrated exceptional performance with 98.0% accuracy on the test dataset and 85.2% accuracy on the external validation data. Therefore, the framework can provide personalized health guidance by identifying and explaining individual factors that contribute to weight change, thereby enabling targeted intervention strategies for childhood obesity prevention.}
}
@article{SHARMA2025,
title = {Artificial Intelligence, Machine Learning and Omic Data Integration in Osteoarthritis},
journal = {Osteoarthritis and Cartilage},
year = {2025},
issn = {1063-4584},
doi = {https://doi.org/10.1016/j.joca.2025.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S1063458425011951},
author = {Divya Sharma},
keywords = {Osteoarthritis, Machine learning, Multi-omics, Transcriptomics, Epigenomics, Precision medicine},
abstract = {Objective
Artificial intelligence (AI), particularly its subfield of machine learning (ML), offer promising tools for integrating and interpreting high-dimensional omic data to advance our understanding of osteoarthritis (OA), a complex, multifactorial disease. The objective of this review is to summarize recent progress in applying ML approaches to single and integrative multi-omic data in OA and to highlight emerging trends, challenges, and opportunities.
Method
We conducted a literature search of PubMed and preprint databases upto April 2025. This search identified studies that applied ML techniques including supervised learning, unsupervised clustering, deep learning, and integrative modeling to OA datasets. These datasets included transcriptomic, epigenomic, proteomic, metabolomic, and multi-omic profiles in human OA samples and relevant preclinical models. We synthesized findings across omic types, ML methodologies, and clinical or mechanistic OA outcomes, highlighting key trends in multi-omic integration strategies and their implications for OA research.
Results
Recent studies have applied ML to identify transcriptomic and epigenomic biomarkers, stratify OA patient subtypes, and predict disease progression. Advanced approaches such as variational autoencoders, contrastive learning, and multimodal transformers are emerging as powerful tools for multi-omic integration. However, challenges remain related to small sample sizes, overfitting, lack of external validation, model interpretability, and demographic underrepresentation in omic datasets.
Conclusions
ML techniques are advancing OA research by enabling nuanced analysis of complex omic datasets. Addressing current limitations and embracing new developments in spatial and single-cell omics, generative models, and federated learning will be essential to unlock the full potential of multi-omic integration for personalized OA diagnosis and treatment.}
}
@article{ELSAYED2025518,
title = {Clinical Implementation of Artificial Intelligence in Gastroenterology: Current Landscape, Regulatory Challenges, and Ethical Issues},
journal = {Gastroenterology},
volume = {169},
number = {3},
pages = {518-530},
year = {2025},
note = {Shaping the Future of Gastroenterology and Hepatology With Artificial Intelligence},
issn = {0016-5085},
doi = {https://doi.org/10.1053/j.gastro.2025.01.254},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525005384},
author = {Ahmed El-Sayed and Laurence B. Lovat and Omer F. Ahmad},
keywords = {Endoscopy, Artificial Intelligence, Regulation, Implementation, Gastroenterology},
abstract = {Artificial intelligence (AI) is set to rapidly transform gastroenterology, particularly in the field of endoscopy, where algorithms have demonstrated efficacy in addressing human operator variability. However, implementing AI in clinical practice presents significant challenges. The regulatory landscape for AI as a medical device continues to evolve with areas of uncertainty. More robust studies generating real-world evidence are required to ultimately demonstrate impacts on patient outcomes. Cost-effectiveness data and reimbursement models will be pivotal for widespread adoption. Novel challenges are posed by emerging technologies, such as generative AI. Ethical and medicolegal concerns exist relating to data governance, patient harm, liability, and bias. This review provides an overview for clinical implementation of AI in gastroenterology and offers potential solutions to current barriers.}
}
@article{CHEN2025113575,
title = {Computational design of indoor lighting supported by artificial intelligence: Recent advances and future prospects},
journal = {Building and Environment},
volume = {285},
pages = {113575},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.113575},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325010479},
author = {Peng Chen and Lixiong Wang and Yuting Wu and Zelin Liang and Juan Yu and Tianyi Chen},
keywords = {Interior lighting, Computational design, Artificial intelligence, Generative design},
abstract = {The growing complexity of indoor lighting requirements demands innovative design approaches. AI-supported computational design has demonstrated potential in generating design solutions under complex constraints, yet the lighting society lacks a comprehensive understanding of this approach. Seventy-nine publications were collected for bibliometric analysis. Then a three-domain framework was proposed and reviewed. For lighting environment integration, (deep) neural networks enable analysis of light intensity, spectrum, and spatial distribution patterns through sparse sensors or RGB images. For lighting performance modeling, ML and ANN achieve real-time, personalized, and environment-aware prediction of lighting performance. For lighting design support, heuristic algorithm-dominated systems intelligently generate luminaire layouts, dimming strategies, and spectral compositions while balancing functional, perceptual, and energy-saving objectives. Deep learning demonstrates end-to-end generative capabilities but is limited by data availability. “Perception-as-generation” is proposed as the future direction for computational lighting design, emphasizing responsiveness to the individual and temporal diversity of perceptual needs. A roadmap is proposed to establishing a lighting decision-making pivot centered on large language models. The associated technical challenges and opportunities are outlined too. This research will help practitioners better understand and apply AI, promote interdisciplinary collaboration in the lighting industry, and inspire lighting design paradigm innovation under the "good lighting" vision.}
}
@article{ALKAN2025112033,
title = {Comparison of the performances of artificial intelligence bots using continuous intuitionistic fuzzy evaluation based on distance from average solution method},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112033},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112033},
url = {https://www.sciencedirect.com/science/article/pii/S095219762502041X},
author = {Nurşah Alkan and Umut Aydın and Akın Menekşe and Cengiz Kahraman},
keywords = {Evaluation based on distance from average solution, Continuous intuitionistic fuzzy sets, Multi-criteria decision-making, Artificial intelligence, Chatbot, Chat generative pre-trained transformer},
abstract = {The rapid evolution of artificial intelligence (AI) has introduced novel opportunities and challenges in various fields. In this study, we present a pioneering approach known as Continuous Intuitionistic Fuzzy (CINFU) Evaluation based on Distance from Average Solution (EDAS), an innovative extension of the EDAS method tailored to Continuous Intuitionistic Fuzzy Sets. This methodology is designed to compare the performance of AI tools. The capabilities of AI bots have been examined through their success rates in various tasks and uncertainty levels in decision-making processes. The study aims to evaluate the effectiveness of different models in decision-making processes by analyzing the performances of AI bots such as Chat Generative Pre-trained Transformer (ChatGPT), Bard, and Claude based on both objective measurements and fuzzy evaluation criteria. The comparison focuses on key performance criteria such as Bots Triggered, User Engagement, Message Click-Through Rate, Chat Handoff, User Retention, Bounce Rate & Dwell Time, Leads Captured, and Customer Satisfaction Score. Ultimately, the validity and robustness of the approach have been tested with sensitivity analysis.}
}
@article{BUCZYNSKI2025106111,
title = {Future themes in regulating artificial intelligence in investment management},
journal = {Computer Law & Security Review},
volume = {56},
pages = {106111},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106111},
url = {https://www.sciencedirect.com/science/article/pii/S0267364925000068},
author = {Wojtek Buczynski and Felix Steffek and Mateja Jamnik and Fabio Cuzzolin and Barbara Sahakian},
keywords = {AI, Artificial intellogence, Investments, investment management, Finance, Financial services, Regulations, law, Laws, Regulation},
abstract = {We are witnessing the emergence of the “first generation” of AI and AI-adjacent soft and hard laws such as the EU AI Act or South Korea's Basic Act on AI. In parallel, existing industry regulations, such as GDPR, MIFID II or SM&CR, are being “retrofitted” and reinterpreted from the perspective of AI. In this paper we identify and analyze ten novel, “second generation” themes which are likely to become regulatory considerations in the near future: non-personal data, managerial accountability, robo-advisory, generative AI, privacy enhancing techniques (PETs), profiling, emergent behaviours, smart contracts, ESG and algorithm management. The themes have been identified on the basis of ongoing developments in AI, existing regulations and industry discussions. Prior to making any new regulatory recommendations we explore whether novel issues can be solved by existing regulations. The contribution of this paper is a comprehensive picture of emerging regulatory considerations for AI in investment management, as well as broader financial services, and the ways they might be addressed by regulations – future or existing ones.}
}
@article{SIMSEK2025e806,
title = {The predictive effect of nursing students' attitudes and acceptance towards artificial intelligence on their clinical competencies},
journal = {Teaching and Learning in Nursing},
volume = {20},
number = {3},
pages = {e806-e814},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.02.036},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725000824},
author = {Enes Şimşek and Aslı Akdeniz Kudubeş and Remziye {Semerci Şahin}},
keywords = {Acceptance, Artificial intelligence, Attitude, Clinical competency, Nursing student},
abstract = {Background
AI integration in education is gaining interest, including in nursing, as students seek formal training on its healthcare applications and limitations.
Aim
To evaluate the predictive effect of nursing students' attitudes and acceptance of artificial intelligence on their clinical competencies.
Methods
This descriptive-correlational study was conducted at 2 universities (February–June 2024) with 441 nursing students. Full-time students in clinical practice participated; those absent or on leave were excluded. The Nursing Students Competency Scale, General Attitudes to Artificial Intelligence Scale, and Generative Artificial Intelligence Acceptance Scale were used. Descriptive statistics and linear regression were used.
Results
The main factors affecting nursing students' clinical competence were “facilitating conditions,” “social influence,” and “negative attitudes” toward AI. A weak correlation was found between positive AI attitudes and acceptance, which explained 8.6% of the competency levels.
Conclusion
Positive perceptions of AI may increase competence, while skepticism may deepen engagement and critical learning. Strategies to improve the acceptance and use of AI are crucial to maximize its benefits in nursing education and practice.}
}
@article{BIGNAMI2025101078,
title = {Artificial intelligence in healthcare: Tailoring education to meet EU AI-Act standards},
journal = {Health Policy and Technology},
volume = {14},
number = {6},
pages = {101078},
year = {2025},
issn = {2211-8837},
doi = {https://doi.org/10.1016/j.hlpt.2025.101078},
url = {https://www.sciencedirect.com/science/article/pii/S2211883725001066},
author = {Elena Bignami and Luigino Jalale Darhour and Wolfgang Buhre and Maurizio Cecconi and Valentina Bellini},
keywords = {Artificial intelligence, AI-Act, Education, Policy},
abstract = {The integration of Artificial Intelligence (AI) in Intensive Care Units (ICUs) has the potential to transform critical care by enhancing diagnosis, management, and clinical decision-making. Generative and Predictive AI technologies offer new opportunities for personalized care and risk stratification, but their implementation must prioritize ethical standards, patient safety, and the sustainability of care delivery. With the EU AI-Act entering into force in February 2025, a structured and responsible adoption of AI is now imperative. This article outlines a strategic framework for ICU AI integration, emphasizing the importance of a formal declaration of intent by each unit, detailing current AI-use, implementation plans, and governance strategies. Central to this approach is the development of tailored AI education programs adapted to four distinct professional profiles, ranging from experienced clinicians with limited AI knowledge to new intensivists with strong AI backgrounds but limited clinical experience. Training must foster critical thinking, contextual interpretation, and a balanced relationship between AI tools and human judgment. A multidisciplinary support team should oversee ethical AI-use and continuous performance monitoring. Ultimately, aligning regulatory compliance with targeted education and practical implementation could enable a safe, effective, and ethically grounded use of AI in intensive care. This balanced approach would support a culture of transparency and accountability, while preserving the central role of human clinical reasoning and improving the overall quality of ICU care.}
}
@article{ROBLES2025100685,
title = {Fundamentals of artificial intelligence},
journal = {Revista de Senología y Patología Mamaria},
volume = {38},
number = {4},
pages = {100685},
year = {2025},
issn = {0214-1582},
doi = {https://doi.org/10.1016/j.senol.2025.100685},
url = {https://www.sciencedirect.com/science/article/pii/S0214158225000210},
author = {Rafael Guzmán Robles},
keywords = {Artificial intelligence, Machine learning, Deep learning, Reinforcement learning, Generative AI, Inteligencia artificial, Aprendizaje automático, Aprendizaje profundo, Aprendizaje por refuerzo, IA generativa},
abstract = {Artificial Intelligence (AI) is revolutionizing various industries, with healthcare being one of the most impacted sectors. This article explores the fundamentals of AI, with a specific focus on machine learning, deep learning, and generative AI. Machine learning, a subset of AI, enables systems to identify patterns in large data sets, improving over time without being explicitly programmed. Deep learning, a more advanced subfield, uses multi-layered neural networks to process complex information. The advent of generative AI, such as GPT and GANs, has expanded the potential of AI to create new content autonomously, transforming areas like drug discovery and personalized medicine. The article also addresses the ethical considerations surrounding the use of AI, particularly concerning data privacy, algorithmic bias, and equitable access to AI-driven technologies. These considerations are essential for ensuring the responsible development and implementation of AI in healthcare.
Resumen
La Inteligencia Artificial (IA) está revolucionando varias industrias, siendo la sanidad uno de los sectores más afectados. Este artículo explora los fundamentos de la IA, centrándose específicamente en el aprendizaje automático, el aprendizaje profundo y la IA generativa. El aprendizaje automático, un subconjunto de la IA, permite a los sistemas identificar patrones en grandes conjuntos de datos, mejorando con el tiempo sin ser programados explícitamente. El aprendizaje profundo, un subcampo más avanzado, utiliza redes neuronales multicapa para procesar información compleja. La llegada de la IA generativa, como las GPT y las GAN, ha ampliado el potencial de la IA para crear nuevos contenidos de forma autónoma, transformando ámbitos como el descubrimiento de fármacos y la medicina personalizada. El artículo también aborda las consideraciones éticas que rodean el uso de la IA, en particular las relativas a la privacidad de los datos, el sesgo algorítmico y el acceso equitativo a las tecnologías impulsadas por la IA. Estas consideraciones son esenciales para garantizar el desarrollo y la aplicación responsables de la IA en la atención sanitaria.}
}
@article{NIGRO20252390,
title = {Artificial Intelligence–Generated Answers to Patients’ Questions on Asthma: The Artificial Intelligence Responses on Asthma Study},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
volume = {13},
number = {9},
pages = {2390-2396},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.04.051},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825004209},
author = {Mattia Nigro and Andrea Aliverti and Alessandra Angelucci and Fulvio Braido and Giorgio W. Canonica and Apostolos Bossios and Hilary Pinnock and Jeanette Boyd and Pippa Powell and Stefano Aliberti},
keywords = {Asthma, Artificial intelligence, AI, Reliability, Accuracy, Comprehensiveness, Understandability, Disease awareness, Personalized medicine},
abstract = {Background
Asthma is a prevalent chronic respiratory disease requiring ongoing patient education and individualized management. The increasing reliance on digital tools, particularly generative artificial intelligence (AI), to answer health-related questions has raised concerns about the accuracy, reliability, and comprehensibility of AI-generated information for people living with asthma.
Objective
To evaluate systematically the reliability, accuracy, comprehensiveness, and understandability of responses generated by three widely used artificial intelligence–based chatbots (ChatGPT, Bard, and Copilot) to common questions formulated by people with asthma.
Methods
In this cross-sectional study, 15 questions regarding asthma management were formulated by patients and categorized by difficulty. Responses from ChatGPT, Bard, and Copilot were evaluated by international experts for accuracy and comprehensiveness, and by patient representatives for understandability. Reliability was assessed through consistency testing across devices. We conducted a blinded evaluation.
Results
A total of 21 experts and 16 patient representatives participated in the evaluation. ChatGPT demonstrated the highest reliability (15 of 15 responses), accuracy (median score, 9.0; interquartile range [IQR], 7.0-9.0), and comprehensiveness (median score, 8.0; IQR, 8.0-9.0) compared with Bard and Copilot (P < .0001). Bard achieved superior scores in understandability (median score, 9.0; IQR, 8.0-10.0; P < .0001). Performance differences were consistent across question difficulty levels.
Conclusions
Artificial intelligence–driven chatbots can provide generally accurate and understandable responses to asthma-related questions. Variability in reliability and accuracy underscores the need for caution in clinical contexts. Artificial intelligence tools may complement but cannot replace professional medical advice in asthma management.}
}
@article{BERLINSKI2024102723,
title = {Artificial imaginaries: Generative AIs as an advanced form of capitalism},
journal = {Critical Perspectives on Accounting},
volume = {99},
pages = {102723},
year = {2024},
issn = {1045-2354},
doi = {https://doi.org/10.1016/j.cpa.2024.102723},
url = {https://www.sciencedirect.com/science/article/pii/S1045235424000224},
author = {Elise Berlinski and Jérémy Morales and Samuel Sponem},
keywords = {Generative AI, ChatGPT, Social imaginaries, Standardization, Domination},
abstract = {In this essay, we characterize three paradoxical imaginaries that structure the development of generative artificial intelligence (genAI). At the institutional level, these technologies develop in a context that celebrates openness and liberality. Yet, both in the US and in Europe, they serve to centralize power and resources. At the organizational level, while the imaginary is that these technologies make work more interesting, we show that they rather produce anxiety and a new class of precarious workers. At the epistemic level, generative artificial intelligence promises access to unlimited knowledge. This knowledge may appear robust, as these technologies become performative. However, the knowledge they produce is doubtful. Overall, these technologies centralize power and exclude, they standardize knowledge, and they produce, reproduce, amplify and extend various structures of domination.}
}
@article{KIM20252214,
title = {Enzyme functional classification using artificial intelligence},
journal = {Trends in Biotechnology},
volume = {43},
number = {9},
pages = {2214-2231},
year = {2025},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2025.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167779925000885},
author = {Ha Rim Kim and Hongkeun Ji and Gi Bae Kim and Sang Yup Lee},
keywords = {deep learning, EC number, enzyme, GO term, machine learning, metabolism},
abstract = {Enzymes are essential for cellular metabolism, and elucidating their functions is critical for advancing biochemical research. However, experimental methods are often time consuming and resource intensive. To address this, significant efforts have been directed toward applying artificial intelligence (AI) to enzyme function prediction, enabling high-throughput and scalable approaches. In this review, we discuss advances in AI-driven enzyme functional annotation, transitioning from traditional machine learning (ML) methods to state-of-the-art deep learning approaches. We highlight how deep learning enables models to automatically extract features from raw data without manual intervention, leading to enhanced performance. Finally, we discuss the discovery of novel enzyme functions and generation of de novo enzymes through the integration of generative AIs and bio big data as future research directions.}
}
@article{ALNUSAIR2025101340,
title = {Artificial intelligence in myeloid malignancies: Clinical applications of machine learning in myelodysplastic syndromes and acute myeloid Leukemia},
journal = {Blood Reviews},
pages = {101340},
year = {2025},
issn = {0268-960X},
doi = {https://doi.org/10.1016/j.blre.2025.101340},
url = {https://www.sciencedirect.com/science/article/pii/S0268960X25000852},
author = {Jowan Al-Nusair and Luca Lanino and Arda Durmaz and Matteo Giovanni Della Porta and Amer M. Zeidan and Tariq Kewan},
keywords = {Myelodysplastic syndromes, Acute myeloid leukemia, Artificial intelligence, Machine learning, Prognostication, Digital twins},
abstract = {This review summarizes applications of machine learning (ML) in acute myeloid leukemia (AML) and myelodysplastic syndrome (MDS), spanning diagnosis, prognostication, treatment prediction, and research tools. In diagnostics, deep learning applied to bone marrow smears, peripheral blood films, and flow cytometry has shown high sensitivity and specificity, outperforming conventional methods. ML-driven unsupervised clustering and consensus classification have refined disease taxonomies, identifying genomic subtypes with prognostic value. Prognostic models and neural networks enable dynamic, personalized survival predictions. In treatment, ML assists in predicting responses to hypomethylating agents and venetoclax-based regimens, supporting clinical decision-making. In research, generative approaches create privacy-preserving synthetic cohorts and digital twins, facilitating trial design and overcoming data limitations. Future integration into clinical practice will require rigorous validation, explainable algorithms, seamless workflow incorporation, and regulatory oversight to ensure trust, equity, and safety. ML has potential to enhance multiple aspects of AML and MDS management.}
}
@article{ZHOU2025114970,
title = {Artificial intelligence-assisted next-generation biomaterials: From design and preparation to medical applications},
journal = {Colloids and Surfaces B: Biointerfaces},
volume = {255},
pages = {114970},
year = {2025},
issn = {0927-7765},
doi = {https://doi.org/10.1016/j.colsurfb.2025.114970},
url = {https://www.sciencedirect.com/science/article/pii/S0927776525004771},
author = {Bixia Zhou and Xin Li and Yuchen Pan and Bingfang He and Bingbing Gao},
keywords = {Artificial Intelligence, Biomaterials, Machine Learning, Materials Design, Biomedical Applications},
abstract = {The Fourth Industrial Revolution (Industry 4.0) has marked a shift from traditional materials to the era of smart materials. The integration of artificial intelligence (AI) with biomaterials is transforming the biosensing and biomedical fields. Although AI-assisted biomaterial manufacturing holds significant promise, the design and synthesis of smart materials remain in the early stages. To accelerate the implementation of AI-assisted biomaterials in fields such as biomedicine and biological intelligent systems, various algorithms have been developed to predict material properties, enable material de novo design, and establish a foundation for the development of next-generation multifunctional biomaterials. This review presents a comprehensive overview of AI-assisted biomaterial design, property prediction, fabrication, and potential biomedical applications. Recent advances in AI-driven protein engineering relevant to materials science are summarized, followed by an analysis of AI's role in designing, predicting, and optimizing next-generation biomaterials. The influence of AI-assisted systems on the structural and functional properties of biosmart materials is also explored. Applications such as therapeutic diagnostics, electronic skin (e-skin), biosensing, and other biomedical technologies are highlighted. Finally, current challenges and future perspectives are discussed, with emphasis on the transformative potential of AI in advancing materials science and biomedicine, as well as its ability to address previously intractable problems.}
}
@article{JIANG2026116321,
title = {Artificial intelligence in wind turbine fault diagnosis: A systematic knowledge mapping and trend analysis},
journal = {Renewable and Sustainable Energy Reviews},
volume = {226},
pages = {116321},
year = {2026},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.116321},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125009943},
author = {Ruolin Jiang and Fang Fang and Juan José Rodríguez-Andina and Ziqiu Song and Jizhen Liu and Yuanye Chen and Hua Wang},
keywords = {Fault diagnosis, Artificial intelligence, Digital twin, Generative large model, Predictive maintenance, Sustainable energy system, Wind turbine},
abstract = {Over the past decade, fault diagnosis technology in the wind energy sector has advanced rapidly, yet existing reviews exhibit methodological and data source fragmentation. This study employs bibliometrics and content analysis to systematically trace the conceptual evolution and technological trajectory of intelligent fault diagnosis for wind turbines. Based on 1736 fault diagnosis papers published in mainstream journals and conferences between 2016 and 2025, it quantitatively reveals trends in research themes, methodologies, and focal points. This study critically examines the strengths, limitations, and application boundaries of existing diagnostic frameworks, highlighting practical challenges such as data imbalance, insufficient open benchmarking, and obstacles to digital twin deployment. It also evaluates emerging trends in integrating foundational models with digital twins, noting their potential for enhancing component-level precision diagnostics. The proposed roadmap centers on deep learning and multimodal models, leveraging robust shared data, unified industry standards, and comprehensive security–privacy protection mechanisms. It emphasizes causal inference and lightweight edge deployment technologies. By tracing historical developments and evaluating existing diagnostic approaches, this study aims to accelerate data-driven practices in wind power operations and maintenance while establishing reliable intelligent fault diagnosis systems—critical for ensuring stable power generation from wind turbines.}
}
@article{ZHANG2025101244,
title = {How can artificial intelligence help college students develop entrepreneurial ability? Evidence from China},
journal = {The International Journal of Management Education},
volume = {23},
number = {3},
pages = {101244},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2025.101244},
url = {https://www.sciencedirect.com/science/article/pii/S1472811725001144},
author = {Qianjun Zhang and Lixu Li and Chenli Xu and Yuanyuan Qi and Xiaorong Zhao},
keywords = {AI knowledge, Generative AI, Entrepreneurship, Creativity, College students},
abstract = {With AI rapidly transforming industries and creating new opportunities, college students are uniquely positioned to leverage artificial intelligence (AI) for entrepreneurial ventures. Nevertheless, despite the growing significance of AI knowledge, students frequently face challenges in connecting theoretical knowledge with practical use, which impedes their capacity to transform AI-driven insights into effective business strategies. Drawing on data from a survey of 1021 Chinese university students, this study investigates the connections between AI knowledge, two modes of generative AI usage (GAU), and entrepreneurial ability, with a special emphasis on the moderating influence of individual creativity. The results indicate that AI knowledge positively influences entrepreneurial ability. Interestingly, two GAU modes (i.e., depth and breadth) serve as important mediators in the relationship between AI knowledge and entrepreneurial ability. Surprisingly, individual creativity enhances the mediation effect of GAU depth between AI knowledge and entrepreneurial ability but does not enhance the mediation effect of GAU breadth between AI knowledge and entrepreneurial ability. This study advances existing research by uncovering the mechanisms and boundary conditions that facilitate the transformation of AI knowledge into substantive entrepreneurial ability. The findings also offer insights into improving instructional design in the age of AI.}
}
@article{TSIAVOS2025103021,
title = {The digital transformation of the film industry: How Artificial Intelligence is changing the seventh art},
journal = {Telecommunications Policy},
volume = {49},
number = {8},
pages = {103021},
year = {2025},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2025.103021},
url = {https://www.sciencedirect.com/science/article/pii/S0308596125001181},
author = {Vasilis Tsiavos and Fotis Kitsios},
keywords = {Digital transformation, Artificial intelligence, Film industry},
abstract = {Although artificial intelligence has played a dominant role in the digital transformation of many industries and has been the focus of multiple academic studies, only a few researchers have explored the impact of AI on the film industry, even after the advances in large language models like ChatGPT and generative AI tools such as Sora. Questions regarding how the use of AI has affected the core functions of the film industry's value chain (Creation, Production, Dissemination and Exhibition) have only been partially or inadequately explored. This paper intends to address this research gap by conducting a systematic literature review of 74 relevant articles based on the Webster & Watson methodology, to be followed by a conceptual analysis of AI-related themes in the film industry. Our findings reveal that artificial intelligence has long played a role in the film industry, and its influence has only grown with recent advancements in AI, having an impact across the film industry's value chain. We also highlight emerging ethical concerns, such as authorship, creative integrity, and labor displacement that accompany AI's expanding role. Whilst our work contributes to the body of research on AI in the film industry, we also identify potential avenues of research that allow room for future exploration.}
}
@article{HUANG2026106527,
title = {Artificial Intelligence in urban design: A systematic review},
journal = {Cities},
volume = {169},
pages = {106527},
year = {2026},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2025.106527},
url = {https://www.sciencedirect.com/science/article/pii/S0264275125008303},
author = {Tianchen Huang and Xinyue Ye and Tan Yigitcanlar and Boqian Xu and Galen Newman and Bo Zhao and Benjamin Ennemoser and Dayong Wu and Junghwan Kim and Dongjie Wang},
keywords = {Artificial Intelligence, Generative AI, Urban Design, Design generation, AI-human collaboration},
abstract = {Artificial Intelligence (AI) is playing an increasingly transformative role in urban design by enhancing the efficiency, scalability, and adaptability of design processes. This study presents a systematic review of AI applications in urban design, with a particular focus on the design generation phase, encompassing data analysis, scheme generation and optimization, and design visualization. AI-driven methodologies facilitate rapid data processing, automated design iterations, and advanced visualizations, thereby mitigating some key limitations in conventional urban design workflows that often rely on manual and time-consuming processes. Despite these advancements, several challenges persist. These include the fragmented integration of AI tools into existing workflows, the incomplete automation of the design process, and the potential for algorithmic bias in AI-generated outcomes. Such shortcomings underscore the importance of developing structured AI workflows, fostering effective human-AI collaboration, and curating diverse, inclusive datasets to promote equitable and context-sensitive design solutions. This review advocates for a balanced approach that leverages AI's computational power while retaining human creativity and contextual judgment. By doing so, AI-enhanced urban design holds the potential to support the creation of more sustainable, efficient, and resilient cities, better equipped to meet the complex challenges of contemporary urbanization.}
}
@article{DENIA2025103266,
title = {AI narratives model: Social perception of artificial intelligence},
journal = {Technovation},
volume = {146},
pages = {103266},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103266},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000987},
author = {Elena Denia},
keywords = {Artificial intelligence, Science communication, Science fiction, Storytelling, Public attitudes, Public engagement, Public understanding, Public narratives},
abstract = {Narratives surrounding Artificial Intelligence (AI) shape its societal reception, technological development, and regulatory framing. This article proposes a theoretical model to interpret these narratives, especially in the context of growing public engagement with generative AI technologies. The model is structured along three key coordinates: apocalypse, assistance and transcendence. Transitions between them are understood through two dominant narrative frames: the Pandora's Box frame (associated with loss of control), and the Social Progress frame (associated with the improvement of human life), each tending toward dystopian and utopian extremes, respectively. Based on this model, two questions are addressed: What types of AI stories predominate in popular culture? And do audiences actually align with them? To answer these, two empirical analyses are conducted. First, a review of the 300 highest-grossing science fiction films in North America reveals a rich variety of narratives across the entire spectrum, rather than clustering around opposing extremes. Second, focus group discussions with categorized audiences of varying levels of familiarity with AI technology show that they align progressively along the narrative spectrum: the general public tends toward apocalyptic framings, the interested public (in science and technology) focuses on assistance narratives, and the engaged public embraces improvement scenarios. This sequential distribution suggests a strong correlation between AI proximity and narrative positioning, with greater engagement associated with more positive —yet nuanced— views of AI. The model opens multiple avenues for future research, including the use of wider data sources, cross-cultural comparisons, longitudinal studies, tracking of narrative shifts, and focused analyses of more complex representations.}
}
@article{KIM2025101123,
title = {Exploring the potential of acupuncture practice education using artificial intelligence},
journal = {Integrative Medicine Research},
volume = {14},
number = {1},
pages = {101123},
year = {2025},
issn = {2213-4220},
doi = {https://doi.org/10.1016/j.imr.2025.101123},
url = {https://www.sciencedirect.com/science/article/pii/S2213422025000034},
author = {Kyeong Han Kim and Hyein Jeong and Gyeong Seo Lee and Seung-Hee Lee},
keywords = {Artificial intelligence, Acupuncture, Education},
abstract = {Generative artificial intelligence (AI) is being applied in various areas such as education, clinical practice, and research within the medical field. This review explores the potential use of AI models in acupuncture practice education. Recent and relevant findings were searched from literature. Active research on the use of AI in acupuncture education, particularly in areas such as acupoint selection and acupuncture manipulation, is ongoing. Additionally, AI-powered educational tools are being developed in the field of traditional medicine. The development of AI-driven educational tools for acupuncture education holds significant potential to enhance the effectiveness and efficiency of traditional medicine education.}
}
@article{PAWLICKI2025131231,
title = {A meta-survey of adversarial attacks against artificial intelligence algorithms, including diffusion models},
journal = {Neurocomputing},
volume = {653},
pages = {131231},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131231},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225019034},
author = {Marek Pawlicki and Aleksandra Pawlicka and Rafał Kozik and Michał Choraś},
keywords = {Adversarial attacks, Artificial intelligence, Deep learning},
abstract = {Deep neural networks have revolutionized artificial intelligence, solving complex issues in areas like healthcare or law enforcement and security. However, they are susceptible to adversarial attacks where small data manipulations can compromise system reliability and security. This paper conducts an umbrella review of the literature on these attacks, synthesizing results from various systematic reviews to assess attack strategies, defense effectiveness, and research gaps. Guided by the PICO framework, this review categorizes and examines adversarial attacks, identifying key challenges in the field. The review finds that even though adversarial vulnerabilities were first explored in computer vision, analogous threats have expanded to domains like graph neural networks, natural language processing, federated learning, and text-to-image models. Despite varied attack surfaces, commonalities can be found.}
}
@article{KHOURY2025,
title = {Preparing Allergists to Practice in 2050 Using Artificial Intelligence},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825009067},
author = {Paneez Khoury and John Oppenheimer and Supinda Bunyavanich and Christina E. Ciaccio and Jay Portnoy},
keywords = {Artificial intelligence, Large language models, Machine learning, Electronic health record, Medical education},
abstract = {As artificial intelligence (AI) becomes deeply embedded in clinical practice, the field of allergy and immunology is poised for transformation by 2050. Artificial intelligence is expected to evolve from a decision support tool to a collaborative partner in diagnostics, treatment personalization, and medical education. Allergy training programs will need to prepare fellows for a technologically advanced landscape by integrating AI literacy, data science, and virtual simulation into curricula. Fellowship programs will need to adopt adaptive learning platforms, high-fidelity simulations, and AI-powered clinical decision support to improve diagnostic acumen, procedural competency, and patient care. This evolution also demands attention to the ethical and legal challenges of AI implementation, including preserving patient autonomy, addressing algorithmic bias, and safeguarding data privacy. Fellows must develop skills to evaluate AI outputs critically and uphold transparent, human-centered care. Artificial intelligence will probably also reshape research practices through predictive analytics, digital twins, and automated trial matching, accelerating discovery in allergic and immunologic disease. Despite these advances, limitations such as the black box problem, lack of emotional intelligence, and misinformed patient self-diagnoses pose challenges. Clinicians will require new communication strategies, including brief cognitive behavioral interventions, to address AI-derived misconceptions and maintain trust. Rather than replacing allergists, AI is likely to expand their roles, freeing time for patient interaction while reinforcing their responsibility as interpreters, educators, and ethical stewards of digital tools. This review explores how graduate medical education and clinical practice in allergy and immunology must evolve to ensure that future allergists remain competent, compassionate, and technologically fluent in a dynamic AI-enhanced health care environment.}
}
@article{MARZI2025103254,
title = {Artificial intelligence and the reconfiguration of NPD Teams: Adaptability and skill differentiation in sustainable product innovation},
journal = {Technovation},
volume = {145},
pages = {103254},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103254},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000860},
author = {Giacomo Marzi and Marco Balzano},
keywords = {Sustainable development goals, Sustainable product innovation, Generative artificial intelligence, New product development teams, Team adaptability, Team skill diversity, Sustainability, Green Innovation},
abstract = {Sustainable product innovation (SPI) is increasingly central to New Product Development (NPD) teams, aligning with global sustainability goals and industry expectations. However, the factors associated with SPI at team level remain underexplored. This study examines the roles of team skill differentiation and team adaptability in fostering SPI, proposing that these factors support teams in the pursuit of sustainability-oriented innovation more effectively. Furthermore, we investigate the moderating role of generative artificial intelligence (GenAI) in shaping the strength of these relationships. Drawing on the double diamond framework and its AI-augmented adaptation, we hypothesize that skill differentiation expands the range of potential solutions in the divergent phase of innovation, while adaptability enhances responsiveness in the convergent phase. GenAI is posited to enhance these effects by augmenting knowledge recombination and real-time strategic adaptation. To test our hypotheses, we conducted a multi-industry survey of NPD teams engaged in sustainability initiatives, applying multiple regression analysis to assess the proposed relationships. All our hypotheses were empirically supported. Overall, this study contributes to SPI research by integrating team capability theory with AI-driven innovation frameworks. The findings highlight the need for firms to cultivate multidisciplinary teams with adaptive capacities while leveraging GenAI as an amplifier rather than a substitute for human expertise. The results also underscore that effective SPI requires both internal knowledge diversity and external responsiveness, alongside AI tools that enhance creativity and sustainability-driven decision-making. Finally, this research provides insights into how NPD teams can enhance their engagement in sustainable innovation, aligning with the broader objectives of Sustainable Development Goals (SDGs) 9 and 12.}
}
@article{MA2025200589,
title = {Artificial intelligence-driven green innovation in packaging: A systematic review of adoption and diffusion challenges},
journal = {Intelligent Systems with Applications},
volume = {28},
pages = {200589},
year = {2025},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2025.200589},
url = {https://www.sciencedirect.com/science/article/pii/S2667305325001152},
author = {Ye Ma and Nor Hidayati Zakaria and Basheer Al-Haimi and Chen Wu},
keywords = {Artificial intelligence (AI), Green innovation, Packaging industry, Machine learning, Sustainable packaging, Systematic literature review},
abstract = {Global concern about environmental protection has intensified the demand for sustainable packaging solutions. Integrating artificial intelligence (AI) into green innovation offers a transformative way to address these challenges. This study applies a systematic literature review (SLR) guided by the PRISMA 2020 framework to examine recent AI-powered packaging innovations. Forty-eight peer-reviewed articles, published between 2020 and 2025, were analyzed. The findings show that Machine Learning, Deep Learning, and general AI applications are the most frequently adopted technologies. Biodegradable packaging materials and smart packaging systems represent the main sustainable packaging types. AI applications are concentrated in process optimization, smart packaging monitoring, fraud detection, computer vision, and natural language processing. However, widespread adoption faces obstacles such as high costs, technical complexity, and regulatory uncertainty. Future trends highlight the importance of scalable technologies, advanced AI models, integration with the circular economy, and interdisciplinary collaboration. This review provides a structured framework to guide academics, industry practitioners, and policymakers in adopting AI-driven green innovation for sustainable packaging.}
}
@article{DAVE2026106122,
title = {Enhancing healthcare worker mental health via artificial intelligence-driven work process improvements: a scoping review},
journal = {International Journal of Medical Informatics},
volume = {205},
pages = {106122},
year = {2026},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2025.106122},
url = {https://www.sciencedirect.com/science/article/pii/S1386505625003399},
author = {Bhavyaa Dave and Priya Martin and Sharel Singh David and Saravana Kumar and Tanmoy Chakraborty},
keywords = {Artificial intelligence (AI), Healthcare workers (HCWs), Mental health, Burnout, Workflow optimisation, Clinical documentation},
abstract = {Background
Healthcare workers (HCWs) are exposed to higher rates of mental health issues, such as burnout, anxiety, cognitive overload, and stress, compared to the general population. These may be exacerbated by administrative activities like extensive paperwork and disintegrated work processes. The implementation of artificial intelligence (AI) in healthcare holds the potential to combat these challenges by streamlining workflow processes, lowering administrative load, and increasing efficiency. The role of AI in supporting HCWs’ mental health is yet to be fully explored. This scoping review mapped the current evidence on how AI can enhance HCWs’ mental health through workflow optimisation.
Methods
This scoping review was informed by best practice in the conduct and reporting of scoping reviews. A comprehensive search of academic and grey literature was performed without date restrictions. A two-stage dual screening process was employed using Covidence. A customised data extraction tool was developed to systematically extract data, which was then summarised descriptively.
Results
Twenty articles were included in the review, most of which were published between 2020 and 2024. These comprised empirical studies, literature reviews, position papers, as well as selected grey literature. The studies explored various AI applications such as Natural Language Processing (NLP), AI-integrated Electronic Health Records (EHR), Machine Learning (ML), Clinical Decision Support Systems (CDSS), and Generative AI-driven tools such as ChatGPT. Burnout was the most frequently addressed mental health issue, followed by stress and cognitive load. Clinical documentation emerged as the most frequently addressed workflow, followed by clinical decision-making and diagnostics. Literature indicated that AI was capable of streamlining workflows, reducing administrative burden, and improving job satisfaction among HCWs. However, challenges such as data integration, algorithmic bias, and increased oversight demands were noted as potential barriers to effective implementation.
Conclusion
AI holds significant potential to improve HCWs’ mental health and well-being by addressing workflow inefficiencies and reducing administrative burden. While available evidence highlights its benefits in enhancing job satisfaction and mitigating burnout, challenges such as data standardisation and user trust must be addressed for successful adoption. Future research should focus on evaluating the long-term impacts of AI on HCWs’ mental well-being and developing strategies to mitigate unintended consequences.}
}
@article{SARIKAYA2025101021,
title = {Path to Artificial General Intelligence: Past, present, and future},
journal = {Annual Reviews in Control},
volume = {60},
pages = {101021},
year = {2025},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2025.101021},
url = {https://www.sciencedirect.com/science/article/pii/S1367578825000367},
author = {Ruhi Sarikaya},
keywords = {Artificial General Intelligence, Artificial Super Intelligence, Generative AI, Foundational Models, LLMs, Transformers},
abstract = {During the past decade, there has been remarkable progress in Artificial Intelligence (AI). More recently, the emergence of Generative AI was an inflection point in cognitive pattern understanding and generation across multiple modalities including speech, text, imagery, and vision, where AI systems are increasingly matching or surpassing human performance on a growing array of cognitive tasks. These models have been seamlessly integrated into numerous applications and products, reaching hundreds of millions of users. As a result, discussions regarding the achievement of Artificial General Intelligence (AGI) have shifted from theoretical speculation to a plausible near to mid-term objective. In this paper, we present a comprehensive review of the evolution of AI from its inception to the present day. We then examine how advances in computational infrastructure, algorithms, and large-scale modeling are converging to drive the generative AI revolution and shaping the trajectory toward AGI, potentially within the next 5-to-10 years. Specifically, we analyze recent progress in compute capabilities, learning algorithms, and model architectures across a broad spectrum of cognitive tasks. We also share our perspective on the key challenges that remain to be solved, and discuss the critical risks that must be addressed to ensure the safe and beneficial development of AI systems that may eventually exceed human-level performance in perception, reasoning, and general cognition.}
}
@article{BIRKHOLZ2025102520,
title = {Navigating artificial intelligence in nursing: An ethical exploration of benefits, risks, and educational shifts},
journal = {Nursing Outlook},
volume = {73},
number = {5},
pages = {102520},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102520},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425001733},
author = {Lorri Birkholz and Michael Martin and Brenda Barnum and Linda Breslin and Shika Kalevor},
keywords = {Artificial intelligence, Nursing, Nursing ethics, Nursing care, Academic integrity},
abstract = {A significant challenge of generative artificial intelligence (AI) is the gap between technological advancements and policies to guide their ethical use. The integration of AI in all aspects of nursing is poised to revolutionize the delivery of nursing care to patients. As such, nursing practice and educational programs will be required to adapt to these advancing technologies while maintaining the core tenets and ethical values inherent in the profession. Schools, colleges, and universities will be called upon to act to safeguard the value of education and the sanctity of the nursing profession Ultimately, it will be the responsibility of nurses to make sure technological advances, including AI, do not compromise learning or the human interactions and relationships that are essential to providing patient-centered care. The purpose of this article is to explore the ethical implications for the nursing profession of these advances as currently known and understood.}
}
@article{MARTIN2025,
title = {Artificial intelligence in personalized prescription: A narrative review of promise, peril, and practicality},
journal = {Therapies},
year = {2025},
issn = {0040-5957},
doi = {https://doi.org/10.1016/j.therap.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0040595725001131},
author = {Guillaume L. Martin and Louis Létinier},
keywords = {Artificial intelligence, Large language models, Clinical decision support system, -prescribing, Medical devices},
abstract = {Summary
The integration of artificial intelligence (AI), particularly large language models (LLMs), into clinical prescription practices represents a transformative shift in healthcare, promising to offer enhanced therapeutic precision, reduced errors, and personalized care. However, rapid adoption is outpacing validation and governance. This narrative review critically examines the benefits, risks, and implementation challenges of AI in pharmacology, with an emphasis on prescribing use cases, highlighting the rapid adoption driven by physician constrained time and increasing complexity of medical knowledge, yet outpaced by validation frameworks. Key benefits include optimized decision support, as suggested by real-world systems like the Penda Health AI Copilot. However, inherent risks such as hallucinations, lack of explainability, spending inflation, and clinical de-skilling pose significant threats, potentially eroding trust and patient safety. We contrast regulatory philosophies [European Union (EU) precaution under the medical devices regulation (MDR) and AI Act vs U.S. flexibility via Food and Drug predetermined change control plans (FDA PCCP)] and spotlight a persistent grey zone in which general-purpose LLMs are used clinically without medical-device oversight. To operationalize trustworthy use, we foreground rigorous evaluation and outline an “architecture of trustworthy clinical AI” (retrieval-augmented generation, structured clinical prompting with abstention/uncertainty, and hybrid LLM–rule safety layers). Finally, we propose an outcomes-first paradigm adapted from French health technologies assessment (HTA) — service rendered by AI (SR-AI) and improvement of service rendered by AI (ISR-AI), with patient outcomes and system resilience as primary endpoints — and recommend a default stance that any generative AI used in health be treated as a medical device, with general-purpose LLMs permitted only via certified clinical wrappers that close the MDR-inconsistent gap.}
}
@article{DHAIGUDE2025100640,
title = {Mapping responsible artificial intelligence in business and management: Trends, influence, and emerging research directions},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {11},
number = {4},
pages = {100640},
year = {2025},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2025.100640},
url = {https://www.sciencedirect.com/science/article/pii/S2199853125001751},
author = {Amol S. Dhaigude and Giridhar B. Kamath},
keywords = {Responsible Artificial Intelligence, Innovation management, Responsible innovation, Business and management, Bibliometric analysis, Bibliographic coupling, VOSviewer, Biblioshiny, Research clusters},
abstract = {The rapid integration of AI into business and management demands ethical and responsible technology design and deployment. While various policies and frameworks exist, there is limited understanding of operationalizing responsible artificial intelligence (RAI). The literature remains fragmented, lacking cohesion and clarity. This bibliometric analysis quantitatively evaluates RAI literature’s research trends, key authors, collaborations, and thematic evolution in the business and management domain. A carefully designed search protocol based on an extensive literature review was used to retrieve 1942 research papers from the Scopus database (1981–2025), reflecting a 13.12 % annual growth rate and an average of 25.79 citations per paper. The study applied bibliographic coupling, keyword co-occurrence, and thematic mapping techniques using VOSviewer and Biblioshiny to identify intellectual structures and conceptual linkages. The results reveal four key clusters: "Ethics and Social Impacts of AI", "AI Adoption and Human-AI Interaction", "Auditing, Explainability, and Accountability in AI", and "Corporate Governance and Data Responsibility in AI". Future research directions for each cluster are proposed, providing valuable insights for practitioners and academicians. The paper highlights critical implications for developing responsible AI strategies in business and offers guidance for advancing scholarly work in this growing field.}
}
@article{ZHAO2025106245,
title = {Artificial intelligence in rock mechanics},
journal = {International Journal of Rock Mechanics and Mining Sciences},
volume = {195},
pages = {106245},
year = {2025},
issn = {1365-1609},
doi = {https://doi.org/10.1016/j.ijrmms.2025.106245},
url = {https://www.sciencedirect.com/science/article/pii/S1365160925002229},
author = {Gao-Feng Zhao and Yuhang Wu},
keywords = {Artificial intelligence, Machine learning, Rock mechanics, Large language model},
abstract = {Artificial Intelligence (AI) has great potential to transform rock mechanics by tackling its inherent complexities, such as anisotropy, nonlinearity, discontinuousness, and multiphase nature. This review explores the evolution of AI, from basic neural networks like the BP model to advanced architectures such as Transformers, and their applications in areas like microstructure reconstruction, prediction of mechanical parameters, and addressing engineering challenges such as rockburst prediction and tunnel deformation. Machine learning techniques, particularly Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs), have been crucial in automating tasks like fracture detection and efficiently generating 3D digital rock models. However, the effectiveness of AI in rock mechanics is limited by data scarcity and the need for high-quality datasets. Hybrid approaches, such as combining physics-informed neural networks (PINNs) with traditional numerical methods, offer promising solutions for solving governing equations. Additionally, Large Language Models (LLMs) are emerging as valuable tools for code generation and decision-making support. Despite these advancements, challenges remain, including issues with reproducibility, model interpretability, and adapting AI models to specific domains. Future progress will hinge on the availability of improved datasets, greater interdisciplinary collaboration, and the integration of spatial intelligence frameworks to bridge the gap between AI's theoretical potential and its practical application in rock engineering.}
}
@article{GOLEC2025100265,
title = {Artificial Intelligence (AI): Foundations, trends and future directions},
journal = {Telematics and Informatics Reports},
volume = {20},
pages = {100265},
year = {2025},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2025.100265},
url = {https://www.sciencedirect.com/science/article/pii/S2772503025000799},
author = {Muhammed Golec and Emir Sahin Hatay and Sukhpal Singh Gill and Rajkumar Buyya},
keywords = {AI, Computing, Quantum computing, Artificial intelligence, Machine learning},
abstract = {Developments in artificial intelligence (AI) technology have revolutionized many areas, from health to education, and from defense to commercial applications, both civilian and military. This article provides a comprehensive overview of the foundations, theoretical, and technological developments of AI, and the application areas it has enabled. It also examines the industrial impact of AI, including recent trending applications such as DeepSeek, ChatGPT, Google Lens, Face ID, and Tesla, as well as the areas of Natural Language Processing, Autonomous Vehicles, and Computer Vision. Beyond these, it highlights on future aspects of AI, such as next-generation Large Language Models (LLMs) and Artificial General Intelligence (AGI), and explores its impact on social ethics. The investigation of all these aspects aims to equip the reader with a comprehensive understanding of the current impact and potential future directions of AI.}
}
@article{HERRERATAPIAS20251184,
title = {Legal Hallucinations and the Adoption of Artificial Intelligence in the Judiciary},
journal = {Procedia Computer Science},
volume = {257},
pages = {1184-1189},
year = {2025},
note = {The 16th International Conference on Ambient Systems, Networks and Technologies Networks (ANT)/ the 8th International Conference on Emerging Data and Industry 4.0 (EDI40)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.03.158},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925008956},
author = {Beliña Annery Herrera-Tapias and Diego {Hernández Guzmán}},
keywords = {Artificial Intelligence, AI, Generative Pretrained Transformers, GPTs, Large Language Models, LLMs, Judiciary, Due Process},
abstract = {This article analyses the use of artificial intelligence in the judiciary, with a focus on Judgment T-343/24 of the Constitutional Court of Colombia. The judgment validates the use of artificial intelligence tools in judicial decision-making, provided they serve as supportive rather than substitutive instruments for judges. This paper highlights the potential of artificial intelligence in improving judicial efficiency and accuracy while also technically addressing the challenges posed by AI-generated "legal hallucinations," where large language models produce credible but incorrect outputs. Through qualitative legal analysis, the study explores the implications of integrating artificial intelligence in the judiciary in addressing those challenges while emphasizing the preservation of the right to a due process.}
}
@article{ENSLIN2025265,
title = {Past, Present, and Future: A History Lesson in Artificial Intelligence},
journal = {Gastrointestinal Endoscopy Clinics of North America},
volume = {35},
number = {2},
pages = {265-278},
year = {2025},
note = {Artificial Intelligence in Endoscopy},
issn = {1052-5157},
doi = {https://doi.org/10.1016/j.giec.2024.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1052515724000850},
author = {Sarah Enslin and Vivek Kaul},
keywords = {Artificial intelligence, Machine learning, Deep learning, Computer-aided detection, Computer-aided diagnosis, Generative artificial intelligence}
}
@article{PROUMEN2025563,
title = {Artificial Intelligence in Medical Education},
journal = {Anesthesiology Clinics},
volume = {43},
number = {3},
pages = {563-576},
year = {2025},
note = {Artificial Intelligence in Anesthesiology},
issn = {1932-2275},
doi = {https://doi.org/10.1016/j.anclin.2025.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S1932227525000382},
author = {LT. Adrian Proumen and Santiago Uribe-Marquez and LCDR. Gregory J. Booth and John D. Mitchell},
keywords = {Artificial intelligence (AI), Machine learning, Education, Technology, Feedback, Precision medical education}
}
@article{ABBARA2025105131,
title = {Artificial intelligence and infectious diseases: Scope and perspectives},
journal = {Infectious Diseases Now},
volume = {55},
number = {7},
pages = {105131},
year = {2025},
issn = {2666-9919},
doi = {https://doi.org/10.1016/j.idnow.2025.105131},
url = {https://www.sciencedirect.com/science/article/pii/S2666991925001101},
author = {S. Abbara and Y. Crabol and J. Goupil {de Bouillé} and A. Dinh and D. Morquin},
keywords = {Infectious diseases, Artificial intelligence, Generative artificial intelligence, Machine learning, Clinical decision support},
abstract = {Artificial intelligence (AI) is set to permeate every facet of infectious disease practice—from prevention and public health surveillance to epidemic management and bedside care. Routine care data (laboratory results, medication orders, progress notes) and research-generated datasets now fuel state-of-the-art machine-learning (ML) pipelines that sharpen diagnosis, prognosis, antimicrobial stewardship, and, by combining both sources, accelerate drug discovery. In diagnostics, deep networks that now flag pneumonia or tuberculosis on chest images are increasingly able to identify—and localize—virtually more infectious processes throughout the body, while simultaneously predicting pathogen identity and antimicrobial resistance from routine microbiology. Prognostic models trained on Electronic Health Records surpass traditional scores in anticipating clinical deterioration or postoperative sepsis, enabling earlier targeted interventions. Predictive analytics can also personalize antimicrobial dosing by fusing real-time drug-monitoring data. Large language models (LLMs) build upon these advances by transforming unstructured clinical narratives into structured phenotypes suitable for predictive modeling, automatically summarizing patient encounters, generating synthetic cohorts for rare conditions, and providing real-time conversational decision support at the patient’s bedside. Despite rapid progress, real-world deployment faces hurdles: high computational and licensing costs, vendor-specific implementation constraints, limited cross-site model transferability, and fragmented governance of safety, bias, and cybersecurity risks. Rigorous, lifecycle-based evaluation frameworks—covering external validation, cost-effectiveness analysis, and post-deployment monitoring—are required to ensure safe, equitable, and sustainable AI adoption. This review synthesizes current applications, evidential strengths, and unresolved challenges, and proposes a translational roadmap aligning technical innovation with clinical and regulatory realities.}
}
@article{HARKEY2025100687,
title = {Artificial intelligence in osteoarthritis research: summary of the 2025 OARSI pre-congress workshop},
journal = {Osteoarthritis and Cartilage Open},
volume = {7},
number = {4},
pages = {100687},
year = {2025},
issn = {2665-9131},
doi = {https://doi.org/10.1016/j.ocarto.2025.100687},
url = {https://www.sciencedirect.com/science/article/pii/S2665913125001232},
author = {Matthew S. Harkey and Kerry E. Costello and Bella Mehta and Chunyi Wen and Anne-Marie Malfait and Henning Madry and Brooke Patterson},
keywords = {Generative AI, Biomechanics, Imaging biomarkers, Large language models, Ethics},
abstract = {Objective
Artificial intelligence (AI) is transforming musculoskeletal research, offering new approaches to diagnosis, prognosis, and patient management in osteoarthritis (OA). However, implementation and ethical challenges persist. This manuscript summarizes insights from the OARSI 2025 Pre-Congress Workshop on Artificial Intelligence in Osteoarthritis Research, highlighting opportunities and challenges in applying AI across biomechanics, imaging, and clinical research domains.
Design
The workshop, organized by the OARSI Early Career Investigator Committee and co-chaired by Drs. Matthew Harkey and Brooke Patterson, convened experts to discuss the use of AI in real-world biomechanics data collection, radiomics for imaging-based biomarkers, and large language models (LLMs) for clinical and research applications. Emphasis was placed on the need for interdisciplinary collaboration and ethical oversight.
Results
In biomechanics, AI-driven markerless motion capture and wearable sensors enable scalable, ecologically valid data collection, though issues such as class imbalance, data privacy, and model interpretability remain. In imaging, radiomics and deep learning models show promise for early OA detection and progression prediction but face challenges in domain adaptation and external validation. In clinical research, LLMs can streamline documentation and thematic analysis but must address concerns around bias, data security, and transparency. Across domains, transparency, reproducibility, and ethical use of AI were emphasized as critical for maintaining scientific rigor.
Conclusions
Cross-disciplinary collaboration and AI literacy are essential to responsibly advance AI integration in OA research. The workshop's collective insights call for ethical, patient-centered approaches that leverage AI's strengths while preserving research integrity and trust.}
}
@article{HUNT2025e00575,
title = {Font of innovation or algorithmic deforestation? The ecosystem impacts of artificial intelligence in entrepreneurship},
journal = {Journal of Business Venturing Insights},
volume = {24},
pages = {e00575},
year = {2025},
issn = {2352-6734},
doi = {https://doi.org/10.1016/j.jbvi.2025.e00575},
url = {https://www.sciencedirect.com/science/article/pii/S2352673425000629},
author = {Richard A. Hunt and Rasim Serdar Kurdoglu},
keywords = {Entrepreneurial ecosystems, Artificial intelligence, Generative AI, Algorithms, Variance minimization, Homogenization, Mutations, Selection, Creativity, Innovation, Techno-social impacts on business venturing, AI ethics},
abstract = {Artificial intelligence (AI) is increasingly embedded in the infrastructures, practices, and decision-making routines of founders, firms, and entrepreneurial ecosystems. For entrepreneurship, this appears to be a tremendous boon to value creation. By widening the aperture of individual entrepreneurs beyond the narrow limits of human cognition, assistive algorithms – and particularly the ground-breaking, readily accessible capabilities of Generative AI (Gen AI) – appear poised to deliver game-changing exploratory tools, enhanced predictive insights, operational efficiencies, and resource-preserving decision-support tools. Yet, the long-term, society-wide impacts are far less clear. One cause for concern is the variance-minimizing features of AI, a foundational design principle that reduces deviation and enhances the predictive stability of AI tools. In this, we identify a paradox wherein AI tools often enhance the individual creativity of entrepreneurs but, at scale, may erode collective entrepreneurial dynamism by filtering out non-algorithmic, highly serendipitous, mutation-generating, and variance-maximizing behaviors. Drawing upon the principles of rainforest logics, we theorize how AI's growing influence on entrepreneurial judgment, strategy, and ecosystem design may lead to a system-wide homogenization in decision-making and a decline in radical experimentation. With this, there is the danger of a corresponding increase in what we have dubbed algorithmic deforestation, involving systemic risks to the vitality and mutation-generating capacity of entrepreneurial ecosystems through the unintentional suppression of cognitive and behavioral diversity.}
}
@article{SEZGIN2025,
title = {Era of Generalist Conversational Artificial Intelligence to Support Public Health Communications},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/69007},
url = {https://www.sciencedirect.com/science/article/pii/S143888712500086X},
author = {Emre Sezgin and Ahmet Baki Kocaballi},
keywords = {messaging apps, public health communication, language models, artificial intelligence, AI, generative AI, conversational AI},
abstract = {The integration of artificial intelligence (AI) into health communication systems has introduced a transformative approach to public health management, particularly during public health emergencies, capable of reaching billions through familiar digital channels. This paper explores the utility and implications of generalist conversational artificial intelligence (CAI) advanced AI systems trained on extensive datasets to handle a wide range of conversational tasks across various domains with human-like responsiveness. The specific focus is on the application of generalist CAI within messaging services, emphasizing its potential to enhance public health communication. We highlight the evolution and current applications of AI-driven messaging services, including their ability to provide personalized, scalable, and accessible health interventions. Specifically, we discuss the integration of large language models and generative AI in mainstream messaging platforms, which potentially outperform traditional information retrieval systems in public health contexts. We report a critical examination of the advantages of generalist CAI in delivering health information, with a case of its operationalization during the COVID-19 pandemic and propose the strategic deployment of these technologies in collaboration with public health agencies. In addition, we address significant challenges and ethical considerations, such as AI biases, misinformation, privacy concerns, and the required regulatory oversight. We envision a future with leverages generalist CAI in messaging apps, proposing a multiagent approach to enhance the reliability and specificity of health communications. We hope this commentary initiates the necessary conversations and research toward building evaluation approaches, adaptive strategies, and robust legal and technical frameworks to fully realize the benefits of AI-enhanced communications in public health, aiming to ensure equitable and effective health outcomes across diverse populations.}
}
@article{RUIZ2025104293,
title = {Artificial intelligence-created personal statements compared with applicant-written personal statements: a survey of obstetric anesthesia fellowship program directors in the United States},
journal = {International Journal of Obstetric Anesthesia},
volume = {61},
pages = {104293},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2024.104293},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X24003054},
author = {A.M. Ruiz and M.B. Kraus and K.W. Arendt and D.R. Schroeder and E.E. Sharpe},
keywords = {Artificial intelligence, Generative AI, Medical education, Obstetric anesthesia, Personal statements, Fellowship},
abstract = {Background
A personal statement is a common requirement in medical residency and fellowship applications. Generative artificial intelligence may be used to create a personal statement for these applications.
Methods
Two personal statements were created using OpenAI’s Chat Generative Pre-trained Transformer (ChatGPT) and two applicant-written statements were collected. A survey was sent to obstetric anesthesia fellowship program directors in the United States to assess the perceived readability, authenticity, and originality of the four personal statements. In addition, the survey assessed perceptions of applicants who use artificial intelligence to write a personal statement, including their integrity, work ethic, reliability, intelligence, and English proficiency.
Results
Surveyed fellowship directors could not accurately discern whether statements were applicant-written or artificial intelligence-generated. The artificial intelligence-generated personal statements were rated as more readable and original than the applicant-written statements. Most program directors were moderately or extremely concerned about the applicant’s integrity, work ethic, and reliability if they suspected the applicant utilized ChatGPT.
Conclusions
Program directors could not accurately discern if the statements were written by a person or artificial intelligence and would have concerns about an applicant suspected of using artificial intelligence. Medical training programs may benefit from outlining their expectations regarding applicants’ use of artificial intelligence.}
}
@article{WEN2025,
title = {EdgeAIGC: Model caching and resource allocation for Edge Artificial Intelligence Generated Content},
journal = {Digital Communications and Networks},
year = {2025},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2025.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2352864825001142},
author = {Wu Wen and Yibin Huang and Xinxin Zhao and Peiying Zhang and Kai Liu and Guowei Shi},
keywords = {Generative AI, Edge Model Caching, Resource Allocation, Edge Intelligence},
abstract = {With the rapid development of Generative Artificial Intelligence technology, the traditional cloud-based centralized model training and inference face significant limitations due to high transmission latency and costs, which restrict user-side in-situ Artificial Intelligence Generated Content (AIGC) service requests. To this end, we propose the Edge Artificial Intelligence Generated Content (EdgeAIGC) framework, which can effectively solve the problems brought by cloud computing by implementing in-situ processing of services close to the data source through edge computing. However, AIGC models usually have a large parameter scale and complex computing requirements, which poses a huge challenge to the storage and computing resources of edge devices. This paper focuses on the edge intelligence model caching and resource allocation problems in the EdgeAIGC framework, aiming to improve the cache hit rate and resource utilization of edge devices for models by optimizing the model caching strategy and resource allocation scheme, and realize in-situ AIGC service processing. With the optimization objectives of minimizing service request response time and execution cost in resource-constrained environments, we employ the Twin Delayed Deep Deterministic Policy Gradient algorithm for optimization. Experimental results show that, compared with other methods, our model caching and resource allocation strategies can effectively improve the cache hit rate by at least 41.06% and reduce the response cost.}
}
@article{LIM2025,
title = {The art of medical synthesis: Where Chinese medical wisdom intersects with artificial intelligence},
journal = {Journal of Traditional Chinese Medical Sciences},
year = {2025},
issn = {2095-7548},
doi = {https://doi.org/10.1016/j.jtcms.2025.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S209575482500078X},
author = {Enoch Chi Ngai Lim and Nga Chong Lisa Cheng and Chi Eung Danforn Lim},
keywords = {Artificial intelligence, Chinese medicine, Western medicine, Regulation, Ethics},
abstract = {Generative artificial intelligence (AI), specifically large language models, such as DeepSeek, has accelerated the digital transformation of healthcare systems in both developing and developed countries. The use of AI in diagnostics, image processing and interpretation, treatment personalization, clinical documentation, and drug discovery is an example of the implementation of AI in Western medicine. The need for evidence-based studies and a standardized approach to scientific medicine aligns well with these applications. AI can leave a lasting impact on the Chinese medicine (CM) landscape by increasing expectations and presenting new challenges. The analogy between the CM-specific diagnostic methods and syndrome differentiation, which is holistic, pattern-oriented, patient-centered, and clinical data analysis, is significant at multiple levels. These qualities pose challenges for AI usage in CM, which heavily relies on structured data and pattern recognition. Despite these adversities, AI can still be used in CM through data standardization, prediction formulation, and treatment planning, provided that the integration of this tool considers the primary principles of CM and adheres to ethical and regulatory considerations. This review examines the dichotomous approach to health and medicine in the contexts of AI and CM, highlighting the evolving potential, inherent limitations, and ethical and regulatory issues associated with the application of AI to CM. It provides a foundation for developing technologically progressive yet culturally and philosophically sensitive strategies that are in harmony with traditional clinical values.}
}
@article{BURNSIDE2025577,
title = {Artificial Intelligence in Radiology: A Leadership Survey},
journal = {Journal of the American College of Radiology},
volume = {22},
number = {5},
pages = {577-585},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025000419},
author = {Elizabeth S. Burnside and Thomas M. Grist and Michael R. Lasarev and John W. Garrett and Elizabeth A. Morris},
keywords = {Artificial intelligence, generative AI, leadership, radiology chairs, survey},
abstract = {Purpose
Surveys to assess views about artificial intelligence (AI) of various diagnostic radiology constituencies have revealed interesting combinations of enthusiasm, caution, and implementation priorities. We surveyed academic radiology leaders about their views on AI and how they intend to approach AI implementation in their departments.
Materials and methods
We conducted a web survey of Society of Chairs of Academic Radiology Departments members between October 5 and October 31, 2023, to solicit optimism or pessimism about AI, target use cases, planned implementation, and perceptions of their workforce. P values are provided only for descriptive purposes and have not been adjusted for multiple testing in this exploratory research.
Results
The survey was sent to the 112 Society of Chairs of Academic Radiology Departments members and 43 responded (38%). Chairs were optimistic, with no statistical difference between views of AI in general versus generative AI. Chairs plan to implement AI to improve quality and efficiency (43 of 43, 100%), burnout (41 of 43, 95%), health care costs (22 of 43, 51%), and equity (27 of 43, 63%) and most likely will target the postprocessing (26 of 43, 60%), interpretation workflow (26 of 43, 60%), and image acquisition (18 of 43, 42%) steps in the imaging value chain. Chairs perceived that radiologists (36 of 43, 84%) and technologists (38 of 43, 88%) were not particularly worried about being displaced but saw trainees as slightly less confident (31 of 43, 72%). Free text responses revealed concerns about the cost of AI and emphasized trade-offs that needed to be balanced.
Conclusion
Radiology chairs are optimistic about AI and poised to tackle departmental challenges. Concerns about generative AI and workforce replacement are minimal.}
}
@article{ROBERTS2024103081,
title = {Artificial intelligence and innovation management: Charting the evolving landscape},
journal = {Technovation},
volume = {136},
pages = {103081},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103081},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001317},
author = {Deborah L. Roberts and Marina Candi},
keywords = {Artificial intelligence, Generative artificial intelligence, Innovation management, Innovation process},
abstract = {The excitement surrounding Artificial Intelligence (AI) is palpable. It is rapidly gaining prevalence in academia, business, and personal use. In particular, the emergence of generative AI, exemplified by large language models such as ChatGPT, has been marked by substantial media attention, discourse, and hype. Like most, if not all, aspects of business, innovation processes have been impacted. However, little is known about the degree of impact or the benefits that might be gained. To cut through the hype and understand the use of AI in innovation processes in businesses today, a large-scale survey amongst innovation managers in the USA was conducted, followed by interviews. The findings indicate that the use of AI in innovation processes is high and widespread, with AI being used for more than half of the surveyed firms' innovation projects. Furthermore, AI is used more in the development stage of the innovation process than in the idea or commercialization stages, which counters much of the existing discourse, which focuses on the idea stage. We uncover interesting differences by comparing the use and impact of generative AI with that of more traditional AI. Among these is a significant difference in expected benefits in making employees’ jobs more fulfilling — managers believe generative AI is more likely to confer this benefit than traditional AI. This paper offers two valuable contributions. First, it enriches the evolving dialogue at the intersection of AI and innovation management by offering much-needed empirical evidence about practical applications. Second, it provides timely managerial implications by examining relationships between the use of AI and innovation performance and understanding the benefits that AI can confer in the innovation process.}
}
@article{JU2025102955,
title = {Screening social anxiety with the Social Artificial Intelligence Picture System},
journal = {Journal of Anxiety Disorders},
volume = {109},
pages = {102955},
year = {2025},
issn = {0887-6185},
doi = {https://doi.org/10.1016/j.janxdis.2024.102955},
url = {https://www.sciencedirect.com/science/article/pii/S0887618524001312},
author = {Qianqian Ju and Zhijian Xu and Zile Chen and Jiayi Fan and Han Zhang and Yujia Peng},
keywords = {Social anxiety, Artificial Intelligence generative model, Social visual stimuli, Picture database, Screening, Machine learning, Longitudinal study},
abstract = {Social anxiety disorder (SAD) is a prevalent anxiety disorder marked by strong fear and avoidance of social scenarios. Early detection of SAD lays the foundation for the introduction of early interventions. However, due to the nature of social avoidance in social anxiety, the screening is challenging in the clinical setting. Classic questionnaires also bear the limitations of subjectivity, memory biases under repeated measures, and cultural influence. Thus, there exists an urgent need to develop a reliable and easily accessible tool to be widely used for social anxiety screening. Here, we developed the Social Artificial Intelligence Picture System (SAIPS) based on generative multi-modal foundation artificial intelligence (AI) models, containing a total of 279 social pictures and 118 control pictures. Social scenarios were constructed to represent core SAD triggers such as fear of negative evaluation, social interactions, and performance anxiety, mapping to specific dimensions of social anxiety to capture its multifaceted nature. Pictures devoid of social interactions were included as a control, aiming to reveal response patterns specific to social scenarios and to improve the system’s precision in predicting social anxiety traits. Through laboratory and online experiments, we collected ratings on SAIPS from five dimensions. Machine learning results showed that ratings on SAIPS robustly reflected and predicted an individual’s trait of social anxiety, especially social anxiety and arousal ratings. The prediction was reliable, even based on a short version with less than 30 pictures. Together, SAIPS may serve as a promising tool to support social anxiety screening and longitudinal predictions.}
}
@article{LEWALLEN2025,
title = {Impact of artificial intelligence in vision science: A systematic review of progress, emerging trends, data domain quantification, and critical gaps},
journal = {Survey of Ophthalmology},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2025.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0039625725001717},
author = {Colby F. Lewallen and Davide Ortolan and Dominik Reichert and Ruchi Sharma and Kapil Bharti},
keywords = {Artificial intelligence, Vision science, Ophthalmic imaging, Multimodal AI, Generative AI, Diabetic Retinopathy, Age-related Macular Degeneration},
abstract = {The prominence of artificial intelligence (AI) is growing exponentially, yet its implementation across research domains is uneven. To quantify AI trends in vision science, we evaluated over 100,000 PubMed article metadata spanning 35 years. Using Medical Subject Headings (MeSH) terms, we analyzed trends across four prominent ocular diseases: age-related macular degeneration, diabetic retinopathy, glaucoma, and cataract. Most articles utilized research techniques from at least one of the following domains: biological models, molecular profiling, image-based analysis, and clinical outcomes. Our quantification reveals that AI prominence is disproportionally concentrated in the image-based analysis domain, and, additionally, among 4 diseases evaluated, AI prevalence in cataract research is lagging. Contributing factors towards these disparities include insufficient data standardization, complex data structures, limited data availability, unresolved ethical concerns, and not gaining meaningful improvements over human-based interpretations. By mapping where AI thrives and where it lags, we offer a quantitative reference for funding agencies, clinicians, and vision scientists. Connecting various research domains with multimodal and generative AI could improve diagnostic utility; enabling earlier diagnosis, personalized therapy, reduced healthcare costs, and accelerate innovation. Future work should move AI in vision science beyond image-centric pattern recognition toward integrative, mechanistic analyses that explain – rather than merely detect – disease.}
}
@article{WONGVIBULSIN2025593,
title = {Educating Dermatologists for the Artificial Intelligence Era},
journal = {Dermatologic Clinics},
volume = {43},
number = {4},
pages = {593-601},
year = {2025},
note = {Artificial Intelligence in Dermatology},
issn = {0733-8635},
doi = {https://doi.org/10.1016/j.det.2025.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S073386352500049X},
author = {Shannon Wongvibulsin and Ivy Lee},
keywords = {Artificial intelligence (AI) in dermatology, Medical education, Patient education, AI literacy, Learning health systems}
}
@article{LAWTON2025,
title = {Artificial intelligence in paediatric respiratory medicine},
journal = {Paediatric Respiratory Reviews},
year = {2025},
issn = {1526-0542},
doi = {https://doi.org/10.1016/j.prrv.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1526054225000818},
author = {Adam Lawton and Dominic Hughes},
keywords = {Artificial intelligence, Machine learning, Paediatric respiratory medicine},
abstract = {Proponents of artificial intelligence (AI) believe that it will revolutionise the modern world, affecting how healthcare is delivered and improve both the clinical care we provide and the ease with which we perform our work. In this paper we explain what is meant by ‘artificial intelligence’ and explore how this technology has been implemented, or might be implemented, with respect to paediatric respiratory medicine. We review the current literature on how AI has been used to improve diagnostics − including examples in radiology, primary ciliary dyskinesia (PCD) diagnostics, sleep medicine, and pulmonary function tests. We also review how AI has been applied to therapeutics and drug discovery, how it will impact evidence-based medicine and literature review, and how clinician support tools will assist us in our work.}
}
@article{STEVENS2025100831,
title = {A Comparison of Artificial Intelligence Platforms in the Utility of Answering Frequently Asked Questions About Carpal Tunnel Syndrome: A Cross-Sectional Study},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100831},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100831},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001513},
author = {Calista Stevens and Mehreen Pasha and Dashun Liu and Andrew Block and Anthony Parrino and Craig Rodner},
keywords = {Carpal tunnel syndrome, Generative artificial intelligence, Hand, Orthopedic surgery},
abstract = {Purpose
The rise of artificial intelligence (AI) in health care comes with increasing concerns about the use and integrity of the information it generates. Chat Generative Pre-Trained Transformer (ChatGPT) 3.5, Google Gemini, and Bing Copilot are free AI chatbot platforms that may be used for answering medical questions and disseminating medical information. Given that carpal tunnel syndrome accounts for 90% of all neuropathies, it is important to understand the accuracy of the information patients may be receiving. The purpose of this study is to determine the use and accuracy of responses generated by ChatGPT, Google Gemini, and Bing Copilot in answering frequently asked questions about carpal tunnel syndrome.
Methods
Two independent authors scored responses using the DISCERN tool. DISCERN consists of 15 questions assessing health information on a five-point scale, with total scores ranging from 15 to 75 points. Then, a two-factor analysis of variance was conducted, with scorer and chatbot type as the factors.
Results
One-way analysis of variance revealed no significant difference in DISCERN scores among the three chatbots. The chatbots each scored in the “fair” range, with means of 45 for ChatGPT, 48 for Bing Copilot, and 46 for Google Gemini. The average Journal of the American Medical Association score for ChatGPT and Google Gemini surpassed that of Bing Copilot, with averages of 2.3, 2.3, and 1.8, respectively.
Conclusions
ChatGPT, Google Gemini, and Bing Copilot platforms generated relatively reliable answers for potential patient questions about carpal tunnel syndrome. However, users should continue to be aware of the shortcomings of the information provided, given the lack of citations, potential for misconstrued information, and perpetuated biases that inherently come with using such platforms. Future studies should explore the response quality for less common orthopedic pathologies and assess patient perceptions of response readability to determine the value of AI as a patient resource across the medical field.
Type of study/level of evidence
Cross-sectional study V}
}
@article{URBINA202514,
title = {Disability Ethics and Education in the Age of Artificial Intelligence: Identifying Ability Bias in ChatGPT and Gemini},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {106},
number = {1},
pages = {14-19},
year = {2025},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2024.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0003999324011912},
author = {Jacob T. Urbina and Peter D. Vu and Michael V. Nguyen},
keywords = {Artificial intelligence, Bias, Digital health technology, Disability discrimination, Rehabilitation},
abstract = {Objective
To identify and quantify ability bias in generative artificial intelligence large language model chatbots, specifically OpenAI's ChatGPT and Google's Gemini.
Design
Observational study of language usage in generative artificial intelligence models.
Setting
Investigation-only browser profile restricted to ChatGPT and Gemini.
Participants
Each chatbot generated 60 descriptions of people prompted without specified functional status, 30 descriptions of people with a disability, 30 descriptions of patients with a disability, and 30 descriptions of athletes with a disability (N=300).
Interventions
Not applicable.
Main Outcome Measures
Generated descriptions produced by the models were parsed into words that were linguistically analyzed into favorable qualities or limiting qualities.
Results
Both large language models significantly underestimated disability in a population of people, and linguistic analysis showed that descriptions of people, patients, and athletes with a disability were generated as having significantly fewer favorable qualities and significantly more limitations than people without a disability in both ChatGPT and Gemini.
Conclusions
Generative artificial intelligence chatbots demonstrate quantifiable ability bias and often exclude people with disabilities in their responses. Ethical use of these generative large language model chatbots in medical systems should recognize this limitation, and further consideration should be taken in developing equitable artificial intelligence technologies.}
}
@article{HELD2025,
title = {Clinician Perceptions of Socrates 2.0: A Multi-Agent Artificial Intelligence Tool to Facilitate Socratic Dialogue},
journal = {Cognitive and Behavioral Practice},
year = {2025},
issn = {1077-7229},
doi = {https://doi.org/10.1016/j.cbpra.2025.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S1077722925000975},
author = {Philip Held and Sarah A. Pridgen and Daniel R. Szoke and Yaozhong Chen and Zuhaib Akhtar and Darpan Amin},
keywords = {Generative artificial intelligence, cognitive behavior therapy, digital mental health, large language models, cognitive restructuring},
abstract = {Cognitive behavioral therapies (CBTs) are effective for various mental health disorders. Socratic dialogue, which helps patients examine and challenge maladaptive beliefs, is a key component of CBTs. Despite their effectiveness, CBTs often face challenges with low homework completion. Digital mental health tools that use generative artificial intelligence (AI), and specifically large language models, may enhance patients’ homework experience by engaging them in interactive Socratic dialogue. This feasibility study explored clinicians’ perceptions of Socrates 2.0, which employs a multi-agent AI approach combining an AI therapist, AI supervisor, and AI external rater. The tool was developed to engage users in Socratic dialogue to help them identify, evaluate, and potentially reframe maladaptive beliefs outside of therapy sessions, and thus reinforce skills, such as cognitive restructuring. A total of nine clinicians with at least a master’s degree were given two weeks of unlimited access to Socrates 2.0 and participated in semi-structured interviews. Transcripts were analyzed thematically. Positive themes included surprise at the tool’s sophistication, its potential as a therapy supplement, empowerment of patients, accessibility, and improved perceptions of AI in mental health care. Negative themes included concerns about repetitive questioning, potential replacement of therapists, limitations in crisis situations, and technology literacy barriers. Clinicians also desired empirical evidence of effectiveness and clarity on data privacy. Overall, clinicians recognized the potential of Socrates 2.0 to enhance CBT but emphasized the importance of careful integration and addressing identified concerns.}
}
@article{AULENBACHER2025,
title = {Development and Reliability Assessment of an Artificial Intelligence-Driven Urticaria Support (AIDUS) Chatbot},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
year = {2025},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2025.07.047},
url = {https://www.sciencedirect.com/science/article/pii/S2213219825007585},
author = {Felix Aulenbacher and Annika Gutsche and Benedict Bihlmaier and Hanna Bonnekoh and Ivan Cherrez-Ojeda and Joachim W. Fluhr and Pavel Kolkhir and Markus Magerl and Martin Metz and Polina Pyatilova and Frank Siebenhaar and Torsten Zuberbier and Sophia Neisinger},
keywords = {Artificial intelligence, Chronic urticaria, ChatGPT},
abstract = {Background
Chronic urticaria (CU) severely impairs patients’ quality of life. Correctly diagnosing and treating CU can take years, so patients seek answers from the Internet to manage the condition.
Objective
We aimed to build a chatbot, Artificial Intelligence-Driven Urticaria Support (AIDUS) for patients with CU and treating physicians and to evaluate its reliability in providing high-quality CU-specific information compared with Chat Generative Pre-Trained Transformer (ChatGPT)-3.5 and ChatGPT-4o.
Methods
AIDUS was developed by an expert committee of urticaria and artificial intelligence specialists using JavaScript and OpenAI’s (https://www.clay.com/dossier/openai-headquarters-office-locations) ChatGPT large language model. PubMed was systematically reviewed to ensure AIDUS contained high-quality information. The chatbot was populated exclusively with selected peer-reviewed CU publications authored by the Charité University, Berlin research group, published after 2014. A total of 254 publications were integrated using ChatGPT-3.5 as the underlying algorithm. We developed A set of 100 validated questions based on current CU knowledge to evaluate the performance of AIDUS. The program was run on the same questions several times and compared for consistency. We tested performance with different chunk- and overlap-size settings to optimize AIDUS’s efficiency and accuracy.
Results
AIDUS outperformed general ChatGPT models in terms of accuracy, consistency, and stability in answering CU-specific questions. AIDUS demonstrated higher average accuracy (94.6%) across multiple test runs compared with ChatGPT-3.5 (42.6%) and ChatGPT-4o (85.7%).
Conclusions
AIDUS provides reliable, high-quality information about CU, addressing patients’ and physicians’ needs for accurate, relevant answers based on peer-reviewed medical literature. AIDUS remains a means of assistance and does not replace consultation with a physician.}
}
@article{ASHKBOUS2026103989,
title = {Artificial intelligence for eco-design: a systematic review},
journal = {Advanced Engineering Informatics},
volume = {69},
pages = {103989},
year = {2026},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103989},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625008821},
author = {Maryam Ashkbous and Elham Ghorbani and Samira Keivanpour},
keywords = {Artificial intelligence, Eco-design, Sustainable product development, Life cycle assessment, Circular economy},
abstract = {Eco-design integrates environmental considerations into product design, recognizing 80% of sustainability impacts determined at the design phase. Artificial intelligence (AI) provides powerful tools for optimizing designs, assessing environmental impacts, and supporting circular economy, making eco-design proactive. Despite AI use in sustainable product development, no review has synthesized these efforts. Therefore, we conducted a systematic review using the PRISMA method, covering 38 studies from 2014 to 2024 applied AI in eco-design. This is the first review to consider all life-cycle stages with eco-design practices, integrating Ellen MacArthur circularity principles, United Nations sustainable development goals (SDGs), life cycle assessment (LCA), industrial applications, and AI methods. Our findings reveal: 1- an imbalanced focus across product life-cycle stages, with most studies addressing design and end-of-life, while production, use-life, and distribution remain underexplored. 2- Common eco-design practices include recycling, energy reduction, and disassembly, with less focus on non-hazardous materials, waste minimization, and remanufacturing. 3- While neural networks and hybrid AI methods are commonly applied for material compatibility and emissions prediction, more advanced AI-based approaches such as generative AI and LLMs have yet to be used in design, LCA, and circularity analysis. 4- No study applies all four Ellen MacArthur Technosphere circular economy strategies. 5- Researchers rarely couple LCA with cradle-to-cradle assessments or embed their results in real-time design simulations. 6- Case studies mostly focus on electronics and household appliances, with limited application in automotive, aviation, maritime, and healthcare. 7- SDG consideration mainly centers on SDGs 12 and 13, with more attention neededforotherSDGs.}
}
@article{MUNIR2025102370,
title = {Taking the plunge together: A student-led faculty learning seminar series on artificial intelligence},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {8},
pages = {102370},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102370},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000917},
author = {Faria Munir and Elma Abdulbaki and Zeba Saiyad and Heather Ipema},
keywords = {Artificial intelligence, Drug information, Higher education, Pharmacy, Faculty, Pharmacy students, Learning series},
abstract = {Objective
This pilot study explored the effectiveness of a student-led faculty development series by evaluating two key outcomes: the capacity of students to deliver meaningful professional development sessions to faculty and the impact of these sessions on faculty perceptions of generative artificial intelligence (AI).
Methods
In a flipped classroom model, two pharmacy students and 12 faculty members engaged in a semester-long learning series on AI. Each week, students presented on a selected topic followed by discussions that facilitated self-directed learning, including decision-making and project management. Faculty perceptions of AI were evaluated before and after the series using an anonymous survey tool (Technology Acceptance Model Edited to Assess ChatGPT Adoption, TAME-ChatGPT). Respondents created a self-chosen code to link their responses. Additionally, students completed a questionnaire to gauge their reflective thinking after the series.
Results
Faculty participation averaged 7 members per session. Twelve faculty completed the pre-survey, while 8 faculty completed the post-survey. Among those who had used ChatGPT (n = 4 pre [33 %], n = 2 post [25 %]), scores for usefulness increased, while concerns about risks decreased. In contrast, faculty who had not used ChatGPT (n = 8 pre [67 %], n = 6 post [75 %]) reported unchanged or improved scores for ease of use and reduced anxiety. Both students responded positively to the reflective thinking questionnaire.
Conclusion
This pilot study demonstrated that a student-led faculty learning series effectively fostered mutual collaborative learning, benefiting both faculty and students. Pharmacy students, often an underutilized resource, can play a valuable role in faculty development. Colleges of pharmacy may enhance faculty engagement by integrating student-led initiatives into their programs.}
}
@article{LIU2025,
title = {Leveraging Artificial Intelligence for Digital Symptom Management in Oncology: The Development of CRCWeb},
journal = {JMIR Cancer},
volume = {11},
year = {2025},
issn = {2369-1999},
doi = {https://doi.org/10.2196/68516},
url = {https://www.sciencedirect.com/science/article/pii/S2369199925000710},
author = {Darren Liu and Yufen Lin and Runze Yan and Zhiyuan Wang and Delgersuren Bold and Xiao Hu},
keywords = {colorectal cancer, health disparity, health equity, generative artificial intelligence, large language model, software engineering, artificial intelligence},
abstract = {Digital health interventions offer promise for scalable and accessible health care, but access is still limited by some participatory challenges, especially for disadvantaged families facing limited health literacy, language barriers, low income, or living in marginalized areas. These issues are particularly pronounced for patients with colorectal cancer (CRC), who often experience distressing symptoms and struggle with educational materials due to complex jargon, fatigue, or reading level mismatches. To address these issues, we developed and assessed the feasibility of a digital health platform, CRCWeb, to improve the accessibility of educational resources on symptom management for disadvantaged patients with CRC and their caregivers facing limited health literacy or low income. CRCWeb was developed through a stakeholder-centered participatory design approach. Two-phase semistructured interviews with patients, caregivers, and oncology experts informed the iterative design process. From the interviews, we developed the following 5 key design principles: user-friendly navigation, multimedia integration, concise and clear content, enhanced accessibility for individuals with vision and reading disabilities, and scalability for future content expansion. Initial feedback from iterative stakeholder engagements confirmed high user satisfaction, with participants rating CRCWeb an average of 3.98 out of 5 on the postintervention survey. Additionally, using generative artificial intelligence tools, including large language models like ChatGPT and multimedia generation tools such as Pictory, complex health care guidelines were transformed into concise, easily comprehensible multimedia content, and made accessible through CRCWeb. User engagement was notably higher among disadvantaged participants with limited health literacy or low income, who logged into the platform 2.52 times more frequently than nondisadvantaged participants. The structured development approach of CRCWeb demonstrates that generative artificial intelligence–powered multimedia interventions can effectively address health care accessibility barriers faced by disadvantaged patients with CRC and caregivers with limited health literacy or low income. This structured approach highlights how digital innovations can enhance health care.
International Registered Report Identifier (IRRID)
RR2-10.2196/48499}
}
@article{SABRI20252443,
title = {The Role of Artificial Intelligence in Improving Diagnostic Accuracy in Medical Imaging: A Review},
journal = {Computers, Materials and Continua},
volume = {85},
number = {2},
pages = {2443-2486},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.066987},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825008586},
author = {Omar Sabri and Bassam Al-Shargabi and Abdelrahman Abuarqoub},
keywords = {Artificial intelligence, artificial intelligence applications, deep learning, medical imaging, diagnostic accuracy, bibliometric analysis},
abstract = {This review comprehensively analyzes advancements in artificial intelligence, particularly machine learning and deep learning, in medical imaging, focusing on their transformative role in enhancing diagnostic accuracy. Our in-depth analysis of 138 selected studies reveals that artificial intelligence (AI) algorithms frequently achieve diagnostic performance comparable to, and often surpassing, that of human experts, excelling in complex pattern recognition. Key findings include earlier detection of conditions like skin cancer and diabetic retinopathy, alongside radiologist-level performance for pneumonia detection on chest X-rays. These technologies profoundly transform imaging by significantly improving processes in classification, segmentation, and sequential analysis across diverse modalities such as X-rays, Computed Tomography (CT), Magnetic Resonance Imaging (MRI), and ultrasound. Specific advancements with Convolutional Neural Networks, Recurrent Neural Networks, and ensemble learning techniques have facilitated more precise diagnosis, prediction, and therapy planning. Notably, Generative Adversarial Networks address limited data through augmentation, while transfer learning efficiently adapts models for scarce labeled datasets, and Reinforcement Learning shows promise in optimizing treatment protocols, collectively advancing patient care. Methodologically, a systematic review (2015–2024) used Scopus and Web of Science databases, yielding 7982 initial records. Of these, 1189 underwent bibliometric analysis using the R package ‘Bibliometrix’, and 138 were comprehensively reviewed for specific findings. Research output surged over the decade, led by Institute of Electrical and Electronics Engineers (IEEE) Access (19.1%). China dominates publication volume (36.1%), while the United States of America (USA) leads total citations (5605), and Hong Kong exhibits the highest average (55.60). Challenges include rigorous validation, regulatory clarity, and fostering clinician trust. This study highlights significant emerging trends and crucial future research directions for successful AI implementation in healthcare.}
}
@article{SOYSAL2025152023,
title = {The relationship between anxiety about artificial intelligence and nurses' perceptions of job security: The impact of technological transformation},
journal = {Applied Nursing Research},
pages = {152023},
year = {2025},
issn = {0897-1897},
doi = {https://doi.org/10.1016/j.apnr.2025.152023},
url = {https://www.sciencedirect.com/science/article/pii/S0897189725001259},
author = {Ganime Esra SOYSAL and Mehmet Ali CALIŞKAN and Aykut TURGUT},
keywords = {Artificial intelligence, Anxiety, Nursing, Employment, Technology},
abstract = {Aim
The objective of this study is to evaluate the anxiety levels of nurses regarding artificial intelligence and its impact on their perception of job security.
Background
The nursing profession, which is affected by artificial intelligence, has concerns about this transformation.
Design
This study employed a cross-sectional and descriptive.
Methods
The was conducted with 104 nurses working in a hospital between December 2024 and March 2025. Data was collected using the Descriptive Information Form, Artificial Intelligence Anxiety Scale and Job Security Perception Scale.
Results
The nurses participating in this study exhibited moderate anxiety towards artificial intelligence according to the scores they received from the Artificial Intelligence Anxiety Scale. The relationship between nurses' artificial intelligence anxiety and the perception of job security was not statistically significant (p ≥ 0.165). Nurses with ≥10 years' experience had higher AIA scores than those with less experience, but this difference was not significant (p = 0.056). It was stated that 80.8 % (n:84) of the nurses did not use ChatGPT or any other application supported by artificial intelligence in their professional life. The Job Security Perception Scale scores were no different between those who saw artificial intelligence as a threat and those who did not (p = 0.870).
Conclusions
It was observed that nurses were inadequate in using artificial intelligence technologies and experienced moderate anxiety, but there was no significant relationship between this anxiety and their perceptions of job security.}
}
@article{HUWER2025100303,
title = {Competencies for teaching with and about artificial intelligence in the natural sciences – DiKoLAN AI},
journal = {Computers and Education Open},
pages = {100303},
year = {2025},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2025.100303},
url = {https://www.sciencedirect.com/science/article/pii/S266655732500062X},
author = {Johannes Huwer and Christoph Thyssen and Sebastian Becker-Genschow and Lena von Kotzebue and Alexander Finger and Erik Kremser and Sandra Berber and Mathea Brückner and Nikolai Maurer and Till Bruckermann and Monique Meier and Lars-Jochen Thoms},
keywords = {Artificial intelligence, STEM education, Digital competencies, AI literacy, TPACK, Preservice teachers},
abstract = {The rapid advancement and widespread adoption of digital technologies have transformed the education sector. Among these developments, the emergence of generative Artificial Intelligence (AI) tools such as ChatGPT has had a considerable impact on teaching and learning practices. While the integration of AI into educational settings is becoming increasingly common, subject-specific analyses, especially in STEM education, are still lacking. This paper examines the specific challenges and potential of AI in the context of STEM education. It does so by exploring how AI has transformed scientific disciplines and how these changes impact teaching and learning. It highlights the necessity for educators to acquire specific competencies to effectively incorporate AI into their instructional practices. Building on existing frameworks such as DigCompEdu and the subject-specific DiKoLAN, the paper proposes an AI-focused framework: DiKoLAN AI. This framework aligns AI-related teacher competencies with instructional practice in science education. It also provides a structure for categorizing existing teacher training programs. The paper outlines the development of the DiKoLAN AI framework and its content consensus validation by a total of 64 experts trough three iterative cycles. Its practical application is demonstrated through 20 case studies from different authors, which offer a practical approach for supporting teacher training and curriculum design in AI-integrated STEM education. The paper concludes with a discussion of opportunities, challenges and future research needs for teacher professionalization.}
}
@article{BALODA2025112405,
title = {Future of humanity in an artificial intelligence centric world},
journal = {Engineering Applications of Artificial Intelligence},
volume = {162},
pages = {112405},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112405},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625024303},
author = {Sunil Baloda and Monika Sharma and Mukesh Kumar},
keywords = {Trustworthy artificial intelligence, Machine learning, Healthcare, Anomaly detection, Societal impact},
abstract = {This scholarly article rigorously investigates the transformative and disruptive roles of artificial intelligence (AI) in influencing the trajectory of human society. By concentrating on three fundamental sectors—healthcare, finance, and education—it evaluates the ways in which AI augments operational efficiency, facilitates intricate decision-making processes, and introduces innovative capabilities such as personalized medicine and automated financial systems. Concurrently, the analysis underscores urgent ethical dilemmas, encompassing algorithmic bias, accountability deficiencies, data privacy vulnerabilities, and workforce displacement. Employing real-world examples such as Deepfakes, and Neuralink, the article contextualizes emerging challenges within a dynamic socio-technical framework. The research offers a cohesive conceptual model that amalgamates technical, ethical, and governance aspects of AI, while presenting policy recommendations designed to promote transparency, equity, and human-centered AI development. The study emphasizes the necessity for reliable AI systems that humans can trust. The conclusions accentuate the immediate necessity for robust regulatory frameworks and sector-specific ethical supervision to ensure that advancements in AI are harmonized with the well-being of society.}
}
@article{MARINO20241490,
title = {The Application of mHealth and Artificial Intelligence to Chronic Rhinitis},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
volume = {12},
number = {6},
pages = {1490-1492},
year = {2024},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2024.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S2213219824004033},
author = {Michael J. Marino and Bernardo Sousa-Pinto and Devyani Lal},
keywords = {Artificial intelligence, AI, Mobile health, mHealth, Rhinitis, Machine learning, Generative AI}
}
@article{SALIDO2025101924,
title = {Integrating critical thinking and artificial intelligence in higher education: A bibliometric and systematic review of skills and strategies},
journal = {Social Sciences & Humanities Open},
volume = {12},
pages = {101924},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101924},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125006527},
author = {Achmad Salido and Irman Syarif and Melyani Sari Sitepu and  Suparjan and Prima Rias Wana and Ryan Taufika and Rahyuni Melisa},
keywords = {Artificial intelligence, Higher education, Critical thinking, Personalized learning, AI literacy},
abstract = {This study examines the academic landscape on integrating artificial intelligence and critical thinking in higher education, revealing conceptualizations, competencies required by students, challenges and recommended learning strategies. The study employs a bibliometric analysis approach combined with a systematic literature review as a qualitative approach. A total of 640 documents were retrieved from the Scopus database using the query: (“critical thinking” AND (“artificial intelligence” OR AI) AND (“higher education” OR university OR college)), accessed on July 10, 2025. The dataset was limited to 2023–2025, reflecting the period following the widespread adoption of ChatGPT and similar generative AI tools in academic contexts. From this, 290 documents were selected for bibliometric analysis, and 23 were in-depth synthesized based on established inclusion criteria. The findings reveal a growing consolidation of research on AI and critical thinking, driven by a small group of highly influential authors and concentrated in prominent interdisciplinary journals. Five thematic clusters were identified: pedagogical innovation, psychological dimensions, academic ethics, systemic integration, and AI-related literacies. Emerging research directions include personalized learning, digital literacy, engineering education, and ethical AI applications. Critical thinking is conceptualized as a purposeful, evaluative, and self-regulated process that must be preserved despite increasing reliance on AI tools. Key challenges include uncritical dependence on AI, digital literacy disparities, lack of system transparency, and institutional limitations. The study highlights the need for inclusive and adaptive instructional frameworks that integrate AI in ways that support critical thinking in diverse higher education settings.}
}
@article{ARBOIT2025110525,
title = {Surgeons’ Awareness, Expectations, and Involvement with Artificial Intelligence: a Survey Pre and Post the GPT Era},
journal = {European Journal of Surgical Oncology},
pages = {110525},
year = {2025},
issn = {0748-7983},
doi = {https://doi.org/10.1016/j.ejso.2025.110525},
url = {https://www.sciencedirect.com/science/article/pii/S0748798325009539},
author = {Lorenzo Arboit and Dennis N. Schneider and Toby Collins and Daniel A. Hashimoto and Silvana Perretta and Bernard Dallemagne and Jacques Marescaux and Yoav Mintz and Kiyokazu Nakajima and Michele Diana and Tim Horeman and Manish Chand and Rosa Maria Jimenez-Rodriguez and Luigi Manfredi and Hans Fuchs and Young Woo Kim and Martin Wagner and Pieter {de Backer} and Felix Nickel and Nicolas Padoy and Pietro Mascagni},
keywords = {Surgical Data Science, Artificial Intelligence, Surgical Survey, Surgical Education},
abstract = {ABSTRACT
Objective
Artificial Intelligence (AI) is transforming medicine, with generative AI models like ChatGPT reshaping perceptions of its potential. This study examines surgeons’ awareness, expectations, and involvement with AI in surgery through comparative surveys conducted in 2021 and 2024.
Materials and Methods
Two cross-sectional surveys were distributed globally in 2021 and 2024, the first before an IRCAD webinar and the second during the annual EAES meeting. The surveys assessed demographics, AI awareness, expectations, involvement, and ethics (2024 only).
Results
The surveys collected a total of 671 responses from 98 countries, 522 and 149 in 2021 and 2024, respectively. Awareness of AI courses rose from 14.5% in 2021 to 44.6% in 2024, while course attendance increased from 12.9% to 23%. Despite this, familiarity with foundational AI concepts remained limited. Expectations for AI’s role shifted in 2024, with hospital management gaining relevance. Ethical concerns gained prominence, with 87.2% of 2024 participants emphasizing accountability and transparency. Infrastructure limitations remained the primary obstacle to the implementation of AI. Interdisciplinary collaboration and structured training were identified as critical for successful AI adoption. Optimism about AI’s transformative potential remained high, with 79.9% of respondents believing AI would positively impact surgery and 96.6% of surgeons willing to integrate AI into clinical practice.
Discussion and Conclusion
Surgeons’ perceptions of AI are evolving, driven by the rise of generative AI and the advancements in surgical data science. While enthusiasm for integration is strong, knowledge gaps and infrastructural challenges persist. Addressing these through education, ethical frameworks, and infrastructure development is essential.}
}
@incollection{KHALEEL20262,
title = {Future Proofing the Integrity of Assessments Within Business Management Studies for the Age of Artificial Intelligence},
editor = {Vanessa Ratten},
booktitle = {International Encyclopedia of Business Management (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {2-8},
year = {2026},
isbn = {978-0-443-13702-0},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00330-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013003303},
author = {Fawad Khaleel and Patrick Harte and Alija Avdukic},
keywords = {Academic dishonesty, Academic integrity, Artificial intelligence, Assessment design, Complexity of assessment design, Coursework, Plagiarism, Word count},
abstract = {The content generative artificial intelligence is developing rapidly, and it is challenging the old norms of assessment design within the HEIs. This chapter discusses the impact of AI on the academic integrity, as we argue that with a slight shift within the assessment design, we can address the academic integrity concerns that surfacing within the higher education. This chapter provides practical and useable guidelines that could be used to reduce the breaches of academic integrity within business management programmes at HEIs. These guidelines focus on word count for coursework, complexity of assessment question and social dynamics of assessment design.}
}
@article{ELSAYED2025103083,
title = {Artificial Intelligence adoption, perceptions, and ethical literacy among Arab academic librarians: A survey},
journal = {The Journal of Academic Librarianship},
volume = {51},
number = {5},
pages = {103083},
year = {2025},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2025.103083},
url = {https://www.sciencedirect.com/science/article/pii/S0099133325000795},
author = {Amany M. Elsayed and Majed {Mohammed Abusharhah}},
keywords = {Artificial intelligence in libraries, Academic libraries, Academic librarians, Artificial intelligence literacy, Artificial intelligence in higher education, Arab countries, Artificial intelligence ethics},
abstract = {The study explored how Arab academic libraries are adopting artificial intelligence (AI) and examined the awareness of AI ethical considerations from the perspectives of Arab academic librarians. It utilized a survey-based approach, employing a snowball sampling technique across 48 academic libraries in 17 Arab countries. The research instrument was a web-based questionnaire, which received responses from a total of 272 participants. The findings revealed that 37.5 % of respondents indicated that their libraries use AI, with cataloging and generating metadata being the most common applications used by 43 % of libraries. The study highlighted several challenges to AI adoption in Arab academic libraries, including a lack of necessary infrastructure and staff training. Moreover, about 81 % of Arab academic librarians believed that intellectual property and copyright are the most important ethical considerations regarding AI. However, only 12% of participants reported having encountered ethical issues related to AI use in their library work. The results indicated that the primary actions taken by Arab academic libraries were offering face-to-face or online seminars and workshops on AI ethics, as well as providing ethical considerations and resources related to academic integrity through their websites. The study recommended that Arab academic libraries organize appropriate training programs to improve AI literacy among staff, develop the necessary infrastructure for AI adoption, and prepare relevant policy documents to guide the ethical use of AI technologies.}
}
@article{HONG2025,
title = {Radiologist Interaction with Artificial Intelligence-Generated Preliminary Reports: A Longitudinal Multireader Study},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025005587},
author = {Eun Kyoung Hong and Chong Hyun Suh and Monika Nukala and Azadehsadat Esfahani and Andro Licaros and Rachna Madan and Andetta Hunsaker and Mark Hammer},
keywords = {Chest radiographs, generative AI, radiologist-AI interaction, report generation},
abstract = {Objectives
To investigate the integration of multimodal AI-generated reports into radiology workflow over time, focusing on their impact on efficiency, acceptability, and report quality.
Methods
A multicase, multireader study involved 756 publicly available chest radiographs interpreted by five radiologists using preliminary reports generated by a radiology-specific multimodal AI model, divided into 7 sequential batches of 108 radiographs each. Two thoracic radiologists assessed the final reports using RADPEER criteria for agreement and 5-point Likert scale for quality. Reading times, rate of acceptance without modification, agreement, and quality scores were measured, with statistical analyses evaluating trends across seven sequential batches.
Results
Radiologists’ reading times for chest radiographs decreased from 25.8 seconds in batch 1 to 19.3 seconds in batch 7 (P < .001). Acceptability increased from 54.6% to 60.2% (P < .001), with normal chest radiographs demonstrating high rates (68.9%) compared with abnormal chest radiographs (52.6%; P < .001). Median agreement and quality scores remained stable for normal chest radiographs but varied significantly for abnormal chest radiographs (all P < .05).
Discussion
The introduction of AI-generated reports improved efficiency of chest radiograph interpretation, and acceptability increased over time. However, agreement and quality scores showed variability, particularly in abnormal cases, emphasizing the need for oversight in the interpretation of complex chest radiographs.}
}
@article{EYO2025757,
title = {A Survey of Artificial Intelligence in Primary Care Fellowships—Practical Tools},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {757-767},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000685},
author = {Eno Eyo and Uzoma Dike},
keywords = {Addiction, Primary care fellowships, Sports medicine, Adolescent medicine, Geriatric medicine, Addiction medicine, Substance use disorder, Artificial intelligence}
}
@article{HELGESON2025622,
title = {Human Reviewers' Ability to Differentiate Human-Authored or Artificial Intelligence–Generated Medical Manuscripts: A Randomized Survey Study},
journal = {Mayo Clinic Proceedings},
volume = {100},
number = {4},
pages = {622-633},
year = {2025},
issn = {0025-6196},
doi = {https://doi.org/10.1016/j.mayocp.2024.08.029},
url = {https://www.sciencedirect.com/science/article/pii/S0025619624004890},
author = {Scott A. Helgeson and Patrick W. Johnson and Nilaa Gopikrishnan and Tapendra Koirala and Pablo Moreno-Franco and Rickey E. Carter and Zachary S. Quicksall and Charles D. Burger},
abstract = {Objective
To assess the ability of humans to differentiate human-authored vs artificial intelligence (AI)–generated medical manuscripts.
Methods
This is a prospective randomized survey study from October 1, 2023, to December 1, 2023, from a single academic center. Artificial intelligence–generated medical manuscripts were created using ChatGPT 3.5 and were evaluated alongside randomly selected human-authored manuscripts. Participants, who were blinded from manuscript selection and creation, were randomized to receive three manuscripts that were either human-authored or AI-generated and had to fill out a survey questionnaire after review regarding who authored the manuscript. The primary outcome was accuracy of human reviewers in differentiating manuscript authors. Secondary outcomes were to identify factors that influenced prediction accuracy.
Results
Fifty-one physicians were included in the study, including 12 post-doctorates, 19 assistant professors, and 20 associate or full professors. The overall specificity of 55.6% (95% CI, 30.8% to 78.5%), sensitivity of 31.2% (95% CI,11.0% to 58.7%), positive predictive value of 38.5% (95% CI,13.9% to 68.4%) and negative predictive value of 47.6% (95% CI, 25.7% to 70.2%). A stratified analysis of human-authored manuscripts indicated that high-impact factor manuscripts were identified with higher accuracy than low-impact factor ones (P=.037). For individual-level data, neither academic rank nor prior manuscript review experience significantly predicted the accuracy. The frequency of AI interaction was a significant factor, with occasional (odds ratio [OR], 8.20; P=.016), fairly frequent (OR, 7.13; P=.033), and very frequent (OR, 8.36; P=.030) use associated with correct identification. Further analysis revealed no significant predictors among the papers' qualities.
Conclusion
Generative AI such as ChatGPT could create medical manuscripts that could not be differentiated from human-authored manuscripts.}
}
@article{ALIER2025103940,
title = {LAMB: An open-source software framework to create artificial intelligence assistants deployed and integrated into learning management systems},
journal = {Computer Standards & Interfaces},
volume = {92},
pages = {103940},
year = {2025},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2024.103940},
url = {https://www.sciencedirect.com/science/article/pii/S0920548924001090},
author = {Marc Alier and Juanan Pereira and Francisco José García-Peñalvo and Maria Jose Casañ and Jose Cabré},
keywords = {Generative artificial intelligence, Education domain, Learning assistant, Retrieval-Augmented Generation (RAG), Large language model (LLM), IMS learning tools interoperability (LTI)},
abstract = {This paper presents LAMB (Learning Assistant Manager and Builder), an innovative open-source software framework designed to create AI-powered Learning Assistants tailored for integration into learning management systems. LAMB addresses critical gaps in existing educational AI solutions by providing a framework specifically designed for the unique requirements of the education sector. It introduces novel features, including a modular architecture for seamless integration of AI assistants into existing LMS platforms and an intuitive interface for educators to create custom AI assistants without coding skills. Unlike existing AI tools in education, LAMB provides a comprehensive framework that addresses privacy concerns, ensures alignment with institutional policies, and promotes using authoritative sources. LAMB leverages the capabilities of large language models and associated generative artificial intelligence technologies to create generative intelligent learning assistants that enhance educational experiences by providing personalized learning support based on clear directions and authoritative fonts of information. Key features of LAMB include its modular architecture, which supports prompt engineering, retrieval-augmented generation, and the creation of extensive knowledge bases from diverse educational content, including video sources. The development and deployment of LAMB were iteratively refined using a minimum viable product approach, exemplified by the learning assistant: “Macroeconomics Study Coach,” which effectively integrated lecture transcriptions and other course materials to support student inquiries. Initial validations in various educational settings demonstrate the potential that learning assistants created with LAMB have to enhance teaching methodologies, increase student engagement, and provide personalized learning experiences. The system's usability, scalability, security, and interoperability with existing LMS platforms make it a robust solution for integrating artificial intelligence into educational environments. LAMB's open-source nature encourages collaboration and innovation among educators, researchers, and developers, fostering a community dedicated to advancing the role of artificial intelligence in education. This paper outlines the system architecture, implementation details, use cases, and the significant benefits and challenges encountered, offering valuable insights for future developments in artificial intelligence assistants for any sector.}
}
@article{SRIDHARAN2025101965,
title = {Artificial intelligence in colloid and interface science: Current research, challenges and future directions},
journal = {Current Opinion in Colloid & Interface Science},
volume = {80},
pages = {101965},
year = {2025},
issn = {1359-0294},
doi = {https://doi.org/10.1016/j.cocis.2025.101965},
url = {https://www.sciencedirect.com/science/article/pii/S1359029425000718},
author = {Simha Sridharan and Tom Bailey and Agnese Marcato and Elena Simone and Nicholas Watson},
keywords = {Artificial intelligence, Machine learning, Colloid science, Interface science},
abstract = {Artificial intelligence (AI) and Machine learning (ML) are transforming colloid and interface science by enabling predictive modelling, autonomous experimentation, and accelerated material design. This review highlights recent advances organised in four topics: (1) prediction of basic physical properties; (2) image analysis; (3) process design, monitoring and optimisation; and (4) morphology and phase behaviour prediction. AI models have improved the prediction accuracy of interfacial tension, critical micelle concentration, foam stability, and complex structure–function relationships, in particular, integrated generative AI approaches support the design of new surfactants and emulsifiers. Image analysis has automated microstructural characterisation and enabled real-time quality control, while AI-enhanced process design has delivered digital twins, closed-loop optimisation, and sustainability-oriented workflows. Morphology and phase behaviour prediction has combined simulation-driven neural networks with generative approaches to accelerate material discovery. The future of AI applications in colloids will be shaped by experimental database design and standardisation, hybrid AI methods integrating physics and surrogate modelling, and AI agents leveraging large language models for literature mining, data curation, and experimental optimisation. Together, these developments promise to establish data-rich, physics informed, and increasingly autonomous research ecosystems for colloids and interface science, accelerating material understanding and design.}
}
@article{CHEEMA2025799,
title = {The Future of Artificial Intelligence and Artificial Intelligence in Primary Care: Challenges and Opportunities},
journal = {Primary Care: Clinics in Office Practice},
volume = {52},
number = {4},
pages = {799-811},
year = {2025},
note = {AI in Primary Care},
issn = {0095-4543},
doi = {https://doi.org/10.1016/j.pop.2025.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0095454325000727},
author = {Alyscia Miriam Cheema},
keywords = {Artificial intelligence in primary care, Primary care practice training with artificial intelligence, Future impacts of AI on primary care, Challenges with AI in primary care}
}
@article{LUKIC2025,
title = {Fundamentals of artificial intelligence for nursing students: Educational innovation},
journal = {Teaching and Learning in Nursing},
year = {2025},
issn = {1557-3087},
doi = {https://doi.org/10.1016/j.teln.2025.08.033},
url = {https://www.sciencedirect.com/science/article/pii/S1557308725002665},
author = {Anita Lukić and Ivan Krešimir Lukić},
keywords = {artificial intelligence, innovation, nursing, teaching, students},
abstract = {Background
In spite of interest in the use of artificial intelligence (AI) in nursing education, there are no studies on teaching nursing students' basics of AI technology.
Innovation
An elective course for undergraduate students of nursing (final year), consigning of 10 hours of lectures, covering the following topics: Basics of AI; Principles and concepts of machine learning; Evaluation of AI-based tools; and Implementation of AI in healthcare.
Results
Nineteen students attended the course and thirteen provided their feedback. Students’ evaluation was positive: 77% (10 out of 13) would pick the same elective again and recommend it to others. They suggested more live demos and dedicating more time to ChatGPT.
Implications
Our experience with a course focusing on basic principles of AI technology as well as list of resources and feedback of our students can be of use to nursing educators when planning similar courses.
Conclusions
Since nursing students’ readiness to embrace AI technology depends on understanding of the technology, educating students on foundational algorithmic principles may have a positive impact on adoption of AI in nursing practice.}
}
@article{HAMADA2025,
title = {Applications of artificial intelligence in tooth extraction: A systematic review},
journal = {Journal of Dental Sciences},
year = {2025},
issn = {1991-7902},
doi = {https://doi.org/10.1016/j.jds.2025.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1991790225003654},
author = {Masakazu Hamada and Ryota Nomura and Tatsuya Akitomo and Satoru Kusaka and Yuko Iwamoto and Shiori Yamamoto and Yuko Ogaya and Kazuhiko Nakano},
keywords = {Artificial intelligence, Machine learning, Deep learning, Oral surgery, Tooth extraction, Review},
abstract = {Background/purpose
Tooth extraction is a common procedure in dental treatment. In recent years, with the advancement of artificial intelligence (AI) technology, research on tooth extraction using AI has been increasing. In the present study, we consider the applicability of AI to tooth extraction through a literature review.
Materials and methods
The PubMed, Scopus, and Web of Science databases were searched for (“tooth extraction”) AND (“artificial intelligence” OR “machine learning” OR “deep learning”) in June 2024.
Results
Thirty-five articles matched the eligibility criteria and were extracted for this review. The most widely covered topics were “relationship between the root of the tooth and the inferior alveolar nerve” and “tooth extraction decision-making” with 10 and 8 articles, respectively. These two topics are considered to be important factors that determine risk and treatment options in clinical decision-making. Next, there were six articles about tooth extraction difficulty, preparation, and time, and four articles about maxillary sinus evaluation. Furthermore, there were three articles about predictive models for osteonecrosis and osteomyelitis of the jaw, and two articles each about post-extraction complications and the use of ChatGPT, which were the fewest in number.
Conclusion
Findings from these papers will contribute to improving decision-making processes, treatment strategies, and preventive measures in dental care and are expected to serve as a foundation for future research. Furthermore, the diversity of each topic reflects the complexity and evolution of dental care and suggests that further exploration is warranted in future research.}
}
@article{SADANANDAM2025,
title = {Artificial Intelligence: What Is Current in Dentistry?},
journal = {Dental Clinics of North America},
year = {2025},
issn = {0011-8532},
doi = {https://doi.org/10.1016/j.cden.2025.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0011853225000515},
author = {Santhiya Sadanandam and Gifty Francis Ruby and Steven R. Singer and Ruchira Shreevats},
keywords = {Artificial intelligence (AI), Automated screening, Deep learning (DL), Machine learning (ML), Dentistry, Digital dentistry, Clinical decision making, Applications of AI}
}
@article{STERN2025,
title = {Detecting Artificial Intelligence-Generated Text in Personal Statements of Adult Reconstruction Fellowship Applicants},
journal = {The Journal of Arthroplasty},
year = {2025},
issn = {0883-5403},
doi = {https://doi.org/10.1016/j.arth.2025.07.072},
url = {https://www.sciencedirect.com/science/article/pii/S0883540325009763},
author = {Jonathan M. Stern and Antonio M. Fernandez-Perez and Natalia Cruz-Ossa and Victor H. Hernandez and Colin A. McNamara and Michele R. D’Apuzzo},
keywords = {Artificial intelligence, ChatGPT, personal statement, fellowship applications, AI generated text, medical education},
abstract = {Background
Artificial intelligence (AI), particularly large language models such as Chat Generative Pre-Trained Transformer (ChatGPT), has expanded across various fields, including medical education and professional applications. However, the extent to which AI is utilized in writing personal statements (PSs) for adult reconstruction fellowship applications remains unclear. This study aimed to analyze the prevalence of AI-generated text in PSs submitted to our institution before and after the release of ChatGPT.
Methods
We retrospectively reviewed PSs submitted to our institution’s adult reconstruction fellowship from 2021 to 2025. The PSs were divided into two cohorts: pre-PS (2021 to 2022) and post-PS (2024 to 2025). The PSs from 2023 were excluded because of uncertainty in AI adoption. All PSs were analyzed using GPTZero, an AI detection software, to determine the proportion of AI-generated versus human-generated text. Descriptive statistics and comparative analyses were conducted.
Results
A total of 421 PSs were analyzed. The pre-PS cohort had an average GPTZero score of 99.5% (SD 1.9) human, 0.4% (SD 0.8) AI, and 0.1% (SD 1.8) mixed, while the post-PS cohort had scores of 83.8% (SD 29.9) human, 15.1% (SD 28.9) AI, and 1.1% mixed (SD 5.2) (P < 0.001). The AI-generated text was significantly more prevalent in the post-PS cohort compared to the pre-PS cohort. In addition, international medical graduates and applicants from non-US residencies demonstrated a higher proportion of AI-generated text in their PSs compared to US applicants (P < 0.001).
Conclusions
The use of AI in PS writing has increased significantly since the release of ChatGPT. Given the role of PSs in candidate selection, these findings highlight the need for transparency, standardized guidelines regarding AI-assisted writing, and re-evaluation of the importance placed on PSs in candidate selection. Further research should expand to other subspecialties and institutions to assess the broader implications of AI in postgraduate medical education.}
}
@article{HABER2025100196,
title = {CanvasHero: The role of artificial intelligence in cultivating resilience among children and youth using the 6-part story method in mass war trauma},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {5},
pages = {100196},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100196},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000805},
author = {Yuval Haber and Inbar Levkovich and Iftach Tzafrir and Karny Gigi and Dror Yinon and Dorit Hadar Shoval and Zohar Elyoseph},
keywords = {Resilience, Mass trauma, Displaced population, Children and youth, AI tools, Imagination},
abstract = {Background
The potential of Generative Artificial Intelligence (GenAI) to promote mental health is of great interest. Specifically, there is growing interest in integrating applied GenAI into psychotherapy or into the teacher/parent-child relationship. This paper describes CanvasHero, a GenAI tool that was developed following the devastating attacks on Israel in October 2023. It aims to promote resilience in children and adolescents who were evacuated from their homes due to the war. CanvasHero serves as a proof of concept for integrating GenAI as an additional element that can enrich and deepen interpersonal interaction.
Tool description
CanvasHero utilizes the BASIC Ph model and 6-Part Story Method for assessing and bolstering coping skills, aided by the interactive scaffolding and synthetic abilities of the GenAI. Key stages comprise (1) collaborative narrative construction between child, meaningful adult, and the GAI; (2) analysis of resilience themes; and (3) generative visualization representing the child's story through DALL-E's imaging capabilities.
Implementation protocol
The CanvasHero is optimally designed for children ages 7–16 under adult supervision, with the HEART Checklist developed to structure this process. Sessions typically occur remotely via videoconference, or in person.
Intended outcomes
CanvasHero aims to create a playful space for processing stress and trauma, identifies resilience resources, and strengthens these capabilities. At the same time, risks in GenAI integration are mitigated via human oversight and an ethics-focused design.
Conclusion
CanvasHero exemplifies a GenAI application that can assist during wartime, serving as a psycho-educational mediator and facilitating an imaginative and playful space between children and meaningful adults. Further studies are required to evaluate effectiveness and potential risks.}
}
@article{DO2025102367,
title = {Artificial intelligence (AI) performance on pharmacy skills laboratory course assignments},
journal = {Currents in Pharmacy Teaching and Learning},
volume = {17},
number = {7},
pages = {102367},
year = {2025},
issn = {1877-1297},
doi = {https://doi.org/10.1016/j.cptl.2025.102367},
url = {https://www.sciencedirect.com/science/article/pii/S1877129725000887},
author = {Vivian Do and Krista L. Donohoe and Apryl N. Peddi and Eleanor Carr and Christina Kim and Virginia Mele and Dhruv Patel and Alexis N. Crawford},
keywords = {Artificial intelligence, Pharmacy education, Pharmacy skills, Educational assessment, Generative language model},
abstract = {Objective
To compare pharmacy student scores to scores of artificial intelligence (AI)-generated results of three common platforms on pharmacy skills laboratory assignments.
Methods
Pharmacy skills laboratory course assignments were completed by four fourth-year pharmacy student investigators with three free AI platforms: ChatGPT, Copilot, and Gemini. Assignments evaluated were calculations, patient case vignettes, in-depth patient cases, drug information questions, and a reflection activity. Course coordinators graded the AI-generated submissions. Descriptive statistics were utilized to summarize AI scores and compare averages to recent pharmacy student cohorts. Interrater reliability for the four student investigators completing the assignments was assessed.
Results
Fourteen skills laboratory assignments were completed utilizing three different AI platforms (ChatGPT, Copilot, and Gemini) by four fourth-year student investigators (n = 168 AI-generated submissions). Copilot was unable to complete 12; therefore, 156 AI-generated submissions were graded by the faculty course coordinators for accuracy and scored from 0 to 100 %. Pharmacy student cohort scores were higher than the average AI scores for all of the skills laboratory assignments except for two in-depth patient cases completed with ChatGPT. Conclusion. Pharmacy students on average performed better on most skills laboratory assignments than three commonly used artificial intelligence platforms. Teaching students the strengths and weaknesses of utilizing AI in the classroom is essential.}
}
@article{DEGIORGIO2025112014,
title = {The need for balancing ’black box’ systems and explainable artificial intelligence: A necessary implementation in radiology},
journal = {European Journal of Radiology},
volume = {185},
pages = {112014},
year = {2025},
issn = {0720-048X},
doi = {https://doi.org/10.1016/j.ejrad.2025.112014},
url = {https://www.sciencedirect.com/science/article/pii/S0720048X25001007},
author = {Fabio De-Giorgio and Beatrice Benedetti and Matteo Mancino and Evis Sala and Vincenzo L. Pascali},
keywords = {Explainable artificial intelligence, Black box systems, Professional liability, Radiology, Ethics},
abstract = {Radiology is one of the medical specialties most significantly impacted by Artificial Intelligence (AI). AI systems, particularly those employing machine and deep learning, excel in processing large datasets and comparing images from similar contexts, fulfilling radiological demands. However, the implementation of AI in radiology presents notable challenges, including concerns about data privacy, informed consent, and the potential for external interferences affecting decision-making processes. Biases represent another critical issue, often stemming from unrepresentative datasets or inadequate system training, which can lead to distorted outcomes and exacerbate healthcare inequalities. Additionally, generative AI systems may produce ‘hallucinations’ arising from their reliance on probabilistic modeling without the ability to distinguish between true and false information. Such risks raise ethical and legal questions, especially when AI-induced errors harm patient health. Concerning liability for medical errors involving AI, healthcare professionals currently retain full accountability for their decisions. AI systems remain tools to support, not replace, human expertise and judgment. Nevertheless, the “black box” nature of many AI models – wherein the reasoning behind outputs remains opaque – limits the possibility of fully informed consent. We advocate for prioritizing Explainable Artificial Intelligence (XAI) in radiology. While potentially less performant than black-box models, XAI enhances transparency, allowing patients to understand how their data is used and how AI influences clinical decisions, aligning with ethical standards.}
}
@article{ALDREABI2025100456,
title = {Unveiling the dynamics of generative AI adoption: A business intelligence analysis through topic modeling-based bibliometric study},
journal = {Computers and Education: Artificial Intelligence},
volume = {9},
pages = {100456},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100456},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000967},
author = {Hanadi Aldreabi and Mohammad Alhur and Manaf Al-Okaily and Dhia Qasim and Nisreen K. Dahdoul and Fadi S. Shiyyab},
keywords = {AI tools, ChatGPT, Generative AI, Educational technology, Business intelligence, Bibliometric study},
abstract = {Generative Artificial Intelligence (GenAI) has gained notable attention in educational literature, with supporters and critics expressing varying opinions. Despite its popularity, only a few reviews are available on the subject, with limitations such as small sample sizes and limited scope. This study aims to clarify the major themes influencing the discussion on GenAI in educational contexts. It employs a strong Business Intelligence paradigm and uses bibliometric analysis and topic modeling focusing on the R program's structural topic model (STM) Package, VOSviewer, and bibliometric software. The results highlight the esteem of GenAI in education and evidence of international collaboration in the research process dedicated to enhancing the rapidly evolving field of GenAI. The scientometric indexes indicate that the diversity of journals has the significant impact on GenAI in education. While Lotka's Law suggests that the field is still in its early stages, the collaborative network demonstrates strong connections among researchers, a positive indicator of future progress. Moreover, the STM method has identified nine pivotal topics grouped into three categories relating to GenAI in education. By shedding light on these emerging themes, this study provides educators and researchers with valuable insights into the future of GenAI in education.}
}
@article{MOROSKY20254,
title = {Practical applications of artificial intelligence chatbots in obstetrics and gynecology medical education},
journal = {American Journal of Obstetrics and Gynecology},
volume = {233},
number = {1},
pages = {4-11},
year = {2025},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2025.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S0002937825002285},
author = {Christopher M. Morosky and Laura Baecher-Lind and Katherine T. Chen and Angela Fleming and Shireen Madani Sims and Helen Kang Morgan and Celeste S. Royce and Tammy Sonn and Alyssa Stephenson-Famy and Jill Sutton and Jonathan Schaffir and Rashmi Bhargava},
keywords = {artificial intelligence, biases, chatbot, ChatGPT, data privacy, faculty development, feedback, hallucinations, informed approach, integration, large language models, learning objectives, medical education, mentorship, responsible use, teaching},
abstract = {Generative artificial intelligence chatbots are sophisticated conversational artificial intelligence tools that have the capability to interpret natural language inputs and produce responses that closely resemble human speech. Artificial intelligence chatbots hold significant promise in revolutionizing medical education by offering invaluable support across various educational domains, including teaching, learning, and assessment. Their practical applications span a wide spectrum, from aligning learning objectives and simplifying administrative tasks to facilitating feedback, aiding faculty development, and supporting mentorship initiatives. However, alongside their potential benefits, concerns exist regarding data privacy, inherent biases, and occasional errors termed “hallucinations,” underscoring the imperative for a cautious and informed approach to their integration within educational settings. It therefore becomes essential for medical educators and academic institutions to proactively engage with artificial intelligence technologies like chatbots, not only to leverage their benefits but also to critically assess and address associated challenges such as bias, privacy, and misinformation. By thoughtfully integrating artificial intelligence tools, medical educators can determine where these technologies are most beneficial, implement safeguards against potential harms, and explore innovative applications to enhance medical education.}
}
@article{WANG2025147,
title = {Understanding users’ effective use of generative conversational AI from a media naturalness perspective: a hybrid structural equation modeling-artificial neural network (SEM-ANN) approach},
journal = {Data Science and Management},
volume = {8},
number = {2},
pages = {147-159},
year = {2025},
issn = {2666-7649},
doi = {https://doi.org/10.1016/j.dsm.2024.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S266676492400047X},
author = {Kun Wang and Yaobin Lu and Zhao Pan},
keywords = {Generative conversational AI, Content naturalness, Style naturalness, Effective use, SEM-ANN method},
abstract = {Although generative conversational artificial intelligence (AI) can answer questions well and hold conversations as a person, the semantic ambiguity inherent in text-based communication poses challenges to effective use. Effective use reflects the users’ utilization of generative conversational AI to achieve their goals, which has not been previously studied. Drawing on the media naturalness theory, we examined how generative conversational AI’s content and style naturalness affect effective use. A two-wave survey was conducted to collect data from 565 users of generative conversational AI. Two techniques were used in this study. Initially, partial least squares structural equation modeling (PLS-SEM) was applied to determine the variables that significantly affected the mechanisms (i.e., cognitive effort and communication ambiguity) and effective use. Secondly, an artificial neural network model was used to evaluate the relative importance of the significant predictors of mechanisms and effective use identified from the PLS-SEM analysis. The results revealed that the naturalness of content and style differed in their effects on cognitive effort and communication ambiguity. Additionally, cognitive effort and communication ambiguity negatively affected effective use. This study advances the literature on effective use by uncovering the psychological mechanisms underlying effective use and their antecedents. In addition, this study offers insights into the design of generative conversational AI.}
}
@article{RAYAGONZALEZ2025110375,
title = {High-precision prototype for garlic apex reorientation based on artificial intelligence models},
journal = {Computers and Electronics in Agriculture},
volume = {235},
pages = {110375},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110375},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925004818},
author = {Luis Enrique Raya-González and Víctor Alfonso Alcántar-Camarena and Alberto Saldaña-Robles and Edgar Francisco Duque-Vazquez and Guillermo Tapia-Tinoco and Noé Saldaña-Robles},
keywords = {Deep learning, Machine learning, Transfer learning, Image analysis,  L},
abstract = {Sowing and harvesting are the most expensive operations in garlic cultivation (Allium sativum L.). For mechanized sowing to be feasible, the garlic clove must be placed in the soil with the apex pointing upwards, otherwise, yield can be reduced by up to 23%. In this context, artificial intelligence (AI) emerges as a viable solution to address these issues, particularly artificial neural networks (ANN). This research presents the development and evaluation of a garlic apex orientation device, which utilizes AI models adapted to all types of garlic clove shapes. The evaluated models are support vector machine (SVM), random forest (RF), ANN, convolutional neural network (CNN), and transfer learning (TL). To increase the number of available images for training, a generative adversarial network (GAN) was used. Three different databases were used to train models to determine achieved the best performance in terms of model accuracy. The databases used are the original database, an augmentation version of the original database incorporating images generated by the GAN model, and only images generated by the GAN model. The results show that the best model (ANN) achieves a validation accuracy of 99.74% when using an augmentation of the original database with artificial images generated by the GAN model.}
}
@article{CROOK2025100793,
title = {Artificial Intelligence in Hand Surgery: The Future is Upon Us},
journal = {Journal of Hand Surgery Global Online},
volume = {7},
number = {6},
pages = {100793},
year = {2025},
issn = {2589-5141},
doi = {https://doi.org/10.1016/j.jhsg.2025.100793},
url = {https://www.sciencedirect.com/science/article/pii/S2589514125001136},
author = {Bryan S. Crook and Eoghan T. Hurley and Marc J. Richard and Suhail K. Mithani and Tyler S. Pidgeon},
keywords = {Artificial intelligence, Burnout, Internet, Machine learning, Patient education},
abstract = {In just the past few years, artificial intelligence (AI) has transformed from a potential disruptive force in health care to a technology being rapidly deployed across multiple fronts in orthopedic care. The growth in AI use and development has largely occurred as computing technology has improved in concert with the massive amounts of data generation made possible by electronic medical records. The resulting impact of these technologies, including machine learning algorithms and large language models, has yet to be fully realized, but has already begun improving patient care, offloading administrative burden, and disrupting clinical research. The purpose of this review is to highlight areas in which AI is poised to change the delivery of surgical care with respect to hand surgery.}
}