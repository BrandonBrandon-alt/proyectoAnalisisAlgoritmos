@article{HABER2024,
title = {The Artificial Third: A Broad View of the Effects of Introducing Generative Artificial Intelligence on Psychotherapy},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/54781},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000544},
author = {Yuval Haber and Inbar Levkovich and Dorit Hadar-Shoval and Zohar Elyoseph},
keywords = {psychoanalysis, generative artificial intelligence, psychotherapy, large language models, narcissism, narcissist, narcissistic, perception, perceptions, critical thinking, transparency, autonomy, mental health, interpersonal, LLM, LLMs, language model, language models, artificial intelligence, generative, AI, ethic, ethics, ethical},
abstract = {This paper explores a significant shift in the field of mental health in general and psychotherapy in particular following generative artificial intelligence’s new capabilities in processing and generating humanlike language. Following Freud, this lingo-technological development is conceptualized as the “fourth narcissistic blow” that science inflicts on humanity. We argue that this narcissistic blow has a potentially dramatic influence on perceptions of human society, interrelationships, and the self. We should, accordingly, expect dramatic changes in perceptions of the therapeutic act following the emergence of what we term the artificial third in the field of psychotherapy. The introduction of an artificial third marks a critical juncture, prompting us to ask the following important core questions that address two basic elements of critical thinking, namely, transparency and autonomy: (1) What is this new artificial presence in therapy relationships? (2) How does it reshape our perception of ourselves and our interpersonal dynamics? and (3) What remains of the irreplaceable human elements at the core of therapy? Given the ethical implications that arise from these questions, this paper proposes that the artificial third can be a valuable asset when applied with insight and ethical consideration, enhancing but not replacing the human touch in therapy.}
}
@article{PARK20242355,
title = {Has generative artificial intelligence solved inverse materials design?},
journal = {Matter},
volume = {7},
number = {7},
pages = {2355-2367},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400242X},
author = {Hyunsoo Park and Zhenzhu Li and Aron Walsh},
abstract = {Summary
The directed design and discovery of compounds with pre-determined properties is a long-standing challenge in materials research. We provide a perspective on progress toward achieving this goal using generative models for chemical compositions and crystal structures based on a set of powerful statistical techniques drawn from the artificial intelligence community. We introduce the central concepts underpinning generative models of crystalline materials. Coverage is provided of early implementations for inorganic crystals based on generative adversarial networks and variational autoencoders through to ongoing progress involving autoregressive and diffusion models. The influence of the choice of chemical representation and the generative architecture is discussed, along with metrics for quantifying the quality of the hypothetical compounds produced. While further developments are required to enable realistic predictions drawn from richer structure and property datasets, generative artificial intelligence is already proving to be complementary to traditional materials design strategies.}
}
@article{WAISBERG20251,
title = {Generative artificial intelligence in ophthalmology},
journal = {Survey of Ophthalmology},
volume = {70},
number = {1},
pages = {1-11},
year = {2025},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000444},
author = {Ethan Waisberg and Joshua Ong and Sharif Amit Kamran and Mouayad Masalkhi and Phani Paladugu and Nasif Zaman and Andrew G. Lee and Alireza Tavakkoli},
keywords = {Generative adversarial networks, Deep learning, ChatGPT, GPT4, Artificial ophthalmic image synthesis, AI, Machine learning},
abstract = {Generative artificial intelligence (AI) has revolutionized medicine over the past several years. A generative adversarial network (GAN) is a deep learning framework that has become a powerful technique in medicine, particularly in ophthalmology for image analysis. In this paper we review the current ophthalmic literature involving GANs, and highlight key contributions in the field. We briefly touch on ChatGPT, another application of generative AI, and its potential in ophthalmology. We also explore the potential uses for GANs in ocular imaging, with a specific emphasis on 3 primary domains: image enhancement, disease identification, and generating of synthetic data. PubMed, Ovid MEDLINE, Google Scholar were searched from inception to October 30, 2022, to identify applications of GAN in ophthalmology. A total of 40 papers were included in this review. We cover various applications of GANs in ophthalmic-related imaging including optical coherence tomography, orbital magnetic resonance imaging, fundus photography, and ultrasound; however, we also highlight several challenges that resulted in the generation of inaccurate and atypical results during certain iterations. Finally, we examine future directions and considerations for generative AI in ophthalmology.}
}
@article{CHARLES2025177508,
title = {AI in action: Changes to student perceptions when using generative artificial intelligence for the creation of a multimedia project-based assessment},
journal = {European Journal of Pharmacology},
volume = {998},
pages = {177508},
year = {2025},
issn = {0014-2999},
doi = {https://doi.org/10.1016/j.ejphar.2025.177508},
url = {https://www.sciencedirect.com/science/article/pii/S0014299925002626},
author = {Kellie A. Charles and Arsalan Yousuf and Han Chow Chua and Slade Matthews and Joanna Harnett and Tina Hinton},
keywords = {Science education, Pharmacology education, Artificial intelligence, AI, ChatGPT},
abstract = {Introduction
New modes of assessments are needed to evaluate of the authenticity of student learning in an artificial intelligence (AI) world. In mid-2023, we piloted a new assessment type; a collaborative group multimedia assessment with AI allowance. The aim of the research study was to explore the experiences of students using AI in a multimedia assessment. We further aimed to determine whether these use cases changed student perceptions of the ways AI can be used in learning and assessment.
Methods
Students enrolled in a capstone Pharmacology interdisciplinary unit (n = 40) were included in an exploratory, qualitative case study methodology. Thematic analysis using an AI role-based conceptual framework was used to explore student perceptions of AI use prior to and during their projects from logbooks documenting the assessment process.
Results
AI was initially perceived by students as having a personal tutor-style role, which aligned with the taxonomy with AI acting as an Arbiter (49 %), Oracle (41 %) and Quant (10 %). In contrast to their earlier perceptions, AI was only used in a limited manner in the early stages of assessment in the idea generation in the role as an Oracle (86 %) or in data analytic purposes as a Quant (14 %), (n = 14 cases in 5 groups). No student group used AI to generate written text for the final assessment.
Discussion
Tension between perceived and actual use of AI is indicative of the uncertainty faced by students with the allowance of AI within assessments. Clear guidance for educators and students about how to assess the AI-supported learning process is needed to ensure the integrity of the assessment system.}
}
@article{DEMIREL2025101127,
title = {Late gadolinium enhancement cardiovascular magnetic resonance with generative artificial intelligence},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101127},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2024.101127},
url = {https://www.sciencedirect.com/science/article/pii/S1097664724011542},
author = {Omer Burak Demirel and Fahime Ghanbari and Christopher W. Hoeger and Connie W. Tsao and Adele Carty and Long H. Ngo and Patrick Pierce and Scott Johnson and Kathryn Arcand and Jordan Street and Jennifer Rodriguez and Tess E. Wallace and Kelvin Chow and Warren J. Manning and Reza Nezafat},
keywords = {Late gadolinium enhancement, Highly accelerated, Deep learning},
abstract = {ABSTRACT
Background
Late gadolinium enhancement (LGE) cardiovascular magnetic resonance (CMR) imaging enables imaging of scar/fibrosis and is a cornerstone of most CMR imaging protocols. CMR imaging can benefit from image acceleration; however, image acceleration in LGE remains challenging due to its limited signal-to-noise ratio. In this study, we sought to evaluate a rapid two-dimensional (2D) LGE imaging protocol using a generative artificial intelligence (AI) algorithm with inline reconstruction.
Methods
A generative AI-based image enhancement was used to improve the sharpness of 2D LGE images acquired with low spatial resolution in the phase-encode direction. The generative AI model is an image enhancement technique built on the enhanced super-resolution generative adversarial network. The model was trained using balanced steady-state free-precession cine images, readily used for LGE without additional training. The model was implemented inline, allowing the reconstruction of images on the scanner console. We prospectively enrolled 100 patients (55 ± 14 years, 72 males) referred for clinical CMR at 3T. We collected three sets of LGE images in each subject, with in-plane spatial resolutions of 1.5 × 1.5-3-6 mm2. The generative AI model enhanced in-plane resolution to 1.5 × 1.5 mm2 from the low-resolution counterparts. Images were compared using a blur metric, quantifying the perceived image sharpness (0 = sharpest, 1 = blurriest). LGE image sharpness (using a 5-point scale) was assessed by three independent readers.
Results
The scan times for the three imaging sets were 15 ± 3, 9 ± 2, and 6 ± 1 s, with inline generative AI-based images reconstructed time of ∼37 ms. The generative AI-based model improved visual image sharpness, resulting in lower blur metric compared to low-resolution counterparts (AI-enhanced from 1.5 × 3 mm2 resolution: 0.3 ± 0.03 vs 0.35 ± 0.03, P < 0.01). Meanwhile, AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images showed similar blur metric (0.30 ± 0.03 vs 0.31 ± 0.03, P = 1.0) Additionally, there was an overall 18% improvement in image sharpness between AI-enhanced images from 1.5 × 3 mm2 resolution and original LGE images in the subjective blurriness score (P < 0.01).
Conclusion
The generative AI-based model enhances the image quality of 2D LGE images while reducing the scan time and preserving imaging sharpness. Further evaluation in a large cohort is needed to assess the clinical utility of AI-enhanced LGE images for scar evaluation, as this proof-of-concept study does not provide evidence of an impact on diagnosis.}
}
@article{ZHAO2024100043,
title = {Advancing microplastic analysis in the era of artificial intelligence: From current applications to the promise of generative AI},
journal = {Nexus},
volume = {1},
number = {4},
pages = {100043},
year = {2024},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2024.100043},
url = {https://www.sciencedirect.com/science/article/pii/S295016012400041X},
author = {Bu Zhao and Ruth E. Richardson and Fengqi You},
keywords = {microplastics, artificial intelligence, machine learning, deep learning, generative AI},
abstract = {Summary
The proliferation of microplastics (MPs) in aquatic and terrestrial environments poses significant threats to ecosystems and human health. Over the past 20 years, significant efforts have been dedicated to understanding the distribution, sources, and impacts of MPs. However, traditional methods for the detection and analysis of MPs rely on labor-intensive and time-consuming techniques, often lacking the needed precision. Recently, artificial intelligence (AI) has emerged as a transformative tool in environmental science, offering innovative solutions to enhance the efficiency and accuracy of MP analysis. Despite significant scientific advancements, there is a lack of critical review that consolidates the key applications of AI in MP analysis, synthesizes knowledge gained, and navigates for future research directions. This review is the first to thoroughly explore the exciting role of AI across the entire life cycle of MP analysis—from collection to characterization, dynamic modeling, impact assessment, and management of MP pollution. Specifically, AI-driven autonomous drones and robotics have emerged as promising solutions to revolutionize MP collection practices. Computer vision systems provide robust solutions for the identification and quantification of MPs in diverse environmental matrices. Additionally, data-driven modeling using machine-learning and deep-learning techniques facilitates accurate evaluation of MP pollution levels and their impacts, facilitating the design of effective management strategies. Despite these advancements, several knowledge gaps remain, including data scarcity and quality issues; the readiness of the AI models; and model interpretability, transparency, and reproducibility issues. Addressing these gaps requires the development of standardized protocols for improved data infrastructure, the adoption of more advanced and groundbreaking AI tools (such as generative AI), and the encouraging of multidisciplinary collaborations. Through these efforts, AI has the potential to revolutionize MP research, leading to a more comprehensive and effective response to MP pollution.}
}
@article{GOFMAN2025S260,
title = {HTA74 Transforming Global Value Dossier (GVD) Drafting: Creation with a Generative Artificial Intelligence (Gen AI)-Driven Coauthoring Accelerator},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S260},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1085},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012100},
author = {Larisa Gofman and Jevin G. Meyerink and Sheetal Sharma}
}
@article{BARCAUI2023100101,
title = {Who is better in project planning?Generative artificial intelligence or project managers?},
journal = {Project Leadership and Society},
volume = {4},
pages = {100101},
year = {2023},
issn = {2666-7215},
doi = {https://doi.org/10.1016/j.plas.2023.100101},
url = {https://www.sciencedirect.com/science/article/pii/S2666721523000224},
author = {André Barcaui and André Monat},
keywords = {Generative, Artificial intelligence, Project management},
abstract = {This paper presents a comparative study of generative artificial intelligence (AI), specifically the GPT-4 model, and a human project manager in the context of a project plan development. The study's objective was to analyze the content and structure of a project plan prepared by this disruptive new technology and its human counterpart, focusing on the digital technology sector. Through a primarily qualitative methodology, the study scrutinizes critical aspects of each part of the project plan, including scope preparation, schedule development, cost estimation, resources evaluation, quality planning, stakeholder mapping, communication planning, and risk analysis. The results indicate unique strengths and weaknesses for both AI-generated and human-generated project plans, revealing them as complementary in the project planning process. It also emphasizes the continued importance of human expertise in refining AI outputs and harnessing the full potential of AI through the process known as prompt engineering. In conclusion, this study illustrates the potential synergy between human experience and AI in project planning, suggesting the careful integration of human and AI capabilities is key to developing robust and trustworthy project plans.}
}
@article{ARCEURRIZA2025104234,
title = {From familiarity to acceptance: The impact of Generative Artificial Intelligence on consumer adoption of retail chatbots},
journal = {Journal of Retailing and Consumer Services},
volume = {84},
pages = {104234},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104234},
url = {https://www.sciencedirect.com/science/article/pii/S096969892500013X},
author = {Marta Arce-Urriza and Raquel Chocarro and Mónica Cortiñas and Gustavo Marcos-Matás},
keywords = {Generative artificial intelligence, Chatbot adoption, Retail technology, Consumer familiarity, Privacy risk, Service robot acceptance model (SRAM)},
abstract = {This study investigates the influence of Generative Artificial Intelligence (GenAI) on consumer adoption of retail chatbots, focusing on how GenAI impacts key adoption determinants, the role of familiarity and assessing its effects across different stages of the customer journey. We conducted two waves of surveys, one pre- and one post-GenAI integration, to compare consumer perceptions across three customer service tasks. Using the Service Robot Acceptance Model (SRAM) as a framework, we found that GenAI enhances consumer perceptions of chatbot usefulness, human-likeness, and familiarity, thereby increasing adoption intentions. However, trust remains largely unchanged, and privacy concerns have risen post-GenAI. Additionally, the relationships remain stable across customer journey stages, with familiarity playing a key role. Our findings extend SRAM to the retail context with GenAI, offering new insights into the temporal stability of chatbot adoption factors. It underscores familiarity's dual role (direct and indirect) in fostering adoption, while highlighting that GenAI impacts specific aspects of consumer interaction. These findings provide insights for retailers to leverage GenAI-powered chatbots to enhance customer engagement and satisfaction.}
}
@article{GUPTA2024100232,
title = {Adoption and impacts of generative artificial intelligence: Theoretical underpinnings and research agenda},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {1},
pages = {100232},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000211},
author = {Ruchi Gupta and Kiran Nair and Mahima Mishra and Blend Ibrahim and Seema Bhardwaj},
keywords = {ChatGPT, Adoption, Generative AI, Chatbots},
abstract = {Large language models (LLMs) have received considerable interest in the field of natural language processing (NLP) owing to their remarkable ability to generate clear, consistent, and contextually relevant materials. Among the numerous LLMs, ChatGPT (Generative Pre-trained Transformer for Chatbots) is emerging as a prominent prospective tool for developing conversational agents such as chatbots. However, there is a need for a clear conceptual understanding of ChatGPT's potential implications for the industry and its role in marketing. This study explores the adoption of ChatGPT in marketing and examines theories that may influence its adoption by marketers and consumers, as well as its implications for marketers. This study discusses how ChatGPT may allow for more personalized and engaging content, better customer experience, and improved ROI. However, adoption also brings challenges, including ethical considerations and the need for new skill development. This study also discusses future research opportunities for the adoption of ChatGPT and other generative artificial intelligence technologies in marketing. The goal is to provide insights for organizations that consider implementing these technologies, and to contribute to the literature on the adoption of Artificial Intelligence (AI) and the use of Generative AI in marketing.}
}
@article{MOULAEI2024105474,
title = {Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications},
journal = {International Journal of Medical Informatics},
volume = {188},
pages = {105474},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105474},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001370},
author = {Khadijeh Moulaei and Atiye Yadegari and Mahdi Baharestani and Shayan Farzanbakhsh and Babak Sabet and Mohammad {Reza Afrash}},
keywords = {Generative artificial intelligence, Health, Artificial intelligence},
abstract = {Background
Generative artificial intelligence (GAI) is revolutionizing healthcare with solutions for complex challenges, enhancing diagnosis, treatment, and care through new data and insights. However, its integration raises questions about applications, benefits, and challenges. Our study explores these aspects, offering an overview of GAI's applications and future prospects in healthcare.
Methods
This scoping review searched Web of Science, PubMed, and Scopus . The selection of studies involved screening titles, reviewing abstracts, and examining full texts, adhering to the PRISMA-ScR guidelines throughout the process.
Results
From 1406 articles across three databases, 109 met inclusion criteria after screening and deduplication. Nine GAI models were utilized in healthcare, with ChatGPT (n = 102, 74 %), Google Bard (Gemini) (n = 16, 11 %), and Microsoft Bing AI (n = 10, 7 %) being the most frequently employed. A total of 24 different applications of GAI in healthcare were identified, with the most common being “offering insights and information on health conditions through answering questions” (n = 41) and “diagnosis and prediction of diseases” (n = 17). In total, 606 benefits and challenges were identified, which were condensed to 48 benefits and 61 challenges after consolidation. The predominant benefits included “Providing rapid access to information and valuable insights” and “Improving prediction and diagnosis accuracy”, while the primary challenges comprised “generating inaccurate or fictional content”, “unknown source of information and fake references for texts”, and “lower accuracy in answering questions”.
Conclusion
This scoping review identified the applications, benefits, and challenges of GAI in healthcare. This synthesis offers a crucial overview of GAI's potential to revolutionize healthcare, emphasizing the imperative to address its limitations.}
}
@article{ASAD2024490,
title = {ChatGPT as artificial intelligence-based generative multimedia for English writing pedagogy: challenges and opportunities from an educator’s perspective},
journal = {International Journal of Information and Learning Technology},
volume = {41},
number = {5},
pages = {490-506},
year = {2024},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-02-2024-0021},
url = {https://www.sciencedirect.com/science/article/pii/S2056488024000131},
author = {Muhammad Mujtaba Asad and Shafaque Shahzad and Syed Hassan Ali Shah and Fahad Sherwani and Norah Mansour Almusharraf},
keywords = {Artificial intelligence, ChatGPT, English language, English writing pedagogy, Composing, Generative multimedia, Personalized learning},
abstract = {Purpose
This paper holds considerable importance in the educational dynamics specifically ChatGPT as generative multimedia in English language writing pedagogy and presents a unique lens, as it uses a narrative literature review to view this cutting-edge topic. This paper compiles the knowledge and information already available regarding the views and integration of ChatGPT in English writing pedagogy. This review attempts to determine the potential that ChatGPT provides for improving pedagogical practices and facilitating individualized learning by looking at the experiences and viewpoints of educators. Simultaneously, it addresses the crucial challenges educators must overcome to optimize the advantages of artificial intelligence (AI) while preserving academic fairness and honesty. The ultimate goal of this paper is to offer a nuanced understanding of ChatGPT’s role in education, especially in English language writing pedagogy, educating researchers, teachers and policymakers on how to integrate generative multimedia successfully AI into teaching and learning and aiding in the creation of inclusive and more effective teaching strategies.
Design/methodology/approach
The review was done using a narrative approach by analyzing the latest international and national studies, research papers, blog posts, newspaper articles and documentaries, and by collecting the data, facts, figures and pictures. This narrative literature review approach provides a contextual understanding of how different English language teachers view ChatGPT in English writing pedagogy allowing for a comprehensive synthesis of data about its opportunities and challenges as well. It also helps in finding patterns and gaps in the body of knowledge, directing future studies and emphasizing areas that require more research, which is important for this new cutting-edge invention. The narrative approach, in contrast to systematic reviews, enables a detailed qualitative analysis that is necessary for delving into complex topics. This review offers useful insights into the prospects and practical challenges of integrating ChatGPT in English language writing pedagogy by concentrating on the experiences of teachers. The narrative literature review is a useful and relevant means of comprehending and using AI in educational settings since its ultimate goal is to synthesize current knowledge and provide practical recommendations for teachers, students, administrators and, last but not least, policymakers for the effective integration of ChatGPT as generative multimedia specifically in the English language writing pedagogy.
Findings
Grounded on findings, it is essential to mention here that ChatGPT holds immense value in terms of English language writing pedagogy. The findings deal with the three research questions: each research question has a main theme followed by sub-themes about the views of teachers on ChatGPT integration into English writing pedagogy, its benefits and, last but not least, challenges; however, very few traces of AI have been found in the early most downloaded Language learning apps, but ChatGPT covers it all with the features like personalized learning, contextually adaptable feedback, human-like conversational skills and preparation of standard tests, which make ChatGPT stand apart and stand tall in the race of new AI inventions. On the contrary, the paper identifies vital challenges associated with ChatGPT. First, there is a severe concern that students’ creativity may be at risk. Second, the concern of data privacy is a critical consideration. Finally, dealing with the trust issue of English language teachers regarding the use of ChatGPT for English language writing pedagogy and, last but not least, the paper also talks about low digital literacy as an additional challenge to integrating ChatGPT in educational settings. The incorporation of ChatGPT is not only a new trend but also a door to future AI wonders, so the education community needs to make the most of it.
Practical implications
The paper has broad implications that address multiple aspects of educational theory, practice, policy and future research when incorporating AI systems such as ChatGPT into English language writing pedagogy. The findings imply that ChatGPT can result in more dynamic and customized learning experiences, which has important implications for improving English language writing pedagogy with the integration of ChatGPT. AI can help teachers customize lessons to each student’s needs, which could increase student engagement in writing classes and improve learning results. Additionally, for the school administration and policymakers, the integration of ChatGPT depends upon access to smooth internet connection and other resources needed for effective learning of the students. Policymakers can develop policies as per the changing needs of the hour by providing professional development training to the teachers for the incorporation of AI inventions such as ChatGPT for English language writing pedagogy. Furthermore, the research also highlights significant ethical and policy issues, especially those dealing with academic integrity. Policies by the administration and teachers must be developed to stop students from misusing ChatGPT and to guarantee that AI tools are applied morally and responsibly in educational contexts because students can utilize the tool to complete assignments in an unethical manner.
Originality/value
This narrative literature review is unique as it provides insights into the new invention of OpenAI ChatGPT from the education perspective, specifically about the teaching of English language writing pedagogy, and offers some exciting revelations that have not been done previously.}
}
@article{ASSAD2024677,
title = {Enhancing sustainability in manufacturing through cognitive digital twins powered by generative artificial intelligence},
journal = {Procedia CIRP},
volume = {130},
pages = {677-682},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.147},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013040},
author = {Fadi Assad and John Patsavellas and Konstantinos Salonitis},
keywords = {ChatGPT, Cognitive manufacturing, digital twin, generative artificial intelligence, Internet of Things, sustainable manufacturing},
abstract = {The rise of Industry 4.0 has brought new advancements in manufacturing, with a focus on integrating digital technologies to optimise processes and increase sustainability. Cognitive Digital Twins (CDTs) are emerging as a powerful paradigm in this area. They leverage advanced analytics, artificial intelligence (AI), and machine learning to create dynamic, real-time representations of physical manufacturing systems. This paper explores how CDTs can improve sustainability within the manufacturing sector. It proposes integrating generative artificial intelligence (GenAI) into the platforms that operate these digital twins to grant them cognitive capabilities. The work introduces a method for mapping and integrating energy consumption data to an Internet of Things (IoT) platform that includes the digital twin and a generative AI language model, such as ChatGPT. This proposed approach serves as a stepping stone towards unlocking the full potential of CDTs. It empowers manufacturers to achieve higher levels of sustainability and environmental responsibility.}
}
@article{MESSNER2025101622,
title = {Quantification of cultural practices and diversity: An empirical experiment with generative artificial intelligence},
journal = {Journal of World Business},
volume = {60},
number = {3},
pages = {101622},
year = {2025},
issn = {1090-9516},
doi = {https://doi.org/10.1016/j.jwb.2025.101622},
url = {https://www.sciencedirect.com/science/article/pii/S1090951625000112},
author = {Wolfgang Messner},
keywords = {Artificial intelligence, Cultural dimensions, Cultural diversity, Culture, Evolution, Generative artificial intelligence (genAI), GLOBE, Hofstede, Large language model (LLM)},
abstract = {Culture is often viewed as a value system that shapes cultural practices. Frameworks like Hofstede, GLOBE, and Schwartz identify and quantify various cultural dimensions; however, these rely on surveys that are criticized for limited country coverage, lack of psychometric robustness, small sample sizes, and cultural biases. This article presents an empirical experiment designed to quantify cultural practices and diversity across 216 countries and territories by prompting large language models using a zero-shot learning strategy. This approach enables subnational and segment-specific analyses, equipping researchers with powerful tools for deeper cultural insights.}
}
@article{MAYOL2025109496,
title = {Generative artificial intelligence and scientific publishing: Turning noise into trust},
journal = {Surgery},
volume = {183},
pages = {109496},
year = {2025},
issn = {0039-6060},
doi = {https://doi.org/10.1016/j.surg.2025.109496},
url = {https://www.sciencedirect.com/science/article/pii/S0039606025003484},
author = {Julio Mayol and Caitlin W. Hicks and Steven D. Wexner}
}
@article{RAWLINSON2025,
title = {Generative Artificial Intelligence to Automate the Adaptation of Excel Health Economic Models and Word Technical Reports},
journal = {Value in Health},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S109830152502399X},
author = {William Rawlinson and Siguroli Teitsson and Tim Reason and Bill Malcolm and Andy Gimblett and Sven L. Klijn},
keywords = {artificial intelligence, large language models},
abstract = {Objectives
In health economics and outcomes research (HEOR), many repetitive tasks could be performed by large language models (LLMs), including adapting Excel-based health economic models and associated Word technical reports to a new setting. However, it is vital to develop robust methods so that the LLM delivers at least human-level accuracy.
Methods
We developed LLM-based pipelines to automate parameter value adaptations for Excel-based models and subsequent reporting of the model results. Chain-of-thought prompting, ensemble shuffling, and task decomposition were used to enhance the accuracy of the LLM-generated content. We tested the pipelines by adapting 3 Excel-based models (2 cost-effectiveness models [CEMs] and 1 budget impact model [BIM]) and their associated technical reports. The quality of reporting was evaluated by 2 expert health economists.
Results
The accuracy of parameter value adaptations was 100% (147 of 147), 100% (207 of 207), and 98.7% (158 of 160) for the 2 CEMs and 1 budget impact model, respectively. The parameter value adaptations were performed without human intervention in 195 seconds, 245 seconds, and 189 seconds. For parameter value adaptations, the application programming interface costs associated with running the pipeline were $13.36, $6.48, and $2.65. The accuracy of report adaptations was 94.4% (17 of 18), 100% (54 of 54), and 95.1% (39 of 41), respectively. The report adaptations were performed in 128 seconds, 336 seconds, and 286 seconds. For report adaptations, the application programming interface costs associated with running the pipeline were $1.53, $4.24, and $4.05.
Conclusions
LLM-based toolchains have the potential to accurately and rapidly perform routine adaptations of Excel-based CEMs and technical reports at a low cost. This could expedite health technology assessments and improve patient access to new treatments.}
}
@article{RESELFOLKERSMA2025S1749,
title = {A0902 – Evaluation of the quality of the responses regarding Lower Urinary Tract Symptoms (LUTS) of different generative Artificial Intelligence (AI) App in comparison with UrologuIA (generative AI App developed by urologists and urogynecologists)},
journal = {European Urology},
volume = {87},
pages = {S1749},
year = {2025},
note = {Abstracts EAU25 - 40th Annual EAU Congress},
issn = {0302-2838},
doi = {https://doi.org/10.1016/j.eururo.2025.09.4082},
url = {https://www.sciencedirect.com/science/article/pii/S0302283825045919},
author = {L. {Resel Folkersma} and B. {Padilla Fernández} and C. {González Enguita} and J.L. Gago and M. {García Sanz} and P. {Blasco Hernández} and R. Vozmediano and S. Arlandis and S. Zubillaga and J. {Medina Polo}}
}
@article{KATHAIT20241575,
title = {Assessing Laterality Errors in Radiology: Comparing Generative Artificial Intelligence and Natural Language Processing},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {10},
pages = {1575-1582},
year = {2024},
note = {Focus on Innovation},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400591X},
author = {Anjaneya Singh Kathait and Emiliano Garza-Frias and Tejash Sikka and Thomas J. Schultz and Bernardo Bizzo and Mannudeep K. Kalra and Keith J. Dreyer},
keywords = {generative AI, large language models, natural language processing, patient safety, radiology errors},
abstract = {Purpose
We compared the performance of generative artificial intelligence (AI) (Augmented Transformer Assisted Radiology Intelligence [ATARI, Microsoft Nuance, Microsoft Corporation, Redmond, Washington]) and natural language processing (NLP) tools for identifying laterality errors in radiology reports and images.
Methods
We used an NLP-based (mPower, Microsoft Nuance) tool to identify radiology reports flagged for laterality errors in its Quality Assurance Dashboard. The NLP model detects and highlights laterality mismatches in radiology reports. From an initial pool of 1,124 radiology reports flagged by the NLP for laterality errors, we selected and evaluated 898 reports that encompassed radiography, CT, MRI, and ultrasound modalities to ensure comprehensive coverage. A radiologist reviewed each radiology report to assess if the flagged laterality errors were present (reporting error—true-positive) or absent (NLP error—false-positive). Next, we applied ATARI to 237 radiology reports and images with consecutive NLP true-positive (118 reports) and false-positive (119 reports) laterality errors. We estimated accuracy of NLP and generative AI tools to identify overall and modality-wise laterality errors.
Results
Among the 898 NLP-flagged laterality errors, 64% (574 of 898) had NLP errors and 36% (324 of 898) were reporting errors. The text query ATARI feature correctly identified the absence of laterality mismatch (NLP false-positives) with a 97.4% accuracy (115 of 118 reports; 95% confidence interval [CI] = 96.5%-98.3%). Combined vision and text query resulted in 98.3% accuracy (116 of 118 reports or images; 95% CI = 97.6%-99.0%), and query alone had a 98.3% accuracy (116 of 118 images; 95% CI = 97.6%-99.0%).
Conclusion
The generative AI-empowered ATARI prototype outperformed the assessed NLP tool for determining true and false laterality errors in radiology reports while enabling an image-based laterality determination. Underlying errors in ATARI text query in complex radiology reports emphasize the need for further improvement in the technology.}
}
@article{GARCIA20253136,
title = {Generative artificial intelligence in human resource management: a critical reflection on impacts, resilience and roles},
journal = {International Journal of Contemporary Hospitality Management},
volume = {37},
number = {9},
pages = {3136-3158},
year = {2025},
issn = {0959-6119},
doi = {https://doi.org/10.1108/IJCHM-01-2025-0159},
url = {https://www.sciencedirect.com/science/article/pii/S0959611925000452},
author = {R.L. Fernando Garcia and Linchi Kwok},
keywords = {Critical reflection, Artificial intelligence, Generative AI, Human resource management, Information technology, Employee lifecycle},
abstract = {Purpose
This study aims to address three questions: RQ1 – What significant changes has generative artificial intelligence (GenAI) brought to human resource (HR) functions? RQ2 – How can HR professionals sustain a critical role in an organization when GenAI is transforming traditional HR functions? RQ3 – What research questions can be addressed to support organizations and HR professionals in a new GenAI-empowered work environment?
Design/methodology/approach
As a critical reflection of the authors’ corporate HR experience and research expertise, a narrative review of purposefully selective relevant literature, industry white papers and news updates across the six stages of the employee lifecycle was carried out to answer RQ1. A provoking reflection was further synthesized to answer RQ2 and RQ3.
Findings
Three categories of HR duties (those likely and unlikely to be replaced by GenAI and those likely to emerge due to GenAI implications) were synthesized, leading to the advancement of three propositions. Recommendations for HR professionals, organizations and future research were summarized.
Research limitations/implications
This paper presents a series of specific research questions, inspiring new research ideas that help organizations improve HR work with GenAI-empowered tools while mitigating its negative impacts.
Practical implications
This paper proposes detailed recommendations to help HR professionals maintain their critical roles within the organization. In addition to hospitality and tourism businesses, for-profit or nonprofit organizations across all sectors can refer to the answers to RQ1 to restructure their HR departments.
Social implications
Beyond the HR profession, this work signals a broader societal shift in job functions and structures, urging individuals and organizations to rethink what is needed in the new GenAI-empowered work environments. It also raises awareness of the need for human oversight and responsible AI governance in redesigning future work and organizational structures.
Originality/value
This paper synthesizes GenAI’s significant impact on various HR functions across the six stages of the employee lifecycle. It offers specific practical recommendations and research ideas to help organizations leverage GenAI’s power in HR operations.}
}
@article{TAIWO2025672,
title = {Generative artificial intelligence in construction: A Delphi approach, framework, and case study},
journal = {Alexandria Engineering Journal},
volume = {116},
pages = {672-698},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.12.079},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824016776},
author = {Ridwan Taiwo and Idris Temitope Bello and Sulemana Fatoama Abdulai and Abdul-Mugis Yussif and Babatunde Abiodun Salami and Abdullahi Saka and Mohamed El Amine {Ben Seghier} and Tarek Zayed},
keywords = {Generative artificial intelligence, Generative pre-trained transformer, Large language model, Multimodal AI, Retrieval augmented generation, Construction industry, GenAI, RAG, LLM, GPT, ChatGPT},
abstract = {The construction industry plays a crucial role in the global economy, contributing approximately $10 trillion and employing over 220 million workers worldwide, but encounters numerous productivity challenges with only 1 % annual growth compared to 2.8 % for the global economy. These challenges span various processes, including design, planning, procurement, inspection, and maintenance. Generative artificial intelligence (GenAI), capable of producing new and realistic data or content such as text, images, videos, or code from given inputs or existing knowledge, presents innovative solutions to these challenges. While there is an increasing interest in the applications of GenAI in construction, a detailed analysis of its practical uses, advantages, and areas ripe for development is still evolving. This study contributes to this emerging area by offering an insightful analysis of the current state of generative AI in construction. It has three objectives: (1) to identify and categorize the existing and emerging generative AI opportunities and challenges in the construction industry via a Delphi study; (2) to propose a framework enabling construction firms to build customized GenAI solutions; and (3) to illustrate this framework through a case study that employs GenAI model for querying contract documents. Through systematic review and expert consultation, the study identified 76 potential GenAI applications across construction phases and 18 key challenges distributed across domain-specific, technological, adoption, and ethical categories. The case study's findings show that retrieval augmented generation (RAG) improves the baseline large language model (LLM), GPT-4, by 5.2, 9.4, and 4.8 % in terms of quality, relevance, and reproducibility. The study recommends a structured approach to GenAI implementation, emphasizing the need for domain-specific customization, robust validation protocols, and careful consideration of ethical implications. This study equips academics and construction professionals with a comprehensive analysis and practical framework, facilitating the integration of GenAI techniques to enhance productivity, quality, safety, and sustainability across the construction industry.}
}
@article{HIDAYATULLAH2025100213,
title = {Exploring community pharmacist's psychological intentions to adopt generative artificial intelligence (GenAI) chatbots for patient information, education, and counseling},
journal = {Neuroscience Informatics},
volume = {5},
number = {3},
pages = {100213},
year = {2025},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2025.100213},
url = {https://www.sciencedirect.com/science/article/pii/S2772528625000287},
author = {Hafidz Ihsan Hidayatullah and Muhammad Taufiq Saifullah and Muhammad Thesa Ghozali and Ayesha Aziz},
keywords = {Artificial intelligence, Communal pharmacy, Social intention, Procreative AI, Technology acceptance},
abstract = {Generative AI (GenAI) chatbots, driven by advanced machine learning algorithms, are emerging as transformative tools for enhancing patient education, information dissemination, and counseling (EIC) in healthcare. This study investigated the psychological determinants of community pharmacists' intentions to adopt GenAI chatbots using the Extended Technology Acceptance Model (ETAM). A cross-sectional survey of 240 licensed community pharmacists across several Indonesian provinces assessed key constructs, including self-efficacy (SE), perceived usefulness (PU), perceived ease of use (PEU), attitude toward technology (ATT), trust (TT), and behavioral intention (BI). Structural equation modeling revealed that SE significantly influenced PU (β=0.37) and PEU (β=0.57), indicating that confidence in using technology positively affects perceived utility and usability. PU further predicted ATT (β=0.39) and BI (β=0.236), emphasizing the motivational role of perceived benefits. Trust emerged as a crucial mediator, channeling favorable attitudes into actionable behavioral intentions (indirect β=0.148). The model demonstrated strong fit indices (χ2=263.09, RMSEA = 0.019, GFI = 0.915, CFI = 0.991), supporting the psychological framework. These findings highlight the importance of fostering trust, improving perceived usability, and enhancing self-efficacy through targeted training to promote GenAI chatbot adoption. Future research should explore longitudinal behavioral changes and contextual influences to support sustainable AI integration in pharmacy practice.}
}
@incollection{SMITH2026421,
title = {Chapter 16 - Generative artificial intelligence for research translation in environmental toxicology and the ethical considerations∗},
editor = {Zhoumeng Lin and Wei-Chun Chou},
booktitle = {Machine Learning and Artificial Intelligence in Toxicology and Environmental Health},
publisher = {Academic Press},
pages = {421-432},
year = {2026},
isbn = {978-0-443-30010-3},
doi = {https://doi.org/10.1016/B978-0-443-30010-3.00013-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300103000131},
author = {Ted Smith},
keywords = {Artificial intelligence (AI), ChatGPT, Environmental health, Generative AI, Large language model (LLM), Plain language summaries (PLS), Prompt development},
abstract = {This chapter explores the potential of generative artificial intelligence (AI) for increasing the accessibility of the toxicological research published for the scientific community for nonspecialist audiences who may need this information for a wide range of important purposes. Translating and summarizing, in plain language, the specialized terminology, intricate statistical models, and interdisciplinary knowledge inherent in this field presents significant challenges which have historically been addressed with human intermediaries and their associated cost and time. Freely available chat-enabled large language models offer the ability to automatically generate a range of cost-effective plain language summaries. These capabilities are accompanied by several limitations such as oversimplification and the risk of inaccuracies which must be considered. Also considered are the ethical considerations such as the need to emphasize transparency, cultural sensitivities, and mitigation of bias in generative AI outputs. The importance of human quality assurance in maintaining scientific accuracy, context, and public trust is critical to responsible applications of this approach. By advocating for a balanced approach that leverages AI's scalability while preserving scientific rigor, this chapter promotes the thoughtful integration of AI in environmental toxicology research translation, ultimately envisioning its role in enhancing public understanding, informing policy, and fostering equitable access to scientific knowledge. An illustrative case exercise provides a step-by-step process for creating these summaries.}
}
@article{MORTLOCK2024100481,
title = {Generative artificial intelligence (Gen-AI) in pharmacy education: Utilization and implications for academic integrity: A scoping review},
journal = {Exploratory Research in Clinical and Social Pharmacy},
volume = {15},
pages = {100481},
year = {2024},
issn = {2667-2766},
doi = {https://doi.org/10.1016/j.rcsop.2024.100481},
url = {https://www.sciencedirect.com/science/article/pii/S2667276624000787},
author = {R. Mortlock and C. Lucas},
keywords = {Artificial intelligence, Academic integrity, ChatGPT, Pharmacy education, Machine learning},
abstract = {Introduction
Generative artificial intelligence (Gen-AI), exemplified by the widely adopted ChatGPT, has garnered significant attention in recent years. Its application spans various health education domains, including pharmacy, where its potential benefits and drawbacks have become increasingly apparent. Despite the growing adoption of Gen-AI such as ChatGPT in pharmacy education, there remains a critical need to assess and mitigate associated risks. This review exploresthe literature and potential strategies for mitigating risks associated with the integration of Gen-AI in pharmacy education.
Aim
To conduct a scoping review to identify implications of Gen-AI in pharmacy education, identify its use and emerging evidence, with a particular focus on strategies which mitigate potential risks to academic integrity.
Methods
A scoping review strategy was employed in accordance with the PRISMA-ScR guidelines. Databases searched includedPubMed, ERIC [Education Resources Information Center], Scopus and ProQuestfrom August 2023 to 20 February 2024 and included all relevant records from 1 January 2000 to 20 February 2024 relating specifically to LLM use within pharmacy education. A grey literature search was also conducted due to the emerging nature of this topic. Policies, procedures, and documents from institutions such as universities and colleges, including standards, guidelines, and policy documents, were hand searched and reviewed in their most updated form. These documents were not published in the scientific literature or indexed in academic search engines.
Results
Articles (n = 12) were derived from the scientific data bases and Records (n = 9) derived from the grey literature. Potential use and benefits of Gen-AI within pharmacy education were identified in all included published articles however there was a paucity of published articles related the degree of consideration to the potential risks to academic integrity. Grey literature recordsheld the largest proportion of risk mitigation strategies largely focusing on increased academic and student education and training relating to the ethical use of Gen-AI as well considerations for redesigning of current assessments likely to be a risk for Gen-AI use to academic integrity.
Conclusion
Drawing upon existing literature, this review highlights the importance of evidence-based approaches to address the challenges posed by Gen-AI such as ChatGPT in pharmacy education settings. Additionally, whilst mitigation strategies are suggested, primarily drawn from the grey literature, there is a paucity of traditionally published scientific literature outlining strategies for the practical and ethical implementation of Gen-AI within pharmacy education. Further research related to the responsible and ethical use of Gen-AI in pharmacy curricula; and studies related to strategies adopted to mitigate risks to academic integrity would be beneficial.}
}
@article{ABUMALLOH2024104128,
title = {Impact of generative artificial intelligence models on the performance of citizen data scientists in retail firms},
journal = {Computers in Industry},
volume = {161},
pages = {104128},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104128},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000563},
author = {Rabab Ali Abumalloh and Mehrbakhsh Nilashi and Keng Boon Ooi and Garry Wei Han Tan and Hing Kai Chan},
keywords = {Generative AI models, ChatGPT, Citizen Data science, Retail firms, Industrial growth, Industrial and innovation},
abstract = {Generative Artificial Intelligence (AI) models serve as powerful tools for organizations aiming to integrate advanced data analysis and automation into their applications and services. Citizen data scientists—individuals without formal training but skilled in data analysis—combine domain expertise with analytical skills, making them invaluable assets in the retail sector. Generative AI models can further enhance their performance, offering a cost-effective alternative to hiring professional data scientists. However, it is unclear how AI models can effectively contribute to this development and what challenges may arise. This study explores the impact of generative AI models on citizen data scientists in retail firms. We investigate the strengths, weaknesses, opportunities, and threats of these models. Survey data from 268 retail companies is used to develop and validate a new model. Findings highlight that misinformation, lack of explainability, biased content generation, and data security and privacy concerns in generative AI models are major factors affecting citizen data scientists’ performance. Practical implications suggest that generative AI can empower retail firms by enabling advanced data science techniques and real-time decision-making. However, firms must address drawbacks and threats in generative AI models through robust policies and collaboration between domain experts and AI developers.}
}
@incollection{FU2024,
title = {Generative artificial intelligence in operations},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00057-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934000573},
author = {Yingxuan Fu and Hing Kai Chan and Zhao Cai},
keywords = {Generative AI, , Generative adversarial network, Large language model, Transformer, Variational autoencoder},
abstract = {The rise of generative artificial intelligence (AI) may present a significant opportunity for a profound revolution in operations and supply chain management. However, such technological advancement is accompanied by a scholarly discourse that navigates the balance between its promising abilities and challenges. This chapter provides an overview of generative AI in operations and supply chain management. It begins by expositing its fundamental technical concepts and role alongside existing AI technologies. Subsequently, it delves into potential applications and challenges in implementing generative AI in operations. A future research agenda and takeaways for practitioners and Operations Management (OM) researchers are proposed at the end.}
}
@article{COHEN2025100405,
title = {A comparative analysis of generative artificial intelligence responses from leading chatbots to questions about endometriosis},
journal = {AJOG Global Reports},
volume = {5},
number = {1},
pages = {100405},
year = {2025},
issn = {2666-5778},
doi = {https://doi.org/10.1016/j.xagr.2024.100405},
url = {https://www.sciencedirect.com/science/article/pii/S2666577824000996},
author = {Natalie D. Cohen and Milan Ho and Donald McIntire and Katherine Smith and Kimberly A. Kho},
keywords = {chatbots, endometriosis education, health information technology, large language models, patient education, patient information},
abstract = {Introduction
The use of generative artificial intelligence (AI) has begun to permeate most industries, including medicine, and patients will inevitably start using these large language model (LLM) chatbots as a modality for education. As healthcare information technology evolves, it is imperative to evaluate chatbots and the accuracy of the information they provide to patients and to determine if there is variability between them.
Objective
This study aimed to evaluate the accuracy and comprehensiveness of three chatbots in addressing questions related to endometriosis and determine the level of variability between them.
Study Design
Three LLMs, including Chat GPT-4 (Open AI), Claude (Anthropic), and Bard (Google) were asked to generate answers to 10 commonly asked questions about endometriosis. The responses were qualitatively compared to current guidelines and expert opinion on endometriosis and rated on a scale by nine gynecologists. The grading scale included the following: (1) Completely incorrect, (2) mostly incorrect and some correct, (3) mostly correct and some incorrect, (4) correct but inadequate, (5) correct and comprehensive. Final scores were averaged between the nine reviewers. Kendall's W and the related chi-square test were used to evaluate the reviewers’ strength of agreement in ranking the LLMs’ responses for each item.
Results
Average scores for the 10 answers amongst Bard, Chat GPT, and Claude were 3.69, 4.24, and 3.7, respectively. Two questions showed significant disagreement between the nine reviewers. There were no questions the models could answer comprehensively or correctly across the reviewers. The model most associated with comprehensive and correct responses was ChatGPT. Chatbots showed an improved ability to accurately answer questions about symptoms and pathophysiology over treatment and risk of recurrence.
Conclusion
The analysis of LLMs revealed that, on average, they mainly provided correct but inadequate responses to commonly asked patient questions about endometriosis. While chatbot responses can serve as valuable supplements to information provided by licensed medical professionals, it is crucial to maintain a thorough ongoing evaluation process for outputs to provide the most comprehensive and accurate information to patients. Further research into this technology and its role in patient education and treatment is crucial as generative AI becomes more embedded in the medical field.}
}
@article{AWIDI2024100226,
title = {Comparing expert tutor evaluation of reflective essays with marking by generative artificial intelligence (AI) tool},
journal = {Computers and Education: Artificial Intelligence},
volume = {6},
pages = {100226},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000274},
author = {Isaiah T. Awidi}
}
@article{SINGH2024100531,
title = {Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100531},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000702},
author = {Shiwangi Singh and Surabhi Singh and Sascha Kraus and Anuj Sharma and Sanjay Dhir},
keywords = {Generative AI, Technology roadmapping, Patents, Text-mining, Structural topic modeling, Patent data mining},
abstract = {This study aims to identify generative AI (GenAI) applications and develop a roadmap for the near, mid, and far future. Structural topic modeling (STM) is used to discover latent semantic patterns and identify the key application areas from a text corpus comprising 2,398 patents published between 2017 and 2023. The study identifies six latent topics of GenAI application, including object detection and identification; medical applications; intelligent conversational agents; image generation and processing; financial and information security applications; and cyber-physical systems. Emergent topic terms are listed for each topic, and inter-topic correlations are explored to understand the thematic structures and summarize the semantic relationships among GenAI application areas. Finally, a technology roadmap is developed for each identified application area for the near, mid, and far future. This study provides valuable insights into the evolving GenAI landscape and helps practitioners make strategic business decisions based on the GenAI roadmap.}
}
@article{ZHANG2025S-318,
title = {1299: GENERATIVE ARTIFICIAL INTELLIGENCE FOR DYNAMIC RISK ASSESSMENT TO PREDICT TRAJECTORIES IN PATIENTS WITH ACUTE GASTROINTESTINAL BLEEDING IN THE INTENSIVE CARE UNIT},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-318},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01677-4},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525016774},
author = {Xi Zhang and Jun Yup Kim and Yuan Pu and Andrew J. Loza and Alexander Tong and Dennis Shung}
}
@article{FENG2024100090,
title = {Latest developments of generative artificial intelligence and applications in ophthalmology},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100090},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100090},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000914},
author = {Xiaoru Feng and Kezheng Xu and Ming-Jie Luo and Haichao Chen and Yangfan Yang and Qi He and Chenxin Song and Ruiyao Li and You Wu and Haibo Wang and Yih Chung Tham and Daniel Shu Wei Ting and Haotian Lin and Tien Yin Wong and Dennis Shun-chiu Lam},
keywords = {Generative artificial intelligence, Ophthalmology, Risk management, Clinical workflow, AI in medical research},
abstract = {The emergence of generative artificial intelligence (AI) has revolutionized various fields. In ophthalmology, generative AI has the potential to enhance efficiency, accuracy, personalization and innovation in clinical practice and medical research, through processing data, streamlining medical documentation, facilitating patient-doctor communication, aiding in clinical decision-making, and simulating clinical trials. This review focuses on the development and integration of generative AI models into clinical workflows and scientific research of ophthalmology. It outlines the need for development of a standard framework for comprehensive assessments, robust evidence, and exploration of the potential of multimodal capabilities and intelligent agents. Additionally, the review addresses the risks in AI model development and application in clinical service and research of ophthalmology, including data privacy, data bias, adaptation friction, over interdependence, and job replacement, based on which we summarized a risk management framework to mitigate these concerns. This review highlights the transformative potential of generative AI in enhancing patient care, improving operational efficiency in the clinical service and research in ophthalmology. It also advocates for a balanced approach to its adoption.}
}
@article{KANAKALA2024103175,
title = {Generative artificial intelligence for small molecule drug design},
journal = {Current Opinion in Biotechnology},
volume = {89},
pages = {103175},
year = {2024},
issn = {0958-1669},
doi = {https://doi.org/10.1016/j.copbio.2024.103175},
url = {https://www.sciencedirect.com/science/article/pii/S0958166924001113},
author = {Ganesh Chandan Kanakala and Sriram Devata and Prathit Chatterjee and Udaykumar Deva Priyakumar},
abstract = {In recent years, the rapid advancement of generative artificial intelligence (GenAI) has revolutionized the landscape of drug design, offering innovative solutions to potentially expedite the discovery of novel therapeutics. GenAI encompasses algorithms and models that autonomously create new data, including text, images, and molecules, often mirroring characteristics of existing datasets. This comprehensive review delves into the realm of GenAI for drug design, emphasizing recent advancements and methodologies that have propelled the field forward. Specifically, we focus on three prominent paradigms: transformers, diffusion models, and reinforcement learning algorithms, which have been exceptionally impactful in the last few years. By synthesizing insights from a myriad of studies and developments, we elucidate the potential of these approaches in accelerating the drug discovery process. Through a detailed analysis, we explore the current state and future directions of GenAI in the context of drug design, highlighting its transformative impact on pharmaceutical research and development.}
}
@article{RAJARAM2024629,
title = {Generative artificial intelligence in small and medium enterprises: Navigating its promises and challenges},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {629-648},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000685},
author = {Kumaran Rajaram and Patrick Nicolas Tinguely},
keywords = {Generative artificial intelligence, Small and medium enterprises, AI management, Competitiveness, Digital innovation},
abstract = {The latest technological developments in generative artificial intelligence (GenAI) offer powerful capabilities to small and medium enterprises (SMEs) as they facilitate the democratization of scalability and creativity. With little technical expertise or financial resources, SMEs can leverage this technology to streamline work processes and unleash innovation, improving their product offerings and long-term competitiveness. In this article, we discuss how SMEs can navigate both the promises and challenges of GenAI and offer a roadmap for deploying the technology. We then introduce a sailing metaphor that reveals key strategic dimensions for GenAI deployment: competency of employees, effective leadership and work values, organizational culture, collaboration and cooperation, and relationships with third parties. We conclude with practical recommendations for successfully deploying GenAI in SMEs.}
}
@article{TOROUS2025683,
title = {Assessing generative artificial intelligence for mental health},
journal = {The Lancet},
volume = {406},
number = {10504},
pages = {683},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)01237-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625012371},
author = {John Torous and Eric J Topol}
}
@article{CHO2025101418,
title = {Exploring international students' perceptions of adopting generative artificial intelligence (GenAI) technologies in learning},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101418},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101418},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125001457},
author = {Changwhan Cho and Duke Ofosu-Anim},
abstract = {This study explores international students' perceptions of GenAI technologies in higher education, focusing on how gender and age influence their willingness to adopt. A survey of 122 international graduate students from a private university in South Korea showed that the students are generally familiar with GenAI and its uses in learning. However, its usage varied in frequency. The study also finds that male students are more likely to use GenAI than female students. Additionally, the study revealed age-related differences in the willingness of international students to adopt GenAI, with younger students showing more interest and willingness than older students. However, despite the differences in interest levels in adopting GenAI among genders and ages, the study revealed that overall, there is a general willingness among international students to learn and apply GenAI technologies to their studies. The South Korean education system can be reformed to accommodate the emerging and growing relevance of GenAI in education by developing ethical capacities that will enhance learning while addressing students’ concerns.}
}
@article{WALLER2025102227,
title = {Reliable answers to patients’ questions: A fundamental need in any patient education tool, especially generative artificial intelligence},
journal = {Journal of Nuclear Cardiology},
volume = {47},
pages = {102227},
year = {2025},
issn = {1071-3581},
doi = {https://doi.org/10.1016/j.nuclcard.2025.102227},
url = {https://www.sciencedirect.com/science/article/pii/S1071358125001011},
author = {Alfonso H. Waller and Baoqiong Liu},
keywords = {Artificial intelligence, Generative artificial intelligence, ChatGPT, Nuclear stress, Fluorodeoxyglucose, Positron emission tomography}
}
@article{MOUSSA2025202990,
title = {Validation of a generative artificial intelligence tool for the critical appraisal of articles on the epidemiology of mental health: Its application in the Middle East and North Africa},
journal = {Journal of Epidemiology and Population Health},
volume = {73},
number = {2},
pages = {202990},
year = {2025},
issn = {2950-4333},
doi = {https://doi.org/10.1016/j.jeph.2025.202990},
url = {https://www.sciencedirect.com/science/article/pii/S2950433325001843},
author = {Cheima Moussa and Sarah Altayyar and Marion Vergonjeanne and Thibaut Gelle and Pierre-Marie Preux},
keywords = {Artificial intelligence, ChatGPT, Critical appraisal, Mental health, MENA},
abstract = {Mental health disorders have a high disability-adjusted life years in the Middle East and North Africa. This rise has led to a surge in related publications, prompting researchers to use AI tools like ChatGPT to reduce time spent on routine tasks. Our study aimed to validate an AI-assisted critical appraisal (CA) tool by comparing it with human raters. We developed customized GPT models using ChatGPT-4. These models were tailored to evaluate studies using the Newcastle-Ottawa Scale (NOS) or the Jadad Scale in one model, while another model evaluated STROBE or CONSORT guidelines. Our results showed a moderate to good agreement between human CA and our GPTs for the NOS for cohort, case control and cross-sectional studies and for the Jadad scale, with an ICC of 0.68 [95 %CI: 0.24–0.82], 0.69 [95 %CI: 0.31–0.88], 0.76 [95 %CI: 0.47–0.90] and 0.84 [95 %CI: 0.57–0.94] respectively. There was also a moderate to substantial agreement between the two methods for STROBE in cross sectional, cohort, case control studies, and for CONSORT in trial design, with a K of 0.63 [95 %CI: 0.56–0.70], 0.57 [95 %CI: 0.47–0.66], 0.48 [95 %CI: 0.38–0.50] and 0.70 [95 %CI: 0.63–0.77] respectively. Our custom GPT models produced hallucinations in 6.5 % and 4.9 % of cases, respectively. Human raters took an average of 19.6 ± 4.3 min per article, whereas our customized GPTs took only 1.4. ChatGPT could be a useful tool for handling repetitive tasks yet its effective application relies on the critical expertise of researchers.}
}
@article{JIANG2024102883,
title = {When generative artificial intelligence meets multimodal composition: Rethinking the composition process through an AI-assisted design project},
journal = {Computers and Composition},
volume = {74},
pages = {102883},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102883},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000598},
author = {Jialei Jiang},
keywords = {Generative artificial intelligence, Multimodal composition process, Adobe Firefly, DALL·E, Wicked problems, Design, Writing studies},
abstract = {This study explores the integration of generative artificial intelligence (GenAI) design technologies, including Adobe Firefly and DALL·E, into the teaching and learning of multimodal composition. Through focus group discussions and case studies, this paper demonstrates the potential of GenAI in reshaping the various stages of the composition process, including invention, designing, and revising. The findings reveal that GenAI technologies have the potential to enhance students’ multimodal composition practices and offer alternative solutions to the wicked problems encountered during the design process. Specifically, GenAI facilitates invention by offering design inspirations and enriches designing by expanding, removing, and editing the student-produced design contents. The students in this study also shared their critical stance on the revision process by modifying and iterating their designs after their uses of GenAI. Through showcasing both the opportunities and challenges of GenAI technologies, this paper contributes to the ongoing scholarly conversations on multimodal composition and pedagogy. Moreover, the paper offers implications for the future research and teaching of GenAI-assisted multimodal composition projects, with the aim of encouraging thoughtful integration of GenAI technologies to foster critical AI literacy among college composition students.}
}
@article{ALLEN2025S64,
title = {OS03-09 Surveying the Landscape: A Modular Generative Artificial Intelligence Workflow to Identify NAMs for Systemic Toxicity},
journal = {Toxicology Letters},
volume = {411},
pages = {S64},
year = {2025},
note = {Abstracts of the 59th Congress of the European Societies of Toxicology (EUROTOX 2025) TOXICOLOGY ADDRESSES SOCIETY'S REAL LIFE RISKS FOR SUSTAINABLE HEALTH AND WELL BEING},
issn = {0378-4274},
doi = {https://doi.org/10.1016/j.toxlet.2025.07.180},
url = {https://www.sciencedirect.com/science/article/pii/S0378427425017631},
author = {D. Allen and E. Martin and J. Hamm and J. Wignall and K. To and T. Feiler and C. Lemeris and P. Kukic},
abstract = {To identify the areas of systemic toxicity with the greatest need, and which present the best opportunities for human-relevant model (i.e., new approach methodologies [NAMs]) development, standardization, and implementation, we conducted a landscape analysis to collect information on ongoing efforts in the NAMs space. This type of analysis traditionally requires the collection, manual review, summary, and synthesis of an extensive literature base that requires hundreds of hours to complete. To increase both speed and efficiency, we utilized a reproducible workflow that incorporates multiple computational tools including generative artificial intelligence (GenAI) to quickly summarize a large literature database. Our integrated approach coupled subject matter expertise with sorting and extraction algorithms to provide a comprehensive overview of the state of the science for NAMs used for, or potentially useful for, the assessment of systemic toxicity of cosmetics. To identify potentially relevant studies, we conducted a literature search with keywords related to NAMs across three major topic areas: in silico, in chemico, and in vitro. We prioritized studies by coupling supervised clustering, topic extraction and keyword analysis algorithms. These methods led to the prioritization of 8,418 studies. To identify relevant studies, subject matter experts were employed in conjunction with active machine learning to identify relevant studies that were then summarized via GenAI. Given the objective was to provide sufficient coverage of the landscape to both address pragmatic, near-term needs, as well as shaping the future of how safety assessments are performed, we designed prompts to characterize the current and past systematic efforts directed towards developing and refining NAMs, including both success stories, scientific and technical challenges, and roadblocks to wider adoption. Our analysis identified 3,010 peer-reviewed publications and 38 consortium websites cataloguing NAMs that were applicable to the cosmetics regulatory process, from hazard-focused endpoints to exposure-based waiving of studies altogether. Additionally, they covered the full spectrum of maturity, from those approaches that show promise at the research and development phase to fully validated approaches ready for immediate regulatory use. To the extent available, we identified the molecular/cellular endpoints associated with each NAM and the reference dataset that was used to develop and/or evaluate usefulness and limitations across a total of 60,960 endpoints. The landscape also captured opportunities to validate mature NAMs to support their regulatory use and market adoption. These results will support the development and identification of NAMs to be included in frameworks for assessing systemic toxicity potential.}
}
@article{COSCI2025112113,
title = {Generative artificial intelligence: A hot topic to face with},
journal = {Journal of Psychosomatic Research},
volume = {192},
pages = {112113},
year = {2025},
issn = {0022-3999},
doi = {https://doi.org/10.1016/j.jpsychores.2025.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0022399925000777},
author = {Fiammetta Cosci and Antonina Mikocka-Walus}
}
@article{SUN2025103974,
title = {A methodological exploration of generative artificial intelligence (AI) for efficient qualitative analysis on hotel guests’ delightful experiences},
journal = {International Journal of Hospitality Management},
volume = {124},
pages = {103974},
year = {2025},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2024.103974},
url = {https://www.sciencedirect.com/science/article/pii/S027843192400286X},
author = {Hala Sun and MiRan Kim and Soyeon Kim and Laee Choi},
keywords = {Artificial Intelligence, ChatGPT, Customer, Delight grounded theory, Hospitality industry, Qualitative content analysis},
abstract = {This study explores the use of generative artificial intelligence (AI), specifically ChatGPT, in analyzing qualitative data on hotel guests’ delightful experiences. To assess the utility and trustworthiness of ChatGPT as a supplementary tool, we compared human coding, guided by Grounded Theory and Qualitative Content Analysis method, with AI-augmented coding using developed prompts in analyzing survey data. Our findings reveal that the majority of ChatGPT's themes and codes of customer delight closely match those identified by human coders, suggesting its potential to streamline data analysis. However, there are also notable differences, as human coders emphasized customer-to-customer interactions and safety and security, which were not identified by ChatGPT. The research contributes to hospitality literature by establishing a methodology for using ChatGPT in qualitative analysis, highlighting its efficiency in analyzing comments and open-ended survey data.}
}
@article{FELICETTI2024100545,
title = {Artificial intelligence and project management: An empirical investigation on the appropriation of generative Chatbots by project managers},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100545},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000842},
author = {Alberto Michele Felicetti and Antonio Cimino and Alberto Mazzoleni and Salvatore Ammirato},
keywords = {Project managers, Generative artificial intelligence, Chatgpt, Appropriation Theory, Structural Equation Modeling},
abstract = {The integration of generative AI tools, such as chatbots, into project management is revolutionizing the field. This paper explores how project managers are adopting and adapting these tools, specifically focusing on ChatGPT, for enhanced project management. Using Adaptive Structuration Theory, the study examines project managers' appropriation of generative AI. It considers factors like Innovation Attitude, Peer Influence, and Task-Technology Fit, employing a survey of Italian project managers. The approach adopted to analyze data is based on Partial Least Square - Structural Equation Modeling. The research confirms the significance of the hypothesized antecedents in AI tool appropriation. Innovation Attitude and Peer Influence are shown to positively impact the creative and 'unfaithful' use of AI in project management. Task-Technology Fit is crucial for effective AI integration, impacting both creative behaviour and unfaithful appropriation. The study highlights the role of an innovative mindset, peer dynamics, and task compatibility in the effective use of AI tools in project management. It suggests potential areas for future research, including exploring cultural and organizational contexts and the rapid evolution of AI technologies.}
}
@article{RASHID2025S268,
title = {MT14 Role of Generative Artificial Intelligence in Assisting Systematic Review Process in Health Research: A Systematic Review},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S268},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1124},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525012495},
author = {Muhammed Rashid and Cheng Su Yi and Suwapat Lawin and Pongsapat Limhensin and Suppachai Insuk and Sajesh K. Veettil and Nai Ming Lai and Xiangyang Ye and Nathorn Chaiyakunapruk and Teerapon Dhippayom}
}
@article{ZHAO2025108654,
title = {“Positive” or “Threatened”? The impact of the features in generative artificial intelligence on continued behavior},
journal = {Computers in Human Behavior},
volume = {168},
pages = {108654},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108654},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225001013},
author = {Li Zhao and Yun Xu and Sheng-kai Zhou},
keywords = {Artificial intelligence generated content (AIGC), Positive awe, Threatened awe, Continued usage intention},
abstract = {Artificial intelligence technologies have empowered marketers with advanced tools and insights, fostering unparalleled efficiency and personalization decision-making. To provide marketers with targeted and actionable guidance, this study investigated the behavioral mechanisms underlying the adoption of artificial intelligence-generated content (AIGC) technology. Specifically, it examined the influence of AIGC features (accuracy, competence, anthropomorphism, and interactivity) and the distinct psychological mechanisms of awe on users' behavioral intentions. A mixed-methods approach was employed, combining quantitative data (N = 860) with qualitative research (user reviews). The analysis revealed that the awe experience significantly influences AIGC users' preferences to continue using the technology. Positive awe had a significant positive effect, while threatened awe had a comparatively weaker negative effect. The four features (accuracy, competence, anthropomorphism, and interactivity) of AIGC contribute significantly to its users' continued usage intention. Notably, positive awe induced by competence, anthropomorphism, and interactivity significantly outweighed threatened awe, with the exception of accuracy. The findings reveal that the unique features of AIGC not only evoke users’ perceived awe but also strengthen their intentions to continue using the technology.}
}
@article{KENOPURUM2025S301,
title = {MSR139 Application of Generative Artificial Intelligence for Extracting Structured Data from Unstructured Bladder Cancer Pathology Reports},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S301},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1290},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525014159},
author = {Jennifer Ken-Opurum and Sidharth Singh and P. Pranav and Rahul Bhonsle and Shekhar Thumake and Heather Marino and Luke Dunlap}
}
@article{KARELL2025101966,
title = {Synthetic duality: A framework for analyzing generative artificial intelligence's representation of social reality},
journal = {Poetics},
volume = {108},
pages = {101966},
year = {2025},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101966},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24001049},
author = {Daniel Karell and Jeffrey Sachs and Ryan Barrett},
keywords = {Duality, Mondo-Breiger, Socio-semantic networks, Large language models, Generative artificial intelligence},
abstract = {The development of generative artificial intelligence (genAI) has caused concern about its potential risks, including how its ability to generate human-like texts could affect our shared perception of the social world. Yet, it remains unclear how best to assess and understand genAI's influence on our understanding of social reality. Building on insights into the representation of social worlds within texts, we introduce a framework for analyzing genAI's content and its consequences for perceptions of social reality. We demonstrate this “synthetic duality” framework in two parts. First, we show that genAI can create, with minimal guidance, reasonable portrayals of actors and ascribe relational meaning to those actors – virtual social worlds within texts, or “Mondo-Breigers”. Second, we examine how these synthetic documents with interior social worlds affect readers’ view of social reality. We find that they change individuals’ perceptions of actors depicted in the documents, likely by updating individuals’ expectations about the actors and their meanings. However, additional exploratory analyses suggest it is texts’ style, not their construction of “Mondo-Breigers”, that might be influencing people's perceptions. We end with a discussion of theoretical and methodological implications, including how genAI may unsettle structural notions of individuality. Namely, reimagining the duality of individuals and groups could help theorize growing homogeneity in an increasingly genAI-informed world.}
}
@article{RUIZ2025206,
title = {71361968-2415 - Is the use of Generative-Artificial Intelligence suitable for diagnosing Maxillofacial Pathologies?},
journal = {International Journal of Oral and Maxillofacial Surgery},
volume = {54},
pages = {206},
year = {2025},
note = {ICOMS Singapore 2025},
issn = {0901-5027},
doi = {https://doi.org/10.1016/j.ijom.2025.04.562},
url = {https://www.sciencedirect.com/science/article/pii/S0901502725006769},
author = {O. Peña Ruiz and J. Castellanos and J. Sifuentes-Cervantes and M. Villarroel-Dorrego and F. Bermudez}
}
@article{GANJOO2024,
title = {Beyond boundaries: exploring a generative artificial intelligence assignment in graduate, online science courses},
journal = {Journal of Microbiology & Biology Education},
volume = {25},
number = {3},
year = {2024},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00127-24},
url = {https://www.sciencedirect.com/science/article/pii/S1935787724000893},
author = {Rohini Ganjoo and James Rankin and Benjamin Lee and Lisa Schwartz},
keywords = {generative artificial intelligence, graduate courses, assignment, online education, health professional education},
abstract = {ABSTRACT

Generative artificial intelligence (GAI) offers increased accessibility and personalized learning, though the potential for inaccuracies, biases, and unethical use is concerning. We present a newly developed research paper assignment that required students to utilize GAI. The assignment was implemented within three online, asynchronous graduate courses for medical laboratory sciences. Student learning was assessed using a rubric, which rated students’ effective integration and evaluation of GAI-generated content against peer-reviewed research articles, thus demonstrating their critical thinking and synthesis skills, among other metrics. Overall rubric scores were high, suggesting that learning outcomes were met. After field testing, we administered a 16-item survey about GAI utilization, contribution to learning, and ethical concerns. Data (n = 32) were analyzed, and free-response answers were thematically coded. While 93.8% of respondents found the GAI-generated content to be “very good” or “excellent,” 28.1% found inaccuracies, and 68.8% “strongly agreed” or “agreed” that GAI should be allowed to be used as a tool to complete academic assignments. Interestingly, however, only 28.1% “strongly agreed” or “agreed” that GAI may be used for assignments if not explicitly authorized by the instructor. Though GAI allowed for more efficient completion of the project and better understanding of the topic, students noted concerns about academic integrity and the lack of citations in GAI responses. The assignment can easily be modified for different learning preferences and course environments. Raising awareness among students and faculty about the ethical use and limitations of GAI is crucial in today’s evolving pedagogical landscape.}
}
@article{CURRIE2025423,
title = {Generative Artificial Intelligence Biases, Limitations and Risks in Nuclear Medicine: An Argument for Appropriate Use Framework and Recommendations},
journal = {Seminars in Nuclear Medicine},
volume = {55},
number = {3},
pages = {423-436},
year = {2025},
note = {Artificial Intelligence},
issn = {0001-2998},
doi = {https://doi.org/10.1053/j.semnuclmed.2024.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0001299824000461},
author = {Geoffrey M. Currie and K. Elizabeth Hawk and Eric M. Rohren},
abstract = {Generative artificial intelligence (AI) algorithms for both text-to-text and text-to-image applications have seen rapid and widespread adoption in the general and medical communities. While limitations of generative AI have been widely reported, there remain valuable applications in patient and professional communities. Here, the limitations and biases of both text-to-text and text-to-image generative AI are explored using purported applications in medical imaging as case examples. A direct comparison of the capabilities of four common text-to-image generative AI algorithms is reported and recommendations for the most appropriate use, DALL-E 3, justified. The risks use and biases are outlined, and appropriate use guidelines framed for use of generative AI in nuclear medicine. Generative AI text-to-text and text-to-image generation includes inherent biases, particularly gender and ethnicity, that could misrepresent nuclear medicine. The assimilation of generative AI tools into medical education, image interpretation, patient education, health promotion and marketing in nuclear medicine risks propagating errors and amplification of biases. Mitigation strategies should reside inside appropriate use criteria and minimum standards for quality and professionalism for the application of generative AI in nuclear medicine.}
}
@article{KANAPARTHY2025,
title = {Real-World Evidence Synthesis of Digital Scribes Using Ambient Listening and Generative Artificial Intelligence for Clinician Documentation Workflows: Rapid Review},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/76743},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000808},
author = {Naga Sasidhar Kanaparthy and Yenny Villuendas-Rey and Tolulope Bakare and Zihan Diao and Mark Iscoe and Andrew Loza and Donald Wright and Conrad Safranek and Isaac V Faustino and Alexandria Brackett and Edward R Melnick and R Andrew Taylor},
keywords = {digital scribes, artificial intelligence in medicine, clinical documentation, speech recognition software, patient-clinician communication},
abstract = {Background
As physicians spend up to twice as much time on electronic health record tasks as on direct patient care, digital scribes have emerged as a promising solution to restore patient-clinician communication and reduce documentation burden—making it essential to study their real-world impact on clinical workflows, efficiency, and satisfaction.
Objective
This study aimed to synthesize evidence on clinician efficiency, user satisfaction, quality, and practical barriers associated with the use of digital scribes using ambient listening and generative artificial intelligence (AI) in real-world clinical settings.
Methods
A rapid review was conducted to evaluate the real-world evidence of digital scribes using ambient listening and generative AI in clinical practice from 2014 to 2024. Data were collected from Ovid MEDLINE, Embase, Web of Science–Core Collection, Cochrane CENTRAL and Reviews, and PubMed Central. Predefined eligibility criteria focused on studies addressing clinical implementation, excluding those centered solely on technical development or model validation. The findings of each study were synthesized and analyzed through the QUEST human evaluation framework for quality and safety and the Systems Engineering Initiative for Patient Safety (SEIPS) 3.0 model to assess integration into clinicians’ workflows and experience.
Results
Of the 1450 studies identified, 6 met the inclusion criteria. These studies included an observational study, a case report, a peer-matched cohort study, and survey-based assessments conducted across academic health systems, community settings, and outpatient practices. The major themes noted were as follows: (1) they decreased self-reported documentation times, with associated increased length of notes; (2) physician burnout measured using standardized scales was unaffected, but physician engagement improved; (3) physician productivity, assessed via billing metrics, was unchanged; and (4) the studies fell short when compared to standardized frameworks.
Conclusions
Digital scribes show promise in reducing documentation burden and enhancing clinician satisfaction, thereby supporting workflow efficiency. However, the currently available evidence is sparse. Future real-world, multifaceted studies are needed before AI scribes can be recommended unequivocally.}
}
@article{LI2025S280,
title = {MSR33 Automated Extraction of Kaplan-Meier Survival Curves Using Generative Artificial Intelligence and Computer Vision},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S280},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.1185},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525013105},
author = {Ying Li and Augustine Annan and Majid R. Mojarad and Jingcheng Du and Yingxin Xu}
}
@article{MCDONALD2025100121,
title = {Generative artificial intelligence in higher education: Evidence from an analysis of institutional policies and guidelines},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {3},
pages = {100121},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100121},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000052},
author = {Nora McDonald and Aditya Johri and Areej Ali and Aayushi Hingle Collier},
abstract = {The release of ChatGPT in November 2022 prompted a massive uptake of generative artificial intelligence (GenAI) across higher education institutions (HEIs). In response, HEIs focused on regulating its use, particularly among students, before shifting towards advocating for its productive integration within teaching and learning. Since then, many HEIs have increasingly provided policies and guidelines to direct GenAI. This paper presents an analysis of documents produced by 116 US universities classified as as high research activity or R1 institutions providing a comprehensive examination of the advice and guidance offered by institutional stakeholders about GenAI. Through an extensive analysis, we found a majority of universities (N = 73, 63%) encourage the use of GenAI, with many offering detailed guidance for its use in the classroom (N = 48, 41%). Over half the institutions provided sample syllabi (N = 65, 56%) and half (N = 58, 50%) provided sample GenAI curriculum and activities that would help instructors integrate and leverage GenAI in their teaching. Notably, the majority of guidance focused on writing activities focused on writing, whereas references to code and STEM-related activities were infrequent, and often vague, even when mentioned (N = 58, 50%). Finally, more than half of institutions talked about the ethics of GenAI on a broad range of topics, including Diversity, Equity and Inclusion (DEI) (N = 60, 52%). Based on our findings we caution that guidance for faculty can become burdensome as policies suggest or imply substantial revisions to existing pedagogical practices.}
}
@article{ERIKSEN2024100016,
title = {Generative artificial intelligence for increasing accessibility of patient information videos in ophthalmology},
journal = {AJO International},
volume = {1},
number = {1},
pages = {100016},
year = {2024},
issn = {2950-2535},
doi = {https://doi.org/10.1016/j.ajoint.2024.100016},
url = {https://www.sciencedirect.com/science/article/pii/S2950253524000169},
author = {Nathalie S. Eriksen and Moug Al-Bakri and Kirstine B. Boysen and Oliver N. Klefter and Diana C. Schmidt and Kirsten Reinwaldt and Jakob Grauslund and Lars M. Holm and Yousif Subhi},
keywords = {Artificial intelligence, Accessibility, Patient information videos},
abstract = {Purpose
Patient information videos are excellent for conveying information on eye health. Language barriers lead to inaccessibility for ethnic minorities. So far, overcoming language barriers have been very expensive, but in this short communications paper, we share our experiences with an inexpensive generative artificial intelligence-based translation system for videos.
Design
Explorative study.
Methods
We developed a patient information video on a very common and broadly relevant issue: how to use eye drops. The original video was made in Danish. We used HeyGen (HeyGen, Los Angeles, California, USA) to translate the video into three categories according to distance from Danish according to comparative linguistics: highly related (English and German), remotely related (French and Polish), and no recognizable relationship (Arabic and Turkish). Ophthalmologists with high proficiency in Danish and each of these languages evaluated and commented on the accuracy of the translations.
Results
All translations resulted in a recognizable clone of the original individual with synchronized lip movements and understandable language. We observed certain inaccuracies in the translation, however, these differed across languages without a specific pattern. Inconsistencies in formal/informal pronouns were observed across languages. But overall, the general information was conveyed across all languages.
Conclusion
Modern generative artificial intelligence-based translation tools can help tearing down language barriers and improve accessibility of patient information videos in ophthalmology.}
}
@article{YOGARATNAM2025100226,
title = {What Becomes of the Human Touch in the Age of Generative Artificial Intelligence?},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {2},
pages = {100226},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2025.100226},
url = {https://www.sciencedirect.com/science/article/pii/S2949761225000331},
author = {Kishwen Kanna {Yoga Ratnam}}
}
@article{WANG2025100996,
title = {A systematic literature review on the application of generative artificial intelligence (GAI) in teaching within higher education: Instructional contexts, process, and strategies},
journal = {The Internet and Higher Education},
volume = {65},
pages = {100996},
year = {2025},
issn = {1096-7516},
doi = {https://doi.org/10.1016/j.iheduc.2025.100996},
url = {https://www.sciencedirect.com/science/article/pii/S1096751625000053},
author = {Peijun Wang and Yuhui Jing and Shusheng Shen},
keywords = {GAI, Higher education, Systematic literature review, Chatgpt, Instructional strategies},
abstract = {Represented by ChatGPT, Generative Artificial Intelligence (GAI) is revolutionizing the field of education. Despite a series of related studies and reviews around GAI, existing reviews predominantly focus on macro-level discussions covering overall development trends, core issues, opportunities and risks. There has been a lack of systematic reviews from a meso-level perspective examining the application of GAI in classroom teaching within higher education. This study employs a systematic literature review method, examining 139 articles from Web of Science, EBSCO, and Scopus databases. Findings include: (1)In terms of disciplines and types of GAI applications, engineering, health and medicine, and language are the most popular, while humanities, social sciences, basic sciences, mathematics, sports sciences, and interdisciplinary fields have fewer applications. Based on Strobel's classification of GAI(2024), it is found that Generators, Reimaginators, and Assistants are the most widely applied types of GAI. In contrast, Synthesizers and Enablers are less commonly utilized. Regarding the adoption trends across disciplines, engineering and language have a diverse range of GAI product types applied, whereas health and medicine has fewer types of GAI products in use. Due to smaller sample sizes, the analysis of GAI product types in the remaining six disciplines is also relatively limited. (2)In terms of the application of GAI across different disciplines, a small portion of GAI applications reflect distinctive disciplinary characteristics. Regarding the roles mapped out by the application of GAI, based on Xu and Ouyang's classification(2022), instructors or students predominantly perceive GAI as “New Subject” or “Direct Mediator", with less emphasis on the role of “Supplement Assistant”. Regarding the integration into the classroom, as assessed through the SAMR framework, most GAI applications are in the Augmentation level. There are also some in the Substitution and Modification levels, while applications in the Redefinition level are relatively rare. (3)In terms of the selection of instructional strategies under GAI applications, there are 18 types of strategies across four orientations, primarily emphasizing constructive and reflective orientations. Strategies focusing on didactic and authentic orientiations are less frequently utilized. Regarding the roles GAI plays as reflected in instructional strategies, it predominantly assumes roles as “New Subject” and “Direct Mediator", with the role of “Supplementary Assistant” yet to be explored. Finally, this study evaluated the instructional application research of GAI from three dimensions: GAI product type and applied discipline, discipline-specific application and integration level, instructional strategies and GAI role, and put forward relevant research suggestions.}
}
@article{ABDALLAH2025,
title = {Generative Artificial Intelligence Models for Developing Neuroimaging Markers of Psychiatric Disorders},
journal = {Biological Psychiatry},
year = {2025},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2025.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0006322325011849},
author = {Chadi G. Abdallah and David {van Dijk}}
}
@article{ALEXANDER2025101416,
title = {Exploring Generative Artificial Intelligence to Enhance Reflective Writing in Pharmacy Education},
journal = {American Journal of Pharmaceutical Education},
volume = {89},
number = {6},
pages = {101416},
year = {2025},
issn = {0002-9459},
doi = {https://doi.org/10.1016/j.ajpe.2025.101416},
url = {https://www.sciencedirect.com/science/article/pii/S0002945925000610},
author = {Kaitlin M. Alexander and Margeaux Johnson and Michelle Z. Farland and Amy Blue and Emily K. Bald},
keywords = {Artificial intelligence, Reflective writing, Reflection techniques, Self-assessment, Pharmacy education},
abstract = {The integration of generative artificial intelligence (AI) holds the potential to impact teaching and learning. In this commentary, we explore the opportunity for AI to enhance reflective writing (RW) among student pharmacists. AI-guided RW has the potential to strengthen students’ reflective capacity, deepen their autobiographical memory, and develop their self-confidence. This commentary presents examples of how AI can be utilized to enrich RW and includes a sample prompt aimed at facilitating student self-reflection. We explore how integrating AI-facilitated RW assignments into the pharmacy curriculum can help students develop detailed examples for self-reflection and gain exposure to the potential uses of AI in their professional development and career advancement.}
}
@article{LEE2025,
title = {Use of a Medical Communication Framework to Assess the Quality of Generative Artificial Intelligence Replies to Primary Care Patient Portal Messages: Content Analysis},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/71966},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25005220},
author = {Natalie S Lee and Nathan Richards and Jodi Grandominico and Robert M Cronin and Amanda K Hendricks and Ravi S Tripathi and Daniel E Jonas},
keywords = {communication, artificial intelligence, primary care, electronic health record, patient portal, health communication},
abstract = {Background
There is growing interest in applying generative artificial intelligence (GenAI) to respond to electronic patient portal messages, particularly in primary care where message volumes are highest. However, evaluations of GenAI as an inbox communication tool are limited. Qualitative analysis of when and how often GenAI responses achieve communication goals can inform estimates of impact and guide continuous improvement.
Objective
This study aims to evaluate GenAI responses to primary care messages using a medical communication framework.
Methods
This was a descriptive quality improvement study of 201 GenAI replies to a purposively sampled, diverse pool of real primary care patient messages in a large midwestern academic medical center. Two physician reviewers (NSL and NR) used a hybrid deductive-inductive approach to qualitatively identify and define themes, guided by constructs from the “best practice” medical communication framework. After achieving thematic saturation, the reviewers assessed the presence or absence of identified communication themes, both independently and collaboratively. Discrepant observations were reconciled via discussion. Frequencies of identified themes were tallied.
Results
Themes in strengths and limitations emerged across 5 communication domains. In the domain of rapport building, expressing respect and restating key phrases were strengths, while inappropriate or inadequate rapport building statements were limitations. For information gathering, questions that built toward a plan or elicited patient needs were strengths, while questions that were out of place or redundant were limitations. For information delivery, accurate content delivered clearly and professionally was a strength, but delivery of inaccurate content was an observed limitation. GenAI responses could facilitate next steps by outlining choices or providing instruction, but sometimes those next steps were inappropriate or premature. Finally, in responding to emotion, strengths were that emotions were named and validated, while inadequate or absent acknowledgment of emotion was a limitation. Overall, 26.4% (53/201) of all messages displayed communication strengths without limitations, 27.4% (55/201) had limitations without strengths, and the remaining 46.3% (93/201) had both. Strengths outnumbered limitations in rapport building (87/201, 43.3% vs 35/201, 17.4%) and facilitating next steps (73/201, 36.3% vs 39/201, 19.4%). Limitations outnumbered strengths in the remaining domains of information delivery (89/201, 44.3% vs 43/201, 21.4%), information gathering (60/201, 29.9% vs 43/201, 21.4%), and responding to emotion (7/201, 8.5% vs 9/201, 4.5%).
Conclusions
GenAI response quality on behalf of primary care physicians and advanced practice providers may vary by communication function. Expressions of respect or descriptions of common next steps may be appropriate, but gathering and delivering appropriate information, or responding to emotion, may be limited. While communication standards were often met, they were also often compromised. Understanding these strengths and limitations can inform decisions about whether, when, and how to apply GenAI as a tool for primary care inbox communication.}
}
@article{CHENG2025100374,
title = {Asking generative artificial intelligence the right questions improves writing performance},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100374},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100374},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000141},
author = {Yixin Cheng and Yizhou Fan and Xinyu Li and Guanliang Chen and Dragan Gašević and Zachari Swiecki},
keywords = {Generative AI, ChatGPT, Question asking, Help seeking, Epistemic network analysis, Mediation analysis},
abstract = {Generative Artificial Intelligence (GenAI) tools are widely used by learners and this trend is poised to continue. However, little is known about whether and how GenAI use impacts learning and performance. This study aimed to investigate the effect of GenAI on performance by examining a key affordance of GenAI—seeking help via question asking. We compared the questions that learners asked GenAI versus a human tutor online during a writing task. Using quantitative ethnographic methods, we found that: (a) participants in the GenAI condition asked significantly more questions compared to those in the Tutor condition; (b) GenAI participants tended to ask one-off questions, while Tutor participants tended to have longer conversational exchanges; (c) GenAI participants tended to question pragmatically, asking direct questions about conceptual and procedural knowledge, while Tutor participants tended to make indirect request for feedback; (d) question asking, as measured by epistemic network analysis, mediated the relationship between experimental condition and performance—the more pragmatic the questions, and thus the more like questions in the GenAI condition, the better the performance; and (e) questions in the GenAI condition were driven by social coordination and knowledge deficits, while questions in the Tutor condition were driven by social coordination and establishing common ground. These findings suggest learners may be less hesitant to admit knowledge deficits and more willing to repair them when interacting with GenAI compared to human tutors. Thus, GenAI can be a useful educational tool when improved performance is the goal and human tutoring may benefit from creating a space where learners are more comfortable revealing a lack of knowledge.}
}
@article{BUGHIN2024658,
title = {What drives the corporate payoffs of using generative artificial intelligence?},
journal = {Structural Change and Economic Dynamics},
volume = {71},
pages = {658-668},
year = {2024},
issn = {0954-349X},
doi = {https://doi.org/10.1016/j.strueco.2024.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0954349X24001413},
author = {Jacques Bughin},
keywords = {AI, Generative AI, Productivity impact, Capabilities, Entropy},
abstract = {Artificial Intelligence, a set of technologies that aim to replicate human cognitive functions, has seen remarkable improvements over the last decade. In particular, generative AI (GenAI), a subset of AI able to generate content tasks based on Large Language Models (LLM), has recently gained momentum. Based on an extensive analysis of generative AI use cases in large enterprises, we find that Gen AI shows strong labor productivity improvements across metrics such as throughput time, unit cost, and task effectiveness. However, the distribution of gains is asymmetric in favor of a few companies. While the current distribution of gains does not provide evidence of a power law effect, the current asymmetry reflects differences in AI resources/capabilities across companies - mainly data access, AI talent, or AI governance.}
}
@article{DERAKHSHAN2025102114,
title = {EFL students’ perceptions about the role of generative artificial intelligence (GAI)-mediated instruction in their emotional engagement and goal orientation: A motivational climate theory (MCT) perspective in focus},
journal = {Learning and Motivation},
volume = {90},
pages = {102114},
year = {2025},
issn = {0023-9690},
doi = {https://doi.org/10.1016/j.lmot.2025.102114},
url = {https://www.sciencedirect.com/science/article/pii/S0023969025000219},
author = {Ali Derakhshan},
keywords = {Achievement goal theory, Emotional engagement, Generative artificial intelligence (GAI), Goal orientation, L2 education, Motivational climate theory (MCT), Self-determination theory (SDT)},
abstract = {Research on the contributions of generative artificial intelligence (GAI) technologies to second language (L2) education has soared in the past couple of years. However, there is limited evidence pertaining to the impact of AI-mediated instruction on postgraduate students’ psycho-affective factors and the overall learning climate in English as a foreign language (EFL) context. To address this gap, the present study drew on motivational climate theory (MCT) to explore postgraduate EFL students’ perceptions of the role of GAI technologies in their emotional engagement and goal orientation. To do so, an interview was conducted with 30 postgraduate students using maximum variation sampling. The results of the inductive thematic analysis revealed that AI-mediated instruction had affected both the emotional engagement and goal orientation of the students. In particular, it was found that GAI tools fostered emotional engagement by ‘enlightening teacher-student classroom relationships’, ‘making the overall classroom culture/climate engaging, motivating, and updated’, ‘improving teachers’ action, instruction, and feedback quality’, ‘providing a personalized, interactive, and autonomy supporting education’, and ‘taping into learner-specific idiosyncrasies and individual differences’. Furthermore, GAI tools affected the students’ goal orientation by ‘facilitating the mastery of course content’, ‘setting personalized and achievable goals’, ‘fostering students’ performance comparison in the classroom’, and ‘providing a reflective and adaptive learning environment’. The findings are discussed and implications are provided for EFL teachers, students, teacher educators, and policymakers concerning the interplay of GAI, emotions, goal orientation, and motivational climate.}
}
@article{DUONG2025910,
title = {Exploring the role of generative artificial intelligence (ChatGPT) adoption in digital social entrepreneurship: a serial mediation model},
journal = {Social Enterprise Journal},
volume = {21},
number = {5},
pages = {910-936},
year = {2025},
issn = {1750-8614},
doi = {https://doi.org/10.1108/SEJ-03-2024-0029},
url = {https://www.sciencedirect.com/science/article/pii/S1750861425000106},
author = {Cong Doanh Duong and Thanh Hieu Nguyen and Minh Hoa Nguyen and Ngoc Su Dang and Anh Trong Vu and Ngoc Diep Do},
keywords = {GenAI (ChatGPT) adoption in social entrepreneurship, Perceived feasibility, Perceived desirability, Intention toward digital social entrepreneurship},
abstract = {Purpose
Using an integrated framework of the Entrepreneurial Event Model and the Stimulus–Organism–Response theory, this study aims to investigate how artificial intelligence (AI)-driven stimulus [Generative AI (ChatGPT) adoption in digital social entrepreneurship] affects individuals’ cognitive processes (perceived feasibility and perceived desirability), which subsequently influence their behavioral intentions (digital social entrepreneurial intention).
Design/methodology/approach
This research used a stratified sampling method to survey 986 higher education students in Vietnam. Hypotheses were tested using structural equation modeling.
Findings
The results indicate that GenAI (ChatGPT) adoption in digital social entrepreneurship significantly enhances both perceived feasibility and perceived desirability. These cognitive perceptions are positively associated with intentions to engage in digital social entrepreneurship. In addition, this study finds that GenAI (ChatGPT) adoption in digital social entrepreneurship poses a serial indirect effect on digital social entrepreneurial intention through a perceived feasibility–perceived desirability path.
Practical implications
The findings provide actionable recommendations for aspiring students (potential future entrepreneurs), educators and policymakers to foster the use of AI technologies in promoting digital social entrepreneurship.
Originality/value
This study offers substantial theoretical contributions by merging the Entrepreneurial Event Model and the Stimulus–Organism–Response framework. Thus, it advances the extant understanding of the cognitive mechanisms driving digital social entrepreneurial decision-making in the context of AI adoption. This research addresses a critical gap and establishes a foundation for future theoretical advancements in digital social entrepreneurship and AI integration.}
}
@article{CALLARI2025266,
title = {Can generative artificial intelligence productivity tools support workplace learning? A qualitative study on employee perceptions in a multinational corporation},
journal = {Journal of Workplace Learning},
volume = {37},
number = {3},
pages = {266-283},
year = {2025},
issn = {1366-5626},
doi = {https://doi.org/10.1108/JWL-11-2024-0258},
url = {https://www.sciencedirect.com/science/article/pii/S1366562625000026},
author = {Tiziana C. Callari and Lucia Puppione},
keywords = {Organisational socialisation, Meaningful work, Formal and informal learning, Incidental learning, Sociotechnical capital},
abstract = {Purpose
The purpose of this study was to explore employees’ perceptions and firsthand experiences of the impact of generative artificial intelligence (AI) productivity tools, specifically Microsoft 365 Copilot, on individual and collective learning processes within a multinational corporation. In doing so, the study provides insights into how these tools can shape workplace learning dynamics, fostering both individual skill development and collaborative knowledge-sharing practices.
Design/methodology/approach
The authors collected responses from 357 participants through a survey that included both multiple-choice and open-ended questions. This study focuses exclusively on the qualitative responses. The reflexive thematic analysis method was used to capture and interpret employees’ perceptions of the role of Microsoft 365 Copilot – a generative AI-powered assistant integrated into the Microsoft 365 suite of applications (e.g., Word, Excel, PowerPoint, Outlook, Teams) – in enhancing their work and learning opportunities in the workplace.
Findings
The results highlight four key themes contributing to workplace learning. At the individual level, Task Support illustrates the extent to which generative AI productivity tools transform work practices and facilitate both formal and informal learning pathways, while Meaningful Work underscores the tools’ role in enhancing employees’ foundational knowledge through enriched information. At the organisational level, organisational culture suggests the importance of fostering a supportive environment for AI integration, while organisational socialisation highlights its influence on team cohesion and the informal knowledge-sharing processes essential for effective collaboration within and among team members.
Practical implications
The results of this study offer actionable insights for organisations integrating generative AI productivity tools in the workplace. Understanding employees’ perceptions of the role of AI in workplace learning can inform the design of targeted training programmes that promote individual skill development and foster collaborative knowledge sharing. Furthermore, a supportive organisational culture that positions AI as a complementary resource can improve employee engagement, reduce resistance to new technologies and encourage a growth-oriented mindset, ultimately driving both personal and organisational development.
Originality/value
This study shifts the narrative around the role of AI in the workplace by examining how generative AI productivity tools can enhance workplace learning at both individual and organisational levels, rather than focusing solely on their potential to disrupt work through displacement and automation. By positioning AI-based applications as complementary to human work, this approach highlights their potential as enablers of skill development, knowledge sharing and job enrichment, fostering a more adaptive and learning-oriented work environment.}
}
@article{ALNASER2025102122,
title = {Geographic prompting and content fidelity in generative Artificial Intelligence: A multi-model study of demographics and imaging equipment in AI-generated videos and images of Canadian medical radiation technologists},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {56},
number = {6},
pages = {102122},
year = {2025},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2025.102122},
url = {https://www.sciencedirect.com/science/article/pii/S1939865425002711},
author = {Yousif Al-Naser and Sonali Sharma and Ken Niure and Kevin Ibach and Faisal Khosa and Charlotte J. Yong-Hing},
keywords = {Artificial intelligence, Medical radiation technologist, Generative ai, Demographics},
abstract = {Background
As generative AI tools increasingly produce medical imagery and videos for education, marketing, and communication, concerns have arisen about the accuracy and equity of these representations. Existing research has identified demographic biases in AI-generated depictions of healthcare professionals, but little is known about their portrayal of Medical Radiation Technologists (MRTs), particularly in the Canadian context.
Methods
This study evaluated 690 AI-generated outputs (600 images and 90 videos) created by eight leading text-to-image and text-to-video models using the prompt ``Image [or video] of a Canadian Medical Radiation Technologist.'' Each image and video was assessed for demographic characteristics (gender, race/ethnicity, age, religious representation, visible disabilities), and the presence and accuracy of imaging equipment. These were compared to real-world demographic data on Canadian MRTs (n = 20,755).
Results
Significant demographic discrepancies were observed between AI-generated content and real-world data. AI depictions included a higher proportion of visible minorities (as defined by Statistics Canada) (39% vs. 20.8%, p < 0.001) and males (41.4% vs. 21.2%, p < 0.001), while underrepresenting women (58.5% vs. 78.8%, p < 0.001). Age representation skewed younger than actual workforce demographics (p < 0.001). Equipment representation was inconsistent, with 66% of outputs showing CT/MRI and only 4.3% showing X-rays; 26% included inaccurate or fictional equipment.
Conclusion
Generative AI models frequently produce demographically and contextually inaccurate depictions of MRTs, misrepresenting workforce diversity and clinical tools. These inconsistencies pose risks for educational accuracy, public perception, and equity in professional representation. Improved model training and prompt sensitivity are needed to ensure reliable and inclusive AI-generated medical content.
Résumé
Alors que les outils d'IA générative produisent de plus en plus d'images et de vidéos médicales à des fins éducatives, promotionnelles et communicationnelles, des inquiétudes ont été soulevées quant à l'exactitude et à l'équité de ces représentations. Les recherches existantes ont mis en évidence des biais démographiques dans les représentations générées par l'IA des professionnels de la santé, mais on en sait peu sur leur représentation des technologues en radiation médicale (TRM), en particulier dans le contexte canadien.
Méthodologie
Cette étude a évalué 690 productions générées par l'IA (600 images et 90 vidéos) créées par huit modèles de pointe de conversion de texte en image et de texte en vidéo à partir de la commande « Image [ou vidéo] d'un technologue en radiation médicale canadien ». Chaque image et vidéo a été évaluée en fonction de caractéristiques démographiques (sexe, race/ethnicité, âge, représentation religieuse, handicaps visibles) et de la présence et de l'exactitude des équipements d'imagerie. Ces données ont été comparées aux données démographiques réelles sur les TRM canadiens (n = 20 755).
Résultats
Des écarts démographiques significatifs ont été observés entre le contenu généré par l'IA et les données réelles. Les représentations générées par l'IA comprenaient une proportion plus élevée de minorités visibles (telles que définies par Statistique Canada) (39 % contre 20,8 %, p < 0001) et d'hommes (41,4 % contre 21,2 %, p < 0001), tandis que les femmes étaient sous-représentées (58,5 % contre 78,8 %, p < 0001). La représentation des âges était plus jeune que la démographie réelle de la main-d'œuvre (p < 0001). La représentation des équipements était incohérente, 66 % des résultats montrant des appareils de TDM/IRM et seulement 4,3 % des radiographies; 26 % comprenaient des équipements inexacts ou fictifs.
Conclusion
les modèles d'IA générative produisent souvent des représentations démographiques et contextuelles inexactes des TRM, donnant une image faussée de la diversité de la main-d'œuvre et des outils cliniques. Ces incohérences posent des risques pour l'exactitude pédagogique, la perception du public et l'équité dans la représentation professionnelle. Une amélioration de la formation des modèles et une sensibilité immédiate sont nécessaires pour garantir un contenu médical fiable et inclusif généré par l'IA.}
}
@article{KOOLI2025104476,
title = {Generative artificial intelligence addiction syndrome: A new behavioral disorder?},
journal = {Asian Journal of Psychiatry},
volume = {107},
pages = {104476},
year = {2025},
issn = {1876-2018},
doi = {https://doi.org/10.1016/j.ajp.2025.104476},
url = {https://www.sciencedirect.com/science/article/pii/S1876201825001194},
author = {Chokri Kooli and Youssef Kooli and Eya Kooli},
keywords = {Generative AI Addiction, Behavioral Addiction, Artificial Intelligence Dependency, Digital Addiction, Cognitive and Emotional Well-being, AI and Mental Health, Human-AI Interaction}
}
@article{FOSSOWAMBA2025103235,
title = {Generative artificial intelligence and the challenges to adding value ethically},
journal = {Technovation},
volume = {144},
pages = {103235},
year = {2025},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2025.103235},
url = {https://www.sciencedirect.com/science/article/pii/S0166497225000677},
author = {Samuel {Fosso Wamba} and Maciel M. Queiroz and Krithika Randhawa and Gaurav Gupta},
keywords = {Generative AI, Gen-AI, LLMs, Ethical tensions, Business value, Innovation},
abstract = {Generative Artificial Intelligence (Gen-AI) is reshaping business models, innovation processes, and organizational strategies across industries. This editorial highlights its transformative potential through multiple lenses, including business model adaptation, strategic agility, social impact, creative industries, and ethical governance. The special issue “Generative artificial intelligence and the challenges to adding value ethically” presents diverse perspectives on how firms leverage Gen-AI to gain competitive advantage, drive value creation, and enhance resilience while addressing regulatory, ethical, and operational challenges. The accepted papers examine Gen-AI-driven shifts in entrepreneurship, decision-making, and digital ecosystems using quantitative, qualitative, and mixed-method approaches. Their findings point out both the opportunities and tensions of Gen-AI adoption, highlighting the need for responsible governance, strategic alignment, and human-AI collaboration. By integrating multidisciplinary perspectives, this collection offers a rigorous foundation for scholars, practitioners, and policymakers to understand how Gen-AI can be harnessed to drive sustainable and strategic innovation in an evolving and challenging digital landscape.}
}
@article{ALKHATIB2024102676,
title = {How can generative artificial intelligence improve digital supply chain performance in manufacturing firms? Analyzing the mediating role of innovation ambidexterity using hybrid analysis through CB-SEM and PLS-SEM},
journal = {Technology in Society},
volume = {78},
pages = {102676},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102676},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002240},
author = {Ayman wael Al-khatib and Moh'd Anwer AL-Shboul and Mais Khattab},
keywords = {Generative artificial intelligence, Innovation ambidexterity, Digital supply chain, Manufacturing firms, Performance, Hybrid analysis, Jordan},
abstract = {Artificial intelligence capabilities (AIC) can influence supply chain management (SCM) in multiple ways. This study explores how generative artificial intelligence capabilities (GAIC) could affect digital supply chain performance (DSCP) through ambidexterity innovation (AMI), which includes both elements, exploratory and exploitative innovations in the manufacturing firms (MFs) in Jordan as a developing and emerging economy. This study adopted a quantitative methodology for the data collection process applying a cross-sectional approach through testing deductive-hypotheses techniques. 263 valid surveys were used for analysis using hybrid analysis measurements (i.e., PLS-SEM, and CB-SEM). Further, it was applied data reliability, convergent validity, and discriminant validity tests. Additionally, examined the mediating effect of exploratory innovation (EXPI), and exploitative innovation (EXTI) on DSCP. The study findings assured that the proposed direct and indirect causal associations illustrated in the study model were accepted due to that all associations between the dimensions s were statistically significant. The findings of the GAIC supported a positive relationship between GAIC and the DSCP, GAIC on EXPI and EXTI, and EXPI and EXTI on DSCP respectively. Furthermore, the mediating effect of EXPI and EXTI is statistically significant, which was confirmed. This study developed a conceptual model to merge GAIC, AMI, and DSCP. This study provides new outcomes that bridge the existing research gap in the literature by testing the mediation model with a focus on the MF benefits of GAIC to improve levels of EXPI, EXTI, and DSCP in Jordan as a developing and emerging economy. Furthermore, this study is considered unique, as it was the first study in Jordan, and through applying hybrid analysis measurements using both PLS-SEM and CB-SEM methods.}
}
@article{MARZOUK2025118228,
title = {Editorial: Generative Artificial Intelligence for Predictive Simulations and Decision-Making in Science and Engineering},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {445},
pages = {118228},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118228},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525005006},
author = {Youssef Marzouk and Benjamin Peherstorfer}
}
@article{HERMANN2024114720,
title = {Artificial intelligence and consumer behavior: From predictive to generative AI},
journal = {Journal of Business Research},
volume = {180},
pages = {114720},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114720},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324002248},
author = {Erik Hermann and Stefano Puntoni},
keywords = {Artificial intelligence, Consumer behavior, Algorithms, Predictive AI, Generative AI},
abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI’s remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15 years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.}
}
@article{RAPP2025103375,
title = {How do people experience the images created by generative artificial intelligence? An exploration of people's perceptions, appraisals, and emotions related to a Gen-AI text-to-image model and its creations},
journal = {International Journal of Human-Computer Studies},
volume = {193},
pages = {103375},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2024.103375},
url = {https://www.sciencedirect.com/science/article/pii/S1071581924001587},
author = {Amon Rapp and Chiara {Di Lodovico} and Federico Torrielli and Luigi {Di Caro}},
keywords = {AI, Generative AI, Stable diffusion, User experience, Anthropomorphising, Humanness, Uncanny valley},
abstract = {Generative Artificial Intelligence (Gen-AI) has rapidly advanced in recent years, potentially producing enormous impacts on industries, societies, and individuals in the near future. In particular, Gen-AI text-to-image models allow people to easily create high-quality images possibly revolutionizing human creative practices. Despite their increasing use, however, the broader population's perceptions and understandings of Gen-AI-generated images remain understudied in the Human-Computer Interaction (HCI) community. This study investigates how individuals, including those unfamiliar with Gen-AI, perceive Gen-AI text-to-image (Stable Diffusion) outputs. Study findings reveal that participants appraise Gen-AI images based on their technical quality and fidelity in representing a subject, often experiencing them as either prototypical or strange: these experiences may raise awareness of societal biases and evoke unsettling feelings that extend to the Gen-AI itself. The study also uncovers several “relational” strategies that participants employ to cope with concerns related to Gen-AI, contributing to the understanding of reactions to uncanny technology and the (de)humanization of intelligent agents. Moreover, the study offers design suggestions on how to use the anthropomorphizing of the text-to-image model as design material, and the Gen-AI images as support for critical design sessions.}
}
@article{LENGUYEN2024138836,
title = {Generative artificial intelligence and optimisation framework for concrete mixture design with low cost and embodied carbon dioxide},
journal = {Construction and Building Materials},
volume = {451},
pages = {138836},
year = {2024},
issn = {0950-0618},
doi = {https://doi.org/10.1016/j.conbuildmat.2024.138836},
url = {https://www.sciencedirect.com/science/article/pii/S0950061824039783},
author = {Khuong {Le Nguyen} and Minhaz Uddin and Thong M. Pham},
keywords = {Concrete mixture design, Machine learning approach, Generative AI, Compressive strength prediction, Multi-objective optimisation},
abstract = {This research presents a generative Artificial Intelligence (AI) and design framework that integrates machine learning (ML) and optimisation methodologies to discover new concrete mixture designs. Unlike traditional ML models that predict based on existing data, this framework innovatively generates new concrete mix designs that meet specific requirements such as strength, cost-efficiency, and reduced embodied CO2. To propose a powerful and reliable generative AI model, several advanced ML algorithms were considered, e.g., CatBoost, XGBoost, and LGBM. These models were trained on a unique dataset consisting of 4,936 data points collected from five different batching plants and have not been published yet. Bayesian Optimisation was employed to fine-tune model hyperparameters, resulting in the most effective models attaining R2 values of 0.94 and 0.89 for raw and grouped data, respectively. To verify the trained generative AI model, a case study was conducted, in which the model was requested to provide designs of a mix with pre-determined strength and optimised cost and embodied CO2. The mix designs generated by the framework were successfully validated through experimental tests, corroborating the predictive outcomes. The research culminated in the development of a web application, a tool crafted to streamline the concrete mixture design and optimisation process. This generative AI design framework can be applied to many other aspects of material design and engineering problems.}
}
@article{MARIANI2024114542,
title = {Generative artificial intelligence in innovation management: A preview of future research developments},
journal = {Journal of Business Research},
volume = {175},
pages = {114542},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.114542},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324000468},
author = {Marcello Mariani and Yogesh K. Dwivedi},
keywords = {Generative artificial intelligence, Delphi study, Management, Innovation},
abstract = {This study outlines the future research opportunities related to Generative Artificial Intelligence (GenAI) in innovation management. To this end, it combines a review of the academic literature with the results of a Delphi study involving leading innovation management scholars. Ten major research themes emerged that can guide future research developments at the intersection of GenAI and innovation management: 1) Gen AI and innovation types; 2) GenAI, dominant designs and technology evolution; 3) Scientific and artistic creativity and GenAI-enabled innovations; 4) GenAI-enabled innovations and intellectual property; 5) GenAI and new product development; 6) Multimodal/unimodal GenAI and innovation outcomes; 7) GenAI, agency and ecosystems; 8) Policymakers, lawmakers and anti-trust authorities in the regulation of GenAI-enabled innovation; 9) Misuse and unethical use of GenAI leading to biased innovation; and 10) Organizational design and boundaries for GenAI-enabled innovation. The paper concludes by discussing how these themes can inform theoretical development in innovation management studies.}
}
@article{SALAH2024101872,
title = {The good, the bad, and the GPT: Reviewing the impact of generative artificial intelligence on psychology},
journal = {Current Opinion in Psychology},
volume = {59},
pages = {101872},
year = {2024},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2024.101872},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X2400085X},
author = {Mohammed Salah and Fadi Abdelfattah and Hussam {Al Halbusi}},
keywords = {Generative artificial intelligence, Psychology, Ethical considerations, Therapeutic personalization, Natural language processing},
abstract = {This review explores the impact of Generative Artificial Intelligence (GenAI)—a technology capable of autonomously creating new content, ideas, or solutions by learning from extensive data—on psychology. GenAI is changing research methodologies, diagnostics, and treatments by enhancing diagnostic accuracy, personalizing therapeutic interventions, and providing deeper insights into cognitive processes. However, these advancements come with significant ethical concerns, including privacy, bias, and the risk of depersonalization in therapy. By focusing on the current capabilities of GenAI, this study aims to provide a balanced understanding and guide the ethical integration of AI into psychological practices and research. We argue that while GenAI presents profound opportunities, its integration must be approached cautiously using robust ethical frameworks.}
}
@article{SHIN2025108662,
title = {Artificial intelligence versus clinical judgement: how accurately do generative models reflect CNS guidelines for chiari malformation?},
journal = {Clinical Neurology and Neurosurgery},
volume = {248},
pages = {108662},
year = {2025},
issn = {0303-8467},
doi = {https://doi.org/10.1016/j.clineuro.2024.108662},
url = {https://www.sciencedirect.com/science/article/pii/S0303846724005493},
author = {David Shin and Hyunah Park and Isabel Shaffrey and Vahe Yacoubian and Taha M. Taka and Justin Dye and Olumide Danisa},
keywords = {Artificial intelligence, Chatgpt, Chiari malformation, Guidelines},
abstract = {Objective
This study investigated the response and readability of generative artificial intelligence (AI) models to questions and recommendations proposed by the 2023 Congress of Neurological Surgeons (CNS) guidelines for Chiari 1 malformation.
Methods
Thirteen questions were generated from CNS guidelines and asked to Perplexity, ChatGPT 4o, Microsoft Copilot, and Google Gemini. AI answers were divided into two categories, "concordant" and "non-concordant," according to their alignment with current CNS guidelines. Non-concordant answers were sub-categorized as “insufficient” or “over-conclusive.” Responses were evaluated for readability via the Flesch-Kincaid Grade Level, Gunning Fog Index, SMOG (Simple Measure of Gobbledygook) Index, and Flesch Reading Ease test.
Results
Perplexity displayed the highest concordance rate of 69.2 %, with non-concordant responses classified as 0 % insufficient and 30.8 % over-conclusive. ChatGPT 4o had the lowest concordance rate at 23.1 %, with 0 % insufficient and 76.9 % over-conclusive classifications. Copilot showed a 61.5 % concordance rate, with 7.7 % insufficient and 30.8 % over-conclusive. Gemini demonstrated a 30.8 % concordance rate, with 7.7 % insufficient and 61.5 % as over-conclusive. Flesch-Kincaid Grade Level scores ranged from 14.48 (Gemini) to 16.48 (Copilot), Gunning Fog Index scores varied between 16.18 (Gemini) and 18.8 (Copilot), SMOG Index scores ranged from 16 (Gemini) to 17.54 (Copilot), and Flesch Reading Ease scores were low across all models, with Gemini showing the highest mean score of 21.3.
Conclusion
Perplexity and Copilot emerged as the best-performing for concordance, while ChatGPT and Gemini displayed the highest over-conclusive rates. All responses showcased high complexity and difficult readability. While AI can be valuable in certain aspects of clinical practice, the low concordance rates show that AI should not replace clinician judgement.}
}
@article{MARTIKAINEN2025,
title = {Evaluation of Generative Artificial Intelligence Implementation Impacts in Social and Health Care Language Translation: Mixed Methods Case Study},
journal = {JMIR Formative Research},
volume = {9},
year = {2025},
issn = {2561-326X},
doi = {https://doi.org/10.2196/73658},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X25006420},
author = {Miia Martikainen and Kari Smolander and Johan Sanmark and Enni Sanmark},
keywords = {generative artificial intelligence, large language model, ChatGPT, pretrained language model, language translation, machine translation evaluation, public social and health care},
abstract = {Background
Generative artificial intelligence (GAI) is expected to enhance the productivity of the public social and health care sector while maintaining, at minimum, current standards of quality and user experience. However, empirical evidence on GAI impacts in practical, real-life settings remains limited.
Objective
This study investigates productivity, machine translation quality, and user experience impacts of the GPT-4 language model in an in-house language translation services team of a large well-being services county in Finland.
Methods
A mixed methods study was conducted with 4 in-house translators between March and June 2024. Quantitative data of 908 translation segments were collected in real-life conditions using the computer-assisted language translation software Trados (RWS) to assess productivity differences between machine and human translation. Quality was measured using 4 automatic metrics (human-targeted translation edit rate, Bilingual Evaluation Understudy, Metric for Evaluation of Translation With Explicit Ordering, and Character n-gram F-score) applied to 1373 GAI-human segment pairs. User experience was investigated through 5 semistructured interviews, including the team supervisor.
Results
The findings indicate that, on average, postediting machine translation is 14% faster than translating texts from scratch (2.75 vs 2.40 characters per second, P=.03), and up to 37% faster when the number of segments is equalized across translators. However, productivity varied notably between individuals, with improvements ranging from −2% to 102%. Regarding translation quality, 11% (141/1261) of Finnish-Swedish and 16% (18/112) of Finnish-English GAI outputs were accepted without edits. Average human-targeted translation edit rate scores were 55 (Swedish) and 46 (English), indicating that approximately half of the words required editing. Bilingual Evaluation Understudy scores averaged 43 for Swedish and 38 for English, suggesting good translation quality. Metric for Evaluation of Translation With Explicit Ordering and Character n-gram F-scores reached 63 and 68 for Swedish and 59 and 57 for English, respectively. All metrics have been converted to an equivalent scale from 0 to 100, with 100 reflecting a perfect match. Interviewed translators expressed mixed reviews on productivity gains but generally perceived value in using GAI, especially for repetitive, generic content. Identified challenges included inconsistent or incorrect terminology, lack of document-level context, and limited system customization.
Conclusions
Based on this case study, GPT-4–based GAI shows measurable potential to enhance translation productivity and quality within an in-house translation team in the public social and health care sector. However, its effectiveness appears to be influenced by factors, such as translator postediting skills, workflow design, and organizational readiness. These findings suggest that, in similar contexts, public social and health care organizations could benefit from investing in translator training, optimizing technical integration, redesigning workflows, and implementing effective change management. Future research should examine larger translator teams to assess the generalizability of these results and further explore how translation quality and user experience can be improved through domain-specific customization.}
}
@article{LUO2025e117,
title = {Transparent reporting of generative artificial intelligence use in systematic reviews},
journal = {Journal of the American Academy of Dermatology},
volume = {93},
number = {3},
pages = {e117-e118},
year = {2025},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2025.03.101},
url = {https://www.sciencedirect.com/science/article/pii/S0190962225022078},
author = {Xufei Luo and Yaolong Chen},
keywords = {cutaneous squamous cell carcinoma, generative AI, reporting guideline, systematic review}
}
@article{LIU2024124511,
title = {Generative artificial intelligence and data augmentation for prognostic and health management: Taxonomy, progress, and prospects},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124511},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124511},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013782},
author = {Shen Liu and Jinglong Chen and Yong Feng and Zongliang Xie and Tongyang Pan and Jingsong Xie},
keywords = {Fault diagnosis, Generative artificial intelligence, Data augmentation, Data generation, Prognostics and health management},
abstract = {Intelligent fault diagnosis, detection, and prognostics (DDP) for complex equipment prognostics and health management (PHM) have achieved remarkable breakthroughs. Equipment in industrial scenarios often operates in normal conditions, resulting in missing anomalies, limited failures, and incomplete degradation paths. Thus the limited information on the state of the equipment collected from sensor readings severely hinders the cognitive capabilities of discriminative artificial intelligence (AI) for PHM. Data augmentation and generation (DA&G) techniques, represented by generative AI, have shown great promise in overcoming the limitations of PHM application scenarios. Research on DA&G has yielded significant achievements, but a comprehensive review in the mechanical field is still lacking. To this end, this paper provides a comprehensive review of DA&G techniques aimed at solving the DDP problems, which are divided into three categories insights of data, mechanism, and features. The data-based randomized approach applies controlled randomness for augmentation. The mechanism-based domain-specific techniques advocate for exploring relationships between the physical entity and monitoring data for generating by reasoned inference. The feature-based generative model aims to identify the latent space of data and subsequently resample it. Finally, the paper explores strategies for evaluating DA&G and provides a deep insight into the challenges and opportunities of DA&G techniques.}
}
@article{DAS2025102546,
title = {Generative artificial intelligence, integrative bioinformatics, and single-cell analysis reveal Alzheimer’s genetic and immune landscape},
journal = {Molecular Therapy Nucleic Acids},
volume = {36},
number = {2},
pages = {102546},
year = {2025},
issn = {2162-2531},
doi = {https://doi.org/10.1016/j.omtn.2025.102546},
url = {https://www.sciencedirect.com/science/article/pii/S2162253125001003},
author = {Arpita Das and Manojit Bhattacharya and Ali Saber Abdelhameed and Sang-Soo Lee and Chiranjib Chakraborty},
keywords = {Bioinformatics, GenAI, single-cell analysis, Alzheimer’s disease, genetic and immune landscape},
abstract = {The research aims to understand Alzheimer’s genetic and immune landscapes using the amalgamation of three technologies: artificial intelligence (GenAI), integrative bioinformatics, and single-cell analysis. First, the study aims to identify and characterize the significant genes associated with Alzheimer’s disease (AD) using three GenAI models (GPT‑4o, Gemini model, and DeepSeek). After the genes were accumulated from GenAI models, 27 genes associated with AD were recoded. Furthermore, they were analyzed using integrative bioinformatics methods. Similarly, the immune landscape of AD using single-cell analysis was also explored, which reveals a high percentage of effector CD8+ T cells (33.42%) and naive T cells (45.95%). The single-cell study found that effector memory T cells have two subsets. It also found that the macrophage population has started to spread and dendritic cells have decreased in Alzheimer’s patients. The single-cell gene expression study reveals the top ten highly expressed genes (NDUFV2, CAT, MRPS34, PBX3, THOC2, CCDC57, PBXIP1, SDHAF3, PPP4C, and MAP3K8). The clonal frequency indicates that CD8+ T and naive T cell populations show the highest clonal frequency in healthy and AD individuals and are further noted them in the clonotype cell proportion study. Following our GenAI and single-cell profiling strategy, future studies will help in quickly understanding the genetic and immune basis of many diseases.}
}
@article{KOHNKE2025108600,
title = {Enhancing the emotional aspects of language education through generative artificial intelligence (GenAI): A qualitative investigation},
journal = {Computers in Human Behavior},
volume = {167},
pages = {108600},
year = {2025},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2025.108600},
url = {https://www.sciencedirect.com/science/article/pii/S0747563225000470},
author = {Lucas Kohnke and Benjamin Luke Moorhouse},
keywords = {GenAI, Motivation, Emotions, Positive psychology},
abstract = {This qualitative study investigates the impact of generative artificial intelligence (GenAI) on the emotional engagement, motivation and well-being of first-year university students in Hong Kong. We conducted semi-structured interviews with 21 students and three instructors to explore their perceptions of how GenAI influences the affective dimensions of language learning. The data were analyzed using manual coding and inductive thematic analysis to identify key themes. The findings revealed that GenAI generally enhances students’ motivation, reduces anxiety and stress, and fosters an emotionally supportive learning environment. However, challenges related to cultural context and technical issues were also identified. The study highlights the pivotal role of instructors in shaping students’ experiences with GenAI and underscores the need for ongoing support and professional development. It also demonstrates the importance of cultural sensitivity, technological infrastructure and balance. The study is valuable for those who aim to harness GenAI while preserving the irreplaceable human elements of teaching. It contributes to the growing body of knowledge on integrating AI in language learning.}
}
@article{CHEAH2025100363,
title = {Integrating generative artificial intelligence in K-12 education: Examining teachers’ preparedness, practices, and barriers},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100363},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100363},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000037},
author = {Yin Hong Cheah and Jingru Lu and Juhee Kim},
keywords = {Generative artificial intelligence, In-service teachers, Preparedness, Practices, Barriers, K-12 education},
abstract = {Despite the growing body of research on developing K-12 teachers' generative AI (GenAI) knowledge and skills, its integration into daily teaching practices remains underexplored. Using a snowball sampling method, this study examined the preparedness, practices, and barriers encountered by 89 U.S. teachers in the state of Idaho. Participants were predominantly White, female teachers serving in rural schools. A mixed-methods analysis of survey responses revealed that teachers were generally underprepared for integrating GenAI, with fewer than half incorporating it into their educational practices. Unlike the widespread classroom integration patterns observed with general educational technologies, teachers in this study tended to use GenAI for out-of-classroom duties (i.e., lesson preparation, assessment, and administrative tasks) rather than for real-time teaching and learning. These preferences could be attributed to key barriers teachers faced, including doubts about GenAI's ability to manage risks (i.e., technology value beliefs), reduced human interaction in instruction (i.e., pedagogical beliefs), ethical considerations, and the absence of policies and guidance. This study highlights the need to develop support systems and targeted policies to facilitate teachers' GenAI integration, offering implications for Idaho's education system and the broader U.S. context.}
}
@article{LEE2024102846,
title = {Generating TRIZ-inspired guidelines for eco-design using Generative Artificial Intelligence},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102846},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102846},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004944},
author = {C.K.M. Lee and Jingying Liang and K.L. Yung and K.L. Keung},
keywords = {Eco-design, TRIZ, Large Language Models, Generative AI},
abstract = {Environmental considerations are emerging as stimuli for innovation during the eco-design ideation process. Integrating TRIZ (Teoriya Resheniya Izobretatelskikh Zadatch─Theory of Inventive Problem Solving) methodology into eco-design offers a structured problem-solving approach to address sustainability challenges. However, developing innovative designs requires expertise in TRIZ concepts and access to resources, which makes it a time-consuming process and can limit its application for eco-design innovation quickly. This study leverages the analytical and generative capabilities of large language models (LLMs) to enhance the TRIZ methodology and automate the ideation process in eco-design. An intelligent tool, “Eco-innovate Assistant,” is designed to provide users with eco-innovative solutions with design sketches. Its effectiveness is validated and evaluated through comparative studies. The findings demonstrate the potential of LLMs in automating design processes, catalyzing a transformation in AI-driven innovation and ideation in eco-design.}
}
@article{SHLOBIN2024e769,
title = {Ethical Incorporation of Artificial Intelligence into Neurosurgery: A Generative Pretrained Transformer Chatbot-Based, Human-Modified Approach},
journal = {World Neurosurgery},
volume = {187},
pages = {e769-e791},
year = {2024},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.04.165},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024007381},
author = {Nathan A. Shlobin and Max Ward and Harshal A. Shah and Ethan D.L. Brown and Daniel M. Sciubba and David Langer and Randy S. D'Amico},
keywords = {Bioethics, ChatGPT, Deep learning, Machine learning, Medical ethics, Neurologic surgery},
abstract = {Introduction
Artificial intelligence (AI) has become increasingly used in neurosurgery. Generative pretrained transformers (GPTs) have been of particular interest. However, ethical concerns regarding the incorporation of AI into the field remain underexplored. We delineate key ethical considerations using a novel GPT-based, human-modified approach, synthesize the most common considerations, and present an ethical framework for the involvement of AI in neurosurgery.
Methods
GPT-4, ChatGPT, Bing Chat/Copilot, You, Perplexity.ai, and Google Bard were queried with the prompt “How can artificial intelligence be ethically incorporated into neurosurgery?”. Then, a layered GPT-based thematic analysis was performed. The authors synthesized the results into considerations for the ethical incorporation of AI into neurosurgery. Separate Pareto analyses with 20% threshold and 10% threshold were conducted to determine salient themes. The authors refined these salient themes.
Results
Twelve key ethical considerations focusing on stakeholders, clinical implementation, and governance were identified. Refinement of the Pareto analysis of the top 20% most salient themes in the aggregated GPT outputs yielded 10 key considerations. Additionally, from the top 10% most salient themes, 5 considerations were retrieved. An ethical framework for the use of AI in neurosurgery was developed.
Conclusions
It is critical to address the ethical considerations associated with the use of AI in neurosurgery. The framework described in this manuscript may facilitate the integration of AI into neurosurgery, benefitting both patients and neurosurgeons alike. We urge neurosurgeons to use AI only for validated purposes and caution against automatic adoption of its outputs without neurosurgeon interpretation.}
}
@article{REN2024100073,
title = {Rapid estimation of γ' solvus temperature for composition design of Ni-based superalloy via physics-informed generative artificial intelligence},
journal = {Journal of Alloys and Metallurgical Systems},
volume = {6},
pages = {100073},
year = {2024},
issn = {2949-9178},
doi = {https://doi.org/10.1016/j.jalmes.2024.100073},
url = {https://www.sciencedirect.com/science/article/pii/S2949917824000208},
author = {Yunfei Ren and Tao Hu and Songzhe Xu and Chaoyue Chen and Weidong Xuan and Zhongming Ren},
keywords = {Ni-based superalloy, γ' Solvus temperature, Composition deviation index, Generative artificial intelligence, Thermodynamic calculation},
abstract = {The exceptional high-temperature mechanical properties of Ni-based superalloys are mainly stemmed from the L12 γ' phase, therefore it is crucial to discover Ni-based superalloys with high γ' solvus temperatures. Utilizing generative artificial intelligence, we have developed a framework to swiftly evaluate the γ' solvus temperature and tailor Ni-based superalloys, accelerating the process of discovering Ni-based superalloys. Physics-informed artificial neural network emerged as the optimal choice for reverse engineering, outperforming other models with an R2 score of 0.917 and a mean absolute error of 15 K. In the reverse design process, 20,000 virtual alloy samples were generated based on divide-and-conquer variational autoencoder which divides the dataset into distinct clusters by K-means algorithm provides a structured representation of the alloy composition space, thereby facilitating a more nuanced understanding of its inherent complexities. In a specific alloy design example, 563 samples were identified through screening based on criteria like γ' solvus temperature, composition deviation index, price, and density. Thermodynamic calculations were used to further screen Ni-based superalloys with exceptional high-temperature properties. The showcase of BA alloy discovery through generative artificial intelligence demonstrates the potential of our research to steer the creation of novel compositions for Ni-based superalloys with outstanding high-temperature properties.}
}
@article{HEINKE2024100089,
title = {A review of ophthalmology education in the era of generative artificial intelligence},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100089},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100089},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000902},
author = {Anna Heinke and Niloofar Radgoudarzi and Bonnie B. Huang and Sally L. Baxter},
keywords = {Generative AI, Large Language Models (LLMs), Ophthalmology Education, Artificial Intelligence (AI)},
abstract = {Purpose
To explore the integration of generative AI, specifically large language models (LLMs), in ophthalmology education and practice, addressing their applications, benefits, challenges, and future directions.
Design
A literature review and analysis of current AI applications and educational programs in ophthalmology.
Methods
Analysis of published studies, reviews, articles, websites, and institutional reports on AI use in ophthalmology. Examination of educational programs incorporating AI, including curriculum frameworks, training methodologies, and evaluations of AI performance on medical examinations and clinical case studies.
Results
Generative AI, particularly LLMs, shows potential to improve diagnostic accuracy and patient care in ophthalmology. Applications include aiding in patient, physician, and medical students’ education. However, challenges such as AI hallucinations, biases, lack of interpretability, and outdated training data limit clinical deployment. Studies revealed varying levels of accuracy of LLMs on ophthalmology board exam questions, underscoring the need for more reliable AI integration. Several educational programs nationwide provide AI and data science training relevant to clinical medicine and ophthalmology.
Conclusions
Generative AI and LLMs offer promising advancements in ophthalmology education and practice. Addressing challenges through comprehensive curricula that include fundamental AI principles, ethical guidelines, and updated, unbiased training data is crucial. Future directions include developing clinically relevant evaluation metrics, implementing hybrid models with human oversight, leveraging image-rich data, and benchmarking AI performance against ophthalmologists. Robust policies on data privacy, security, and transparency are essential for fostering a safe and ethical environment for AI applications in ophthalmology.}
}
@article{SOLAIMAN2024102028,
title = {Generative artificial intelligence (GenAI) and decision-making: Legal & ethical hurdles for implementation in mental health},
journal = {International Journal of Law and Psychiatry},
volume = {97},
pages = {102028},
year = {2024},
issn = {0160-2527},
doi = {https://doi.org/10.1016/j.ijlp.2024.102028},
url = {https://www.sciencedirect.com/science/article/pii/S0160252724000773},
author = {Barry Solaiman},
keywords = {Generative artificial intelligence (GenAI), Mental health, Psychiatry, Ethics, Law, Healthcare},
abstract = {This article argues that significant risks are being taken with using GenAI in mental health that should be assessed urgently. It recommends that guidelines for using generative artificial intelligence (GenAI) in mental health care must be established promptly. Currently, clinicians using chatbots without appropriate approval risk undermining legal protections for patients. This could harm the patient and undermine the standards of the profession, undermining trust in an area where human involvement in decision-making is critical. To explore these concerns, this paper is divided into three parts. First, it examines the needs of patients in mental health. Second, it explores the potential benefits of GenAI in mental health and highlights the risks of its use as it pertains to patient needs. Third, it notes the ethical and legal concerns around data use and medical liability that require careful attention. The impact of the European Union's (EU) Artificial Intelligence Act (AI-Act) is also considered. It will be seen that these laws are insufficient in the context of mental health. As such, the paper recommends that guidelines should be developed to help resolve the existing legal gaps until codified rules are established.}
}
@article{GUNTUKA2024140,
title = {Application of Generative Artificial Intelligence in Minimizing Cyber Attacks on Vehicular Networks},
journal = {Procedia Computer Science},
volume = {251},
pages = {140-149},
year = {2024},
note = {15th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 14th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare EUSPN/ICTH 2024},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.094},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924033283},
author = {Sony Guntuka and Elhadi Shakshuki},
keywords = {Cyber attacks, GenAI, Vehicular Networks},
abstract = {This paper explores the innovative applications of Generative Artificial Intelligence (GenAI) for strengthening the cybersecurity of vehicular networks. With the advent of intelligent transport systems and autonomous vehicles, the cybersecurity landscape has evolved significantly, which necessitating new strategies to tackle sophisticated threats. GenAI provides advanced capabilities for automating defenses, enhancing threat intelligence, and fostering dynamic security frameworks in vehicular networks. However, the incorporation of GenAI also introduces new risks, requiring robust ethical, legal, and technical oversight. This research paper outlines the current state of GenAI in vehicular network cybersecurity, showcases the Vehicular Threat Intelligence Flowchart (VTIF), focuses on the threat detection rule algorithm in VTIF, highlights the potential benefits and challenges, and proposes future research directions for developing resilient and ethical cybersecurity mechanisms.}
}
@article{GHANBARI2025101901,
title = {Free-breathing single-beat exercise cardiovascular magnetic resonance with generative artificial intelligence for evaluation of volumetric and functional cardiac indices: A reproducibility study},
journal = {Journal of Cardiovascular Magnetic Resonance},
volume = {27},
number = {1},
pages = {101901},
year = {2025},
issn = {1097-6647},
doi = {https://doi.org/10.1016/j.jocmr.2025.101901},
url = {https://www.sciencedirect.com/science/article/pii/S1097664725000638},
author = {Fahime Ghanbari and Alexander Schulz and Manuel A. Morales and Jennifer Rodriguez and Jordan A. Street and Kathryn Arcand and Scott Johnson and Patrick Pierce and Christopher W. Hoeger and Connie W. Tsao and Warren J. Manning and Reza Nezafat},
keywords = {Exercise-CMR, Free-breathing single-beat cine, Biventricular volumetric and functional indices},
abstract = {Background
Exercise cardiovascular magnetic resonance (Ex-CMR) can reveal pathophysiologies not evident at rest by quantifying biventricular volume and function during or immediately after exercise. However, achieving reproducible Ex-CMR measurements is challenging due to limited spatial and temporal resolution. This study aimed to develop and evaluate a free-breathing, high-spatiotemporal-resolution single-beat Ex-CMR cine enhanced by generative artificial intelligence. We assessed image analysis reproducibility, scan-rescan reproducibility, and impact of the reader's experience on the analysis.
Methods
Imaging was performed on a 3T CMR system using a free-breathing, highly accelerated, multi-slice, single-beat cine sequence (in-plane spatiotemporal resolution of 1.9 × 1.9 mm² and 37 ms, respectively). High acceleration was achieved by combining compressed sensing reconstruction with a resolution-enhancement generative adversarial inline neural network. Ex-CMR was performed using a supine ergometer positioned immediately outside the magnet bore. Single-beat cine images were acquired at rest and immediately post-exercise. In a prospective study, the protocol was evaluated in 141 subjects. A structured image analysis workflow was implemented. Four expert readers, with or without prior training in single-beat Ex-CMR, independently rated all images for diagnostic and image quality. The subjective assessment used two 3-point Likert scales. Biventricular parameters were calculated. Inter- and intra-observer reproducibility were assessed. Fifteen healthy subjects were re-imaged 1 year later for scan-rescan reproducibility. Reproducibility was assessed using intraclass correlation coefficient (ICC), with agreement evaluated via Bland-Altman analysis, linear regression, and Pearson correlation.
Results
Free-breathing, single-beat Ex-CMR cine enabled imaging of the beating heart within 30 ± 6 s, with technically successful scans in 96% (136/141) of subjects. Post-exercise single-beat cine images were assessed as diagnostic in 98% (133/136), 96% (131/136), 82% (112/136), and 65% (89/136) of cases by four readers (ordered by descending years of Ex-CMR experience). Good image quality was reported in 74% (100/136) to 80% (109/136) of subjects. Biventricular parameters were successfully measured in all subjects, demonstrating good to excellent inter-observer reproducibility. Scan/rescan reproducibility over 1 year, assessed by two independent readers, showed excellent inter-visit ICCs (0.96–1.0) and strong correlations (R² ≥ 0.92, p < 0.001 for left ventricle; R² ≥ 0.95, p < 0.001 for right ventricle).
Conclusion
Single-beat Ex-CMR enabled evaluation of biventricular volumetric and functional indices with excellent reproducibility.}
}
@article{CHUNG2025S-173,
title = {742: RANDOMIZED CONTROLLED TRIAL EVALUATING THE EFFICACY OF HUMAN-GENERATIVE ARTIFICIAL INTELLIGENCE TEAMING ON TECHNOLOGY ACCEPTANCE, USABILITY, AND TRUST: THE GUT-GPT SIMULATION STUDY},
journal = {Gastroenterology},
volume = {169},
number = {1, Supplement },
pages = {S-173},
year = {2025},
issn = {0016-5085},
doi = {https://doi.org/10.1016/S0016-5085(25)01346-0},
url = {https://www.sciencedirect.com/science/article/pii/S0016508525013460},
author = {Sunny Chung and Niroop Rajashekar and Yuan Pu and Yeo Eun Shin and Mauro Giuffrè and Colleen Chan and Kisung You and Theo Saarinen and Allen Hsiao and Jasjeet Sekhon and Ambrose Wong and Leigh Evans and Terika McCall and Rene F. Kizilcec and Loren Laine and Dennis Shung}
}
@article{CHAN2025102733,
title = {Generative artificial intelligence in a VUCA world: the ‘Lived Experiences’ of Southeast Asian teachers’ use of AI in higher education},
journal = {International Journal of Educational Research},
volume = {133},
pages = {102733},
year = {2025},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2025.102733},
url = {https://www.sciencedirect.com/science/article/pii/S088303552500206X},
author = {Nee Nee Chan and Richard Peter Bailey and Mabel Hwee Joo Tan and Genevieve Flores Dipolog and Garry Wei Han Tan and Saeid Motevalli and Nadia Samsudin and Chin Siang Ang},
keywords = {ChatGPT, Hermeneutic phenomenology, VUCA model, Educational quality, AI policy guidelines},
abstract = {This study explores how generative intelligence (GenAI) is used in teaching and learning, assessments, and research at Southeast Asian (SEA) universities. Using hermeneutic phenomenology as the philosophical underpinning and research methodology, SEA teachers’ ‘lived experiences’ of using ChatGPT and other GenAI tools were uncovered. 38 teachers from 10 SEA countries participated in 11 focus group interviews over five months. Three themes emerged: Learning Anew; Disequilibrium and Lack of Rootedness; and Ambiguity about New Norms, New Practices. It was found that teachers work with GenAI in deeply personal, fragmented, and continuously evolving ways. GenAI took the form of novel work companions, enhancing the efficiency and effectiveness of some work practices. It also was a disruptor to old habits of thinking, behaviour and practices. Teachers were in a state of disequilibrium in this new world beset by VUCA (volatility, uncertainty, complexity, and ambiguity). Some felt overwhelmed and ‘at breaking point’. A lack of rootedness in teachers’ beliefs and practices emerged. Teachers were generally against the notions of plagiarism and academic integrity held by students who believed the ends justified the means. However, with new ways of teaching, learning and assessment, many teachers recognised their beliefs and practices would have to change. Thus, in the absence of detailed AI guidelines, they called for the urgent need to establish boundaries and teach AI literacy to promote innovative and responsible use. In this VUCA world, more targeted change management training for teachers and students was strongly needed.}
}
@article{LI2025112349,
title = {Generative artificial intelligence-based framework for bridging lifecycle gaps in semiconductor HVAC systems},
journal = {Journal of Building Engineering},
volume = {105},
pages = {112349},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.112349},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225005868},
author = {Yanlin Li and Chi-Yun Liu and Hsiao-Ping Ni and Fermodelie Paul and Wai Oswald Chong and Jui-Sheng Chou},
keywords = {HVAC system performance, Semiconductor manufacturing facility, HVAC equipment degradation prediction, AI-Driven models, Advanced building systems},
abstract = {The production of modern semiconductor chips is susceptible to variations in air temperature, humidity, and quality, mainly as chip dimensions shrink to smaller than atmospheric dust particles. Heating, ventilation, and air-conditioning (HVAC) systems are critical in this context, given their role in stabilizing these environmental factors. Gaps in Design and Construction (D&C) can critically undermine the reliability, performance, quality, and lifespan of HVAC systems during their Operation and Maintenance (O&M) stages. Current studies illustrate how existing models predicted performance degradation and how the Design, Construction, Operations, and Maintenance (DCOM) gap arises. Despite the substantial implications for Semiconductor Manufacturing Facilities (SMFs), research on HVAC performance degradation remains limited, particularly in capturing and quantifying degradation-related patterns. Compared to other types of buildings, the renovation and transformation of high-end manufacturing facilities are more frequent, and customized design and equipment also lead to model application issues, such as data limitations and incompatibility. This paper aims to propose a novel HVAC system degradation prediction model utilizing Generative Adversarial Networks (GAN) and Informer algorithms based on the building characteristics and operation mode of semiconductor facilities to overcome the limitations of data scarcity and long-term prediction, evaluate the comprehensive impact of the gap between D&C and O&M stages on HVAC systems. By integrating data augmentation, this model reduces data dependency and can handle incomplete, inconsistent, or discrete data for early prediction in operation, bridging the gap between D&C and O&M stages, and improving the overall efficiency and effectiveness of facility operation and maintenance. In addition to SMFs, the proposed model exhibits considerable application potential in other high-precision building types due to the structural variability.}
}
@article{LIM2025105306,
title = {Development and implementation of a generative artificial intelligence-enhanced simulation to enhance problem-solving skills for pre-service teachers},
journal = {Computers & Education},
volume = {232},
pages = {105306},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105306},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000740},
author = {Jieun Lim and Unggi Lee and Junbo Koh and Yeil Jeong and Yunseo Lee and Gyuri Byun and Haewon Jung and Yoonsun Jang and Sanghyeok Lee and Jewoong Moon},
keywords = {Generative AI, Virtual simulation, Teacher education, Problem-based learning, Design-based research},
abstract = {Effective teachers should be equipped to solve complex problems across diverse instructional and learning contexts. However, many teacher training programs struggle to bridge the gap between theoretical knowledge to real-world applications. The current study tackles this challenge by developing a generative artificial intelligence (GenAI)-enhanced simulation to improve preservice teachers’ problem-solving abilities. Using design-based research (DBR), we created a virtual environment that integrates problem-based learning (PBL) with GenAI technology. The simulation was rigorously refined through expert review and usability testing before being implemented in a teacher training program. We evaluated its effectiveness by comparing three groups: (1) a text-based scenario, (2) a rule-based simulation, and (3) a GenAI-enhanced simulation. Pre- and post-test results showed significant improvements in problem-solving skills for both the rule-based and GenAI-enhanced simulation groups compared to the text-based scenario group. Notably, qualitative findings revealed that students reported heightened realism and immersion in the GenAI-enhanced simulation, attributing this to more dynamic interactions with AI agents that helped them better contextualize PBL and increased their motivation. Our study findings contribute design principles for developing GenAI-enhanced simulations in teacher education, offering promising insights into leveraging AI technology to create more engaging and effective training experiences.}
}
@article{LI2024118988,
title = {Inverse design of cellular structures with the geometry of triply periodic minimal surfaces using generative artificial intelligence algorithms},
journal = {Engineering Structures},
volume = {321},
pages = {118988},
year = {2024},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2024.118988},
url = {https://www.sciencedirect.com/science/article/pii/S0141029624015505},
author = {Zhou Li and Junhao Li and Jiahao Tian and Shiqi Xia and Kai Li and Maojun Li and Yao Lu and Mengyuan Ren and Zhengyi Jiang},
keywords = {Triply periodic minimal surface, Generative artificial intelligence algorithms, Additive manufacturing, Inverse design, Numerical simulation},
abstract = {Triply periodic minimal surfaces (TPMS) exhibit excellent mechanical and energy absorption properties due to their structural advantages. However, existing porous TPMS structural design methods are constrained to a forward process from structural parameters to mechanical properties. This study proposed an inverse design method that combines bidirectional generative adversarial networks (BiGAN) and mechanical performance targets, resulting in a combined TPMS structure of Primitive and IWP types with superior buffering and energy absorption capabilities. The results show that under a single load value target condition of the designed structure, the minimum deviation index (R2) between the load value corresponding to the displacement point and the target load value is only 0.987, and the maximum mean absolute percentage error (MAPE) is only 5.92 %. When considering the elastic modulus target, the approach successfully conducts two sets of combined structural designs meeting the requirements of both high and low elastic moduli. When targeting the specified load-displacement curve conditions, specifically when combining high elastic modulus with ascending plasticity, the designed structures exhibit an error of only 2.2 % compared to the target property. Moreover, the quasi-static uniaxial compression experiments conducted on additively manufactured designed structures confirm that the experimental curves match the target curves in terms of deformation trends and load value ranges. The success of this inverse design approach for cellular TPMS structures has the potential to expedite new structural material development processes.}
}
@article{WOBST2025115571,
title = {Avoiding algorithm errors in textual analysis: A guide to selecting software, and a research agenda toward generative artificial intelligence},
journal = {Journal of Business Research},
volume = {199},
pages = {115571},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2025.115571},
url = {https://www.sciencedirect.com/science/article/pii/S0148296325003947},
author = {Janice Wobst and Rainer Lueg},
keywords = {Generative AI, Large language models, Textual analysis, Software selection, Algorithm error, Validity, Reliability, Value-based management},
abstract = {The use of textual analysis is expanding in organizational research, yet software packages vary in their compatibility with complex constructs. This study helps researchers select suitable tools by focusing on phrase-based dictionary methods. We empirically evaluate four software packages—LIWC, DICTION, CAT Scanner, and a custom Python tool—using the complex construct of value-based management as a test case. The analysis shows that software from the same methodological family produces highly consistent results, while popular but mismatched tools yield significant errors such as miscounted phrases. Based on this, we develop a structured selection guideline that links construct features with software capabilities. The framework enhances construct validity, supports methodological transparency, and is applicable across disciplines. Finally, we position the approach as a bridge to AI-enabled textual analysis, including prompt-based workflows, reinforcing the continued need for theory-grounded construct design.}
}
@article{CARROLL2024102899,
title = {Integrating large language models and generative artificial intelligence tools into information literacy instruction},
journal = {The Journal of Academic Librarianship},
volume = {50},
number = {4},
pages = {102899},
year = {2024},
issn = {0099-1333},
doi = {https://doi.org/10.1016/j.acalib.2024.102899},
url = {https://www.sciencedirect.com/science/article/pii/S0099133324000600},
author = {Alexander J. Carroll and Joshua Borycz},
keywords = {Generative artificial intelligence, Large language models, Information literacy, STEM education, Information retrieval, Critical thinking},
abstract = {Generative artificial intelligence (AI) and large language models (LLMs) have induced a mixture of excitement and panic among educators. However, there is a lack of consensus over how much experience science and engineering students have with using these tools for research-related tasks. Likewise, it is not yet known how educators and information professionals can leverage these tools to teach students strategies for information retrieval and knowledge synthesis. This study assesses the extent of students' use of AI tools in research-related tasks and if information literacy instruction could impact their perception of these tools. Responses to Likert-scale questions indicate that many students did not have extensive experience using LLMs for research-related purposes prior to the information literacy sessions. However, after participating in a didactic lecture and discussion with an engineering librarian that explored how to use these tools effectively and responsibly, many students reported viewing these tools as potentially useful for future assignments. Student responses to open-response questions suggest that librarian-led information literacy training can assist students in developing more sophisticated understandings of the limitations and use cases for artificial intelligence in inquiry-based coursework.}
}
@article{RUIZ202542,
title = {71361968-2414 - Is Generative-Artificial Intelligence (AI) able to diagnose and classify facial trauma as an Oral Surgeon?},
journal = {International Journal of Oral and Maxillofacial Surgery},
volume = {54},
pages = {42},
year = {2025},
note = {ICOMS Singapore 2025},
issn = {0901-5027},
doi = {https://doi.org/10.1016/j.ijom.2025.04.126},
url = {https://www.sciencedirect.com/science/article/pii/S0901502725002401},
author = {O. Peña Ruiz and J. Sifuentes-Cervantes and J. Castellanos and F. Bermudez}
}
@article{ZHANG20252238,
title = {Research on the impact of generative artificial intelligence (GenAI) on enterprise innovation performance: a knowledge management perspective},
journal = {Journal of Knowledge Management},
volume = {29},
number = {7},
pages = {2238-2257},
year = {2025},
issn = {1367-3270},
doi = {https://doi.org/10.1108/JKM-10-2024-1198},
url = {https://www.sciencedirect.com/science/article/pii/S136732702500033X},
author = {Qichao Zhang and Jiaxiang Zuo and Songlin Yang},
keywords = {Generative artificial intelligence, Knowledge management, Enterprise innovation performance, Human–AI collaboration},
abstract = {Purpose
This study aims to investigate the impact of generative artificial intelligence (GenAI) on enterprise innovation performance, particularly from the perspective of knowledge management. It addresses key challenges in GenAI adoption – such as data biases, information overload and technological dependence – and proposes strategies to overcome these obstacles to enhance innovation.
Design/methodology/approach
Adopting a theoretical approach, this research analyzes the role of knowledge management in bridging the gap between GenAI and enterprise innovation. A structured framework based on four essential knowledge management processes – knowledge creation, retrieval and storage, transfer and sharing and application – is developed to tackle these challenges effectively.
Findings
The study reveals that while GenAI presents both opportunities and challenges for enterprise innovation, leveraging a structured knowledge management framework is key to unlocking its potential. It underscores the critical role of human–AI collaboration in mitigating issues such as data biases and integration challenges, ultimately improving innovation performance. The findings highlight the importance of complementing AI capabilities with human judgment to ensure successful outcomes in GenAI-driven innovation.
Research limitations/implications
This conceptual study calls for further empirical research to validate the findings and expand their generalizability. Future studies should explore contextual factors such as organizational characteristics, business environments and policy frameworks to refine the proposed framework.
Originality/value
This research offers novel insights into the intersection of GenAI, knowledge management and enterprise innovation. It stresses the importance of human involvement alongside GenAI, providing actionable recommendations for organizations navigating the complexities of AI adoption. In addition, it contributes to the evolving discourse on AI and innovation management, offering pathways for businesses to harness GenAI’s full potential and drive performance.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@article{ALHUSBAN202421,
title = {Exploring professional perspectives on integrating generative artificial intelligence into corporate learning and development: an organizational change perspective},
journal = {Development and Learning in Organizations: An International Journal},
volume = {39},
number = {2},
pages = {21-24},
year = {2024},
issn = {1477-7282},
doi = {https://doi.org/10.1108/DLO-05-2024-0131},
url = {https://www.sciencedirect.com/science/article/pii/S1477728224000522},
author = {Mohammad Issa Alhusban and Hashem Alshurafat and Ibrahim N. Khatatbeh},
keywords = {Learning and development, Expert interviews, Organizational change, ChatGPT, Generative artificial intelligence},
abstract = {Purpose
The primary aim of this study is to investigate the integration of generative artificial intelligence, specifically ChatGPT, into workplace L&D practices, exploring the associated advantages and challenges such integration from an organizational change perspective.
Design/methodology/approach
This study uses a qualitative approach, conducting semi-structured interviews with twelve learning and development (L&D) experts.
Findings
This study indicates that ChatGPT can positively impact L&D by streamlining processes and potentially enhancing employee performance, engagement and satisfaction. However, to mitigate employee resistance, organizations must clearly communicate the necessity and rationale behind the change, involve employees in the implementation process and address trust issues. Key challenges such as overreliance on ChatGPT, AI skill shortages and technology issues like privacy breaches and misinformation must be managed through strong governance frameworks, including policies, guidelines and regular audits.
Research limitations/implications
The study’s scope is confined to semi-structured interviews with L&D experts, potentially limiting its generalizability. Further research could explore the long-term effects and broader implications of ChatGPT integration in different organizational contexts.
Practical implications
By framing GenAI integration within the context of organizational change, this study offers insights into managing the transition effectively by providing guidance for managers on effectively integrating ChatGPT into L&D practices, emphasizing the importance of mitigating potential negative consequences while maximizing benefits.
Social implications
Integrating ChatGPT into organizational L&D has the potential to reshape how employees acquire new skills and knowledge, potentially influencing organizational culture and dynamics. However, careful consideration is required to ensure that the integration process aligns with ethical and social norms, minimizing adverse impacts.
Originality/value
This research contributes foundational insights into the integration of ChatGPT in corporate L&D by researching and understanding the opinions of corporate professionals. It serves as a starting point for organizations to identify challenges in adopting GenAI.}
}
@article{WISLOCKI2025,
title = {Comparing Generative Artificial Intelligence and Mental Health Professionals for Clinical Decision-Making With Trauma-Exposed Populations: Vignette-Based Experimental Study},
journal = {JMIR Mental Health},
volume = {12},
year = {2025},
issn = {2368-7959},
doi = {https://doi.org/10.2196/80801},
url = {https://www.sciencedirect.com/science/article/pii/S2368795925001040},
author = {Katherine E Wislocki and Sabahat Sami and Gahl Liberzon and Alyson K Zalta},
keywords = {generative artificial intelligence, trauma, mental health professionals, diagnosis, treatment},
abstract = {Background
Trauma exposure is highly prevalent and associated with various health issues. However, health care professionals can exhibit trauma-related diagnostic overshadowing bias, leading to misdiagnosis and inadequate treatment of trauma-exposed populations. Generative artificial intelligence (GAI) models are increasingly used in health care contexts. No research has examined whether GAI demonstrates this bias in decision-making and how rates of this bias may compare to mental health professionals (MHPs).
Objective
This study aimed to assess trauma-related diagnostic overshadowing among frontier GAI models and compare evidence of trauma-related diagnostic overshadowing between frontier GAI models and MHPs.
Methods
MHPs (N=232; mean [SD] age 43.7 [15.95] years) completed an experimental paradigm consisting of 2 vignettes describing adults presenting with obsessive-compulsive symptoms or substance abuse symptoms. One vignette included a trauma exposure history (ie, sexual trauma or physical trauma), and one vignette did not include a trauma exposure history. Participants answered questions about their preferences for diagnosis and treatment options for clients within the vignettes. GAI models (eg, Gemini 1.5 Flash, ChatGPT-4o mini, Claude Sonnet, and Meta Llama 3) completed the same experimental paradigm, with each block being reviewed by each GAI model 20 times. Mann-Whitney U tests and chi-square analyses were used to assess diagnostic and treatment decision-making across vignette factors and respondents.
Results
GAI models, similar to MHPs, demonstrated some evidence of trauma-related diagnostic overshadowing bias, particularly in Likert-based ratings of posttraumatic stress disorder diagnosis and treatment when sexual trauma was present (P<.001). However, GAI models generally exhibited significantly less bias than MHPs across both Likert and forced-choice clinical decision tasks. Compared to MHPs, GAI models assigned higher ratings for the target diagnosis and treatment in obsessive-compulsive disorder vignettes (rb=0.43‐0.63; P<.001) and for the target treatment in substance use disorder vignettes (rb=0.57; P<.001) when trauma was present. In forced-choice tasks, GAI models were significantly more accurate than MHPs in selecting the correct diagnosis and treatment for obsessive-compulsive disorder vignettes (χ²1=48.84‐61.07; P<.001) and for substance use disorder vignettes involving sexual trauma (χ²1=15.17‐101.61; P<.001).
Conclusions
GAI models demonstrate some evidence of trauma-related diagnostic overshadowing bias, yet the degree of bias varied by task and model. Moreover, GAI models generally demonstrated less bias than MHPs in this experimental paradigm. These findings highlight the importance of understanding GAI biases in mental health care. More research into bias reduction strategies and responsible implementation of GAI models in mental health care is needed.}
}
@article{BLEASE2025,
title = {Generative Artificial Intelligence in Primary Care: Qualitative Study of UK General Practitioners’ Views},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/74428},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125010520},
author = {Charlotte Blease and Carolina {Garcia Sanchez} and Cosima Locher and Brian McMillan and Jens Gaab and John Torous},
keywords = {generative AI, general practice, primary care, large language models, education, training, online survey questionnaire, qualitative research., artificial intelligence},
abstract = {Background
The potential for generative artificial intelligence (GenAI) to assist with clinical tasks is the subject of ongoing debate within biomedical informatics and related fields.
Objective
This study aimed to explore general practitioners’ (GPs’) opinions about GenAI on primary care.
Methods
In January 2025, we conducted a web-based survey of 1005 UK GPs’ experiences and opinions of GenAI in clinical practice. This study involved a qualitative inductive descriptive analysis of a written response (“comments”) to an open-ended question in the survey. After analysis, the interpretation of themes was also informed by the technology acceptance model.
Results
Out of 1005 respondents, 611 GPs (61%) provided written comments in response to the free text question, totaling 7990 words. Comments were classified into 3 major themes and 8 subthemes in relation to GenAI in clinical practice. The major themes were (1) unfamiliarity, (2) ambivalence and anxiety, and (3) role in clinical tasks. “Unfamiliarity” encompassed a lack of experience and knowledge, and the need for training on GenAI. “Ambivalence and anxiety” included mixed expectations among GPs in relation to these tools, beliefs about diminished human connection, and skepticism about AI accountability. Finally, commenting on the role of GenAI in clinical tasks, GPs believed it would help with documentation. However, respondents questioned AI’s clinical judgment and raised concerns about operational uncertainty concerning these tools. Female GPs were more likely to leave comments than male GPs, with 53% (324/611) of female GPs providing feedback compared to 41.1% (162/394) who did not. Chi-square tests confirmed this difference ((χ²₂= 14.6, P=.001). In addition, doctors who left comments were significantly more likely to have used GenAI in clinical practice compared with those who did not. Among all respondents, 71.7% (438/611) had not used GenAI. However, noncommenters were even less likely to have used it, with 80.7% (318/394) reporting no use. A chi-square test confirmed this difference (χ²₁=10.0, P=.002).
Conclusions
This study provides timely insights into UK GPs’ perspectives on the role, impact, and limitations of GenAI in primary care. However, the study has limitations. The qualitative data analyzed originates from a self-selected subset of respondents who chose to provide free-text comments, and these participants were more likely to have used GenAI tools in clinical practice. However, the substantial number of comments offers valuable insights into the diverse views held by GPs regarding GenAI. Furthermore, the majority of our respondents reported limited experience and training with these tools; however, many GPs perceived potential benefits of GenAI and ambient AI for documentation. Notably, 2 years after the widespread introduction of GenAI, GPs’ persistent lack of understanding and training remains a critical concern. More extensive qualitative work would provide a more in-depth understanding of GPs’ views.}
}
@article{LI2024112,
title = {On the Application of Generative Artificial Intelligence ChatGPT in Digital Trade},
journal = {Procedia Computer Science},
volume = {247},
pages = {112-120},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S187705092402814X},
author = {Rui Li and Qiaoling Zhong},
keywords = {Generative Artificial Intelligence ChatGPT, Natural Language Processing, Customer Service, Dialogue Interaction},
abstract = {The combination of human subjective judgment and machine data processing capabilities in human-machine collaborative evaluation can create a more efficient, accurate, and personalized customer service dialogue interaction system, thereby promoting digital trade efficiency and improving service quality. Generative artificial intelligence has the ability of intelligent interaction and contextual semantic understanding, which is an important means of implementing the concept of human-machine collaboration. This article introduces the basic principles and technical characteristics of ChatGPT, and explores in detail its various application scenarios in digital trade, including automated customer service, personalized recommendations, intelligent marketing, and data analysis. Finally, this article also discusses the challenges and future development directions of ChatGPT in digital trade, in order to provide certain reference value for research and practice in related fields. The data from the questionnaire survey shows that men, aged between 18-30 and 41-50 years old, with high education level, high monthly online shopping expenses, high monthly income, and frequent use of well-known e-commerce platforms, generally have a high level of understanding of ChatGPT.}
}