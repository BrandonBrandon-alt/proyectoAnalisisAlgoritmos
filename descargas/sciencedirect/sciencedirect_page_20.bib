@article{KARWAKI2025,
title = {Balancing Artificial Intelligence Risks and Benefits in an Evolving Legal Environment},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025004387},
author = {Tanya E. Karwaki}
}
@article{ONNIS2024473,
title = {The Role of Artificial Intelligence in Cardiac Imaging},
journal = {Radiologic Clinics of North America},
volume = {62},
number = {3},
pages = {473-488},
year = {2024},
note = {Advances and Innovations in Cardiovascular Imaging},
issn = {0033-8389},
doi = {https://doi.org/10.1016/j.rcl.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0033838924000022},
author = {Carlotta Onnis and Marly {van Assen} and Emanuele Muscogiuri and Giuseppe Muscogiuri and Gabrielle Gershon and Luca Saba and Carlo N. {De Cecco}},
keywords = {Artificial intelligence, Cardiac imaging, Machine learning, Deep learning, Cardiac computed tomography, Cardiac magnetic resonance, Clinical workflow}
}
@article{MILLER20251319,
title = {Leveraging Medical Licensure for Safer Artificial Intelligence Use in Health Care},
journal = {The American Journal of Medicine},
volume = {138},
number = {10},
pages = {1319-1321},
year = {2025},
issn = {0002-9343},
doi = {https://doi.org/10.1016/j.amjmed.2025.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0002934325003018},
author = {D. Douglas Miller and M. Vinayak Kamath and John Albers and David C. Hess}
}
@article{LIU2024100043,
title = {Artificial intelligence-driven health research innovations: Protein sciences},
journal = {Medicine Plus},
volume = {1},
number = {3},
pages = {100043},
year = {2024},
issn = {2950-3477},
doi = {https://doi.org/10.1016/j.medp.2024.100043},
url = {https://www.sciencedirect.com/science/article/pii/S2950347724000392},
author = {Furui Liu and Guiquan Zhang and Zhi Liu and Chao Li and Xingxu Huang}
}
@article{PALERMI2025106329,
title = {Artificial intelligence and the electrocardiogram: A modern renaissance},
journal = {European Journal of Internal Medicine},
volume = {140},
pages = {106329},
year = {2025},
issn = {0953-6205},
doi = {https://doi.org/10.1016/j.ejim.2025.04.036},
url = {https://www.sciencedirect.com/science/article/pii/S0953620525001785},
author = {Stefano Palermi and Marco Vecchiato and Fu Siong Ng and Zachi Attia and Youngjin Cho and Matteo Anselmino and Gaetano Maria {De Ferrari} and Andrea Saglietto and Arunashis Sau and I-Min Chiu and Juan M. Farina and Reza Arsanjani and Giuseppe Biondi Zoccai and Leonarda Galiuto and Luca Nissardi and Veronica Dusi},
keywords = {Artificial intelligence, ECG, Cardiology, Machine learning, Deep learning, Cardiovascular disease},
abstract = {Integrating Artificial Intelligence (AI) with electrocardiograms (ECG) represents a transformative shift in cardiovascular medicine, marking a modern renaissance of this traditional diagnostic technique. This article explores recent advancements in AI-enhanced ECG technologies, highlighting their potential to improve diagnostic accuracy, predict cardiovascular events, and enable personalized patient care. AI-driven ECG interpretation has demonstrated groundbreaking capabilities in the field of both structural and electrical heart diseases. Furthermore, deep learning techniques have expanded diagnostic capabilities by identifying subtle ECG patterns invisible to the human eye, improving the detection of several cardiac disorders. The increasing integration of AI-ECG into wearable technologies extends cardiac monitoring beyond conventional clinical settings, providing continuous, real-time health assessment. Despite these advancements, the widespread adoption of AI-ECG faces several challenges, such as the need for high-quality training data, ensuring algorithm generalizability across diverse populations, addressing bias in model training, and meeting critical regulatory and ethical standards. Moreover, concerns regarding explainability, physician deskilling, legal accountability, and the lack of high-quality studies proving improved patient outcomes remain key obstacles. By enhancing precision in detecting cardiovascular conditions and expanding access to proactive heart health monitoring, AI-enhanced ECG technology holds immense potential for reshaping cardiovascular diagnostics and management, always aiming at maintaining physician trust and patient safety.}
}
@article{INOUYE2024109954,
title = {Artificial intelligence in therapeutic management of hyperlipidemic ocular pathology},
journal = {Experimental Eye Research},
volume = {245},
pages = {109954},
year = {2024},
issn = {0014-4835},
doi = {https://doi.org/10.1016/j.exer.2024.109954},
url = {https://www.sciencedirect.com/science/article/pii/S0014483524001751},
author = {Keiko Inouye and Aelita Petrosyan and Liana Moskalensky and Finosh G. Thankam},
keywords = {Artificial intelligence, Hyperlipidemia, Retinal vascular occlusion, Eye diseases},
abstract = {Hyperlipidemia has many ocular manifestations, the most prevalent being retinal vascular occlusion. Hyperlipidemic lesions and occlusions to the vessels supplying the retina result in permanent blindness, necessitating prompt detection and treatment. Retinal vascular occlusion is diagnosed using different imaging modalities, including optical coherence tomography angiography. These diagnostic techniques obtain images representing the blood flow through the retinal vessels, providing an opportunity for AI to utilize image recognition to detect blockages and abnormalities before patients present with symptoms. AI is already being used as a non-invasive method to detect retinal vascular occlusions and other vascular pathology, as well as predict treatment outcomes. As providers see an increase in patients presenting with new retinal vascular occlusions, the use of AI to detect and treat these conditions has the potential to improve patient outcomes and reduce the financial burden on the healthcare system. This article comprehends the implications of AI in the current management strategies of retinal vascular occlusion (RVO) in hyperlipidemia and the recent developments of AI technology in the management of ocular diseases.}
}
@article{CHEN2025107734,
title = {Artificial intelligence in central-peripheral interaction organ crosstalk: the future of drug discovery and clinical trials},
journal = {Pharmacological Research},
volume = {215},
pages = {107734},
year = {2025},
issn = {1043-6618},
doi = {https://doi.org/10.1016/j.phrs.2025.107734},
url = {https://www.sciencedirect.com/science/article/pii/S1043661825001598},
author = {Yufeng Chen and Mingrui Yang and Qian Hua},
keywords = {Artificial intelligence, Central-peripheral interaction, Drug discovery, Organ crosstalk, Multimodal},
abstract = {Drug discovery before the 20th century often focused on single genes, molecules, cells, or organs, failing to capture the complexity of biological systems. The emergence of protein-protein interaction network studies in 2001 marked a turning point and promoted a holistic approach that considers the human body as an interconnected system. This is particularly evident in the study of bidirectional interactions between the central nervous system (CNS) and peripheral organs, which are critical for understanding health and disease. Understanding these complex interactions requires integrating multi-scale, heterogeneous data from molecular to organ levels, encompassing both omics (e.g., genomics, proteomics, microbiomics) and non-omics data (e.g., imaging, clinical phenotypes). Artificial intelligence (AI), particularly multi-modal models, has demonstrated significant potential in analyzing CNS-peripheral organ interactions by processing vast, heterogeneous datasets. Specifically, AI facilitates the identification of biomarkers, prediction of therapeutic targets, and simulation of drug effects on multi-organ systems, thereby paving the way for novel therapeutic strategies. This review highlights AI's transformative role in CNS-peripheral interaction research, focusing on its applications in unraveling disease mechanisms, discovering drug targets, and optimizing clinical trials through patient stratification and adaptive trial design.}
}
@article{PASCUALTRIANA2025121844,
title = {Overlap Number of Balls Model-Agnostic CounterFactuals (ONB-MACF): A data-morphology-based counterfactual generation method for trustworthy artificial intelligence},
journal = {Information Sciences},
volume = {701},
pages = {121844},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121844},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524017584},
author = {José Daniel Pascual-Triana and Alberto Fernández and Javier {Del Ser} and Francisco Herrera},
keywords = {Explainable artificial intelligence, Model-agnostic explanations, Counterfactual analysis, Data morphology, Trustworthy artificial intelligence},
abstract = {Explainable Artificial Intelligence (XAI) is a pivotal research domain aimed at clarifying AI systems, particularly those considered “black boxes” due to their complex, opaque nature. XAI seeks to make these AI systems more understandable and trustworthy, providing insight into their decision-making processes. By producing clear and comprehensible explanations, XAI enables users, practitioners, and stakeholders to trust a model's decisions. This work analyses the value of data morphology strategies in generating counterfactual explanations. It introduces the Overlap Number of Balls Model-Agnostic CounterFactuals (ONB-MACF) method, a model-agnostic counterfactual generator that leverages data morphology to estimate a model's decision boundaries. The ONB-MACF method constructs hyperspheres in the data space whose covered points share a class, mapping the decision boundary. Counterfactuals are then generated by incrementally adjusting an instance's attributes towards the nearest alternate-class hypersphere, crossing the decision boundary with minimal modifications. By design, the ONB-MACF method generates feasible and sparse counterfactuals that follow the data distribution. Our comprehensive benchmark from a double perspective (quantitative and qualitative) shows that the ONB-MACF method outperforms existing state-of-the-art counterfactual generation methods across multiple quality metrics on diverse tabular datasets. This supports our hypothesis, showcasing the potential of data-morphology-based explainability strategies for trustworthy AI.}
}
@article{NAGARAJU2025217461,
title = {Artificial intelligence in gastrointestinal cancers: Diagnostic, prognostic, and surgical strategies},
journal = {Cancer Letters},
volume = {612},
pages = {217461},
year = {2025},
issn = {0304-3835},
doi = {https://doi.org/10.1016/j.canlet.2025.217461},
url = {https://www.sciencedirect.com/science/article/pii/S0304383525000254},
author = {Ganji Purnachandra Nagaraju and Tatekalva Sandhya and Mundla Srilatha and Swapna Priya Ganji and Madhu Sudhana Saddala and Bassel F. El-Rayes},
keywords = {Gastrointestinal cancer, Artificial intelligence, Diagnosis, Biomarkers, Therapy},
abstract = {GI (Gastrointestinal) malignancies are one of the most common and lethal cancers globally. The dawn of precision medicine and developing technologies have reduced the mortality rates for GI malignancies, underscoring the main role of early detection methods for survival rate improvement. Artificial intelligence (AI) is a new technology that may improve GI cancer screening, treatment, and therapeutic efficiency for better patient care. AI could accelerate the development of targeted therapies by analyzing considerable data from the genome and identifying biomarkers connected with GI tumors. This opens up new avenues toward more tailored and personalized approaches, raising efficacy while reducing undesired side effects. For instance, AI may improve treatment outcomes by accurately predicting patient responses to therapeutic regimens, helping oncologists choose the most effective treatment options. This review will outline the transformative potential of AI in GI oncology by emphasizing the incorporation of AI-based technologies to enhance patient care.}
}
@article{PAPAGIANNIDIS2025101885,
title = {Responsible artificial intelligence governance: A review and research framework},
journal = {The Journal of Strategic Information Systems},
volume = {34},
number = {2},
pages = {101885},
year = {2025},
issn = {0963-8687},
doi = {https://doi.org/10.1016/j.jsis.2024.101885},
url = {https://www.sciencedirect.com/science/article/pii/S0963868724000672},
author = {Emmanouil Papagiannidis and Patrick Mikalef and Kieran Conboy},
keywords = {Artificial intelligence, Responsible AI governance, Governance practices, AI implementation, AI lifecycle},
abstract = {The widespread and rapid diffusion of artificial intelligence (AI) into all types of organizational activities necessitates the ethical and responsible deployment of these technologies. Various national and international policies, regulations, and guidelines aim to address this issue, and several organizations have developed frameworks detailing the principles of responsible AI. Nevertheless, the understanding of how such principles can be operationalized in designing, executing, monitoring, and evaluating AI applications is limited. The literature is disparate and lacks cohesion, clarity, and, in some cases, depth. Subsequently, this scoping review aims to synthesize and critically reflect on the research on responsible AI. Based on this synthesis, we developed a conceptual framework for responsible AI governance (defined through structural, relational, and procedural practices), its antecedents, and its effects. The framework serves as the foundation for developing an agenda for future research and critically reflects on the notion of responsible AI governance.}
}
@article{LAVIA2024101512,
title = {Exploring the potential of artificial intelligence in airway management},
journal = {Trends in Anaesthesia and Critical Care},
volume = {59},
pages = {101512},
year = {2024},
issn = {2210-8440},
doi = {https://doi.org/10.1016/j.tacc.2024.101512},
url = {https://www.sciencedirect.com/science/article/pii/S2210844024001813},
author = {Luigi {La Via} and Antonino Maniaci and David Gage and Giuseppe Cuttone and Giovanni Misseri and Mario Lentini and Daniele Salvatore Paternò and Federico Pappalardo and Massimiliano Sorbello},
keywords = {Artificial intelligence, Airway management, Chat GPT, Clinical decision support, Medical education, Patient safety, Healthcare technology},
abstract = {This review examines the integration of Artificial Intelligence (AI) language models, particularly Chat GPT, in airway management. It explores AI's potential applications in education, clinical decision support, patient communication, and research, as well as its integration with existing medical technologies. The review highlights AI's benefits, including rapid access to current information, care standardization, and potential improvements in patient outcomes. However, it also addresses limitations and ethical considerations such as data security, algorithm bias, and the risk of over-reliance on AI systems. Looking forward, the review discusses AI's potential to revolutionize airway management through predictive analytics, augmented reality, and personalized learning platforms, while acknowledging implementation challenges. The broader implications of AI in healthcare are explored, including its impact on learning, innovation, and the balance between error-free decision-making and human creativity. The review concludes that while AI shows great promise in enhancing airway management, its implementation requires careful consideration of ethical implications and ongoing research. The future of AI in this field lies in its judicious use alongside skilled clinical judgment, potentially leading to significant improvements in patient care and outcomes.}
}
@article{CUNNINGHAM2025722,
title = {The Future of Artificial Intelligence–Assisted Event Adjudication},
journal = {JACC: Heart Failure},
volume = {13},
number = {5},
pages = {722-724},
year = {2025},
issn = {2213-1779},
doi = {https://doi.org/10.1016/j.jchf.2025.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S2213177925002562},
author = {Jonathan W. Cunningham and Christopher M. O’Connor},
keywords = {adjudication, artificial intelligence, natural language processing}
}
@article{LOU2025e53,
title = {Use of Artificial Intelligence to Improve the Readability of Patient Education Materials in Vascular Surgery},
journal = {Journal of Vascular Surgery},
volume = {81},
number = {6},
pages = {e53-e54},
year = {2025},
issn = {0741-5214},
doi = {https://doi.org/10.1016/j.jvs.2025.03.119},
url = {https://www.sciencedirect.com/science/article/pii/S074152142500535X},
author = {Johanna Lou and Bruce L. Tjaden and Yazid Ghanem and Besher Tolaymat and Armaun D. Rouhi and Margaret Butchy and Philip M. Batista and Laurel H. Hastings and Katherine McMackin}
}
@article{JIRSA20245175,
title = {Improving Voice Pathology Classification Using Artificial Data Generation},
journal = {Procedia Computer Science},
volume = {246},
pages = {5175-5184},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.612},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924026644},
author = {Tomáš Jirsa and Laura Verde and Fiammetta Marulli and Stefano Marrone and Jan Vrba},
keywords = {Generative AI, WaveNet, Voice Pathology Detection, Dataset Augmentation, Digital Twin, Dysphonia},
abstract = {Human Digital Twin is an emerging technology that could revolutionize the current healthcare system by enabling the delivery of Personalized Health Services through the use of tools such as Artificial intelligence. However, the considerable complexity of the structure of the human body, brought about by continuous molecular and physiological changes, makes it extremely difficult to process medical data extracted by Artificial intelligence techniques. The latter requires a large amount of data for reliable performance, which is often difficult to obtain due to limited quality and availability. In this paper, we propose a methodology to generate Artificial medical data. In detail, we focus on generating Artificial voice signals. The analysis of voice recordings is fundamental to diagnose specific pneumo-articulatory apparatus diseases, such as dysphonia. The generative neural network employed is based on the WaveNet model, due to its autoregressive sampling, which enables generating recordings of variable length. We propose a setup which enables to generate Artificial samples of required sex and pathology to balance and augment the dataset using only one generative network. The quality of the generative network is assessed by balancing the training dataset by generated data and training a convolutional classifier, which is tested on a dataset which was not introduced to the generative network during training. We achieved reasonable improvements in classification accuracy, particularly for the under-represented sex in terms of accuracy, arguing that this approach is worthy of future research.}
}
@article{MORENOSANCHEZ2026103812,
title = {A design framework for operationalizing trustworthy artificial intelligence in healthcare: Requirements, tradeoffs and challenges for its clinical adoption},
journal = {Information Fusion},
volume = {127},
pages = {103812},
year = {2026},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103812},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525008747},
author = {Pedro A. Moreno-Sánchez and Javier {Del Ser} and Mark {van Gils} and Jussi Hernesniemi},
keywords = {Trustworthy AI, Design framework, Health stakeholders, Medical AI, Healthcare, Explainable AI, Human agency and oversight, AI safety, Privacy, AI fairness},
abstract = {Artificial Intelligence (AI) holds great promise for transforming healthcare, particularly in disease diagnosis, prognosis, and patient care. The increasing availability of digital medical data, such as images, omics data, biosignals, and electronic health records, combined with advances in computing, has enabled AI models to approach expert-level performance. However, widespread clinical adoption remains limited, primarily due to challenges beyond technical performance, including ethical concerns, regulatory barriers, and lack of trust. To address these issues, medical AI systems must align with the principles of Trustworthy AI (TAI), which emphasize human agency and oversight, algorithmic robustness, privacy and data governance, transparency, bias and discrimination avoidance, and accountability. Yet, the complexity of healthcare processes (e.g., screening, diagnosis, prognosis, and treatment) and the diversity of stakeholders (clinicians, patients, providers, regulators) complicate the integration of TAI principles. To bridge the gap between TAI theory and practical implementation, this paper proposes a design framework to support developers in embedding TAI principles into medical AI systems. Thus, for each stakeholder identified across various healthcare processes, we propose a disease-agnostic collection of requirements that medical AI systems should incorporate to adhere to the principles of TAI. Additionally, we examine the challenges and tradeoffs that may arise when applying these principles in practice. To illustrate the discussion, we focus on cardiovascular diseases, which is a field marked by both high prevalence and active AI innovation, and demonstrate how TAI principles have been applied and where key obstacles persist.}
}
@article{QIU2025102548,
title = {A framework for finding the optimal laminate design rules using generative and explainable machine learning models},
journal = {Composites Communications},
volume = {58},
pages = {102548},
year = {2025},
issn = {2452-2139},
doi = {https://doi.org/10.1016/j.coco.2025.102548},
url = {https://www.sciencedirect.com/science/article/pii/S2452213925003018},
author = {Cheng Qiu and Hongwei Song and Jinglei Yang},
keywords = {Laminate optimization, Data-driven method, Quasi-isotropic design, Homogeneous design},
abstract = {The vast design space of composite laminates poses significant challenges to the design process. Thus, establishing simple laminating rules to guide the design of layup sequences is of great importance. This paper presents a novel data-driven framework composed of two machine-learning models. The generative model is used to produce laminate designs that meet the specific design requirements, while their hidden quantitative relation is revealed by the explainable model. The effectiveness of this framework is verified through two classical composite design cases: isotropic and homogeneous laminates. The laminating rules proposed by the data-driven framework are proven to be reasonable and consistent with those in common laminate practices. This work demonstrates the great potential of artificial intelligence not only in guiding laminate design but also in providing new perspectives on discovering composite theory.}
}
@article{KRAKOWSKI2025100560,
title = {Human-AI agency in the age of generative AI},
journal = {Information and Organization},
volume = {35},
number = {1},
pages = {100560},
year = {2025},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2025.100560},
url = {https://www.sciencedirect.com/science/article/pii/S1471772725000065},
author = {Sebastian Krakowski},
keywords = {Generative artificial intelligence, Automation, Augmentation, Human-AI agency, Machine learning, Innovation management},
abstract = {The rapid emergence of generative artificial intelligence (GenAI) is profoundly transforming the nature of work and organizations, challenging prevalent views of AI as primarily enabling prediction and optimization. This paper argues that GenAI represents a qualitative shift that necessitates a fundamental reassessment of AI's role in management and organizations. By identifying and analyzing four critical dimensions (i) GenAI's broad applicability as a general-purpose technology; (ii) its ability to catalyze exploratory and combinatorial innovation; (iii) its capacity to enhance cognitive diversity and decision-making; and (iv) its democratizing effect on AI adoption and value creation the paper highlights GenAI's potential to augment and scale human creativity, learning, and innovation. Building on insights from the AI and management literature, as well as on theory of human-AI agency, the paper develops a novel perspective that challenges the dominant efficiency-oriented narrative. It proposes that a human-complementary approach to GenAI development and implementation, leveraging it as a generative catalyst for exploration, can enable radically increased creativity, innovation, and growth. GenAI's democratizing aspects can amplify these mechanisms, promoting widely shared growth when combined with appropriate policy and managerial choices. Implications for theory, practice, and future research directions are discussed, drawing attention to the need for approaches in GenAI development and deployment that are complementary rather than competitive to human beings. The paper concludes by discussing the theoretical, practical, and policy implications of this transformative technology. It outlines future research directions, emphasizing the critical role of human agency in determining the organizational, societal, and ethical outcomes associated with AI adoption and implementation.}
}
@article{WILLIAMS2023281,
title = {How will artificial intelligence transform cardiovascular computed tomography? A conversation with an AI model},
journal = {Journal of Cardiovascular Computed Tomography},
volume = {17},
number = {4},
pages = {281-283},
year = {2023},
issn = {1934-5925},
doi = {https://doi.org/10.1016/j.jcct.2023.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S1934592523000965},
author = {Michelle C. Williams and James Shambrook},
abstract = {Artificial intelligence (AI) has the potential to transform healthcare, but its clinical use also has important challenges and limitations. Recently natural language processing and generative pre-training transformer (GPT) models have gained particular interest due to their ability to simulate human conversation. We aimed to explore output of the ChatGPT model (OpenAI, https://openai.com/blog/chatgpt) regarding current debates in cardiovascular CT. Prompts included debate questions from the Society of Cardiovascular Computed Tomography 2023 programme as well as questions about high risk plaque (HRP), quantitative plaque analysis, and how AI will transform cardiovascular CT. The AI model rapidly provided plausible responses including both pro and con sides of the argument. Advantages of AI for cardiovascular CT that were described by the AI model included improving image quality, speed of reporting, accuracy, and consistency. The AI model also acknowledged the importance for continued involvement of clinicians in patient care.}
}
@article{QU2025107310,
title = {Artificial intelligence for computational granular media},
journal = {Computers and Geotechnics},
volume = {185},
pages = {107310},
year = {2025},
issn = {0266-352X},
doi = {https://doi.org/10.1016/j.compgeo.2025.107310},
url = {https://www.sciencedirect.com/science/article/pii/S0266352X25002599},
author = {Tongming Qu and Jidong Zhao and Y.T. Feng},
keywords = {Granular materials, Machine learning, Discrete element method, Computational mechanics, Knowledge discovery, Inverse problems},
abstract = {Artificial intelligence (AI) has played a transformative role in accelerating scientific discovery and driving engineering innovations. Here we examine the primary applications of AI in computational granular materials over the past decades, focusing on three key objectives: (i) what machine learning (ML) can do in computational granular mechanics, (ii) how ML is integrated into routine computational simulations of granular media, and (iii) the opportunities and challenges that ML presents in this domain. The review highlights the key objectives of computational granular mechanics and the role of ML in bridging these critical research gaps. It systematically covers three aspects: (i) ML-accelerated computational modelling, (ii) ML-enabled pattern recognition and knowledge discovery, and (iii) ML-assisted inverse analysis in granular mechanics. Pertinent challenges are thoroughly discussed from the perspective of data and models. To promote the development of data-driven computational granular mechanics, we launched “Clear Data Bay”, a metadata website tailored for domain data sharing and management. Despite ongoing challenges, data-driven approaches offer great potential in enabling computational granular mechanics models to tackle previously unattainable challenges.}
}
@article{CLARKE2025106131,
title = {Principles for the responsible application of Generative AI},
journal = {Computer Law & Security Review},
volume = {57},
pages = {106131},
year = {2025},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2025.106131},
url = {https://www.sciencedirect.com/science/article/pii/S2212473X25000045},
author = {Roger Clarke},
keywords = {Risk assessment, Large language models, GenAI artefact, ChatGPT, Regulation},
abstract = {The quest for Artificial Intelligence (AI) has comprised successive waves of excessive enthusiasm followed by long, dispirited lulls. Most recently, during the first 3–4 years of public access to Generative Artificial Intelligence (GenAI), many authors have bought into the bullish atmosphere, replaying consultancies' predictions about gold mines of process efficiency and innovation. A more balanced approach to the technology is needed. Instances of apparently positive results need calm analysis, firstly to distinguish mirages from genuine contributions; secondly, to identify ways to effectively exploit the new capabilities; and thirdly, to formulate guidance for the avoidance and mitigation of negative consequences. This article's first contribution is to ground the evaluation of GenAI's pathway, applications, impacts, implications and risks in a sufficiently deep appreciation of the technology's nature and key features. A wide range of sources is drawn on, in order to present descriptions of the processes involved in text-based GenAI. From those processes, 20 key characteristics are abstracted that together give rise to the promise and the threats GenAI embodies. The effects of GenAI derive not from the technological features alone, but also from the patterns within which it is put to use. By mapping usage patterns across to domains of application, the phenomenon's impacts and implications can be more reliably delineated. The analysis provides a platform whereby the article's final contribution can be made. Previously-formulated principles for the responsible application of AI of all kinds are applied in the particular context of GenAI.}
}
@article{FENG2025200232,
title = {Research on the construction and application of intelligent tutoring system for english teaching based on generative pre-training model},
journal = {Systems and Soft Computing},
volume = {7},
pages = {200232},
year = {2025},
issn = {2772-9419},
doi = {https://doi.org/10.1016/j.sasc.2025.200232},
url = {https://www.sciencedirect.com/science/article/pii/S277294192500050X},
author = {Weiguo Feng and Xinhan Lai and Xin Zhang and Xiaojing Fan and Yinxia Du},
keywords = {English teaching, Generative pre-training model, Teaching method, Intelligence},
abstract = {In the era of globalization and information technology, English is becoming more and more important as the main language of international communication, but the traditional English teaching model is difficult to meet the diverse needs of learners due to the uneven distribution of resources and the lack of personalized tutoring. In order to meet these challenges, this study uses a generative pre-training model to build an intelligent tutoring system for English teaching, aiming to innovate the English learning experience with the help of artificial intelligence technology and achieve personalized and efficient teaching guidance. The construction solution includes collecting data such as learners' English proficiency test scores, learning history, and self-reported learning preferences to create detailed learner profiles, integrating advanced generative pre-trained models such as GPT-based and fine-tuning with data related to English language teaching, and then automatically generating exercises based on learner profiles and dynamically adjusting the difficulty. The application of the system is reflected in the integration of natural language processing technology and generative models to provide immediate feedback after learners complete the exercises, such as analyzing the grammar, vocabulary use and coherence of English passages and pointing out mistakes, giving suggestions and explanations for corrections, as well as providing intelligent tutoring in the form of dialogues, such as examples, comparisons and related exercises to enhance understanding in response to learners' questions about grammar points. The experimental results show that compared with the traditional teaching mode, the use of this intelligent tutoring system increases the learners' progress in English listening, speaking, reading and writing by an average of 30 %, and the learning satisfaction increases by 40 %, especially in the improvement of oral expression and writing skills.}
}
@article{CAMPBELL2025100138,
title = {Artificial intelligence and human decision making: Exploring similarities in cognitive bias},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {4},
pages = {100138},
year = {2025},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2025.100138},
url = {https://www.sciencedirect.com/science/article/pii/S2949882125000222},
author = {Hanna Campbell and Samantha Goldman and Patrick M. Markey},
keywords = {Cognitive bias, Large language models, Artificial intelligence},
abstract = {This research explores the extent to which Artificial Personas (APs) generated by Large Language Models (LLMs), like ChatGPT, can exhibit cognitive biases similar to those observed in humans. Four studies focusing on well-documented psychological biases were conducted: the Halo Effect, In-Group Out-Group Bias, the False Consensus Effect, and the Anchoring Effect. Each study was designed to test whether APs respond to specific scenarios consistent with typical human responses documented in psychological literature. The findings reveal that APs can replicate these biases, suggesting that APs can model some aspects of human cognitive processing. However, the effect sizes observed were unusually large, suggesting that APs replicate and exaggerate these biases, behaving more like caricatures of human cognitive behavior. This exaggeration highlights the potential of APs to magnify underlying cognitive processes but also necessitates caution in applying these findings directly to human behavior.}
}
@incollection{SHIN2026173,
title = {Chapter 7 - Artificial general intelligence and misinformation: balancing innovation and ethical challenges},
editor = {Don Donghee Shin},
booktitle = {Minds, Machines, and Misinformation},
publisher = {Elsevier},
pages = {173-199},
year = {2026},
isbn = {978-0-443-16104-9},
doi = {https://doi.org/10.1016/B978-0-443-16104-9.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161049000087},
author = {Don Donghee Shin},
keywords = {Artificial general intelligence, artificial misinformation, human-level capability},
abstract = {Artificial general intelligence (AGI) is poised to revolutionize multiple aspects of human life, offering unprecedented capabilities for problem-solving, decision-making, and autonomous learning. However, its influence on misinformation remains a critical issue. On the one hand, AGI offers advanced capabilities for combating misinformation, including real-time detection, cognitive inoculation, and automated fact-checking. On the other hand, AGI poses significant risks, such as generating highly sophisticated disinformation, enabling hyperpersonalized propaganda, and exacerbating existing information crises. This paper critically examines AGI’s dual role in the misinformation ecosystem, highlighting its potential as both a powerful tool for mitigation and a source of new threats. Ethical, technical, and governance implications are explored, with actionable recommendations for proactive policy and regulatory frameworks to ensure responsible deployment.}
}
@article{KEASLER2025104353,
title = {Effectiveness of artificial intelligence (AI) chatbots in providing labor epidural analgesia information: are we there yet?},
journal = {International Journal of Obstetric Anesthesia},
volume = {62},
pages = {104353},
year = {2025},
issn = {0959-289X},
doi = {https://doi.org/10.1016/j.ijoa.2025.104353},
url = {https://www.sciencedirect.com/science/article/pii/S0959289X25000251},
author = {Paige M Keasler and Joel Chee Yee Chan and Ban Leong Sng}
}
@incollection{GHODE2026359,
title = {15 - Theranostics and artificial intelligence as tools to detect various cancers},
editor = {Kuttiappan Anitha and Shvetank Bhatt and Santenna Chenchula},
booktitle = {Theranostics in Cancer Management},
publisher = {Academic Press},
pages = {359-378},
year = {2026},
isbn = {978-0-443-34199-1},
doi = {https://doi.org/10.1016/B978-0-443-34199-1.00015-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443341991000156},
author = {Piyush Ghode and Mayank Sharma and Rahul Maheshwari and Sanmati Kumar Jain},
keywords = {Artificial intelligence, cancer, theranostics, bimolecular, diagnostic agents},
abstract = {Cancer is the cause of maximum fatalities by a disease worldwide, prompting the healthcare professionals and scientists to strive toward innovative diagnostic and treatment strategies. Theranostics provides the dual advantage of diagnostic agents and therapeutics and is an active area of research in cancer therapeutics. In the past two decades, artificial intelligence (AI) has revolutionized data analytics, and cancer therapeutics is no exception. The application of AI in theranostics has attracted much attention in the past decade and is showing its capabilities in assisting the healthcare professionals in interpretation of intricate data. The current chapter highlights the role of AI in detection of cancer on different scales ranging from biomolecular to macromolecular. Among these, strategies at the macromolecular scale such as imaging techniques, are able to provide the requisite data in a more timely and cost-effective manner. AI for image analysis has provided extremely valuable information liable to escape the manual investigation. Herein lies the greatest advantage of AI that can play a critical role in cancer diagnostics and care. Consequently, the applications of AI in different aspects of cancer diagnostic such as pathology, treatment, and prognosis is discussed. However, the use of AI comes with certain limitations, which have also been deliberated. In summary, despite its limitations, AI has exhibited its potential to transform cancer theranostics and is poised to revolutionize cancer therapeutics in not a very distant future.}
}
@article{MARTINEZMORENO2024100296,
title = {What motivates future teachers? The influence of Artificial Intelligence on student teachers' career choice},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100296},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100296},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000997},
author = {Judit Martínez-Moreno and Dominik Petko},
keywords = {AI, AIEd, Career choice, (D)FIT-Choice, Digital transformation, Student teachers, Motivations, Agency, Teacher education},
abstract = {Artificial Intelligence in Education (AIEd) is reshaping not only the educational landscape but also potentially influencing the motivations of aspiring teachers. This paper explores whether considerations related to AIEd play a role in student teachers' decision to become teachers. For this aim, the study introduces a new AI subscale within the (D)FIT-Choice scale's Social Utility Value (SUV) factor and validates its effectiveness with a sample of 183 student teachers. Descriptive statistics reveal high mean scores for traditional motivators like Intrinsic Value Teaching, while AI-related factors, although considered, exhibit lower influence. A noticeable disconnection exists between digital motivations and the aspiration to shape the future, suggesting a potential gap in student teachers' understanding of digitalization's future impact. An extreme group analysis reveals a subset of student teachers who significantly consider AI. This group also gives value to Job Security and Make a Social Contribution, suggesting an awareness of AI's societal and professional impacts. Based on these findings, it is recommended to put a focus on teacher education programs to ensure student teachers' understanding of the impact of AI on education and society.}
}
@article{KACHMAN202440,
title = {How artificial intelligence could transform emergency care},
journal = {The American Journal of Emergency Medicine},
volume = {81},
pages = {40-46},
year = {2024},
issn = {0735-6757},
doi = {https://doi.org/10.1016/j.ajem.2024.04.024},
url = {https://www.sciencedirect.com/science/article/pii/S0735675724001815},
author = {Marika M. Kachman and Irina Brennan and Jonathan J. Oskvarek and Tayab Waseem and Jesse M. Pines},
keywords = {Artificial intelligence, Emergency medicine, Transformation, Technology, Emergency department, Machine learning},
abstract = {Artificial intelligence (AI) in healthcare is the ability of a computer to perform tasks typically associated with clinical care (e.g. medical decision-making and documentation). AI will soon be integrated into an increasing number of healthcare applications, including elements of emergency department (ED) care. Here, we describe the basics of AI, various categories of its functions (including machine learning and natural language processing) and review emerging and potential future use-cases for emergency care. For example, AI-assisted symptom checkers could help direct patients to the appropriate setting, models could assist in assigning triage levels, and ambient AI systems could document clinical encounters. AI could also help provide focused summaries of charts, summarize encounters for hand-offs, and create discharge instructions with an appropriate language and reading level. Additional use cases include medical decision making for decision rules, real-time models that predict clinical deterioration or sepsis, and efficient extraction of unstructured data for coding, billing, research, and quality initiatives. We discuss the potential transformative benefits of AI, as well as the concerns regarding its use (e.g. privacy, data accuracy, and the potential for changing the doctor-patient relationship).}
}
@article{CURRIE2023108337,
title = {The emerging role of artificial intelligence and digital twins in pre-clinical molecular imaging},
journal = {Nuclear Medicine and Biology},
volume = {120-121},
pages = {108337},
year = {2023},
issn = {0969-8051},
doi = {https://doi.org/10.1016/j.nucmedbio.2023.108337},
url = {https://www.sciencedirect.com/science/article/pii/S0969805123000240},
author = {Geoffrey M. Currie},
keywords = {Molecular imaging, Deep learning, Artificial intelligence, Digital twin, Mouse twin},
abstract = {Introduction
Pre-clinical molecular imaging, particularly with mice, is an essential part of drug and radiopharmaceutical development. There remain ethical challenges to reduce, refine and replace animal imaging where possible.
Method
A number of approaches have been adopted to reduce the use of mice including using algorithmic approaches to animal modelling. Digital twins have been used to create a virtual model of mice, however, exploring the potential of deep learning approaches to digital twin development may enhance capabilities and application in research.
Results
Generative adversarial networks produce generated images that sufficiently resemble reality that they could be adapted to create digital twins. Specific genetic mouse models have greater homogeneity making them more receptive to modelling and suitable specifically for digital twin simulation.
Conclusion
There are numerous benefits of digital twins in pre-clinical imaging including improved outcomes, fewer animal studies, shorter development timelines and lower costs.}
}
@article{HOSEINI2025108197,
title = {Application of artificial intelligence in attention-deficit hyperactivity disorder deteaction and response to treatment: A systematic review},
journal = {Biomedical Signal Processing and Control},
volume = {110},
pages = {108197},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2025.108197},
url = {https://www.sciencedirect.com/science/article/pii/S1746809425007086},
author = {Reza Hoseini and Ahmad Shalbaf and Afshin Shoeibi and Ram Bilas Pachori},
keywords = {ADHD, Neuroimaging, Artificial intelligence, Response prediction to treatment},
abstract = {Attention-deficit hyperactivity disorder (ADHD) is a widespread neurodevelopmental condition that significantly impacts many children. This review systematically explores the application of artificial intelligence (AI), particularly conventional machine learning (ML) and deep learning (DL), in diagnosing ADHD and predicting treatment responses from clinical data (demographics, questionnaires, cognitive tests, and biological variables) and neuroimaging modalities including electroencephalogram (EEG), functional magnetic resonance imaging (fMRI), structural MRI (sMRI), magnetoencephalogram (MEG), diffusion tensor imaging (DTI), single photon emission computed tomography (SPECT), functional near-infrared spectroscopy (fNIRS), and positron emission tomography (PET). We searched papers published until October 2024 via Scopus, Web of Science (WOS), and PubMed and reviewed 147 studies on ADHD diagnosis and treatment response prediction. This study’s primary contribution is the broad integration of its studies on both diagnosis and response prediction of pharmacological and non-pharmacological treatments in ADHD using AI methods, relying on feature extraction/selection methods and biomarkers rather than focusing on just one part. Furthermore, it is the first review to specifically evaluate the application of AI in predicting response to ADHD treatment. To have a better view, we investigated the data in clinical/demographic categories, neuroimaging techniques, and using neuroimaging/clinical biomarkers for ADHD diagnosis and predicting response to treatment. Our findings emphasize the widespread application of AI in ADHD detection and show promising results with EEG signals (accuracy up to 99.95 %) and MRI modalities (accuracy up to 92.8 % with a combination of sMRI and fMRI) data while highlighting the limited application of AI in predicting treatment responses. Support vector machines (SVMs) and convolutional neural networks (CNNs) methods have been used more among AI methods. Also, extracting and selecting features from EEG signals is more prevalent than other neuroimaging techniques, and functional connectivity biomarkers in fMRI showed superior performance. Future research should aim to develop integrated AI models that can accurately diagnose and predict personalized treatment responses.}
}
@article{SATHE2024772,
title = {How I GPT It: Development of Custom Artificial Intelligence (AI) Chatbots for Surgical Education},
journal = {Journal of Surgical Education},
volume = {81},
number = {6},
pages = {772-775},
year = {2024},
issn = {1931-7204},
doi = {https://doi.org/10.1016/j.jsurg.2024.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S193172042400148X},
author = {Tejas S. Sathe and Joshua Roshal and Ariana Naaseh and Joseph C. L'Huillier and Sergio M. Navarro and Caitlin Silvestri},
keywords = {artificial intelligence, chatbot, surgical education, education technology, innovation},
abstract = {Artificial Intelligence (AI) chatbots provide a novel format for individuals to interact with large language models (LLMs). Recently released tools allow nontechnical users to develop chatbots using natural language. Surgical education is an exciting area in which chatbots developed in this manner may be rapidly deployed, though additional work will be required to ensure their accuracy and safety. In this paper, we outline our initial experience with AI chatbot creation in surgical education and offer considerations for future use of this technology.}
}
@article{MARLER2024101039,
title = {Artificial intelligence, algorithms, and compensation strategy: Challenges and opportunities},
journal = {Organizational Dynamics},
volume = {53},
number = {1},
pages = {101039},
year = {2024},
issn = {0090-2616},
doi = {https://doi.org/10.1016/j.orgdyn.2024.101039},
url = {https://www.sciencedirect.com/science/article/pii/S0090261624000123},
author = {Janet H. Marler},
keywords = {Artificial Intelligence, Compensation, Algorithmic management, Human Resource Management},
abstract = {Compensation strategy plays a crucial role in attracting, motivating, and retaining strategic human capital. Amping up the advantages of being strategic about compensation are advances in technology such as cloud computing and storage along with digitized big data that make the sheer amount of information available and analyzed electronically, a huge competitive opportunity. The good news is these advances have unleashed a tsunami of technology solutions that promise to solve all compensation challenges. In this paper, I synthesize and summarize the literature on artificial intelligence and compensation management and describe four key challenges that companies face in using AI to manage compensation strategically. The first challenge is when and how to use AI to automate and augment compensation tasks and decisions. The second challenge is how to use AI effectively to improve fairness and equity in compensation practices. The third challenge is explaining how AI recommended changes in compensation practices are derived. The fourth challenge is how to actually be strategic using AI solutions. In describing these four challenges, I identify issues, opportunities, gaps, and current limitations of existing AI applications in supporting the strategic management of compensation in organizations.}
}
@article{BANSAL2025101475,
title = {Automated floating debris monitoring using optical satellite imagery and artificial intelligence: Recent trends, challenges and opportunities},
journal = {Remote Sensing Applications: Society and Environment},
volume = {37},
pages = {101475},
year = {2025},
issn = {2352-9385},
doi = {https://doi.org/10.1016/j.rsase.2025.101475},
url = {https://www.sciencedirect.com/science/article/pii/S235293852500028X},
author = {Kamakhya Bansal and Ashish Kumar Tripathi},
keywords = {Optical satellite imagery, Machine learning, Deep learning, Image fusion, Floating debris},
abstract = {Unwanted and harmful floating debris creates aesthetic, economic, social, and ecological harm. The optical satellites provide frequent global coverage across multiple spectral bands. Utilizing this abundant multi-banded optical satellite data for floating debris monitoring, many artificial intelligence-based approaches were proposed. These approaches face various challenges due to the multidimensional nature of the earth observation data visualized on a reduced scale. This work identifies various stages of AI deployment for floating debris identification, classification, segmentation, density estimation, and/or temporal study. The challenges during each stage along with some potential solutions applied in this field or elsewhere have been identified. Since AI approaches are data-driven, the limitation of labeled data with real-time diversity of shape, color, texture, size, and composition of floating debris placed against different backgrounds is most acute. The work proposes the utilization of some recent AI-based systems, like continuous learning, transfer learning, attention-based transformers, explainable AI, etc., to resolve these identified challenges. The work calls for further research into the application of pre-trained models, semi-supervised learning, and multi-modal data fusion for overcoming the labeled data deficiency. Additionally, harmful debris density estimation and factors leading to a change in the estimated density need further research.}
}
@article{KUMAR2025100862,
title = {Game-changing intelligence: Unveiling the societal impact of artificial intelligence in game software},
journal = {Entertainment Computing},
volume = {52},
pages = {100862},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100862},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002301},
author = {Kailash Kumar and N. Veena and T. Aravind and Chandradeep Bhatt and Uma Kuppusamy and Parita Jain},
keywords = {Artificial intelligence (AI), Gaming, Game software, Fine-Tuned Ring Toss Game Optimization Adaptive Artificial Neural Network (FRTGO-AANN), Social impact},
abstract = {Efficient artificial intelligence (AI) in gaming software optimizes development, improves user experiences, and increases industrial production, all of which contribute positively to economic development and technical advancement. Possible drawbacks include employment displacement, ethical problems, algorithmic biases, and excessive reliance on AI; everyone has an impact on society’s dynamics and principles. In this study, we proposed a novel method called Fine-Tuned Ring Toss Game Optimization Adaptive Artificial Neural Network (FRTGO-AANN) to improve user experience in game software, examine social implications to promote ethical growth, explore AI transformational significance in games, and shape new game-play. In this research, we employ a dataset of 250 video game projects. The collected data are undergoing feature extraction by using a Principal Component Analysis (PCA) method. We used a few parameters for our suggested and current approaches to analyze the research’s findings. Our proposed FRTGO-AANN method achieves superior results like accuracy (96.7 %), precision (92.5 %), F1-score (95.3 %), recall (90.6 %).AI in gaming software represents a game changer, transforming user experience, narrative intricacy, along with the world of virtual reality. It has a profound social influence, altering entertainment and promoting innovation, along with difficult ethical considerations.}
}
@article{MOHAMADI2025100250,
title = {Implementation of artificial intelligence in detection, classification, and prognostication of osteosarcoma utilizing different assessment techniques: a systematic review},
journal = {Intelligence-Based Medicine},
volume = {12},
pages = {100250},
year = {2025},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2025.100250},
url = {https://www.sciencedirect.com/science/article/pii/S2666521225000547},
author = {Zhina Mohamadi and Paniz Partovifar and Helia Ahmadzadeh and Elmira Ali Ahmadi and Ali Ghanbari and Sina Feyzipour and Fatemeh Atefat and Nazanin Jahanpeyma and Fatemeh {Haghighi asl} and Armin Zarinkhat and Narges Sharbatdaran and Narges {Hosseinzadeh taher} and Mobina Sedighi and Fatemeh Aghajafari},
keywords = {Osteosarcoma, Artificial intelligence, Deep learning, Machine learning, Diagnosis, Classification, Prognosis},
abstract = {Introduction
Osteosarcoma (OS) is the most common primary bone cancer particularly in individuals aged 0–19, classified into different stages. Early diagnosis improves survival, Determination of prognosis and treatment based on it, and enables limb-sparing surgery. AI, in particular machine learning (ML) and deep learning (DL), helps analyze large datasets, identify biomarkers, predict prognosis, and personalize treatments by assessing the aforementioned features. AI has the potential to improve evaluation procedures, such as imaging and pathology approaches used in OS diagnosis, prognosis, and treatment. This study systematically examines AI's synergistic role with conventional evaluating techniques in OS treatment, improving prognostication, predicting therapy responses, and developing personalized treatment strategies.
Method
We performed an extensive search via several databases until April 23, 2024. Machine learning (ML), deep learning (DL) as the main branches of AI are often utilized in the medical sciences were searched for detection classification, and prognostication of osteosarcoma. RAYYAN.ai was used to screen the articles through the titles and abstracts. We conducted data extraction on the included articles and employed Cochrane and QUIPS tools to assess potential bias in the included non-prognosis and prognosis studies to evaluate their quality, respectively.
Results
There were 8129 articles obtained from the four databases following a thorough search. Of them 8050 ones were excluded and the remaining 78 articles published from 2013 to 2024 were reviewed. A large number of the articles indicated moderate and low risk of bias as a result of the risk of bias assessment. The majority of the articles that were reviewed (n = 48) concerned the clinical aspects of osteosarcoma; of these, 23 and 25 studies assessed diagnosis and prognoses, respectively. Furthermore, 20 articles examined image analysis specifically, 4 examined image segmentation methods, and 16 introduced classifiers to identify osteosarcoma from other diseases.
Conclusion
AI improves biomarker identification, diagnostics, and prognosis of osteosarcoma through medical imaging and data integration. Models like ResNet50 and CNN show high performance but face real-world limitations due to data heterogeneity and overfitting. This study explores AI's role in osteosarcoma diagnosis, emphasizing interdisciplinary collaboration, external validation, and real-world application challenges.}
}
@article{ISMAIL2025100294,
title = {Evolution of vascular surgery training: Simulation, artificial intelligence, and competency-based models},
journal = {JVS-Vascular Insights},
volume = {3},
pages = {100294},
year = {2025},
issn = {2949-9127},
doi = {https://doi.org/10.1016/j.jvsvi.2025.100294},
url = {https://www.sciencedirect.com/science/article/pii/S2949912725001114},
author = {Mariam Ismail and Maham Rahimi},
keywords = {Vascular surgery, Simulation-based training, Virtual reality, Artificial intelligence, Nontechnical skills, Surgical training},
abstract = {Objective
Vascular surgery demands the mastery of complex techniques like anastomosis, where training quality directly impacts patient outcomes. This review synthesizes the evolution of vascular surgery education, from traditional apprenticeships to technology-driven models, and evaluates their efficacy in improving surgical competency.
Methods
Peer-reviewed literature (2000-2024) on vascular surgery training was analyzed, emphasizing randomized trials, meta-analyses, and cohort studies. Technologies assessed include high-fidelity simulators, virtual reality (VR), artificial intelligence (AI), and proficiency-based curricula.
Results
Traditional apprenticeship models lacked standardization, risking patient safety. Simulation-based training has been shown to significantly reduce operative errors and improve performance in trials, and VR platforms enable risk-free rehearsal of rare scenarios. AI-driven analytics can provide real-time feedback, potentially shortening skill acquisition time. Structured assessments (eg, the Objective Structured Assessment of Technical Skill) and interdisciplinary team training further enhanced nontechnical skills. Challenges persist in cost and global access, but low-cost simulators and telementoring show promise.
Conclusions
Technology-enhanced training (VR, AI, and simulation) significantly improves technical and nontechnical skills in vascular surgery. Future efforts must prioritize equitable access and adaptive curricula to keep pace with innovation.
Clinical Relevance
This review provides a roadmap for integrating AI-driven simulation into global vascular surgery training curricula, addressing disparities in surgical education and equipping surgeons and educators with evidence-based strategies to adopt emerging technologies, ultimately optimizing patient outcomes.}
}
@article{LABOONE2024100294,
title = {Overview of the future impact of wearables and artificial intelligence in healthcare workflows and technology},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {2},
pages = {100294},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100294},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000831},
author = {Perry A. LaBoone and Oge Marques},
keywords = {Wearables, Artificial intelligence (AI), Healthcare},
abstract = {Technological advancements have had a significant impact on healthcare throughout history, leading to improved quality of care and greater efficiency, which ultimately benefits patients. The use of wearables and artificial intelligence (AI) in the healthcare industry has the potential to continue this trend. Wearables and AI enable real-time and continuous monitoring of a patient’s medical health information, which helps physicians detect diseases early and monitor patients during their recovery. However, there are challenges in managing the large amounts of data generated by these technologies and integrating them into existing electronic health records (EHRs). Despite these challenges, the introduction of AI promises to revolutionize the healthcare industry, much like the industrial and digital revolutions of the past. This paper will explore the transformative role of wearables and AI technology in healthcare, assess how it will change fundamental workflows, and highlight how AI solutions will become ubiquitous and expected by patients.}
}
@article{ZHANG2024109634,
title = {Research of artificial intelligence operations for wind turbines considering anomaly detection, root cause analysis, and incremental training},
journal = {Reliability Engineering & System Safety},
volume = {241},
pages = {109634},
year = {2024},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2023.109634},
url = {https://www.sciencedirect.com/science/article/pii/S0951832023005483},
author = {Chen Zhang and Di Hu and Tao Yang},
keywords = {Wind turbine, AIOps, Anomaly detection, Root cause analysis, Incremental training},
abstract = {Artificial intelligence operations (AIOps) is emerging as a novel technology in industrial automation to improve operation and maintenance (O&M) efficiency through machine learning methods. In this study, the AIOps for wind turbines based on SCADA data considering anomaly detection, root cause analysis, and incremental training is proposed and researched. A long short-term memory-based asymmetric variational autoencoding Gaussian mixture model (LSTM-AVAGMM) was established and used to detect early anomalies, and the threshold was set with a 99.7% confidence interval for the distribution curve fitted by kernel density estimation (KDE). Moreover, to provide guidance on O&M once an anomaly warning signal is issued, the SHapley Additive exPlanations (SHAP) was introduced to conduct root cause analysis by assigning each feature an importance value for a particular prediction. Finally, a novel incremental training strategy based on deep generative replay and fine-tuning was demonstrated to improve model adaptability in complex environments. Two real cases from a wind farm located in northeast China were presented. Comparative studies showed the robustness and competitiveness of the proposed methods in predicting failures, locating anomalies, and adaptively updating wind turbines, and the effects of various applied parameters were also described.}
}
@article{WANG2025101600,
title = {Integrating artificial intelligence in energy transition: A comprehensive review},
journal = {Energy Strategy Reviews},
volume = {57},
pages = {101600},
year = {2025},
issn = {2211-467X},
doi = {https://doi.org/10.1016/j.esr.2024.101600},
url = {https://www.sciencedirect.com/science/article/pii/S2211467X24003092},
author = {Qiang Wang and Yuanfan Li and Rongrong Li},
keywords = {Artificial intelligence, Energy transition, Clean energy supply, Demand-side management, Technological innovation, Smart grids},
abstract = {The global energy transition, driven by the imperative to mitigate climate change, demands innovative solutions to address the technical, economic, and social challenges of decarbonization. Artificial intelligence (AI) has emerged as a transformative technology in this domain, offering tools to enhance each link in the energy system. This comprehensive review examines the current state of AI applications across key energy transition domains, including renewable energy deployment, energy efficiency, grid stability, and smart grid integration. The study identifies the pivotal role of AI in accelerating the adoption of intermittent renewable energy sources like solar and wind, managing demand-side dynamics with advanced forecasting and optimization, and enabling energy storage and distribution innovations such as vehicle-to-grid systems and hybrid energy solutions. It also highlights the potential of AI to advance energy system stability, address cybersecurity risks, and promote equitable and sustainable energy systems. Despite these advancements, challenges remain, including data quality and accessibility, system interoperability, scalability, and concerns regarding privacy and ethics. By synthesizing recent research and practical case studies, this paper provides insights into the opportunities and limitations of AI-driven energy transformation and offers strategic recommendations to guide future research, development, and policy-making. This review highlights that AI is not just a tool but a transformative catalyst, reshaping global energy systems into equitable, resilient, and sustainable frameworks, essential for achieving a net-zero future.}
}
@article{MENG2025101491,
title = {Artificial-intelligence-enabled catalysis via standardized batch data},
journal = {Chem Catalysis},
volume = {5},
number = {9},
pages = {101491},
year = {2025},
issn = {2667-1093},
doi = {https://doi.org/10.1016/j.checat.2025.101491},
url = {https://www.sciencedirect.com/science/article/pii/S2667109325002295},
author = {Jiaolong Meng and Xuefeng Jiang},
abstract = {Jiaolong Meng received his PhD in organic chemistry from East China Normal University in 2024 and continued his research there as a postdoctoral fellow under the supervision of Prof. Xuefeng Jiang. His research focuses on the application of artificial intelligence (AI) in chemistry and on strategies for plastic degradation. Xuefeng Jiang is a professor at East China Normal University. He earned his PhD in 2008 from the Shanghai Institute of Organic Chemistry, Chinese Academy of Sciences, under the supervision of Prof. Shengming Ma. From 2008 to 2011, he was a postdoctoral fellow, supervised by Prof. K.C. Nicolaou, at the Scripps Research Institute. His current research interests include organosulfur chemistry, AI in chemistry, and plastic degradation.}
}
@article{MARUYAMA2025,
title = {Role of Artificial Intelligence in Surgical Training by Assessing GPT-4 and GPT-4o on the Japan Surgical Board Examination With Text-Only and Image-Accompanied Questions: Performance Evaluation Study},
journal = {JMIR Medical Education},
volume = {11},
year = {2025},
issn = {2369-3762},
doi = {https://doi.org/10.2196/69313},
url = {https://www.sciencedirect.com/science/article/pii/S2369376225000947},
author = {Hiroki Maruyama and Yoshitaka Toyama and Kentaro Takanami and Kei Takase and Takashi Kamei},
keywords = {LLM, ChatGPT, Japan Surgical Board Examination, surgical education, large language models, artificial intelligence, Medical Licensing Examination, diagnostic imaging},
abstract = {Background
Artificial intelligence and large language models (LLMs)—particularly GPT-4 and GPT-4o—have demonstrated high correct-answer rates in medical examinations. GPT-4o has enhanced diagnostic capabilities, advanced image processing, and updated knowledge. Japanese surgeons face critical challenges, including a declining workforce, regional health care disparities, and work-hour-related challenges. Nonetheless, although LLMs could be beneficial in surgical education, no studies have yet assessed GPT-4o’s surgical knowledge or its performance in the field of surgery.
Objective
This study aims to evaluate the potential of GPT-4 and GPT-4o in surgical education by using them to take the Japan Surgical Board Examination (JSBE), which includes both textual questions and medical images—such as surgical and computed tomography scans—to comprehensively assess their surgical knowledge.
Methods
We used 297 multiple-choice questions from the 2021‐2023 JSBEs. The questions were in Japanese, and 104 of them included images. First, the GPT-4 and GPT-4o responses to only the textual questions were collected via OpenAI’s application programming interface to evaluate their correct-answer rate. Subsequently, the correct-answer rate of their responses to questions that included images was assessed by inputting both text and images.
Results
The overall correct-answer rates of GPT-4o and GPT-4 for the text-only questions were 78% (231/297) and 55% (163/297), respectively, with GPT-4o outperforming GPT-4 by 23% (P=<.01). By contrast, there was no significant improvement in the correct-answer rate for questions that included images compared with the results for the text-only questions.
Conclusions
GPT-4o outperformed GPT-4 on the JSBE. However, the results of the LLMs were lower than those of the examinees. Despite the capabilities of LLMs, image recognition remains a challenge for them, and their clinical application requires caution owing to the potential inaccuracy of their results.}
}
@article{DELAROSA2024101843,
title = {Unveiling the adverse effects of artificial intelligence on financial decisions via the AI-IMPACT model},
journal = {Current Opinion in Psychology},
volume = {58},
pages = {101843},
year = {2024},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2024.101843},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X24000563},
author = {Wendy {De La Rosa} and Christopher J. Bechler},
keywords = {Artificial intelligence, AI, Financial decisions, Financial well-being, Marketplace, Pain of paying, Financial literacy, Mental accounting, Subjective wealth, Spending},
abstract = {There is considerable enthusiasm for the potential of artificial intelligence (AI) to improve financial well-being. Despite this enthusiasm, it is important to underscore AI's potential adverse effects on consumers' financial decisions. We introduce the AI-IMPACT model, a unifying theoretical framework for how AI can influence consumers' financial decisions. The model details how AI impacts the marketplace, affecting psychological processes and consumer traits core to financial decision-making (e.g., pain of payment, financial literacy). We use the AI-IMPACT model to illustrate one way AI can reduce financial well-being as its influence on the marketplace (e.g., facilitating biometric payment methods) decreases consumers' pain of payment, increasing spending. Lastly, we use the AI-IMPACT model to identify areas for future research at the intersection of AI and financial decision-making.}
}
@article{WU2025100741,
title = {Access to technology, access to justice: China’s artificial intelligence application in criminal proceedings},
journal = {International Journal of Law, Crime and Justice},
volume = {81},
pages = {100741},
year = {2025},
issn = {1756-0616},
doi = {https://doi.org/10.1016/j.ijlcj.2025.100741},
url = {https://www.sciencedirect.com/science/article/pii/S1756061625000175},
author = {Wanqiang Wu and Xifen Lin},
keywords = {Criminal proceedings, Artificial intelligence, Anchoring effect, Accountability avoidance, China},
abstract = {This article investigates Shanghai's “206” system, recognized as China's leading AI-assisted criminal case handling system, through an analysis of three distinct implementation scenarios in judicial processes. The study explores the role of artificial intelligence in assisting prosecutors and judges across various stages of criminal proceedings, highlighting both the advancements achieved and the limitations encountered. The research identifies critical challenges concerning system utilisation, the accuracy of outputs, and the transparency of underlying algorithms. Furthermore, the findings reveal three significant concerns: the AI system may inadvertently strengthen anchoring effects, compress procedural participation of defendants, and encourage accountability avoidance among judicial officers. Despite these challenges, this article argues that carefully designed judicial procedures can effectively mitigate associated risks while maximizing AI's benefits to criminal proceedings. This analysis contributes to the broader discourse of AI integration in judicial systems and offers practical insights for future implementations.}
}
@article{WU2025100547,
title = {A study on students' behavioural intention and use behaviour of artificial intelligence-generated content in physical education: Employing an extended the unified theory of acceptance and use of technology model},
journal = {Journal of Hospitality, Leisure, Sport & Tourism Education},
volume = {36},
pages = {100547},
year = {2025},
issn = {1473-8376},
doi = {https://doi.org/10.1016/j.jhlste.2025.100547},
url = {https://www.sciencedirect.com/science/article/pii/S1473837625000139},
author = {Qianjin Wu and Shanshan Li and Shuang Xin and Qian Hou and Ping Li},
keywords = {Artificial intelligence-generated content, Physical education, Unified theory of acceptance and use of technology, Partial least squares structural equation modelling},
abstract = {This study examines factors affecting AIGC acceptance among physical education students using the UTAUT model and perceived risk. Analyzing 414 Chinese students via PLS-SEM reveals that performance expectancy, social influence, facilitating conditions, and perceived risk significantly influence behavioural intention, whereas effort expectancy does not. Both facilitating conditions and behavioural intention positively influence use behaviour, with the impact of facilitating conditions being partially mediated by behavioural intention. Gender does not moderate these relationships. Findings suggest promoting AIGC in sports teaching by enhancing performance expectancy, leveraging social influence, optimizing facilitating conditions, and improving risk education.}
}
@article{AHMAD2025,
title = {Examining the Spectrum of Artificial Intelligence Failures:},
journal = {International Journal of Customer Relationship Marketing and Management},
volume = {16},
number = {1},
year = {2025},
issn = {1947-9247},
doi = {https://doi.org/10.4018/IJCRMM.370401},
url = {https://www.sciencedirect.com/science/article/pii/S1947924725000039},
author = {Anam Ahmad and Mohamed Slim {Ben Mimoun} and Hatem El-Gohary},
keywords = {Human and AI Interaction, Artificial Intelligence, Robots and Automation, Al Failure, Customer Behaviour, Systematic Literature Review, Chatbots},
abstract = {ABSTRACT
Artificial Intelligence AI is increasingly becoming a foundation of competitive planning for contemporary organizations. However, even though the implementation of AI in organizations is a critical intervention that can unlock new forms of value, many of these implementations do not meet the expected outcomes. They may result in substantial financial, operational, and reputational negative consequences. This systematic literature review starts with a sample of 3104 articles from well-reputed journals published between 2010-2024. It aims to examine several questions that surround the occurrence of AI failure in organizations: the reasons behind those failures, the categories of the failures, and the disciplinary areas of the failures. Moreover, customers', employees', and management's points of view are considered in the review to extrapolate the potential consequences of the failure of AI systems. The result demonstrates that the AI breakdown often results from a mixture of technology, organization, and people problems and that different industries exhibit diverce types of failures.}
}
@article{AURANGZEB2025106286,
title = {Artificial intelligence- and blockchain-enabled carbon emissions ledger system (AB-CELS) for sustainable construction processes},
journal = {Automation in Construction},
volume = {176},
pages = {106286},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106286},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525003267},
author = {Istiqlal Aurangzeb and Jong Han Yoon},
keywords = {Artificial intelligence, Blockchain, Carbon emissions, Construction processes, Sustainability, Smart contracts},
abstract = {Material transportation and on-site assembly are the building lifecycle phases that produce significant carbon emissions. However, traditional methods for capturing and recording these emissions lack automation, traceability, and immutability. This limitation hinders project stakeholders from data-driven decision-makings to promote sustainable construction practices and effectively implement regulations aimed at reducing carbon emissions. To address these challenges, this paper proposes a proof of concept for a transformational emissions ledger system that integrates an AI-powered large multimodal model for automatic parsing of emission-relevant data and a blockchain-enabled smart contract for a traceable and immutable emissions ledger. The proposed solution enables project stakeholders to automatically generate an immutable emissions ledger recorded on blockchain during the material transportation and on-site assembly phases, thereby enhancing their ability to make informed decisions regarding carbon emissions management. Additionally, this system enables regulatory approaches, including subsidies and tax incentives, all anchored in an immutable emissions ledger based on blockchain.}
}
@article{CHEN2025105357,
title = {Examining the role of Chinese language learners' grit and self-efficacy on their engagement in artificial intelligence-driven settings},
journal = {Acta Psychologica},
volume = {259},
pages = {105357},
year = {2025},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2025.105357},
url = {https://www.sciencedirect.com/science/article/pii/S0001691825006705},
author = {Jingjing Chen},
keywords = {Artificial intelligence-driven setting, International Chinese Education, Engagement, Grit, Resilience, Self-determination theory, Self-efficacy},
abstract = {Background
The presentation of Artificial Intelligence (AI) in the educational domain has turned conventional learning settings into advanced tools that maximize the performance of students. Engagement is a crucial determinant of students' success in AI-driven settings. However, identifying how psychological variables like self-efficacy and grit influence engagement in such settings is an emerging area in education. Directed by Self-determination theory (SDT), the present research aims to examine the interaction between students' grit, self-efficacy, and engagement.
Methods
The data were collected from 382 students in three Chinese universities with a range of academic majors. The three questionnaires were administered, and following data collection, structural equation modeling (SEM) was used to determine the model, and multiple regression analyses tested the predictive power of self-efficacy and grit on learners' engagement.
Results
Grit positively predicts engagement, suggesting that learners with higher levels of perseverance and consistency are more likely to believe in their capabilities and actively participate in learning activities. In turn, self-efficacy has a direct effect on engagement, implying that confidence in one's abilities contributes meaningfully to students' engagement in academic tasks.
Conclusion
The finding suggests that these two psychological constructs play a substantial and statistically significant role in shaping how actively and meaningfully students participate in AI-driven settings. Practical recommendations are aimed at enhancing learners' self-efficacy and grit, thus boosting engagement. These results contribute to a broader picture of SDT's application in AI-driven settings, offering ground for further research into motivational processes in such learning.}
}
@article{BORBA2024103118,
title = {Addressing discriminatory bias in artificial intelligence systems operated by companies: An analysis of end-user perspectives},
journal = {Technovation},
volume = {138},
pages = {103118},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2024.103118},
url = {https://www.sciencedirect.com/science/article/pii/S0166497224001688},
author = {Rafael Lucas Borba and Iuri Emmanuel {de Paula Ferreira} and Paulo Henrique {Bertucci Ramos}},
keywords = {Discrimination, Prevention, Mitigation, IA, Decision-making},
abstract = {The use of AI in different applications for different purposes has raised concerns due to discriminatory biases that have been identified in the technology. This paper aims to identify and analyze some of the main measures proposed by Bill No. 2338/23 of the Federative Republic of Brazil to combat discriminatory bias that companies should adopt to provide and/or operate fair and non-discriminatory AIs. To do so, it will first attempt to measure and analyze people's perceptions of the possibility that AI systems are discriminatory. For this a qualitative descriptive exploratory was made using as a reference sample the inhabitants of the Southeast region of Brasil. The survey results suggest that people are more aware that AIs are not neutral and that they may come to incorporate and reproduce prejudices and discriminations present in society. The incorporation of such biases is the result of issues related to the quality and diversity of the data used, inaccuracies in the algorithms employed, and biases on the part of both developers and operators. Thus, this work sought to reduce this gap and at the same time break the barrier of the lack of dialogue with the public in order to contribute to a democratic debate with society.}
}
@article{QU2024110920,
title = {Global research evolution and frontier analysis of artificial intelligence in brain injury: A bibliometric analysis},
journal = {Brain Research Bulletin},
volume = {209},
pages = {110920},
year = {2024},
issn = {0361-9230},
doi = {https://doi.org/10.1016/j.brainresbull.2024.110920},
url = {https://www.sciencedirect.com/science/article/pii/S0361923024000534},
author = {Mengqi Qu and Yang Xu and Lu Lu},
keywords = {Brain injury, Artificial intelligence, Bibliometrics, CiteSpace, VOSviewer},
abstract = {Research on artificial intelligence for brain injury is currently a prominent area of scientific research. A significant amount of related literature has been accumulated in this field. This study aims to identify hotspots and clarify research resources by conducting literature metrology visualization analysis, providing valuable ideas and references for related fields. The research object of this paper consists of 3000 articles cited in the core database of Web of Science from 1998 to 2023. These articles are visualized and analyzed using VOSviewer and CiteSpace. The bibliometric analysis reveals a continuous increase in the number of articles published on this topic, particularly since 2016, indicating significant growth. The United States stands out as the leading country in artificial intelligence for brain injury, followed by China, which tends to catch up. The core research institutions are primarily universities in developed countries, but there is a lack of cooperation and communication between research groups. With the development of computer technology, the research in this field has shown strong wave characteristics, experiencing the early stage of applied research based on expert systems, the middle stage of prediction research based on machine learning, and the current phase of diversified research focused on deep learning. Artificial intelligence has innovative development prospects in brain injury, providing a new orientation for the treatment and auxiliary diagnosis in this field.}
}
@article{JAVIDAN2024100049,
title = {Evaluating the progression of artificial intelligence and large language models in medicine through comparative analysis of ChatGPT-3.5 and ChatGPT-4 in generating vascular surgery recommendations},
journal = {JVS-Vascular Insights},
volume = {2},
pages = {100049},
year = {2024},
issn = {2949-9127},
doi = {https://doi.org/10.1016/j.jvsvi.2023.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2949912723000466},
author = {Arshia P. Javidan and Tiam Feridooni and Lauren Gordon and Sean A. Crawford},
keywords = {Artificial intelligence, Language model, Large language model, Natural language processing, Vascular surgery},
abstract = {Objective
Artificial intelligence (AI) continues to become increasingly integrated with clinical medicine. Generative AI, and particularly large language models (LLMs) like ChatGPT-3.5 and ChatGPT-4, have shown promise in generating human-like text, providing a potential tool for augmenting clinical care. These online AI chatbots have already demonstrated remarkable clinical potential, having passed the US Medical Licensing Exam, for example. The evaluation of these LLMs in the surgical literature, especially as it applies to judgement and decision-making, is sparse. This study aimed to (1) evaluate the efficacy of ChatGPT-4 in providing clinician-level vascular surgery recommendations and (2) compare its performance with its predecessor, ChatGPT-3.5, to gauge the progression of clinical competencies of LLMs.
Methods
A set of 40 clinician-level questions spanning 4 domains of vascular surgery (carotid artery disease, visceral artery aneurysms, abdominal aortic aneurysms, chronic limb-threatening ischemia) were generated by clinical experts. These domains were chosen based on the availability of updated guidelines published before September 2021, which served as the cutoff date for the training dataset of the LLMs. The questions, devoid of additional context or prompts, were input into ChatGPT-3.5 and ChatGPT-4 between March 20 and March 25, 2023. Responses were independently evaluated by two blinded reviewers using a 5-point Likert scale assessing comprehensiveness, accuracy, and consistency with guidelines. The Flesch-Kincaid grade level of each response was also determined. Independent samples t test and Fisher's exact test were used for comparative analysis.
Results
ChatGPT-4 significantly outperformed ChatGPT-3.5 by providing appropriate recommendations in 38 of 40 questions (95%) as compared with 13 of 40 (32.5%) by ChatGPT-3.5 (Fisher's exact test P < .001). Despite longer response lengths (chatGPT-4 mean 317 ± 58 words vs chatGPT-3.5 mean 265 ± 74 words; P < .001), the reading ease of both models remained similar, corresponding with college-level graduate texts.
Conclusions
ChatGPT-4 can consistently respond accurately to complex clinician-level vascular surgery questions. This also represents a substantial advancement in performance compared with its predecessor, which was released only a few months prior, highlighting the progress of performance of LLMs in clinical medicine. Several limitations persist with the use of LLMs, including hallucinations, data privacy issues, and the black box problem, However, these findings suggest that, with further refinements, LLMs like ChatGPT-4 have the potential to become indispensable tools in clinical decision-making, thereby marking an exciting frontier in the fusion of AI with clinical medicine and vascular surgery.}
}
@article{SUN2024e36620,
title = {Sanctions and opportunities: Factors affecting China's high-tech SMEs adoption of artificial intelligence computing leasing business},
journal = {Heliyon},
volume = {10},
number = {16},
pages = {e36620},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e36620},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024126515},
author = {Wei Sun and Alisher {Tohirovich Dedahanov} and Wei Ping Li and Ho {Young Shin}},
keywords = {Task technology fit, UTAUT, SME, Innovativeness, Artificial intelligence, Computing power leasing},
abstract = {Due to sanctions, more Chinese high-tech SMEs are turning to rent AI computing power through cloud service providers. Therefore, it is necessary to give a variety of suggestions for China's high-tech SMEs to better develop AI applications through computing power leasing. Because traditional theories are difficult to explain this new technology adoption behavior, this research combines and extends TTF and UTAUT2 theories to take an empirical research. A total of 387 questionnaires were received, of which incomplete questionnaires and invalid questionnaires were issued, leaving 281 valid questionnaires. The results indicate that SME innovativeness, perceived risk, performance expectancy, price value and task technology fit are all significantly related to usage, whereas task technology fit moderates the other relationships significantly. Results give a variety of suggestions for China's high-tech SMEs to better develop AI applications through computing power leasing in the context of sanctions. This study not only suggests ways to increase the competitiveness of SMEs by optimizing leasing services but also give directions in investors' investment decisions. The findings are also applicable to the large-scale application of China's domestic AI chips in computing power leasing scenarios in the future.}
}
@article{LU2025166,
title = {Artificial Intelligence–Related Dental Research: Bibliometric and Altmetric Analysis},
journal = {International Dental Journal},
volume = {75},
number = {1},
pages = {166-175},
year = {2025},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2024.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S0020653924014151},
author = {Wei Lu and Xueqian Yu and Yueyang Li and Yi Cao and Yanning Chen and Fang Hua},
keywords = {Dental research, Artificial intelligence, Deep learning, Machine learning, Bibliometrics},
abstract = {Background
Recent years have witnessed an explosive surge in dental research related to artificial intelligence (AI). These applications have optimised dental workflows, demonstrating significant clinical importance. Understanding the current landscape and trends of this topic is crucial for both clinicians and researchers to utilise and advance this technology. However, a comprehensive scientometric study regarding this field had yet to be performed.
Methods
A literature search was conducted in the Web of Science Core Collection database to identify eligible “research articles” and “reviews.” Literature screening and exclusion were performed by 2 investigators. Thereafter, VOSviewer was utilised in co-occurrence analysis and CiteSpace in co-citation analysis. R package Bibliometrix was employed to automatically calculate scientific impacts, determining the core authors and journals. Altmetric data were described narratively and supplemented with Spearman correlation analysis.
Results
A total of 1558 research publications were included. During the past 5 years, AI-related dental publications drastically increased in number, from 36 to 581. Diagnostics and Scientific Reports published the most articles, whereas Journal of Dental Research received the highest number of citations per article. China, the US, and South Korea emerged as the most prolific countries, whilst Germany received the highest number of citations per article (23.29). Charité Universitätsmedizin Berlin was the institution with the highest number of publications and citations per article (29.16). Altmetric Attention Score was correlated with News Mentions (P < .001), and significant associations were observed amongst Dimension Citations, Mendeley Readers, and Web of Science Citations (P < .001).
Conclusions
The publication numbers regarding AI-related dental research have been rising rapidly and may continue their upwards trend. China, the US, South Korea, and Germany had promoted the progress of AI-related dental research. Disease diagnosis, orthodontic applications, and morphology segmentation were current hotspots. Attention mechanism, explainable AI, multimodal data fusion, and AI-generated text assistants necessitate future research and exploration.}
}
@article{MARAQA2024104080,
title = {Comparing performances of french orthopaedic surgery residents with the artificial intelligence ChatGPT-4/4o in the French diploma exams of orthopaedic and trauma surgery},
journal = {Orthopaedics & Traumatology: Surgery & Research},
pages = {104080},
year = {2024},
issn = {1877-0568},
doi = {https://doi.org/10.1016/j.otsr.2024.104080},
url = {https://www.sciencedirect.com/science/article/pii/S1877056824003785},
author = {Nabih Maraqa and Ramy Samargandi and Antoine Poichotte and Julien Berhouet and Rayane Benhenneda},
keywords = {Artificial intelligence, ChatGPT-4, ChatGPT-4o, Diploma of specialized studies, Orthopedic and trauma surgery},
abstract = {Introduction
This study evaluates the performance of ChatGPT, particularly its versions 4 and 4o, in answering questions from the French orthopedic and trauma surgery exam (Diplôme d’Études Spécialisées, DES), compared to the results of French orthopedic surgery residents. Previous research has examined ChatGPT's capabilities across various medical specialties and exams, with mixed results, especially in the interpretation of complex radiological images.
Hypothesis
ChatGPT version 4o was capable of achieving a score equal to or higher (not lower) than that of residents for the DES exam.
Methods
The response capabilities of the ChatGPT model, versions 4 and 4o, were evaluated and compared to the results of residents for 250 questions taken from the DES exams from 2020 to 2024. A secondary analysis focused on the differences in the AI's performance based on the type of data being analyzed (text or images) and the topic of the questions.
Results
The score achieved by ChatGPT-4o was equivalent to that of residents over the past five years: 74.8% for ChatGPT-4o vs. 70.8% for residents (p = 0.32). The accuracy rate of ChatGPT was significantly higher in its latest version 4o compared to version 4 (58.8%, p = 0.0001). Secondary subgroup analysis revealed a performance deficiency of the AI in analyzing graphical images (success rates of 48% and 65% for ChatGPT-4 and 4o, respectively). ChatGPT-4o showed superior performance to version 4 when the topics involved the spine, pediatrics, and lower limb.
Conclusion
The performance of ChatGPT-4o is equivalent to that of French students in answering questions from the DES in orthopedic and trauma surgery. Significant progress has been observed between versions 4 and 4o. The analysis of questions involving iconography remains a notable challenge for the current versions of ChatGPT, with a tendency for the AI to perform less effectively compared to questions requiring only text analysis.
Level of evidence
IV; Retrospective Observational Study.}
}
@incollection{NGUYEN2026937,
title = {Chapter 63 - Big data and artificial intelligence in pediatric heart failure},
editor = {Joseph W. Rossano and John L. Jefferies and Anthony C. Chang and Jeffrey A. Towbin and Robert E. Shaddy and Shelley D. Miyamoto},
booktitle = {Heart Failure in the Child and Young Adult (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {937-948},
year = {2026},
isbn = {978-0-443-13279-7},
doi = {https://doi.org/10.1016/B978-0-443-13279-7.00018-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443132797000183},
author = {Tuyet Nguyen and Anthony C. Chang and Alessandra Toscano},
keywords = {Artificial intelligence, Congenital heart disease, Heart failure, Pediatric heart failure},
abstract = {Artificial intelligence (AI) is defined as a branch of computer science that involves mathematical algorithms aimed at performing tasks that require intelligent behavior. AI is transforming almost every aspect of cardiovascular medicine: improving diagnoses, assessing risks, designing treatments, and aiding clinical decision-making. Pediatric heart failure (PHF) is an extraordinarily complex condition due to the neonate-to-young-adult age spectrum, heterogeneity of anatomy and disease, limited clinical and imaging data, and ethical and logistical challenges that require a multidisciplinary approach with innovative strategies. In this context, AI has gained progress as a transformative technology that can improve diagnosis, prognosis, and treatment of congenital heart disease patients, including ones with PHF.}
}
@article{NOVELLI2024106066,
title = {Generative AI in EU law: Liability, privacy, intellectual property, and cybersecurity},
journal = {Computer Law & Security Review},
volume = {55},
pages = {106066},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.106066},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924001328},
author = {Claudio Novelli and Federico Casolari and Philipp Hacker and Giorgio Spedicato and Luciano Floridi},
keywords = {Generative AI, EU law, Liability, Privacy, Intellectual property, Cybersecurity},
abstract = {The complexity and emergent autonomy of Generative AI systems introduce challenges in predictability and legal compliance. This paper analyses some of the legal and regulatory implications of such challenges in the European Union context, focusing on four areas: liability, privacy, intellectual property, and cybersecurity. It examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA), in addressing the challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the EU legislative framework and proposes recommendations to ensure the safe and compliant deployment of generative models.}
}
@article{LOUCA2025105676,
title = {Artificial intelligence: Friend or foe in the assessment of dental students?},
journal = {Journal of Dentistry},
volume = {156},
pages = {105676},
year = {2025},
issn = {0300-5712},
doi = {https://doi.org/10.1016/j.jdent.2025.105676},
url = {https://www.sciencedirect.com/science/article/pii/S0300571225001216},
author = {C. Louca and I. Tonni and A. Leung and P. Fine},
keywords = {Artificial Intelligence, Assessing dental students, Dental teachers opinions, Knowledge of AI, Confidence with AI},
abstract = {Objectives
Incorporating artificial intelligence (AI) in assessing dental students’ knowledge and skills is in its infancy, despite AI being well established as an aid to aspects of clinical diagnosis and education. This study aimed to investigate whether dental educators perceived AI as beneficial in assessing students.
Methods
This was a mixed methods study where quantitative and qualitative data were generated through a live online polling system, Vevox ™ . Quantitative data were collected, findings of which were immediately shared with dental educators attending the workshop at a European wide dental educators’ conference. Qualitative data were collected at the workshop via word clouds as part of the online questions, and by asking participants to write down their views, opinions and reflections. Analysis was descriptive and thematic respectively.
Results
51 conference delegates attended the workshop. 14 questions had a response rate of over 69 %, two questions had response rates of 53 % and 57 % respectively. 65 % (n = 33) of participants considered that their dental school provided support and training in using AI. Dental educators were uncertain whether assessments of dental students generated by AI were effective in testing students’ knowledge/competence, 47 % (n = 18). One-third-of the participants were sure that AI generated assessments were more effective (34 %; n = 13). Less than half the participants were confident in using AI in assessing dental students (2.24/4; [SD 1.0588]). Thematic analysis revealed key themes: training, effectiveness of AI assessment, current use of AI, concerns, confidence, and advantages/disadvantages.
Conclusions
This study illustrated the diversity in knowledge, confidence and application of AI in the assessment of dental students, and the need for universities and dental schools to invest time and expertise in supporting dental educators in this important area.
Clinical Significance
The education and assessment of dental students should ensure that caring, knowledgeable and skilful practitioners are entrusted with patients care. The use of Artificial Intelligence to support or replace previous assessment techniques need to be understood by dental educators, to ensure that the assessments are robust, validated and workable.}
}
@article{MAJORANA2025905,
title = {Integrating creativity and artificial intelligence capability in entrepreneurial ventures},
journal = {Journal of Small Business and Enterprise Development},
volume = {32},
number = {4},
pages = {905-929},
year = {2025},
issn = {1462-6004},
doi = {https://doi.org/10.1108/JSBED-05-2024-0249},
url = {https://www.sciencedirect.com/science/article/pii/S1462600425000043},
author = {Cristina Doritta Brandão Majorana and Sílvio Luís {de Vasconcellos} and Felipe Mendes Borini},
keywords = {Organizational creativity, Artificial intelligence capability, Organizational performance, Life cycle, Resource orchestration},
abstract = {Purpose
While the literature on artificial intelligence (AI) capability is expanding, gaps remain in understanding how this capability is internally developed in technology-based startups (TBS) across different life cycle phases. This study, grounded in the resource orchestration theory (ROT), investigates the pathway through which TBS use organizational creativity to build AI capability and achieve performance.
Design/methodology/approach
A conceptual framework based on ROT emphasizes the role of organizational creativity in the structuring and bundling processes. Data were collected through a survey of 166 managers and employees of TBS operating in Brazil and international markets, using multiple linear regressions and the Sobel test for analysis. The study validated the AI capability scale in the TBS context.
Findings
AI capability fully mediates the relationship between organizational creativity and performance, confirming that organizational creativity is a critical resource for AI capability development. These findings advance ROT by deepening the understanding of how AI capability is developed in TBS. The study offers a dynamic, process-based view of performance trajectories in TBS, demonstrating that the synchrony between creativity and AI capability creates a cyclical process, maximizing company performance.
Originality/value
This research identifies an alternative pathway for TBS to develop AI capability and achieve performance, highlighting the synchronization and co-evolution of resources and capabilities. It provides novel insights into AI capability’s mediating role and expands understanding of resource management in TBS across life cycle phases.}
}
@article{TIAN2025103695,
title = {Artificial intelligence in scramjet research: Applications and future outlook},
journal = {Chinese Journal of Aeronautics},
pages = {103695},
year = {2025},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2025.103695},
url = {https://www.sciencedirect.com/science/article/pii/S1000936125003012},
author = {Ye TIAN and Yitong ZHAO and Jialing LE}
}
@article{TUSQUELLAS2024100288,
title = {Analysis of the potential of artificial intelligence for professional development and talent management: A systematic literature review},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {2},
pages = {100288},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100288},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000776},
author = {Natalia Tusquellas and Ramon Palau and Raúl Santiago},
keywords = {Artificial intelligence, Corporate education, Professional development, Talent management},
abstract = {The aim of this paper was to analyse the current applications of Artificial Intelligence in professional development and talent management within the corporate world with a focus on corporate training. By means of a Systematic Literature Review based on the PRISMA 2020 reporting criteria this paper highlights the current applications of AI along with the main benefits and drawbacks associated with its implementation. The findings show that AI is being used to enhance recruitment processes, to identify individual training and development skills and needs, to develop personalised training paths, to retain talent and predict attrition, and to detect future workforce skills development needs. It has been outlined that there is a need for automated talent management processes within companies and that talent intelligence should be implemented along with facing the challenges this will entail, such as minimising the risk of bias and hiring high-skilled qualified personnel.}
}
@article{DALBERTI2025103250,
title = {Artificial intelligence-enabled prenatal ultrasound for the detection of fetal cardiac abnormalities: a systematic review and meta-analysis},
journal = {eClinicalMedicine},
volume = {84},
pages = {103250},
year = {2025},
issn = {2589-5370},
doi = {https://doi.org/10.1016/j.eclinm.2025.103250},
url = {https://www.sciencedirect.com/science/article/pii/S2589537025001828},
author = {Elena D'Alberti and Olga Patey and Carolyn Smith and Bojana Šalović and Netzahualcoyotl Hernandez-Cruz and J. Alison Noble and Aris T. Papageorghiou},
keywords = {Congenital heart defect, Fetal ultrasound, Echocardiography, Artificial intelligence, Diagnostic accuracy},
abstract = {Summary
Background
Advances in artificial intelligence (AI) have triggered interest in using intelligent systems to improve prenatal detection of fetal congenital heart defects (CHDs). Our aim is to systematically examine the current literature on diagnostic performance of AI-enabled prenatal cardiac ultrasound.
Methods
This systematic review and meta-analysis was registered with PROSPERO (CRD42024549601). Embase, Medline, Cochrane Central Database of Controlled Trials, and CINAHL were searched from inception until February 2025. Studies evaluating AI performance in prenatal detection of fetal CHDs were eligible for inclusion, and studies focusing on the application of AI before 16 weeks of gestation, or using three- or four-dimensional ultrasound, were excluded. Pooled sensitivity and specificity were obtained using random-effect method, and pooled proportions using the Freeman-Tukey arcsine square root transformation. Heterogeneity was assessed with I2 statistics. Risk of bias and adherence to reporting standards were assessed using QUADAS-2 and TRIPOD+AI, respectively. Risk of publication bias was assessed with Deek's test and certainty of evidence for outcomes with GRADE approach.
Findings
Fifteen studies were included, of which fourteen developed and evaluated a model and one externally evaluated a previously trained model. Images and videos obtained during cardiac screening or fetal echocardiography of 30.121 fetuses were used for training, validation and testing. For the binary task of classifying heart as normal or abnormal, AI models achieved a pooled sensitivity of 0.89 (95% CI 0.83–0.93, I2 = 77.92%) and specificity of 0.91 (95% CI 0.84–0.95, I2 = 77.92%). The subgroup analysis showed that models tested on various CHDs exhibited lower sensitivity compared to those tested for a specific cardiac abnormality (0.85; 95% CI 0.75–0.91 vs 0.92; 95% CI 0.87–0.96), while specificity remained comparable (0.90; 95% CI 0.79–0.96 vs 0.91; 95% CI 0.81–0.97). Overall, AI models performed better than operators with lower expertise and were nearly comparable to experts; however, the human comparator group (median six clinicians, IQR 3–10) was usually small and non-blinded. Relevant sources of heterogeneity were the types of cardiac views collected, the prevalence of CHDs across different datasets, and the types of CHDs examined. The risk of bias was moderate-high and adherence to reporting standards low (>70% in 18/51 TRIPOD+AI items). The risk of publication bias was not statistically significant (Deek's test p = 0.474).
Interpretation
These findings suggest that AI models perform better than clinicians with lower expertise, but this must be interpreted with caution due to the high risk of bias and sources of heterogeneity.
Funding
This study was partly supported by the InnoHK-funded Hong Kong Centre for Cerebro-cardiovascular Health Engineering (COCHE) Project 2.1 (Cardiovascular risks in early life and fetal echocardiography). ATP and JAN are supported by the National Institute for Health and Care Research (NIHR) Oxford Biomedical Research Centre (BRC).}
}
@article{SPENCE2025S13,
title = {P28 The Use of Artificial Intelligence in the Development of Economic Models},
journal = {Value in Health},
volume = {28},
number = {6, Supplement 1},
pages = {S13},
year = {2025},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2025.04.039},
url = {https://www.sciencedirect.com/science/article/pii/S1098301525001639},
author = {Michaela Spence and Belal Howidi and Yixie Zhang and Keith R. Kallmes and Aidan Dineen}
}
@article{ABDULRAB2025602,
title = {Performance of 4 Artificial Intelligence Chatbots in Answering Endodontic Questions},
journal = {Journal of Endodontics},
volume = {51},
number = {5},
pages = {602-608},
year = {2025},
issn = {0099-2399},
doi = {https://doi.org/10.1016/j.joen.2025.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0099239925000020},
author = {Saleem Abdulrab and Hisham Abada and Mohammed Mashyakhy and Nawras Mostafa and Hatem Alhadainy and Esam Halboub},
keywords = {Chatbots, chatgpt, endodontic questions, Gemini Advanced, MedGebra GPT, Meta LIama 3},
abstract = {Introduction
Artificial intelligence models have shown potential as educational tools in healthcare, such as answering exam questions. This study aimed to assess the performance of 4 prominent chatbots: ChatGPT-4o, MedGebra GPT-4o, Meta LIama 3, and Gemini Advanced in answering multiple-choice questions (MCQs) in endodontics.
Methods
The study utilized 100 MCQs, each with 4 potential answers. These MCQs were obtained from 2 well-known endodontic textbooks. The performance of the above chatbots regarding choosing the correct answers was assessed twice with a 1-week interval.
Results
The stability of the performance in the 2 rounds was highest for ChatGPT-4o, followed by Gemini Advanced and Meta Llama 3. MedGebra GPT-4o provided the highest percentage of true answers in the first round (93%) followed by ChatGPT-4o in the second round (90%). Meta Llama 3 provided the lowest percentages in the first (73%) and second rounds (75%). Although the performance of MedGebra GPT-4o was the best in the first round, it was less stable upon the second round (McNemar P > .05; Kappa = 0.725, P < .001).
Conclusions
ChatGPT-4o and MedGebra GPT-4o answered a high fraction of endodontic MCQs, while Meta LIama 3 and Gemini Advanced showed lower performance. Further training and development are required to improve their accuracy and reliability in endodontics.}
}
@article{CANNAROZZI2025104694,
title = {Artificial intelligence and whole slide imaging, a new tool for the microsatellite instability prediction in colorectal cancer: Friend or foe?},
journal = {Critical Reviews in Oncology/Hematology},
volume = {210},
pages = {104694},
year = {2025},
issn = {1040-8428},
doi = {https://doi.org/10.1016/j.critrevonc.2025.104694},
url = {https://www.sciencedirect.com/science/article/pii/S1040842825000824},
author = {Anna Lucia Cannarozzi and Giuseppe Biscaglia and Paola Parente and Tiziana Pia Latiano and Annamaria Gentile and Davide Ciardiello and Luca Massimino and Anna Laura Pia {Di Brina} and Maria Guerra and Francesca Tavano and Federica Ungaro and Fabrizio Bossa and Francesco Perri and Anna Latiano and Orazio Palmieri},
keywords = {MSI, CRC, WSI, AI, Biomarkers},
abstract = {Colorectal cancer (CRC) is the third most common and second most deadly cancer worldwide. Despite advances in screening and treatment, CRC is heterogeneous and the response to therapy varies significantly, limiting personalized treatment options. Certain molecular biomarkers, including microsatellite instability (MSI), are critical in planning personalized treatment, although only a subset of patients may benefit. Currently, the primary methods for assessing MSI status include immunohistochemistry (IHC) for DNA mismatch repair proteins (MMRs), polymerase chain reaction (PCR)-based molecular testing, or next-generation sequencing (NGS). However, these techniques have limitations, are expensive and time-consuming, and often result in inter-method inconsistencies. Deficient mismatch repair (dMMR) or high microsatellite instability (MSI-H) are critical predictive biomarkers of response to immune checkpoint inhibitor (ICI) therapy and MSI testing is recommended to identify patients who may benefit. There is a pressing need for a more robust, reliable, and cost-effective approach that accurately assesses MSI status. Recent advances in computational pathology, in particular the development of technologies that digitally scan whole slide images (WSI) at high resolution, as well as new approaches to artificial intelligence (AI) in medicine, are increasingly gaining ground. This review aims to provide an overview of the latest findings on WSI and advances in AI methods for predicting MSI status, summarize their applications in CRC, and discuss their strengths and limitations in daily clinical practice.}
}
@article{BODDY2025100080,
title = {Enhancing informed consent in oncological surgery through digital platforms and artificial intelligence},
journal = {Clinical Surgical Oncology},
volume = {4},
number = {2},
pages = {100080},
year = {2025},
issn = {2773-160X},
doi = {https://doi.org/10.1016/j.cson.2025.100080},
url = {https://www.sciencedirect.com/science/article/pii/S2773160X25000091},
author = {Alex Boddy},
keywords = {Digital consent, Artificial intelligence, Informed consent, Shared decision making},
abstract = {Informed consent is a cornerstone of ethical medical practice, particularly in high-stakes oncological surgery where treatment options are complex and risks are significant. This paper explores the potential of digital platforms and artificial intelligence (AI) to enhance the informed consent process. The traditional consent process, reliant on face-to-face interactions and paper-based documentation, is increasingly being supplemented by digital solutions that offer remote consultations, personalized patient information, and electronic consent forms. These digital pathways not only improve accessibility and patient comprehension but also streamline documentation, reducing errors and administrative burdens. AI technologies, including ambient digital scribes and large language models (LLMs), could further augment this process by generating personalized risk assessments, simplifying complex medical information, and facilitating multilingual communication. However, success will also depend on addressing ethical concerns, ensuring equitable access, and preserving the irreplaceable human connection between patients and clinicians. By augmenting rather than replacing clinician expertise, digital platforms and AI can empower patients to make truly informed decisions in oncological care.}
}
@incollection{HAMEED2026287,
title = {Chapter 9 - Artificial intelligence in chemical engineering process monitoring and predictive maintenance},
editor = {Farooq Sher},
booktitle = {Artificial Intelligence in Chemical Engineering},
publisher = {Elsevier},
pages = {287-311},
year = {2026},
isbn = {978-0-443-34076-5},
doi = {https://doi.org/10.1016/B978-0-443-34076-5.00022-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443340765000225},
author = {Saman Hameed and Alireza Bigdeli and Noureddine {El Messaoudi} and Slađana Starčević and Anurag Sharma and Yew Heng Teoh and Monica R. Nemţanu and Martin Khzouz},
keywords = {Artificial intelligence, root cause analysis, anomaly detection, chemical engineering, predictive maintenance, internet of things, fault detection, machine learning, data science, operations management, pattern recognition, cognitive process, automation engineering, information systems},
abstract = {Artificial Intelligence (AI), predominantly machine learning (ML), is revolutionizing industries by driving advancements in various scientific domains. This chapter explores AI’s application in real-time chemical engineering (CE), emphasizing predictive maintenance (PdM), fault detection, and root cause analysis. Further, it emphasizes deep learning (DL) techniques for anomaly detection and integration with the industrial internet of things (IIoT) for monitoring and addresses challenges like security and implementation in CE processes. PdM, an initiative-taking maintenance approach, leverages ML algorithms to analyze data, identify patterns, and optimize decision-making, reducing downtime and operational expenditures. With maintenance expenses comprising 15–60% of total costs, PdM proposes efficient and reliable solutions through real-time monitoring, life assessments, and hybrid approaches that integrate data-driven, physical model-based, and knowledge-based techniques. Fault detection and diagnosis (FDD) is critical in CE to pinpoint deviations in system performance. While faults occur in less than 1% of industrial data, effective FDD systems must classify normal and abnormal conditions and determine root causes to authorize timely interventions, preventing accidents and minimizing damage. DL techniques further enhance anomaly detection, offering advanced capabilities in process optimization. The IIoT, a cornerstone of Industry 4.0, integrates internet of things (IoT), automation, and cloud computing to advance smart manufacturing. However, its widespread adoption increases exposure to cyberattacks, with over 25% targeting IoT devices. Advanced technologies like blockchain expand IoT security by decentralizing access, enhancing data integrity, and mitigating fraud risks.}
}
@incollection{SINGH2025199,
title = {Chapter Five - Use of artificial intelligence in soybean breeding and production},
editor = {Donald L. Sparks},
series = {Advances in Agronomy},
publisher = {Academic Press},
volume = {190},
pages = {199-273},
year = {2025},
issn = {0065-2113},
doi = {https://doi.org/10.1016/bs.agron.2024.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0065211324001147},
author = {Asheesh K. Singh and Sarah E. Jones and Liza {Van der Laan} and Timilehin T. Ayanlade and Joscif Raigne and Nasla Saleem and Shambhavi Joshi and Muhammad Arbab Arshad and Hossein ZareMehrjerdi and Ashlyn Rairdin and Juan {Di Salvo} and Dinakaran Elango and Leonardo {De Azevedo Peixoto} and Talukder Z. Jubery and Adarsh Krishnamurthy and Arti Singh and Soumik Sarkar and Baskar Ganapathysubramanian},
keywords = {Artificial intelligence, Phenomics, Genomics, Plant breeding, Crop production, Cyber-agricultural systems, Cyberinfrastructure, Datasets, Digital twin, Immersive environment},
abstract = {Artificial intelligence (AI) in soybean research has revolutionized various crop improvement and production aspects. This review provides predominant areas that have seen the use of AI. AI applications in phenomics have enabled collecting and analyzing high-dimensional data in soybean plants, from below- to above-ground traits, predicting phenotypes, and identifying complex patterns. In genomics, AI has improved genomic selection accuracy and identified genomic regions associated with traits of interest, such as resistance to biotic and abiotic stresses. AI has also been extensively used in detecting and managing biotic and abiotic plant stresses using RGB, multispectral, and thermal imagery from ground-based and aerial platforms. Additionally, AI has shown significant potential in yield prediction, incorporating factors such as vegetation indices, weather data, and soil properties. This review explains the concept of cyber-agricultural systems (CAS) that integrates AI, advanced sensing, computational modeling, and scalable cyberinfrastructure to optimize soybean production, enhance resource management, reduce environmental impact, and improve farm efficiency. We explain the use of CAS in crop improvement as well. We provide an exhaustive listing of challenges and future direction in the integration of AI in soybean production and crop improvement, including multi-modal and layered sensing, data availability and quality, computational modeling, AI models and tools, Cyberinfrastructure, Explainability and interpretability of AI models, AI-related impacts on privacy, ethics, and policy, Impact on Smallholder Farmers, Digital Twin, Large Soybean Datasets for community usage, and Immersive environments.}
}
@article{DELUCA2025359,
title = {The Pivotal Role of Baseline LDCT for Lung Cancer Screening in the Era of Artificial Intelligence},
journal = {Archivos de Bronconeumología},
volume = {61},
number = {6},
pages = {359-367},
year = {2025},
issn = {0300-2896},
doi = {https://doi.org/10.1016/j.arbres.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0300289624004393},
author = {Giulia Raffaella {De Luca} and Stefano Diciotti and Mario Mascalchi},
keywords = {Artificial intelligence, Low-dose computed tomography, Lung cancer, Screening},
abstract = {In this narrative review, we address the ongoing challenges of lung cancer (LC) screening using chest low-dose computerized tomography (LDCT) and explore the contributions of artificial intelligence (AI), in overcoming them. We focus on evaluating the initial (baseline) LDCT examination, which provides a wealth of information relevant to the screening participant's health. This includes the detection of large-size prevalent LC and small-size malignant nodules that are typically diagnosed as LCs upon growth in subsequent annual LDCT scans. Additionally, the baseline LDCT examination provides valuable information about smoking-related comorbidities, including cardiovascular disease, chronic obstructive pulmonary disease, and interstitial lung disease (ILD), by identifying relevant markers. Notably, these comorbidities, despite the slow progression of their markers, collectively exceed LC as ultimate causes of death at follow-up in LC screening participants. Computer-assisted diagnosis tools currently improve the reproducibility of radiologic readings and reduce the false negative rate of LDCT. Deep learning (DL) tools that analyze the radiomic features of lung nodules are being developed to distinguish between benign and malignant nodules. Furthermore, AI tools can predict the risk of LC in the years following a baseline LDCT. AI tools that analyze baseline LDCT examinations can also compute the risk of cardiovascular disease or death, paving the way for personalized screening interventions. Additionally, DL tools are available for assessing osteoporosis and ILD, which helps refine the individual's current and future health profile. The primary obstacles to AI integration into the LDCT screening pathway are the generalizability of performance and the explainability.}
}
@article{MOHAPATRA2025221,
title = {Trends of Artificial Intelligence (AI) Use in Drug Targets, Discovery and Development: Current Status and Future Perspectives},
journal = {Current Drug Targets},
volume = {26},
number = {4},
pages = {221-242},
year = {2025},
issn = {1389-4501},
doi = {https://doi.org/10.2174/0113894501322734241008163304},
url = {https://www.sciencedirect.com/science/article/pii/S1389450125000210},
author = {Manmayee Mohapatra and Chittaranjan Sahu and Snehamayee Mohapatra},
keywords = {Artificial intelligence, targets, drug development, precision medicine, drug discovery, data-driven, machine learning},
abstract = {The applications of artificial intelligence (AI) in pharmaceutical sectors have advanced drug discovery and development methods. AI has been applied in virtual drug design, molecule synthesis, advanced research, various screening methods, and decision-making processes. In the fourth industrial revolution, when medical discoveries are happening swiftly, AI technology is essential to reduce the costs, effort, and time in the pharmaceutical industry. Further, it will aid “genome-based medicine” and “drug discovery.” AI may prepare proactive databases according to diseases, disorders, and appropriate usage of drugs which will facilitate the required data for the process of drug development. The application of AI has improved clinical trials on patient selection in a population, stratification, and sample assessment such as biomarkers, effectiveness measures, dosage selection, and trial length. Various studies suggest AI could be perform better compared to conventional techniques in drug discovery. The present review focused on the positive impact of AI in drug discovery and development processes in the pharmaceutical industry and beneficial usage in health sectors as well.}
}
@article{OTAMENDI2024122526,
title = {Integrated water resource management in the Segura Hydrographic Basin: An artificial intelligence approach},
journal = {Journal of Environmental Management},
volume = {370},
pages = {122526},
year = {2024},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2024.122526},
url = {https://www.sciencedirect.com/science/article/pii/S030147972402512X},
author = {Urtzi Otamendi and Mikel Maiza and Igor G. Olaizola and Basilio Sierra and Markel Florez and Marco Quartulli},
keywords = {Water management, Decision-making, Optimization, Remote sensing, Artificial intelligence},
abstract = {Managing resources effectively in uncertain demand, variable availability, and complex governance policies is a significant challenge. This paper presents a paradigmatic framework for addressing these issues in water management scenarios by integrating advanced physical modelling, remote sensing techniques, and Artificial Intelligence algorithms. The proposed approach accurately predicts water availability, estimates demand, and optimizes resource allocation on both short- and long-term basis, combining a comprehensive hydrological model, agronomic crop models for precise demand estimation, and Mixed-Integer Linear Programming for efficient resource distribution. In the study case of the Segura Hydrographic Basin, the approach successfully allocated approximately 642 million cubic meters (hm3) of water over six months, minimizing the deficit to 9.7% of the total estimated demand. The methodology demonstrated significant environmental benefits, reducing CO2 emissions while optimizing resource distribution. This robust solution supports informed decision-making processes, ensuring sustainable water management across diverse contexts. The generalizability of this approach allows its adaptation to other basins, contributing to improved governance and policy implementation on a broader scale. Ultimately, the methodology has been validated and integrated into the operational water management practices in the Segura Hydrographic Basin in Spain.}
}
@article{YANG2024991,
title = {Intelligent metasurfaces: Integration of artificial intelligence technology and metasurfaces},
journal = {Chinese Journal of Physics},
volume = {89},
pages = {991-1008},
year = {2024},
issn = {0577-9073},
doi = {https://doi.org/10.1016/j.cjph.2024.03.043},
url = {https://www.sciencedirect.com/science/article/pii/S0577907324001321},
author = {Yunyun Yang and Haoxuan Xin and Yixin Liu and Haoliang Cheng and Yongxing Jin and Chenxia Li and Jianxun Lu and Bo Fang and Zhi Hong and Xufeng Jing},
keywords = {Metasurface, Deep learning, Artificial intelligence, Automatic design},
abstract = {Over the past decade, metasurfaces have attracted great interest in the global research community due to their extraordinary performance parameters and electromagnetic properties. However, due to the simulation nature of metasurfaces, most of the initial research focused on manipulating the electromagnetic field and waves. It was not until the concept of digitally coded metasurfaces was proposed that the space for the digital design of metasurfaces was opened up, and the rapid development of artificial intelligence (AI) introduced new methods for metasurface design. The intelligent metasurface formed by the combination of AI and information metasurfaces has become an emerging concept. This review mainly introduces the principles and properties of intelligent metasurfaces, including the concept of information metasurfaces, the programmability and real-time control capabilities of intelligent metasurfaces, etc. Then, the progress in achieving automated design of metasurfaces using AI technology is introduced, and the current applications, development prospects, and challenges of intelligent metasurfaces are discussed.}
}
@article{HUANBUTTA2024106938,
title = {Artificial intelligence-driven pharmaceutical industry: A paradigm shift in drug discovery, formulation development, manufacturing, quality control, and post-market surveillance},
journal = {European Journal of Pharmaceutical Sciences},
volume = {203},
pages = {106938},
year = {2024},
issn = {0928-0987},
doi = {https://doi.org/10.1016/j.ejps.2024.106938},
url = {https://www.sciencedirect.com/science/article/pii/S0928098724002513},
author = {Kampanart Huanbutta and Kanokporn Burapapadh and Pakorn Kraisit and Pornsak Sriamornsak and Thittaporn Ganokratanaa and Kittipat Suwanpitak and Tanikan Sangnim},
keywords = {Artificial intelligence, Machine learning, Pharmaceutical industry, Drug discovery, Drug manufacturing, Supply chain management},
abstract = {The advent of artificial intelligence (AI) has catalyzed a profound transformation in the pharmaceutical industry, ushering in a paradigm shift across various domains, including drug discovery, formulation development, manufacturing, quality control, and post-market surveillance. This comprehensive review examines the multifaceted impact of AI-driven technologies on all stages of the pharmaceutical life cycle. It discusses the application of machine learning algorithms, data analytics, and predictive modeling to accelerate drug discovery processes, optimize formulation development, enhance manufacturing efficiency, ensure stringent quality control measures, and revolutionize post-market surveillance methodologies. By describing the advancements, challenges, and future prospects of harnessing AI in the pharmaceutical landscape, this review offers valuable insights into the evolving dynamics of drug development and regulatory practices in the era of AI-driven innovation.}
}
@article{HU2024609,
title = {Research on Video Sample Collection and Processing Methods Based on Artificial Intelligence Platform},
journal = {Procedia Computer Science},
volume = {247},
pages = {609-616},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.073},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924028734},
author = {An Hu and Qi Wang and Xiaoguang Xu and Yao Zhao and Qian Ji and Lei Pei},
keywords = {Artificial Intelligence, Video Processing, Deep Learning, Convolutional Neural Network},
abstract = {This paper summarizes the video sample collection and processing methods based on artificial intelligence platform, focusing on video noise cancellation, content segmentation and classification, and feature extraction and representation techniques. The paper believes that the deep learning technology, especially the convolutional neural network, shows great potential in image recognition and video analysis, and effectively improves the level of automation and accuracy of video processing. This paper discusses the importance of building a large-scale and high-quality video sample library, and how to improve the processing efficiency and accuracy of video data through intelligent technology.}
}
@article{MORANTECARBALLO2025230,
title = {Artificial intelligence applications in hydrological studies and ecological restoration of watersheds: A systematic review},
journal = {Watershed Ecology and the Environment},
volume = {7},
pages = {230-248},
year = {2025},
issn = {2589-4714},
doi = {https://doi.org/10.1016/j.wsee.2025.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S2589471425000191},
author = {Fernando Morante-Carballo and Mirka Arcentales-Rosado and Jhon Caicedo-Potosí and Paúl Carrión-Mero},
keywords = {Hydrogeology, Bibliometrics, Neural network, Genetic algorithm, Machine learning},
abstract = {Water resources management is fundamental to the sustainability of river basins. Water quality is affected by pollution caused by human activities. In this context, the restoration of degraded watersheds helps soil recovery, sustainable water management, reforestation, biodiversity conservation and mitigation of human impacts. Artificial intelligence (AI) innovates data management and analysis processes by optimising decision-making and data analysis in hydrological studies and ecological restoration. This research aims to analyse scientific information related to the integration of AI in studies on hydrogeology and ecological restoration of watersheds by analysing scientific databases for knowledge of the intellectual structure, lines and trends of research. The methodology includes three phases: i) search criteria and data processing (Scopus-Web of Science); ii) analysis of the intellectual and conceptual structure; and iii) application of the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) method. The results indicate that there is a total of 171 records, with a 4.49% growth in scientific production in the last four years, focusing on artificial neural networks (10.53%), artificial intelligence (3.51%), genetic algorithms (1.17%) and machine learning (1.17%). This increase is due to the climatic variation generated in recent years, driven by anthropogenic pressures, especially in the agricultural sector due to the high demand for fertiliser and pesticide pollution. This problem has prompted the search for more far-reaching environmental management technologies, making it a potential niche for study. China (72.51%) and the United States (25.73%) are the most outstanding contributors to production in this area. On the other hand, there is less research in this area in developing countries such as South Africa (2.92%), Colombia (1.17%), and Argentina (0.58%), among others. This analysis identifies opportunities and challenges in applying AI for water resource optimisation and water quality prediction, providing an innovative conceptual framework for sustainable watershed management.}
}
@article{CHALLA2025100547,
title = {ChatGPT and American Society of Anesthesiologists (ASA) classifications - utilizing artificial intelligence in ASA classification of pediatric surgical patients},
journal = {Perioperative Care and Operating Room Management},
volume = {40},
pages = {100547},
year = {2025},
issn = {2405-6030},
doi = {https://doi.org/10.1016/j.pcorm.2025.100547},
url = {https://www.sciencedirect.com/science/article/pii/S2405603025000883},
author = {Chaitanya Challa and Abdulla Ahmed and Giuliana Geng-Ramos and Jennica Luu and Sohel Rana and Jessica A. Cronin},
keywords = {Machine learning, ASA classification, Mortality},
abstract = {Background
The American Society of Anesthesiologists (ASA) physical status classification system is a widely used tool to assess preoperative risk. However, variability in assigning ASA scores due to subjectivity among healthcare workers remains an issue. Advances in artificial intelligence (AI) present an opportunity to improve the consistency of ASA classifications. The aim of this study was to evaluate the potential of ChatGPT, a large language model (LLM), to assign ASA scores in pediatric surgical patients. The authors hypothesized that ChatGPT's classifications would correlate with anesthesiologist-determined ASA scores.
Methods
This retrospective cross-sectional pilot study was conducted at a tertiary pediatric hospital, including 203 pediatric patients who underwent surgery between June 4–7, 2023. Summaries of each patient's medical history and surgery details were created and reviewed by a board-certified anesthesiologist. These summaries were presented to both a study anesthesiologist and entered into ChatGPT (x2) for ASA classification. The ASA classifications by ChatGPT were compared to those provided by both the study anesthesiologist and the day-of-surgery (DOS) anesthesiologist. Cohen's kappa with linear weighting was used to assess inter-rater agreement between ChatGPT and anesthesiologists and to measure intra-rater reliability between different ChatGPT outputs.
Results
A total of 203 pediatric cases were analyzed. The agreement between repeated ASA classifications from ChatGPT was significant (κ=0.61, 95% CI 0.52–0.69) with 66% exact match in classifications. The agreement between the first ChatGPT output and the study anesthesiologist showed statistical agreement (κ=0.60, 95% CI 0.51–0.69), with a 66% match. Similarly, the second ChatGPT output had agreement with the study anesthesiologist (κ=0.59, 95% CI 0.50–0.68), with a 67% match. The highest agreement (κ=0.72, 95% CI 0.62–0.81) was observed between the DOS anesthesiologist and the study anesthesiologist, with a 75% match.
Conclusions
The correlation between ChatGPT's ASA scores and those assigned by the pilot study anesthesiologist was found to be 66–67%. These findings indicate that AI has the potential to support pediatric anesthesiologists in determining patient ASA classifications.}
}
@article{ABID2024104732,
title = {Modelling for disability: How does artificial intelligence affect unemployment among people with disability? An empirical analysis of linear and nonlinear effects},
journal = {Research in Developmental Disabilities},
volume = {149},
pages = {104732},
year = {2024},
issn = {0891-4222},
doi = {https://doi.org/10.1016/j.ridd.2024.104732},
url = {https://www.sciencedirect.com/science/article/pii/S0891422224000647},
author = {Mehdi Abid and Ousama Ben-Salha and Karim Gasmi and Nasareldeen Hamed Ahmed Alnor},
keywords = {Artificial intelligence, Unemployment, People with disability, Dynamic panel data, Threshold effects},
abstract = {There is a growing debate among scholars regarding the impact of artificial intelligence (AI) on the employment opportunities and professional development of people with disability. Although there has been an increasing body of empirical research on the topic, it has generally yielded conflicting findings. This study contributes to the ongoing debate by examining the linear and nonlinear effects of AI on the unemployment of people with disability in 40 countries between 2007 and 2021. Using the system Generalized Methods of Moments and panel smooth transition regression, the main conclusions are as follows. First, AI reduces the unemployment of people with disability in the full sample. Second, upon disaggregating the sample based on income level (high income/non-high income) and gender (men/women), the linear model only detects an inverse correlation between AI and unemployment among people with disability in high-income countries and among men, whereas it does not influence unemployment in non-high-income countries and women. Third, the panel smooth transition regression model suggests that the effects of AI on the unemployment of people with disability and among women are only observed once artificial intelligence interest search exceeds a specific threshold level. The effects of AI in non-high-income economies and among women are not significant in the lower regime, which confirms the nonlinear association between AI and the unemployment rate of people with disability. These findings have important policy implications for facilitating the integration of people with disability into the labor market.}
}
@article{JI2025100715,
title = {Physical Color Calibration of Digital Pathology Scanners for Robust Artificial Intelligence–Assisted Cancer Diagnosis},
journal = {Modern Pathology},
volume = {38},
number = {5},
pages = {100715},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2025.100715},
url = {https://www.sciencedirect.com/science/article/pii/S0893395225000110},
author = {Xiaoyi Ji and Richard Salmon and Nita Mulliqi and Umair Khan and Yinxi Wang and Anders Blilie and Henrik Olsson and Bodil Ginnerup Pedersen and Karina Dalsgaard Sørensen and Benedicte Parm Ulhøi and Svein R. Kjosavik and Emilius A.M. Janssen and Mattias Rantalainen and Lars Egevad and Pekka Ruusuvuori and Martin Eklund and Kimmo Kartasalo},
keywords = {artificial intelligence, color calibration, computational pathology, foundation model, prostate cancer, whole slide scanning},
abstract = {The potential of artificial intelligence (AI) in digital pathology is limited by technical inconsistencies in the production of whole slide images (WSIs). This causes degraded AI performance and poses a challenge for widespread clinical application, as fine-tuning algorithms for each site is impractical. Changes in the imaging workflow can also compromise diagnostic accuracy and patient safety. Physical color calibration of scanners, relying on a biomaterial-based calibrant slide and a spectrophotometric reference measurement, has been proposed for standardizing WSI appearance, but its impact on AI performance has not been investigated. We evaluated whether physical color calibration can enable robust AI performance. We trained fully supervised and foundation model–based AI systems for detecting and Gleason grading prostate cancer using WSIs of prostate biopsies from the STHLM3 clinical trial (n = 3651) and evaluated their performance in 3 external cohorts (n = 1161) with and without calibration. With physical color calibration, the fully supervised system’s concordance with pathologists’ grading (Cohen linearly weighted κ) improved from 0.439 to 0.619 in the Stavanger University Hospital cohort (n = 860), from 0.354 to 0.738 in the Karolinska University Hospital cohort (n = 229), and from 0.423 to 0.452 in the Aarhus University Hospital cohort (n = 72). The foundation model’s concordance improved as follows: from 0.739 to 0.760 (Karolinska), from 0.424 to 0.459 (Aarhus), and from 0.547 to 0.670 (Stavanger). This study demonstrated that physical color calibration provides a potential solution to the variation introduced by different scanners, making AI-based cancer diagnostics more reliable and applicable in diverse clinical settings.}
}
@article{SAEEDI2025171,
title = {Assessing the diagnostic capacity of artificial intelligence chatbots for dysphonia types: Model development and validation},
journal = {European Annals of Otorhinolaryngology, Head and Neck Diseases},
volume = {142},
number = {4},
pages = {171-178},
year = {2025},
issn = {1879-7296},
doi = {https://doi.org/10.1016/j.anorl.2025.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1879729625000250},
author = {S. Saeedi and M. Aghajanzadeh},
keywords = {ChatGPT, Perplexity AI, Diagnosis, Organic dysphonia, Functional dysphonia, Neurological dysphonia},
abstract = {Purpose
User-friendly artificial intelligence (AI) chatbots are increasingly being explored to assist healthcare teams in their decision-making processes. As accurate diagnosis in all medical fields is vital in treatment planning, this research seeks to explore the function of two specific AI chatbots, ChatGPT and Perplexity AI, in distinguishing the various types of dysphonia (organic, functional, and neurological).
Material and methods
In experiment 1, a script combining voice self-assessments plus the acoustic analysis, and in experiment 2, only the acoustic analysis of 37 dysphonic patients was fed into the ChatGPT and Perplexity AI chatbots specifying the type and asked to develop a complex AI-based model to determine dysphonia type. Then, the same process was redone with data from a sample of 27 other patients as a test.
Results
Although ChatGPT could not analyze the data and only provided guidance, the Cohen's Kappa agreement between experts’ diagnoses and Perplexity AI diagnoses in experiment 1 (P=0.773) and experiment 2 (P=0.067) lacked statistically significance.
Conclusion
Regarding the preliminary poor performance of AI chatbots in differential diagnosis of dysphonia type, it is not currently recommended to use them in clinical settings. However, modifications in AI chatbots in the future might provide more promising results in determining the dysphonia type. Further research is needed to shed light on AI chatbots ability in voice clinics.}
}
@article{SOORI2025200198,
title = {Additive Manufacturing Modification by Artificial Intelligence, Machine Learning, and Deep Learning: A Review},
journal = {Additive Manufacturing Frontiers},
volume = {4},
number = {2},
pages = {200198},
year = {2025},
issn = {2950-4317},
doi = {https://doi.org/10.1016/j.amf.2025.200198},
url = {https://www.sciencedirect.com/science/article/pii/S2950431725000085},
author = {Mohsen Soori and Fooad Karimi Ghaleh Jough and Roza Dastres and Behrooz Arezoo},
keywords = {Additive manufacturing, Optimization, Artificial intelligence, Machine learning, Deep learning},
abstract = {The manufacturing sector has been transformed owing to additive manufacturing (AM), which has made it possible to create intricate, personalized items with little material waste. However, optimizing and enhancing AM processes remain challenging owing to the intricacies involved in design, material selection, and process parameters. This review explores the integration of artificial intelligence (AI), machine learning (ML), and deep learning (DL) techniques to improve and innovate in the field of AM. AI-driven design optimization procedures offer innovative solutions for the 3D printing of complex geometries and lightweight structures. By leveraging machine learning (ML) algorithms, these procedures analyze extensive data from previous manufacturing processes to enhance efficiency and productivity. ML models facilitate design and production automation by learning from historical data and identifying intricate patterns that human operators may miss. Deep learning (DL) further augments this capacity by utilizing sophisticated neural networks to manage and interpret complex information and provide deeper insights into the manufacturing process. Integrating AI, ML, and DL into AM enables the creation of optimized, lightweight components that are crucial for reducing fuel consumption in the automotive and aviation industries. These advanced AI techniques optimize the design and production processes and enhance predictive modeling for process optimization and defect detection, leading to improved performance and reduced manufacturing costs. Therefore, integrating AI, ML, and DL into AM improves precision in component fabrication, enabling advanced material design innovations and opening new possibilities for innovation in product design and material science. This review discusses and highlights significant advancements and identifies future directions for applying AI, ML, and DL in AM. By leveraging these technologies, AM processes can achieve unprecedented levels of precision, customization, and productivity for analysis and modification.}
}
@article{DUBRAVOVA2024237,
title = {Artificial Intelligence as an Innovative Element of Support in Policing},
journal = {Procedia Computer Science},
volume = {237},
pages = {237-244},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011177},
author = {Hana Dubravova and Jan Cap and Kristyna Holubova and Lukas Hribnak},
keywords = {artificial intelligence, police, GPT, large language model, administrative burden, chat},
abstract = {Currently, the public security sector is faced with an increasing administrative burden that limits the ability of police officers to focus on core security tasks. This paper focuses on the possibility of using large-scale language models (LSMs) as an innovative tool to address this challenge. Based on a careful literature review and analysis of current trends in artificial intelligence, the author team develops a concept for integrating GPTs into police practice, with an emphasis on the potential for reducing administrative burden and supporting efficient processing of relevant information. As part of this research, we have identified key areas of policing where AI could bring significant value, including data analysis and document production assistance. However, it should be emphasized that this technology is still in its early stages of development and its implementation would require a carefully considered approach involving interdisciplinary collaboration and further research to test the theoretical assumptions presented in this study. Thus, this paper contributes to a deeper understanding of the potential benefits and challenges of integrating GPT into policing practice and outlines a path towards future innovative solutions in the field of public safety.}
}
@article{ZHANG2025,
title = {The Current Application and Knowledge Production of Artificial Intelligence in the Field of Ideological and Political Education in China},
journal = {International Journal of Cognitive Informatics and Natural Intelligence},
volume = {19},
number = {1},
year = {2025},
issn = {1557-3958},
doi = {https://doi.org/10.4018/IJCINI.385944},
url = {https://www.sciencedirect.com/science/article/pii/S1557395825000119},
author = {Yuyun Zhang},
keywords = {Artificial Intelligence, Large Models, Ideological and Political Education, Current Application, Knowledge Production},
abstract = {ABSTRACT
Because academic research on the integration of artificial intelligence and ideological and political education is lacking, the progress in practical applications is slow. To address this gap, this study took disciplinary system theory as the analytical framework, knowledge sociology as the theoretical perspective, and the Chinese literature database as the source, using data visualization software CiteSpaceVI to examine the knowledge production situation in the combination of artificial intelligence and ideological and political education in China. Through word segmentation technology and cluster analysis, this study found that research in this field began in 2018 and peaked in 2021 and 2023; scholars from more than 10 different disciplines participated in the research, and five stable research areas were formed. This field of study received support from 45 national funds and 29 funds from the Ministry of Education, along with various provincial fund projects. As a result, there are many urgent issues in this field waiting for more in-depth research and exploration in the future.}
}
@article{SINGHRANA2025516,
title = {A Glossary of Terms in Artificial Intelligence for Healthcare},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {2},
pages = {516-531},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324005838},
author = {S. Shamtej {Singh Rana} and Jacob S. Ghahremani and Joshua J. Woo and Ronald A. Navarro and Prem N. Ramkumar},
abstract = {In recent decades, artificial intelligence (AI) has infiltrated a variety of domains, including media, education, and medicine. There exists no glossary, lexicon, or reference for the uninitiated medical professional to explore the new terminology. As AI-driven technologies and applications become more available for clinical use in healthcare settings, an understanding of basic components, models, and tasks related to AI is crucial for clinical and academic appraisal. Here, we present a glossary of AI definitions that healthcare professionals can utilize to augment personal understanding of AI during this fourth industrial revolution.
Level of Evidence
Level V, expert opinion.}
}
@article{DESSEVRES2025411,
title = {Artificial intelligence for the detection of interictal epileptiform discharges in EEG signals},
journal = {Revue Neurologique},
volume = {181},
number = {5},
pages = {411-419},
year = {2025},
note = {ADVANCES IN EPILEPSY},
issn = {0035-3787},
doi = {https://doi.org/10.1016/j.neurol.2025.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0035378725004928},
author = {E. Dessevres and M. Valderrama and M. {Le Van Quyen}},
keywords = {Electroencephalogram, Interictal epileptiform discharges, Automated detection, Machine learning, Deep learning, Convolutional neural networks.},
abstract = {Introduction
Over the past decades, the integration of modern technologies — such as electronic health records, cloud computing, and artificial intelligence (AI) — has revolutionized the collection, storage, and analysis of medical data in neurology. In epilepsy, Interictal Epileptiform Discharges (IEDs) are the most established biomarker, indicating an increased likelihood of seizures. Their detection traditionally relies on visual EEG assessment, a time-consuming and subjective process contributing to a high misdiagnosis rate. These limitations have spurred the development of automated AI-driven approaches aimed at improving accuracy and efficiency in IED detection.
Methods
Research on automated IED detection began 45 years ago, spanning from morphological methods to deep learning techniques. In this review, we examine various IED detection approaches, evaluating their performance and limitations.
Results
Traditional machine learning and deep learning methods have produced the most promising results to date, and their application in IED detection continues to grow. Today, AI-driven tools are increasingly integrated into clinical workflows, assisting clinicians in identifying abnormalities while reducing false-positive rates.
Discussion
To optimize the clinical implementation of automated AI-based IED detection, it is essential to render the codes publicly available and to standardize the datasets and metrics. Establishing uniform benchmarks will enable objective model comparisons and help determine which approaches are best suited for clinical use.}
}
@article{BADUGE2022104440,
title = {Artificial intelligence and smart vision for building and construction 4.0: Machine and deep learning methods and applications},
journal = {Automation in Construction},
volume = {141},
pages = {104440},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104440},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522003132},
author = {Shanaka Kristombu Baduge and Sadeep Thilakarathna and Jude Shalitha Perera and Mehrdad Arashpour and Pejman Sharafi and Bertrand Teodosio and Ankit Shringi and Priyan Mendis},
keywords = {Artificial intelligence, Machine learning, Deep learning, Automation, Internet of things, Building information modelling, Smart vision, Convolution neural network, Generative adversarial network, Artificial neural network},
abstract = {This article presents a state-of-the-art review of the applications of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) in building and construction industry 4.0 in the facets of architectural design and visualization; material design and optimization; structural design and analysis; offsite manufacturing and automation; construction management, progress monitoring, and safety; smart operation, building management and health monitoring; and durability, life cycle analysis, and circular economy. This paper presents a unique perspective on applications of AI/DL/ML in these domains for the complete building lifecycle, from conceptual stage, design stage, construction stage, operational and maintenance stage until the end of life. Furthermore, data collection strategies using smart vision and sensors, data cleaning methods (post-processing), data storage for developing these models are discussed, and the challenges in model development and strategies to overcome these challenges are elaborated. Future trends in these domains and possible research avenues are also presented.}
}
@article{CHEN2024123180,
title = {Does artificial intelligence promote common prosperity within enterprises? —Evidence from Chinese-listed companies in the service industry},
journal = {Technological Forecasting and Social Change},
volume = {200},
pages = {123180},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2023.123180},
url = {https://www.sciencedirect.com/science/article/pii/S004016252300865X},
author = {Kaiming Chen and Xiaoqian Chen and Zhan-ao Wang and Roman Zvarych},
keywords = {Artificial intelligence, Share of labor income, Service industry, Employment structure effect, Wage-productivity effect},
abstract = {As the largest industry that absorbs labor from different levels of employment and provides different levels of labor remuneration, the service industry has faced severe challenges from the wave of artificial intelligence replacement. This study examines whether artificial intelligence promotes shared prosperity among service industry enterprises based on microdata of listed companies in the Chinese service industry from 2008 to 2022. The main research results indicate that the application of artificial intelligence in the service industry significantly reduces enterprises' labor income share. The main mechanisms of action include the employment structure effect of squeezing out low-educated and frontline workers and the wage-productivity effect that improves labor productivity but benefits capital income, leading to an unequal income distribution. Research has found that improving the integration of regional labor markets and workers' bargaining power can help alleviate the negative effects of artificial intelligence applications on the share of labor income in the service industry. This study helps developing countries, such as China, manage the impact of the widespread application of artificial intelligence on the labor market in the service industry and provides important policy insights for achieving common prosperity.}
}
@article{CARHUANCHO2025100143,
title = {Generating high-resolution climate data in the Andes using artificial intelligence: A lightweight alternative to the WRF model},
journal = {Artificial Intelligence in Geosciences},
volume = {6},
number = {2},
pages = {100143},
year = {2025},
issn = {2666-5441},
doi = {https://doi.org/10.1016/j.aiig.2025.100143},
url = {https://www.sciencedirect.com/science/article/pii/S2666544125000395},
author = {Christian Carhuancho and Edwin Villanueva and Christian Yarleque and Romel Erick Principe and Marcia Castromonte},
keywords = {Andean regions, Atmospheric variables, Regional climate models, Weather Research Forecasting (WRF), Artificial intelligence (AI), Computational cost, Deep learning models, RNN models, Climate data generation},
abstract = {In weather forecasting, generating atmospheric variables for regions with complex topography, such as the Andean regions with peaks reaching 6500 m above sea level, poses significant challenges. Traditional regional climate models often struggle to accurately represent the atmospheric behavior in such areas. Furthermore, the capability to produce high spatio-temporal resolution data (less than 27 km and hourly) is limited to a few institutions globally due to the substantial computational resources required. This study presents the results of atmospheric data generated using a new type of artificial intelligence (AI) models, aimed to reduce the computational cost of generating downscaled climate data using climate regional models like the Weather Research and Forecasting (WRF) model over the Andes. The WRF model was selected for this comparison due to its frequent use in simulating atmospheric variables in the Andes. Our results demonstrate a higher downscaling performance for the four target weather variables studied (temperature, relative humidity, zonal and meridional wind) over coastal, mountain, and jungle regions. Moreover, this AI model offers several advantages, including lower computational costs compared to dynamic models like WRF and continuous improvement potential with additional training data.}
}
@article{SCOTT2025102406,
title = {Taming the Wild West: Harnessing the Future of Artificial Intelligence},
journal = {Nursing Outlook},
volume = {73},
number = {2},
pages = {102406},
year = {2025},
issn = {0029-6554},
doi = {https://doi.org/10.1016/j.outlook.2025.102406},
url = {https://www.sciencedirect.com/science/article/pii/S0029655425000594},
author = {Linda D. Scott}
}
@article{TYTGAT2024108034,
title = {A personal view on the history of toxins: From ancient times to artificial intelligence},
journal = {Toxicon},
volume = {248},
pages = {108034},
year = {2024},
issn = {0041-0101},
doi = {https://doi.org/10.1016/j.toxicon.2024.108034},
url = {https://www.sciencedirect.com/science/article/pii/S0041010124006068},
author = {Jan Tytgat},
keywords = {Toxins, Bacteria, Plants, Animals, Discovery},
abstract = {Bioactive substances found in plants, microorganisms and animals have fascinated mankind since time immemorial. This review will focus on the progress that has been made over the centuries and our growing insights. The developments relate to both the discovery and characterization of novel bioactive substances, as well as the ceaseless implementation of refined techniques, the use of high-end instruments and breakthroughs in artificial intelligence with deep learning-based computational methods. As these approaches possess great translational potential, with many applications in different fields, such as therapeutic, diagnostic and agrochemical use, there is a good rationale to continue investing in toxinology-related research.}
}
@article{SMITSSERENA2025,
title = {The Use of Artificial Intelligence and Wearable Inertial Measurement Units in Medicine: Systematic Review},
journal = {JMIR mHealth and uHealth},
volume = {13},
year = {2025},
issn = {2291-5222},
doi = {https://doi.org/10.2196/60521},
url = {https://www.sciencedirect.com/science/article/pii/S2291522225000142},
author = {Ricardo {Smits Serena} and Florian Hinterwimmer and Rainer Burgkart and Rudiger {von Eisenhart-Rothe} and Daniel Rueckert},
keywords = {artificial intelligence, accelerometer, gyroscope, IMUs, time series data, wearable, systematic review, patient care, machine learning, data collection},
abstract = {Background
Artificial intelligence (AI) has already revolutionized the analysis of image, text, and tabular data, bringing significant advances across many medical sectors. Now, by combining with wearable inertial measurement units (IMUs), AI could transform health care again by opening new opportunities in patient care and medical research.
Objective
This systematic review aims to evaluate the integration of AI models with wearable IMUs in health care, identifying current applications, challenges, and future opportunities. The focus will be on the types of models used, the characteristics of the datasets, and the potential for expanding and enhancing the use of this technology to improve patient care and advance medical research.
Methods
This study examines this synergy of AI models and IMU data by using a systematic methodology, following PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, to explore 3 core questions: (1) Which medical fields are most actively researching AI and IMU data? (2) Which models are being used in the analysis of IMU data within these medical fields? (3) What are the characteristics of the datasets used for in this fields?
Results
The median dataset size is of 50 participants, which poses significant limitations for AI models given their dependency on large datasets for effective training and generalization. Furthermore, our analysis reveals the current dominance of machine learning models in 76% on the surveyed studies, suggesting a preference for traditional models like linear regression, support vector machine, and random forest, but also indicating significant growth potential for deep learning models in this area. Impressively, 93% of the studies used supervised learning, revealing an underuse of unsupervised learning, and indicating an important area for future exploration on discovering hidden patterns and insights without predefined labels or outcomes. In addition, there was a preference for conducting studies in clinical settings (77%), rather than in real-life scenarios, a choice that, along with the underapplication of the full potential of wearable IMUs, is recognized as a limitation in terms of practical applicability. Furthermore, the focus of 65% of the studies on neurological issues suggests an opportunity to broaden research scope to other clinical areas such as musculoskeletal applications, where AI could have significant impacts.
Conclusions
In conclusion, the review calls for a collaborative effort to address the highlighted challenges, including improvements in data collection, increasing dataset sizes, a move that inherently pushes the field toward the adoption of more complex deep learning models, and the expansion of the application of AI models on IMU data methodologies across various medical fields. This approach aims to enhance the reliability, generalizability, and clinical applicability of research findings, ultimately improving patient outcomes and advancing medical research.}
}
@article{FOGLI2025101023,
title = {Artificial intelligence-based pharmacological approach in non-small cell lung cancer in the precision medicine era},
journal = {Cancer Treatment and Research Communications},
volume = {45},
pages = {101023},
year = {2025},
issn = {2468-2942},
doi = {https://doi.org/10.1016/j.ctarc.2025.101023},
url = {https://www.sciencedirect.com/science/article/pii/S2468294225001595},
author = {Stefano Fogli and Alessandro Barberis and Marzia Del Re and Stefania Crucitta and Martina Ruglioni and Giovanna Luculli and Giorgio Guglielmi and Cristina Scavone and Iacopo Petrini and Nicola Panzeri and Andrea Pierini and Christian Rolfo and Romano Danesi},
keywords = {Drugs, Liquid biopsy, Next-generation sequencing, Radiomics, Artificial intelligence},
abstract = {The increasing knowledge in the molecular pathophysiology of non-small-cell lung cancer (NSCLC) allowed early identification of druggable targets; however, the advanced disease remains incurable mainly due to drug resistance. Therefore, it is essential to explore new methodological approaches for pharmacological strategies based on longitudinal molecular and imaging monitoring of NSCLC evolution, which can support decision-making for personalized treatments in clinical practice and provide new insight for the design of innovative clinical trials. The advent of artificial intelligence (AI) presents an extraordinary opportunity to develop algorithms capable of decoding the complex, multifaceted patterns of NSCLC progression. AI needs input information from biomarker analyses on liquid biopsies, radiomic data, actionable targets involved in cancer drug resistance, and clinically relevant information for choosing personalized next-line therapies, including existing drugs that could target previously unconsidered resistance pathways (drug repurposing), and selecting sequential or combinatorial therapeutic approaches as a fundamental part of precision medicine. This narrative review explores the opportunity of integrating AI-based multiparametric models into reactive and proactive algorithms to offer patients new therapeutic options for long-term quality-adjusted survival.}
}
@incollection{BASIT2026635,
title = {Chapter 27 - Panomics, artificial intelligence, and precision medicine},
editor = {Ramish Riaz and Maria Shabbir and Yasmin Badshah and Abdullah Ahmad and Khushbukhat Khan},
booktitle = {Nanotheranostics and Precision Oncology},
publisher = {Academic Press},
pages = {635-657},
year = {2026},
isbn = {978-0-443-34671-2},
doi = {https://doi.org/10.1016/B978-0-443-34671-2.00028-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443346712000281},
author = {Mahnoor Basit and Momna Jamil and Rohma Jamil and Muhammad Haroon and Khushbukhat Khan},
keywords = {Artificial intelligence, Genomics, Machine learning, Precision medicine, Proteomics},
abstract = {The integration of artificial intelligence (AI) with panomics and personalized medicine provides deeper insights into the molecular underpinnings of diseases. Panomics is an amalgamation of multidimensional omics data related to metabolomics, proteomics, transcriptomics, and genomics. With such large datasets, interpretation and conclusive findings can be an arduous task at hand. AI, along with its machine learning algorithms, plays a pivotal role not only in the screening of the data but also in uncovering the complex relationships between molecules and disease manifestations. The use of AI in biological data analysis allows researchers to uncover novel biomarkers, therapeutic targets, as well as disease subtypes which may not have been evident through the conventional time-taking methodology. Moreover, role of AI is not just restricted to disease identification; it can also help in the high throughput screening of compounds, and shortlisting them for targeted therapies. In this contemporary era, genetic medicines are being designed to cater to personalized proteomes. AI's role in precision medicine exceeds beyond the interpretation of biological data. Billions of compounds can be screened, docked, and simulated to aid with the development of targeted treatment. However, AI-driven approaches rely solely on the appropriate management of these technologies. AI is there to predict and narrow down the parameters. They must be validated through clinical trials for complete reliability. As genome sequencing becomes more readily available, and as AI-driven panomics matures, the promise of personalized medicine tailored to individual genetic profiles is becoming a reality. However, these technologies should augment rather than replace, the expertise of clinicians, ensuring that AI serves as a powerful tool in the hands of healthcare professionals.}
}
@article{AGYARE2025100365,
title = {A cross-national assessment of artificial intelligence (AI) Chatbot user perceptions in collegiate physics education},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100365},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2025.100365},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X25000050},
author = {Benjamin Agyare and Joseph Asare and Amani Kraishan and Isaac Nkrumah and Daniel Kwasi Adjekum},
abstract = {This study explores the perception of artificial intelligence (AI)-based Chatbots, specifically Open AI's ChatGPT use, among physics students in four universities in Ghana, Jordan, and the United States. We utilized a survey instrument adapted from the Technology Acceptance Model (TAM) to elicit responses from 804 students. TAM constructs: Perceived Usefulness (PU), Perceived Ease of Use (PEU), Subjective Norms (SN), Attitude Towards Technology Use (ATU), Behavioral Intention (BI), and User Behavior (UB) were assessed. We also assessed perceptions of ethical use (EU) and student learning outcomes (SLO) using a Structural Equation Model (SEM) approach. A measurement model had good fit indices and validated most hypotheses. A path analysis (PA) for hypothesized relationships suggested PEU and SN are significant predictors of BI and UB, whereas PU's influence on BI was indirect. Significantly, EU concerns negatively moderated the relationship between BI and UB, suggesting that higher ethical concerns can reduce ChatGPT usage. Cross-cultural analysis uncovered significant differences in perceptions and usage patterns influenced by institutional policies, academic levels, and demographic factors. Our findings affirm TAM's robustness in predicting technology use across various cultural and institutional settings. Findings also underscore the crucial roles of social influence in fostering positive user behaviors for Chat GPT. This study provides insights for educators and policymakers to develop strategies for integrating AI Chatbots responsibly and effectively in collegiate physics education while addressing ethical concerns. A longitudinal survey of the relationships between consistent AI Chatbot use, institutional support, student motivation, and learning outcomes is recommended.}
}
@article{AZZAHRO2025101518,
title = {Examining factors shaping citizens’ perception of artificial intelligence in government: A systematic literature review},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101518},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101518},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125002463},
author = {Fatimah Azzahro and Achmad Nizar Hidayanto and Muhammad Rifki Shihab},
keywords = {Artificial intelligence, Digital government, Public sector, Citizen perception, Systematic literature review, PRISMA},
abstract = {The adoption of Artificial Intelligence (AI) in government services has the potential to revolutionize public administration by enhancing efficiency, accuracy, and accessibility. However, the success of AI implementation heavily relies on public perception, which influences trust, acceptance, and willingness to adopt these technologies. Although previous studies have outlined benefits, risks, and challenges of AI use in government, a gap remains in understanding AI use in government from the perspective of citizens. With this goal in mind, this paper examines research related to AI use in the government services from the perspective of citizens. A review of the literature covering 41 articles available in four research databases was completed using the PRISMA protocol for literature reviews. The results revealed six key factors that influence citizens’ perception towards AI use in government: perceived benefit, perceived concern, characteristic of AI-based government services, trust, individual characteristic, and external factors. Based on the findings, a conceptual framework is proposed. These findings provide a foundation for future research and practical strategies to foster successful AI adoption in the public sector.}
}
@article{ZGAMBO2025106796,
title = {Artificial intelligence and academic integrity in nursing education: A mixed methods study on usage, perceptions, and institutional implications},
journal = {Nurse Education Today},
volume = {153},
pages = {106796},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106796},
url = {https://www.sciencedirect.com/science/article/pii/S0260691725002321},
author = {Maggie Zgambo and Martina Costello and Melanie Buhlmann and Justine Maldon and Edah Anyango and Esther Adama},
keywords = {Academic integrity, Academic misconduct, Artificial intelligence, Implications, Intention to adopt, Nursing education, Nursing students, Mixed methods},
abstract = {Background
The rise of artificial intelligence (AI) use in higher education has generated substantial debate among academics and students, given the potential for students to engage in academic misconduct through the misuse of AI. Academics argue that AI poses a serious threat to the foundational development of nurses through the questionable integrity of AI-generated academic work and by undermining the development of critical thinking skills essential for professional practice. However, there is limited research on nursing students' integration of AI technologies in their studies.
Method
This study utilised a convergent parallel mixed methods approach to develop a multiphase approach with convergent parallel techniques for the qualitative and quantitative phases. The quantitative method utilised a Qualtrics-powered online survey to engage 188 nursing students, exploring various domains related to AI use. In the qualitative phase, in-depth interviews with 13 purposively sampled students provided deeper insights. The qualitative data were analysed using an inductive thematic analysis approach, while the quantitative data were analysed using SPSS.
Result
In the survey, 24 % of respondents reported using AI, ranging from moderate to extensive usage. In logistics regression analysis, hearing about AI (OR = 3.9; CI 1.07–10.2; p < 0.05), the belief that AI was useful in the studies (OR = 5.5; CI 1.7–17.3; p < 0.01), and the perception that learning to use AI is easy (OR = 3.4; CI 1.1–11.1; p < 0.05) predicted AI use. Qualitative findings revealed that all students used AI for various academic purposes. The ‘fascinating’, ‘intelligent’ and ‘efficient’ nature of AI in handling ‘time-consuming’ academic tasks motivated its use. However, concerns about breaching academic integrity and the value of achieving success through personal effort served as deterrents.
Conclusion
The findings suggest that while AI's efficiency drives students to adopt it, they remain cautious about its ethical implications, leading to uncertainty in its application within academic practices. This highlights the critical need for institutional support and explicit guidelines on responsible AI integration in educational settings.}
}
@article{HABS202536,
title = {Using artificial intelligence (AI) for form and content checks of medical reports: Proofreading by ChatGPT4.0 in a neurology department},
journal = {Zeitschrift für Evidenz, Fortbildung und Qualität im Gesundheitswesen},
volume = {195},
pages = {36-41},
year = {2025},
issn = {1865-9217},
doi = {https://doi.org/10.1016/j.zefq.2025.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1865921725000790},
author = {Maximilian Habs and Stefan Knecht and Tobias Schmidt-Wilcke},
keywords = {Medical reports, ChatGPT, Artificial intelligence (AI), Proofreading, Medical errors, Prompting, Arztbrief, ChatGPT, Künstliche Intelligenz (KI), Korrekturlesen, Behandlungsfehler, Prompting},
abstract = {Introduction
Medical reports contain critical information and require concise language, yet often display errors despite advances in digital tools. This study compared the effectiveness of ChatGPT 4.0 in reporting orthographic, grammatical, and content errors in German neurology reports to a human expert.
Materials and Methods
Ten neurology reports were embedded with ten linguistic errors each, including typographical and grammatical mistakes, and one significant content error. The reports were reviewed by ChatGPT 4.0 using three prompts: (1) check the text for spelling and grammatical errors and report them in a list format without altering the original text, (2) identify spelling and grammatical errors and generate a revised version of the text, ensuring content integrity, (3) evaluate the text for factual inaccuracies, including incorrect information and treatment errors, and report them without modifying the original text. Human control was provided by an experienced medical secretary. Outcome parameters were processing time, percentage of identified errors, and overall error detection rate.
Results
Artificial intelligence (AI) accuracy in error detection was 35% (median) for Prompt 1 and 75% for Prompt 2. The mean word count of erroneous medical reports was 980 (SD = 180). AI-driven report generation was significantly faster than human review (AI Prompt 1: 102.4 s; AI Prompt 2: 209.4 s; Human: 374.0 s; p < 0.0001). Prompt 1, a tabular error report, was faster but less accurate than Prompt 2, a revised version of the report (p = 0.0013). Content analysis by Prompt 3 identified 70% of errors in 34.6 seconds.
Conclusions
AI-driven text processing for medical reports is feasible and effective. ChatGPT 4.0 demonstrated strong performance in detecting and reporting errors. The effectiveness of AI depends on prompt design, significantly impacting quality and duration. Integration into medical workflows could enhance accuracy and efficiency. AI holds promise in improving medical report writing. However, proper prompt design seems to be crucial. Appropriately integrated AI can significantly enhance supervision and quality control in health care documentation.
Zusammenfassung
Einleitung
Arztbriefe enthalten wichtige Informationen und erfordern eine präzise Sprache. Sie weisen jedoch trotz Fortschritten in der modernen Textbearbeitung häufig Fehler auf. Unsere Studie vergleicht die Effektivität von ChatGPT 4.0 bezüglich der Identifikation und Korrektur orthografischer, grammatikalischer und inhaltlicher Fehler in deutschen neurologischen Arztbriefen mit dem Korrekturlesen durch eine medizinisch versierte Fachkraft.
Material und Methoden
Zehn neurologische Musterarztbriefe wurden jeweils mit zehn sprachlichen Fehlern, darunter orthografische und grammatikalische Fehler, sowie einem schwerwiegenden inhaltlichen Fehler versehen. Die Überprüfung durch ChatGPT 4.0 erfolgte anhand dreier unterschiedlicher Eingabeaufforderungen (Prompts): (1) Identifikation von Rechtschreib- und Grammatikfehlern mit tabellarischer Auflistung der Fehler, ohne den Originaltext zu verändern, (2) Erkennung von Rechtschreib- und Grammatikfehlern mit anschließender Erstellung einer überarbeiteten Textversion unter Wahrung der inhaltlichen Integrität, (3) Überprüfung des Textes auf inhaltliche Ungenauigkeiten, einschließlich fehlerhafter Informationen und Behandlungsfehler, mit Fehlerbericht ohne entsprechende Textmodifikation. Als Kontrolle diente eine erfahrene medizinische Schreibkraft. Die Evaluationsparameter umfassten die Bearbeitungszeit, den prozentualen Anteil erkannter Fehler sowie die Gesamtfehlererkennungsrate.
Ergebnisse
Die Fehlererkennungsgenauigkeit der künstlichen Intelligenz (KI) betrug für Prompt 1 im Median 35% und für Prompt 2 im Median 75%. Die durchschnittliche Länge der fehlerhaften Arztbriefe lag bei 980 Wörtern (SD = 180). Die KI-basierte Fehleranalyse erfolgte signifikant schneller als die menschliche Korrektur (KI Prompt 1: 102,4 s; KI Prompt 2: 209,4 s; Mensch: 374,0 s; p < 0,0001). Während Prompt 1 als tabellarischer Fehlerbericht schneller, jedoch weniger präzise war, erwies sich Prompt 2 mit einer überarbeiteten Textversion als genauer (p = 0,0013). Die inhaltliche Analyse durch Prompt 3 identifizierte 70% der Fehlinformationen in 34,6 s.
Schlussfolgerungen
Die KI-gestützte Textüberprüfung für Arztbriefe ist schon jetzt praktikabel und effektiv. ChatGPT 4.0 zeigte gute Leistungen mit einer schnellen Fehlererkennung und Fehlerberichterstattung. Die Effektivität der KI hängt maßgeblich vom Prompt-Design ab, das Qualität und Bearbeitungsdauer signifikant beeinflusst. Eine Integration solcher Tools in die Arztbriefschreibung hat das Potenzial, die Genauigkeit und Effizienz des Prozesses zu steigern. KI-Unterstützung stellt daher eine vielversprechende Möglichkeit zur Verbesserung von Arztbriefen dar. Eine smarte Promptgestaltung erscheint auch bei dieser Aufgabe für große Sprachmodelle (LLM) entscheidend zu sein. Durch die Einbindung von KI können die Supervision und die Qualitätskontrolle in der medizinischen Dokumentation erheblich verbessert werden.}
}
@incollection{KALITA2026287,
title = {Chapter 18 - Limitations and future perspectives of artificial intelligence in crop breeding and agriculture},
editor = {Jen-Tsung Chen},
booktitle = {AI Technologies for Crop Breeding},
publisher = {Academic Press},
pages = {287-299},
year = {2026},
isbn = {978-0-443-33633-1},
doi = {https://doi.org/10.1016/B978-0-443-33633-1.00018-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443336331000186},
author = {Indrajit Kalita and Sharmistha Sarma Kalita and Bhaben Tanti and Sourav Bhattacharjee},
keywords = {Agriculture, Algorithm bias, Artificial intelligence, Crop breeding, Data privacy, Sustainability},
abstract = {The integration of artificial intelligence (AI) in crop breeding and agriculture presents significant opportunities alongside notable limitations. In this chapter, we examined the key challenges hindering the widespread adoption of AI technologies, including high initial costs, complexity requiring specialized technical expertise, and concerns regarding data privacy and security. Additionally, algorithmic bias and the dependency on reliable connectivity pose risks to effective implementation. In this chapter, we emphasized the need for a balanced approach that addresses these limitations while harnessing AI potential to enhance agricultural productivity and sustainability. Future perspectives include fostering collaboration among stakeholders to improve access to AI tools, developing training programs for farmers and establishing robust data governance frameworks. By addressing these challenges, the agricultural sector can leverage AI to revolutionize crop breeding practices and promote sustainable farming methods.}
}
@article{LI2024118023,
title = {New revolution for quality control of TCM in industry 4.0: Focus on artificial intelligence and bioinformatics},
journal = {TrAC Trends in Analytical Chemistry},
volume = {181},
pages = {118023},
year = {2024},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2024.118023},
url = {https://www.sciencedirect.com/science/article/pii/S0165993624005065},
author = {Yaolei Li and Jing Fan and Xianlong Cheng and Hongyu Jin and Ying Wang and Feng Wei and Fudong An and Shuangcheng Ma},
keywords = {Traditional Chinese medicine, Industry 4.0, Artificial intelligence, Bioinformatics, Machine learning, Quality control, Network pharmacology},
abstract = {Quality controllability of traditional Chinese medicine (TCM) is the cornerstone for safety and efficacy. Under Industry 4.0, what are the great transformations of quality control for TCM in global is the current urgent concern. Heren, we foresight focus on artificial intelligence and bioinformatics perspectives to reveal the progress of TCM quality control in intelligent era. Integrating the complexity, technological innovations, and outputs, the unique advantages of both directions in quality control of TCM are presented. Furthermore, we also provide insightful analyses of shortcomings and propose potential specialized solutions. In new quality productive forces, important directions in future cross-cutting areas of high-quality TCM formation, smart testing, and regulatory science are prospectively and systematically outlooked. This review dedicated to insight into intelligent of TCM quality control. It has profound significance to guide TCM internationalization.}
}
@article{WANG2026103082,
title = {Governance efficiency and upgrade pathways of international generative AI policies and regulations},
journal = {Technology in Society},
volume = {84},
pages = {103082},
year = {2026},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2025.103082},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X25002726},
author = {Xu Wang and Fang Xie and Binbin Liu},
keywords = {Generative AI, Policies and regulations, Governance efficiency, Upgrade paths, fsQCA, NCA},
abstract = {Analyzing the governance efficiency of policies and regulations on generative artificial intelligence (GAI) not only facilitates the advancement of GAI technological innovation and theoretical research but also enhances the precision and efficiency of information governance across nations. First, based on governance theory, institutional theory, resource-based theory, and administrative ecology theory, this paper analyzes the factors influencing the governance efficiency of GAI policies & regulations from three dimensions: government governance, resource endowment, and technology environment. Second, this paper examines the policies and regulations on GAI from 24 countries as samples. Employing the fsQCA and NCA method, along with PMC index evaluation results, this paper explores potential pathways to enhance the governance efficiency of GAI policies and regulations. Third, the configurational pathway analysis of governance efficiency in GAI policies and regulations identifies six critical influencing factors: policy and regulatory quality, government actions, venture capital investment, AI governance capacities, public stakeholder engagement, and AI safety mechanisms. Finally, through necessity analysis, configurational analysis, and robustness testing of these six factors, the paper reveals that technology-resource driven, policy-actor coordinated, and government-resource mediated implementation configurations can effectively achieve high-level governance efficiency in GAI policies and regulations. Therefore, it provides a reference for optimizing the governance practice of GAI policies and regulations.}
}
@article{ASSAREH2025151880,
title = {Artificial Intelligence-based multi-objective optimization of a solar-driven system for hydrogen production with integrated oxygen and power Co-generation across different climates},
journal = {International Journal of Hydrogen Energy},
volume = {184},
pages = {151880},
year = {2025},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2025.151880},
url = {https://www.sciencedirect.com/science/article/pii/S0360319925048839},
author = {Ehsanolah Assareh and Behzad Rismanchi and Nima Izadyer and Ali Bedakhanian and Elmira Jamei and Jagadeesh Kumar Alagarasan},
keywords = {Artificial intelligence optimization, Climate-responsive design, Hydrogen production, Multi-generation energy systems, Proton exchange membrane electrolyzer, Solar thermal energy},
abstract = {This study develops and optimizes a solar-powered system for hydrogen generation with oxygen and power co-products, addressing the need for efficient, scalable carbon-free energy solutions. The system combines a linear parabolic collector, a Steam Rankine cycle, and a Proton Exchange Membrane Electrolyzer (PEME) to produce electricity for electrolysis. Thermodynamic modeling was accomplished in Engineering Equation Solver, while a hybrid Artificial Intelligence (AI) framework combining Artificial Neural Networks and Genetic Algorithms in Statistica, coupled with Technique for Order Preference by Similarity to Ideal Solution (TOPSIS) decision support, optimized technical and economic performance. Optimization considered seven key decision variables, covering collector design, thermodynamic inputs, and component efficiencies. The optimization achieved energy and exergy efficiencies of 30.83 % and 26.32 %, costing 47.02 USD/h and avoiding CO2 emissions equivalent to 190 USD/ton. Economic and exergy analyses showed the solar and hydrogen units had the highest costs (38.17 USD/h and 9.61 USD/h), with 4503 kWh of exergy destruction to generate 575 kWh of electricity. A case study across six cities suggested that Perth, Bunbury, and Adelaide, with higher solar irradiance, delivered the highest annual power and hydrogen outputs, consistent with irradiance–electrolyzer correlation. Unlike conventional single-site studies, this work delivers a climate-responsive, multi-city analysis integrating solar thermal and PEME within an AI-driven framework. By linking techno-economic performance with quantified environmental value and co-production synergies of hydrogen, oxygen, and electricity, the study highlights a novel pathway for scalable clean hydrogen, measurable CO2 reductions, and global decarbonization, with future work focused on digital twins and dynamic, uncertainty-aware optimization.}
}
@article{SHEN2024,
title = {Empathy Toward Artificial Intelligence Versus Human Experiences and the Role of Transparency in Mental Health and Social Support Chatbot Design: Comparative Study},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/62679},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924001057},
author = {Jocelyn Shen and Daniella DiPaola and Safinah Ali and Maarten Sap and Hae Won Park and Cynthia Breazeal},
keywords = {empathy, large language models, ethics, transparency, crowdsourcing, human-computer interaction},
abstract = {Background
Empathy is a driving force in our connection to others, our mental well-being, and resilience to challenges. With the rise of generative artificial intelligence (AI) systems, mental health chatbots, and AI social support companions, it is important to understand how empathy unfolds toward stories from human versus AI narrators and how transparency plays a role in user emotions.
Objective
We aim to understand how empathy shifts across human-written versus AI-written stories, and how these findings inform ethical implications and human-centered design of using mental health chatbots as objects of empathy.
Methods
We conducted crowd-sourced studies with 985 participants who each wrote a personal story and then rated empathy toward 2 retrieved stories, where one was written by a language model, and another was written by a human. Our studies varied disclosing whether a story was written by a human or an AI system to see how transparent author information affects empathy toward the narrator. We conducted mixed methods analyses: through statistical tests, we compared user’s self-reported state empathy toward the stories across different conditions. In addition, we qualitatively coded open-ended feedback about reactions to the stories to understand how and why transparency affects empathy toward human versus AI storytellers.
Results
We found that participants significantly empathized with human-written over AI-written stories in almost all conditions, regardless of whether they are aware (t196=7.07, P<.001, Cohen d=0.60) or not aware (t298=3.46, P<.001, Cohen d=0.24) that an AI system wrote the story. We also found that participants reported greater willingness to empathize with AI-written stories when there was transparency about the story author (t494=–5.49, P<.001, Cohen d=0.36).
Conclusions
Our work sheds light on how empathy toward AI or human narrators is tied to the way the text is presented, thus informing ethical considerations of empathetic artificial social support or mental health chatbots.}
}
@article{GALDO2024195,
title = {Artificial intelligence in paediatrics: Current events and challenges},
journal = {Anales de Pediatría (English Edition)},
volume = {100},
number = {3},
pages = {195-201},
year = {2024},
issn = {2341-2879},
doi = {https://doi.org/10.1016/j.anpede.2024.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S2341287924000383},
author = {Brais Galdo and Carla Pazos and Jerónimo Pardo and Alfonso Solar and Daniel Llamas and Enrique Fernández-Blanco and Alejandro Pazos},
keywords = {Artificial intelligence, 7P medicine, Machine learning, Paediatrics, Personalized medicine, Inteligencia artificial, Medicina de las 7P, Aprendizaje máquina, Pediatría, Medicina personalizada},
abstract = {This article examines the use of artificial intelligence (AI) in the field of paediatric care within the framework of the 7P medicine model (Predictive, Preventive, Personalized, Precise, Participatory, Peripheral and Polyprofessional). It highlights various applications of AI in the diagnosis, treatment and management of paediatric diseases as well as the role of AI in prevention and in the efficient management of health care resources and the resulting impact on the sustainability of public health systems. Successful cases of the application of AI in the paediatric care setting are presented, placing emphasis on the need to move towards a 7P health care model. Artificial intelligence is revolutionizing society at large and has a great potential for significantly improving paediatric care.
Resumen
Se examina el uso de la inteligencia artificial (IA) en el campo de la atención a la salud pediátrica dentro del marco de la "Medicina de las 7P" (Predictiva, Preventiva, Personalizada, Precisa, Participativa, Periférica y Poliprofesional). Se destacan diversas aplicaciones de la IA en el diagnóstico, el tratamiento y el control de enfermedades pediátricas, así como su papel en la prevención y en la gestión eficiente de los recursos médicos con su repercusión en la sostenibilidad de los sistemas públicos de salud. Se presentan casos de éxito de la aplicación de la IA en el ámbito pediátrico y se hace un gran énfasis en la necesidad de caminar hacia la Medicina de las 7P. La IA está revolucionando la sociedad en general ofreciendo un gran potencial para mejorar significativamente el cuidado de la salud en pediatría.}
}
@article{IDRIS2025,
title = {Use of a generative AI tool to design RNA-based antiviral therapeutics for undergraduate virology laboratory teaching},
journal = {Journal of Microbiology & Biology Education},
volume = {26},
number = {2},
year = {2025},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00223-24},
url = {https://www.sciencedirect.com/science/article/pii/S1935787725000681},
author = {Adi Idris},
keywords = {generative AI, siRNA, virology, Biomod AI},
abstract = {ABSTRACT

RNA medicines have taken the drug development world by storm since the introduction of mRNA vaccines post-pandemic. As this field is rapidly evolving at an unprecedented speed, it is crucial that higher education institutions keep up with this at all levels of teaching, including at the undergraduate level. In parallel, the necessity of embedding the fast-changing artificial intelligence (AI) landscape in undergraduate teaching and learning is also crucial. Here, I have developed a succinct but informative, in silico-based laboratory activity using a generative AI tool called Biomod AI (https://biomodai.com) for designing RNA-based drugs. This activity was designed for undergraduate level students to equip them with a unique AI-driven RNA drug design methodology. To my knowledge, this is the first use of generative AI for designing RNA drugs in undergraduate teaching.}
}