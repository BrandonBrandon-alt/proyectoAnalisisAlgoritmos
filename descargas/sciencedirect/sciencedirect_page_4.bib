@article{HEROLD2025101012,
title = {Brave new procurement deals: An experimental study of how generative artificial intelligence reshapes buyer–supplier negotiations},
journal = {Journal of Purchasing and Supply Management},
volume = {31},
number = {4},
pages = {101012},
year = {2025},
issn = {1478-4092},
doi = {https://doi.org/10.1016/j.pursup.2025.101012},
url = {https://www.sciencedirect.com/science/article/pii/S1478409225000214},
author = {Silke Herold and Jonas Heller and Frank Rozemeijer and Dominik Mahr},
keywords = {Artificial intelligence, Chatbots, Negotiation},
abstract = {The technological breakthrough of artificial intelligence (AI) is impacting buyer-supplier negotiations, which are increasingly moving toward human-to-machine negotiations using AI-based chatbots. While the first AI-powered negotiation solutions are currently being used by procurement professionals to negotiate for non-critical spend items, which is an example of structural influence, the behavioral influence of AI-based chatbots (i.e., on negotiation approach) remains unknown. It is unclear in which behavioral settings these chatbots deliver value to the buying firm in terms of economic, psychological, and relational outcomes. To fill this gap, we conduct three experiments in buyer–supplier negotiation settings, two in a lab-setting with undergraduate business students and one online experiment with professional negotiators. In our interactive simulations, participants play the role of the supplier, while a ChatGPT-based custom-trained chatbot acts as the buyer. We find that when the chatbot deploys a competitive, as compared to a collaborative, negotiation approach, it will achieve a higher price discount, better payment terms, and a quicker negotiation. However, suppliers trust a collaboratively prompted, as compared to a competitively prompted, chatbot more and demonstrate higher outcome satisfaction, as well as a stronger desire for future interaction. A text analysis of the chat interactions indicates a higher level of similarity when a competitively prompted chatbot is employed, which implies that suppliers also use more insistent and intimidating language, thereby matching the chatbot's negotiation approach to a greater degree. While the negotiation approach is a significant influencing factor, we do not find significant evidence that item type, in our case non-critical or bottleneck, matters, which indicates that AI-based chatbots can be effective in various buyer–supplier settings.}
}
@article{PUGLIESE2025667,
title = {Generative Artificial Intelligence in Nutrition: A Revolution in Accessibility and Personalization},
journal = {The Journal of Nutrition},
volume = {155},
number = {3},
pages = {667-668},
year = {2025},
issn = {0022-3166},
doi = {https://doi.org/10.1016/j.tjnut.2025.01.025},
url = {https://www.sciencedirect.com/science/article/pii/S002231662500032X},
author = {Nicola Pugliese and Federico Ravaioli}
}
@article{LV2023208,
title = {Generative artificial intelligence in the metaverse era},
journal = {Cognitive Robotics},
volume = {3},
pages = {208-217},
year = {2023},
issn = {2667-2413},
doi = {https://doi.org/10.1016/j.cogr.2023.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667241323000198},
author = {Zhihan Lv},
abstract = {Generative artificial intelligence (AI) is a form of AI that can autonomously generate new content, such as text, images, audio, and video. Generative AI provides innovative approaches for content production in the metaverse, filling gaps in the development of the metaverse. Products such as ChatGPT have the potential to enhance the search experience, reshape information generation and presentation methods, and become new entry points for online traffic. This is expected to significantly impact traditional search engine products, accelerating industry innovation and upgrading. This paper presents an overview of the technologies and prospective applications of generative AI in the breakthrough of metaverse technology and offers insights for increasing the effectiveness of generative AI in creating creative content.}
}
@article{CHEN2024100531,
title = {Generative Artificial Intelligence Enhancements for Reducing Image-based Training Data Requirements},
journal = {Ophthalmology Science},
volume = {4},
number = {5},
pages = {100531},
year = {2024},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2666914524000678},
author = {Dake Chen and Ying Han and Jacque Duncan and Lin Jia and Jing Shan},
keywords = {Glaucoma, Generative AI, Data scarcity},
abstract = {Objective
Training data fuel and shape the development of artificial intelligence (AI) models. Intensive data requirements are a major bottleneck limiting the success of AI tools in sectors with inherently scarce data. In health care, training data are difficult to curate, triggering growing concerns that the current lack of access to health care by under-privileged social groups will translate into future bias in health care AIs. In this report, we developed an autoencoder to grow and enhance inherently scarce datasets to alleviate our dependence on big data.
Design
Computational study with open-source data.
Subjects
The data were obtained from 6 open-source datasets comprising patients aged 40–80 years in Singapore, China, India, and Spain.
Methods
The reported framework generates synthetic images based on real-world patient imaging data. As a test case, we used autoencoder to expand publicly available training sets of optic disc photos, and evaluated the ability of the resultant datasets to train AI models in the detection of glaucomatous optic neuropathy.
Main Outcome Measures
Area under the receiver operating characteristic curve (AUC) were used to evaluate the performance of the glaucoma detector. A higher AUC indicates better detection performance.
Results
Results show that enhancing datasets with synthetic images generated by autoencoder led to superior training sets that improved the performance of AI models.
Conclusions
Our findings here help address the increasingly untenable data volume and quality requirements for AI model development and have implications beyond health care, toward empowering AI adoption for all similarly data-challenged fields.
Financial Disclosure(s)
The authors have no proprietary or commercial interest in any materials discussed in this article.}
}
@article{BERA20258735,
title = {Accurate prediction of the kinetic sequence of physicochemical states using generative artificial intelligence††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d5sc00108k},
journal = {Chemical Science},
volume = {16},
number = {20},
pages = {8735-8751},
year = {2025},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d5sc00108k},
url = {https://www.sciencedirect.com/science/article/pii/S2041652025006327},
author = {Palash Bera and Jagannath Mondal},
abstract = {Capturing the time evolution and predicting kinetic sequences of states of physicochemical systems present significant challenges due to the precision and computational effort required. In this study, we demonstrate that ‘Generative Pre-trained Transformer (GPT)’, an artificial intelligence model renowned for machine translation and natural language processing, can be effectively adapted to predict the dynamical state-to-state transition kinetics of biologically relevant physicochemical systems. Specifically, by using sequences of time-discretized states from Molecular Dynamics (MD) simulation trajectories akin to the vocabulary corpus of a language, we show that a GPT-based model can learn the complex syntactic and semantic relationships within the trajectory. This enables GPT to predict kinetically accurate sequences of states for a diverse set of biomolecules of varying complexity, at a much quicker pace than traditional MD simulations and with a better efficiency than other baseline time-series prediction approaches. More significantly, the approach is found to be equally adept at forecasting the time evolution of out-of-equilibrium active systems that do not maintain detailed balance. An analysis of the mechanism inherent in GPT reveals the crucial role of the ‘self-attention mechanism’ in capturing the long-range correlations necessary for accurate state-to-state transition predictions. Together, our results highlight generative artificial intelligence's ability to generate kinetic sequences of states of physicochemical systems with statistical precision.}
}
@article{WENG2024100315,
title = {Personality traits for self-regulated learning with generative artificial intelligence: The case of ChatGPT},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100315},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100315},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001188},
author = {Xiaojing Weng and Qi Xia and Zubair Ahmad and Thomas K.F. Chiu},
keywords = {GenAI, Personality traits, Self-regulated learning, Instructional design, Higher education},
abstract = {Personality traits and educational technology may affect how well students utilise their abilities and strategies to achieve their learning objectives and potential. As generative artificial intelligence (GenAI) is creating new learning experiences, understanding the impact of five representative personality traits on students' self-regulated learning (SRL) while learning with GenAI tools can help to predict which personality traits indicate better self-regulation when learning with this innovative educational technology. Such a prediction can help educators to design effective learning activities by providing educational experiences that cater to students' different personality traits for specific learning objectives in the GenAI context. This study explored how variations in five representative personality traits affect students’ SRL performance when learning with ChatGPT. It used an explanatory approach based on structural equation modelling with a path analysis design. Four hundred and nine university students participated in the study and finished a self-reported questionnaire with validated items that are driven by previous studies. The results revealed that the personality traits of openness, extraversion, and agreeableness were significant predictors of all three stages of SRL; conscientiousness was a significant predictor of the forethought and self-reflection stages; and neuroticism failed to predict any of the three stages of SRL. These results may be attributable to the subjective nature of personality traits and the cognitive characteristics of SRL skills. The findings enrich the literature on SRL by introducing personality traits and GenAI as innovative perspectives and suggesting corresponding strategies for supporting different stages of SRL.}
}
@article{RODMAN2025689,
title = {Is generative artificial intelligence capable of clinical reasoning?},
journal = {The Lancet},
volume = {405},
number = {10480},
pages = {689},
year = {2025},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(25)00348-4},
url = {https://www.sciencedirect.com/science/article/pii/S0140673625003484},
author = {Adam Rodman and Eric J Topol}
}
@article{BLEASE2024115724,
title = {Psychiatrists’ experiences and opinions of generative artificial intelligence in mental healthcare: An online mixed methods survey},
journal = {Psychiatry Research},
volume = {333},
pages = {115724},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115724},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000118},
author = {Charlotte Blease and Abigail Worthen and John Torous},
keywords = {Chatbots, LLM, Workforce, Psychiatry, Artificial intelligence},
abstract = {Following the launch of ChatGPT in November 2022, interest in large language model (LLM)-powered chatbots has surged with increasing focus on the clinical potential of these tools. Missing from this discussion, however, are the perspectives of physicians. The current study aimed to explore psychiatrists’ experiences and opinions on this new generation of chatbots in mental health care. An online survey including both quantitative and qualitative responses was distributed to a non-probability sample of psychiatrists affiliated with the American Psychiatric Association. Findings revealed 44 % of psychiatrists had used OpenAI's ChatGPT-3.5 and 33 % had used GPT-4.0 “to assist with answering clinical questions.” Administrative tasks were cited as a major benefit of these tools: 70 % somewhat agreed/agreed “documentation will be/is more efficient”. Three in four psychiatrists (75 %) somewhat agreed/agreed “the majority of their patients will consult these tools before first seeing a doctor”. Nine in ten somewhat agreed/agreed that clinicians need more support/training in understanding these tools. Open-ended responses reflected these opinions but respondents also expressed divergent opinions on the value of generative AI in clinical practice, including its impact on the future of the profession.}
}
@article{DAUNGSUPAWONG2024848,
title = {Generative artificial intelligence in ophthalmology: Correspondence},
journal = {Survey of Ophthalmology},
volume = {69},
number = {5},
pages = {848},
year = {2024},
issn = {0039-6257},
doi = {https://doi.org/10.1016/j.survophthal.2024.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0039625724000717},
author = {Hinpetch Daungsupawong and Viroj Wiwanitkit}
}
@article{BRUNS2024103790,
title = {Do you create your content yourself? Using generative artificial intelligence for social media content creation diminishes perceived brand authenticity},
journal = {Journal of Retailing and Consumer Services},
volume = {79},
pages = {103790},
year = {2024},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2024.103790},
url = {https://www.sciencedirect.com/science/article/pii/S0969698924000869},
author = {Jasper David Brüns and Martin Meißner},
keywords = {Generative artificial intelligence, Content creation, Brand authenticity, Algorithm aversion, Social media},
abstract = {Recent studies have demonstrated the potential of generative artificial intelligence (GenAI) in enhancing marketing content. However, its impact on consumer behavior has remained empirically untested. In response to social media platforms mandating the disclosure of GenAI content, we investigate how followers perceive brands that use GenAI for content creation. Drawing from literature on algorithm aversion and brand authenticity, the results of three experimental studies indicate that brands' GenAI adoption induces negative attitudinal and behavioral follower reactions. These effects are mediated by followers' perceptions of brand authenticity and can be triggered by GenAI disclosure. Negative reactions are attenuated if GenAI is used to assist humans in content creation rather than to replace them through automation. Our findings underscore the need for nuance in brands’ GenAI adoption to unlock economic benefits without compromising on relationships with consumers.}
}
@article{LIU2023798,
title = {Generative artificial intelligence and its applications in materials science: Current situation and future perspectives},
journal = {Journal of Materiomics},
volume = {9},
number = {4},
pages = {798-816},
year = {2023},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352847823000771},
author = {Yue Liu and Zhengwei Yang and Zhenyao Yu and Zitu Liu and Dahui Liu and Hailong Lin and Mingqing Li and Shuchang Ma and Maxim Avdeev and Siqi Shi},
keywords = {Machine learning, Artificial intelligence, Generative artificial intelligence, Materials science, Novel materials discovery, Deep learning},
abstract = {Generative Artificial Intelligence (GAI) is attracting the increasing attention of materials community for its excellent capability of generating required contents. With the introduction of Prompt paradigm and reinforcement learning from human feedback (RLHF), GAI shifts from the task-specific to general pattern gradually, enabling to tackle multiple complicated tasks involved in resolving the structure-activity relationships. Here, we review the development status of GAI comprehensively and analyze pros and cons of various generative models in the view of methodology. The applications of task-specific generative models involving materials inverse design and data augmentation are also dissected. Taking ChatGPT as an example, we explore the potential applications of general GAI in generating multiple materials content, solving differential equation as well as querying materials FAQs. Furthermore, we summarize six challenges encountered for the use of GAI in materials science and provide the corresponding solutions. This work paves the way for providing effective and explainable materials data generation and analysis approaches to accelerate the materials research and development.}
}
@article{HAASE2023100066,
title = {Artificial muses: Generative artificial intelligence chatbots have risen to human-level creativity},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100066},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100066},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000250},
author = {Jennifer Haase and Paul H.P. Hanel},
keywords = {Creativity, Originality, AI, Generative artificial intelligence},
abstract = {A widespread view is that Artificial Intelligence cannot be creative. We tested this assumption by comparing human-generated ideas with those generated by six Generative Artificial Intelligence (GAI) chatbots: alpa.ai, Copy.ai, ChatGPT (versions 3 and 4), Studio.ai, and YouChat. Humans and a specifically trained AI independently assessed the quality and quantity of ideas. We found no qualitative difference between AI and human-generated creativity, although there are differences in how ideas are generated. Interestingly, 9.4 % of humans were more creative than the most creative GAI, GPT-4. Our findings suggest that GAIs are valuable assistants in the creative process. Continued research and development of GAI in creative tasks is crucial to fully understand this technology's potential benefits and drawbacks in shaping the future of creativity. Finally, we discuss the question of whether GAIs are capable of being “truly” creative.}
}
@article{BEWERSDORFF2025102601,
title = {Taking the next step with generative artificial intelligence: The transformative role of multimodal large language models in science education},
journal = {Learning and Individual Differences},
volume = {118},
pages = {102601},
year = {2025},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102601},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024001948},
author = {Arne Bewersdorff and Christian Hartmann and Marie Hornberger and Kathrin Seßler and Maria Bannert and Enkelejda Kasneci and Gjergji Kasneci and Xiaoming Zhai and Claudia Nerdel},
keywords = {Artificial Intelligence, Large Language Models (LLMs), ChatGPT, Multimodal learning, Cognitive Theory of Multimedia Learning, Science education},
abstract = {The integration of Artificial Intelligence (AI), particularly Large Language Model (LLM)-based systems, in education has shown promise in enhancing teaching and learning experiences. However, the advent of Multimodal Large Language Models (MLLMs) like GPT-4 Vision, capable of processing multimodal data including text, sound, and visual inputs, opens a new era of enriched, personalized, and interactive learning landscapes in education. This paper derives a theoretical framework for integrating MLLMs into multimodal learning. This framework serves to explore the transformative role of MLLMs in central aspects of science education by presenting exemplary innovative learning scenarios. Possible applications for MLLMs range from content creation to tailored support for learning, fostering engagement in scientific practices, and providing assessments and feedback. These applications are not limited to text-based and uni-modal formats but can be multimodal, thus increasing personalization, accessibility, and potential learning effectiveness. Despite the many opportunities, challenges such as data protection and ethical considerations become salient, calling for robust frameworks to ensure responsible integration. This paper underscores the necessity for a balanced approach in implementing MLLMs, where the technology complements rather than supplants the educators' roles, ensuring an effective and ethical use of AI in science education. It calls for further research to explore the nuanced implications of MLLMs for educators and to extend the discourse beyond science education to other disciplines. Through developing a theoretical framework for the integration of MLLMs into multimodal learning and exploring the associated potentials, challenges, and future implications, this paper contributes to a preliminary examination of the transformative role of MLLMs in science education and beyond.}
}
@article{WAQAS2023100255,
title = {Revolutionizing Digital Pathology With the Power of Generative Artificial Intelligence and Foundation Models},
journal = {Laboratory Investigation},
volume = {103},
number = {11},
pages = {100255},
year = {2023},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2023.100255},
url = {https://www.sciencedirect.com/science/article/pii/S0023683723001988},
author = {Asim Waqas and Marilyn M. Bui and Eric F. Glassy and Issam {El Naqa} and Piotr Borkowski and Andrew A. Borkowski and Ghulam Rasool},
keywords = {artificial intelligence, computational and digital pathology, foundation models, large language models, multimodal data, vision-language models},
abstract = {Digital pathology has transformed the traditional pathology practice of analyzing tissue under a microscope into a computer vision workflow. Whole-slide imaging allows pathologists to view and analyze microscopic images on a computer monitor, enabling computational pathology. By leveraging artificial intelligence (AI) and machine learning (ML), computational pathology has emerged as a promising field in recent years. Recently, task-specific AI/ML (eg, convolutional neural networks) has risen to the forefront, achieving above-human performance in many image-processing and computer vision tasks. The performance of task-specific AI/ML models depends on the availability of many annotated training datasets, which presents a rate-limiting factor for AI/ML development in pathology. Task-specific AI/ML models cannot benefit from multimodal data and lack generalization, eg, the AI models often struggle to generalize to new datasets or unseen variations in image acquisition, staining techniques, or tissue types. The 2020s are witnessing the rise of foundation models and generative AI. A foundation model is a large AI model trained using sizable data, which is later adapted (or fine-tuned) to perform different tasks using a modest amount of task-specific annotated data. These AI models provide in-context learning, can self-correct mistakes, and promptly adjust to user feedback. In this review, we provide a brief overview of recent advances in computational pathology enabled by task-specific AI, their challenges and limitations, and then introduce various foundation models. We propose to create a pathology-specific generative AI based on multimodal foundation models and present its potentially transformative role in digital pathology. We describe different use cases, delineating how it could serve as an expert companion of pathologists and help them efficiently and objectively perform routine laboratory tasks, including quantifying image analysis, generating pathology reports, diagnosis, and prognosis. We also outline the potential role that foundation models and generative AI can play in standardizing the pathology laboratory workflow, education, and training.}
}
@article{KATHAIT20241575,
title = {Assessing Laterality Errors in Radiology: Comparing Generative Artificial Intelligence and Natural Language Processing},
journal = {Journal of the American College of Radiology},
volume = {21},
number = {10},
pages = {1575-1582},
year = {2024},
note = {Focus on Innovation},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2024.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S154614402400591X},
author = {Anjaneya Singh Kathait and Emiliano Garza-Frias and Tejash Sikka and Thomas J. Schultz and Bernardo Bizzo and Mannudeep K. Kalra and Keith J. Dreyer},
keywords = {generative AI, large language models, natural language processing, patient safety, radiology errors},
abstract = {Purpose
We compared the performance of generative artificial intelligence (AI) (Augmented Transformer Assisted Radiology Intelligence [ATARI, Microsoft Nuance, Microsoft Corporation, Redmond, Washington]) and natural language processing (NLP) tools for identifying laterality errors in radiology reports and images.
Methods
We used an NLP-based (mPower, Microsoft Nuance) tool to identify radiology reports flagged for laterality errors in its Quality Assurance Dashboard. The NLP model detects and highlights laterality mismatches in radiology reports. From an initial pool of 1,124 radiology reports flagged by the NLP for laterality errors, we selected and evaluated 898 reports that encompassed radiography, CT, MRI, and ultrasound modalities to ensure comprehensive coverage. A radiologist reviewed each radiology report to assess if the flagged laterality errors were present (reporting error—true-positive) or absent (NLP error—false-positive). Next, we applied ATARI to 237 radiology reports and images with consecutive NLP true-positive (118 reports) and false-positive (119 reports) laterality errors. We estimated accuracy of NLP and generative AI tools to identify overall and modality-wise laterality errors.
Results
Among the 898 NLP-flagged laterality errors, 64% (574 of 898) had NLP errors and 36% (324 of 898) were reporting errors. The text query ATARI feature correctly identified the absence of laterality mismatch (NLP false-positives) with a 97.4% accuracy (115 of 118 reports; 95% confidence interval [CI] = 96.5%-98.3%). Combined vision and text query resulted in 98.3% accuracy (116 of 118 reports or images; 95% CI = 97.6%-99.0%), and query alone had a 98.3% accuracy (116 of 118 images; 95% CI = 97.6%-99.0%).
Conclusion
The generative AI-empowered ATARI prototype outperformed the assessed NLP tool for determining true and false laterality errors in radiology reports while enabling an image-based laterality determination. Underlying errors in ATARI text query in complex radiology reports emphasize the need for further improvement in the technology.}
}
@article{OGRADY2024S450,
title = {MSR63 Prompt Engineering for the Use of Generative Artificial Intelligence (AI) in Health Economic Modeling: Findings From a Targeted Literature Review},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S450},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2297},
url = {https://www.sciencedirect.com/science/article/pii/S109830152405160X},
author = {M O'Grady and N Adair and R Arguello and J Benner}
}
@article{DUAH2024180,
title = {How generative artificial intelligence has blurred notions of authorial identity and academic norms in higher education, necessitating clear university usage policies},
journal = {International Journal of Information and Learning Technology},
volume = {41},
number = {2},
pages = {180-193},
year = {2024},
issn = {2056-4880},
doi = {https://doi.org/10.1108/IJILT-11-2023-0213},
url = {https://www.sciencedirect.com/science/article/pii/S2056488024000015},
author = {James Ewert Duah and Paul McGivern},
keywords = {Students, Universities, Artificial intelligence, Education, Educational policy, Psychology},
abstract = {Purpose
This study examines the impact of generative artificial intelligence (GenAI), particularly ChatGPT, on higher education (HE). The ease with which content can be generated using GenAI has raised concerns across academia regarding its role in academic contexts, particularly regarding summative assessments. This research makes a unique contribution to the literature by examining university student and staff perceptions of current and future issues pertaining to the role of GenAI in universities.
Design/methodology/approach
A qualitative method involving five one-to-one semi-structured interviews with four students and a lecturer explored the ethical and practical issues of GenAI text generation in academia. An inductive thematic analysis was chosen as it provided nuanced insights aligned with the study’s goals.
Findings
Use of GenAI was discussed within the context of a range of topics, including perceptions of academic misconduct, authorial integrity and issues pertaining to university policies. Participants universally defined traditional classifications of academic misconduct but were unable to provide clear definitions where the use of GenAI was included for writing summative assessments. Students showed a more open engagement with GenAI, considering it a tool for overcoming obstacles rather than a means to plagiarise. Educators were generally more cautious and less optimistic about the academic role of GenAI. Lack of clear institutional policies surrounding such tools also contributed to ethical ambiguities.
Originality/value
The study highlights diverging perspectives between students and academics, which necessitate a forum for dialogue, ensuring the need to develop clear policies to steer the integration of GenAI in a manner that is beneficial for students and academics.}
}
@incollection{MUKHUTY202537,
title = {Chapter 3 - Industry 5.0 era of digital supply chain: A generative artificial intelligence (GenAI) action model for workforce engagement},
editor = {Syed Abdul Rehman Khan and Adnan Ahmed Sheikh and Jyri Vilko and Sajid Nazir and Mahmood Ali and Marko Torkkeli},
booktitle = {Technological Innovations and Industry 5.0},
publisher = {Elsevier},
pages = {37-53},
year = {2025},
series = {Developments and Advances in the Supply Chain Industry},
isbn = {978-0-443-33813-7},
doi = {https://doi.org/10.1016/B978-0-443-33813-7.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443338137000038},
author = {Sumona Mukhuty and Robert Dixon and Arvind Upadhyay},
keywords = {Generative artificial intelligence, Industry 4.0, Industry 5.0, Productivity enhancement, Supply chains},
abstract = {Industry 5.0 advocates triangulating the technology-centric emphasis of Industry 4.0 with human-centricity and sustainability. The focus is on creating an inclusive work environment facilitating human-machine reconciliation leading to “sustainable social welfare.” Within this context, the advent and accessibility of generative artificial intelligence (GenAI) have been received with equal measures of excitement and existential dread. This is a major disruptive digital technology that has begun to shake the equilibrium and stability of business survival and job security. Yet, the potential of GenAI in enhancing efficiency is revolutionary, spanning all sectors, including supply chains. Organizational success within the Industry 5.0 context is heavily dependent on the appropriate skills and capabilities. However, the rapid advancement and adoption of GenAI has left organizations with severe knowledge and skills gaps. In this study, we conduct a succinct review of GenAI’s impact on supply chains. Thereafter we draw upon strategic management theories and organizational change theories to develop an organizational GenAI action model to enable supply chain organizations to transition workers from a state of “unconscious GenAI incompetence” to “conscious GenAI competence,” working through the five stages of the model: getting urgent, exploration, formulation, iteration, and embedding. We will predominantly draw upon high-impact peer-reviewed articles, complemented by relevant gray literature, including the European Commission publications, in developing this review and conceptual model. We will close by highlighting the model’s applicability and future research directions.}
}
@article{CHONG2025103583,
title = {1345 A Generative Artificial Intelligence Framework for Automated Pathologic Diagnosis of Gastric Endoscopic Biopsy Samples},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103583},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103583},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032616},
author = {Yosep Chong and Anh Nguyen and Jin Sol Song and Kwangil Yim and Jumi Park and Jin Tae Kwak}
}
@article{YASSIN2025102284,
title = {Evaluating a generative artificial intelligence accuracy in providing medication instructions from smartphone images},
journal = {Journal of the American Pharmacists Association},
volume = {65},
number = {1},
pages = {102284},
year = {2025},
issn = {1544-3191},
doi = {https://doi.org/10.1016/j.japh.2024.102284},
url = {https://www.sciencedirect.com/science/article/pii/S1544319124003157},
author = {Yusef Yassin and Thien Nguyen and Krishna Panchal and Katharine Getchell and Timothy Aungst},
abstract = {Background
The Food and Drug Administration mandates patient labeling materials like the Medication Guide (MG) and Instructions for Use (IFU) to support appropriate medication use. However, challenges such as low health literacy and difficulties navigating these materials may lead to incorrect medication usage, resulting in therapy failure or adverse outcomes. The rise of generative AI, presents an opportunity to provide scalable, personalized patient education through image recognition and text generation.
Objective
This study aimed to evaluate the accuracy and safety of medication instructions generated by ChatGPT based on user-provided drug images, compared to the manufacturer's standard instructions.
Methods
Images of 12 medications requiring multiple steps for administration were uploaded to ChatGPT's image recognition function. ChatGPT's responses were compared to the official IFU and MG using text classifiers, Count Vectorization (CountVec), and Term Frequency-Inverse Document Frequency (TF-IDF). The clinical accuracy was further evaluated by independent pharmacists to determine if ChatGPT responses were valid for patient instruction.
Results
ChatGPT correctly identified all medications and generated patient instructions. CountVec outperformed TF-IDF in text similarity analysis, with an average similarity score of 76%. However, clinical evaluation revealed significant gaps in the instructions, particularly for complex administration routes, where ChatGPT's guidance lacked essential details, leading to lower clinical accuracy scores.
Conclusion
While ChatGPT shows promise in generating patient-friendly medication instructions, its effectiveness varies based on the complexity of the medication. The findings underscore the need for further refinement and clinical oversight to ensure the safety and accuracy of AI-generated medical guidance, particularly for medications with complex administration processes.}
}
@article{TEIXEIRADASILVA2025111607,
title = {Editing companies have the responsibility of ensuring their declared use of generative artificial intelligence},
journal = {Journal of Clinical Epidemiology},
volume = {177},
pages = {111607},
year = {2025},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2024.111607},
url = {https://www.sciencedirect.com/science/article/pii/S0895435624003639},
author = {Jaime A. {Teixeira da Silva}}
}
@article{TAN2023100394,
title = {Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology: Clinical Applications and Challenges},
journal = {Ophthalmology Science},
volume = {3},
number = {4},
pages = {100394},
year = {2023},
issn = {2666-9145},
doi = {https://doi.org/10.1016/j.xops.2023.100394},
url = {https://www.sciencedirect.com/science/article/pii/S2666914523001264},
author = {Ting Fang Tan and Arun James Thirunavukarasu and J. Peter Campbell and Pearse A. Keane and Louis R. Pasquale and Michael D. Abramoff and Jayashree Kalpathy-Cramer and Flora Lum and Judy E. Kim and Sally L. Baxter and Daniel Shu Wei Ting},
keywords = {Artificial intelligence, Chatbots, ChatGPT, Large language models},
abstract = {The rapid progress of large language models (LLMs) driving generative artificial intelligence applications heralds the potential of opportunities in health care. We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and Scopus using the following terms: “large language models,” “generative artificial intelligence,” “ophthalmology,” “ChatGPT,” and “eye,” based on relevance to this review. From a clinical viewpoint specific to ophthalmologists, we explore from the different stakeholders’ perspectives—including patients, physicians, and policymakers—the potential LLM applications in education, research, and clinical domains specific to ophthalmology. We also highlight the foreseeable challenges of LLM implementation into clinical practice, including the concerns of accuracy, interpretability, perpetuating bias, and data security. As LLMs continue to mature, it is essential for stakeholders to jointly establish standards for best practices to safeguard patient safety.
Financial Disclosure(s)
Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article.}
}
@article{OOI2025417,
title = {Unveiling the potential of generative artificial intelligence: a multidimensional journey into the future},
journal = {Industrial Management & Data Systems},
volume = {125},
number = {2},
pages = {417-432},
year = {2025},
issn = {0263-5577},
doi = {https://doi.org/10.1108/IMDS-10-2023-0703},
url = {https://www.sciencedirect.com/science/article/pii/S0263557724000228},
author = {Keng-Boon Ooi and Alex Koohang and Eugene Cheng-Xi Aw and Tat-Huei Cham and Cihan Cobanoglu and Charles Dennis and Yogesh K Dwivedi and Jun-Jie Hew and Heather {Linton Kelly} and Laurie Hughes and Chieh-Yu Lin and Anubhav Mishra and Ian Phau and Ramakrishnan Raman and Marianna Sigala and Yun-Chia Tang and Lai-Wan Wong and Garry Wei-Han Tan},
keywords = {Generative artificial intelligence, Artificial intelligence, Large language model, ChatGPT, Hospitality, Tourism, Marketing, Retailing, Service operations, Manufacturing, Healthcare},
abstract = {Purpose
The launch of ChatGPT has brought the large language model (LLM)-based generative artificial intelligence (GAI) into the spotlight, triggering the interests of various stakeholders to seize the possible opportunities implicated by it. Nevertheless, there are also challenges that the stakeholders should observe when they are considering the potential of GAI. Given this backdrop, this study presents the viewpoints gathered from various subject experts on six identified areas.
Design/methodology/approach
Through an expert-based approach, this paper gathers the viewpoints of various subject experts on the identified areas of tourism and hospitality, marketing, retailing, service operations, manufacturing and healthcare.
Findings
The subject experts first share an overview of the use of GAI, followed by the relevant opportunities and challenges in implementing GAI in each identified area. Afterwards, based on the opportunities and challenges, the subject experts propose several research agendas for the stakeholders to consider.
Originality/value
This paper serves as a frontier in exploring the opportunities and challenges implicated by the GAI in six identified areas that this emerging technology would considerably influence. It is believed that the viewpoints offered by the subject experts would enlighten the stakeholders in the identified areas.}
}
@article{ROWE2024469,
title = {Artificial intelligence in radiation therapy: An emerging revolution that will be driven by generative methodologies},
journal = {Diagnostic and Interventional Imaging},
volume = {105},
number = {12},
pages = {469-470},
year = {2024},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2024.09.006},
url = {https://www.sciencedirect.com/science/article/pii/S2211568424001992},
author = {Steven P. Rowe and N. Ari Wijetunga},
keywords = {Artificial intelligence, Generative AI, Large-language models, Machine learning, Radiation therapy}
}
@article{ZENG2024,
title = {Assessing the Role of the Generative Pretrained Transformer (GPT) in Alzheimer’s Disease Management: Comparative Study of Neurologist- and Artificial Intelligence–Generated Responses},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/51095},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124007325},
author = {Jiaqi Zeng and Xiaoyi Zou and Shirong Li and Yao Tang and Sisi Teng and Huanhuan Li and Changyu Wang and Yuxuan Wu and Luyao Zhang and Yunheng Zhong and Jialin Liu and Siru Liu},
keywords = {Alzheimer's disease, artificial intelligence, AI, large language model, LLM, Generative Pretrained Transformer, GPT, ChatGPT, patient information},
abstract = {Background
Alzheimer’s disease (AD) is a progressive neurodegenerative disorder posing challenges to patients, caregivers, and society. Accessible and accurate information is crucial for effective AD management.
Objective
This study aimed to evaluate the accuracy, comprehensibility, clarity, and usefulness of the Generative Pretrained Transformer’s (GPT) answers concerning the management and caregiving of patients with AD.
Methods
In total, 14 questions related to the prevention, treatment, and care of AD were identified and posed to GPT-3.5 and GPT-4 in Chinese and English, respectively, and 4 respondent neurologists were asked to answer them. We generated 8 sets of responses (total 112) and randomly coded them in answer sheets. Next, 5 evaluator neurologists and 5 family members of patients were asked to rate the 112 responses using separate 5-point Likert scales. We evaluated the quality of the responses using a set of 8 questions rated on a 5-point Likert scale. To gauge comprehensibility and participant satisfaction, we included 3 questions dedicated to each aspect within the same set of 8 questions.
Results
As of April 10, 2023, the 5 evaluator neurologists and 5 family members of patients with AD rated the 112 responses: GPT-3.5: n=28, 25%, responses; GPT-4: n=28, 25%, responses; respondent neurologists: 56 (50%) responses. The top 5 (4.5%) responses rated by evaluator neurologists had 4 (80%) GPT (GPT-3.5+GPT-4) responses and 1 (20%) respondent neurologist’s response. For the top 5 (4.5%) responses rated by patients’ family members, all but the third response were GPT responses. Based on the evaluation by neurologists, the neurologist-generated responses achieved a mean score of 3.9 (SD 0.7), while the GPT-generated responses scored significantly higher (mean 4.4, SD 0.6; P<.001). Language and model analyses revealed no significant differences in response quality between the GPT-3.5 and GPT-4 models (GPT-3.5: mean 4.3, SD 0.7; GPT-4: mean 4.4, SD 0.5; P=.51). However, English responses outperformed Chinese responses in terms of comprehensibility (Chinese responses: mean 4.1, SD 0.7; English responses: mean 4.6, SD 0.5; P=.005) and participant satisfaction (Chinese responses: mean 4.2, SD 0.8; English responses: mean 4.5, SD 0.5; P=.04). According to the evaluator neurologists’ review, Chinese responses had a mean score of 4.4 (SD 0.6), whereas English responses had a mean score of 4.5 (SD 0.5; P=.002). As for the family members of patients with AD, no significant differences were observed between GPT and neurologists, GPT-3.5 and GPT-4, or Chinese and English responses.
Conclusions
GPT can provide patient education materials on AD for patients, their families and caregivers, nurses, and neurologists. This capability can contribute to the effective health care management of patients with AD, leading to enhanced patient outcomes.}
}
@article{PREIKSAITIS2023,
title = {Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review},
journal = {JMIR Medical Education},
volume = {9},
year = {2023},
issn = {2369-3762},
doi = {https://doi.org/10.2196/48785},
url = {https://www.sciencedirect.com/science/article/pii/S2369376223000697},
author = {Carl Preiksaitis and Christian Rose},
keywords = {medical education, artificial intelligence, ChatGPT, Bard, AI, educator, scoping, review, learner, generative},
abstract = {Background
Generative artificial intelligence (AI) technologies are increasingly being utilized across various fields, with considerable interest and concern regarding their potential application in medical education. These technologies, such as Chat GPT and Bard, can generate new content and have a wide range of possible applications.
Objective
This study aimed to synthesize the potential opportunities and limitations of generative AI in medical education. It sought to identify prevalent themes within recent literature regarding potential applications and challenges of generative AI in medical education and use these to guide future areas for exploration.
Methods
We conducted a scoping review, following the framework by Arksey and O'Malley, of English language articles published from 2022 onward that discussed generative AI in the context of medical education. A literature search was performed using PubMed, Web of Science, and Google Scholar databases. We screened articles for inclusion, extracted data from relevant studies, and completed a quantitative and qualitative synthesis of the data.
Results
Thematic analysis revealed diverse potential applications for generative AI in medical education, including self-directed learning, simulation scenarios, and writing assistance. However, the literature also highlighted significant challenges, such as issues with academic integrity, data accuracy, and potential detriments to learning. Based on these themes and the current state of the literature, we propose the following 3 key areas for investigation: developing learners’ skills to evaluate AI critically, rethinking assessment methodology, and studying human-AI interactions.
Conclusions
The integration of generative AI in medical education presents exciting opportunities, alongside considerable challenges. There is a need to develop new skills and competencies related to AI as well as thoughtful, nuanced approaches to examine the growing use of generative AI in medical education.}
}
@article{GALHOTRA2025S19,
title = {ID: 4349993 QUALITATIVE EVALUATION FRAMEWORK FOR COMPARING THE EFFECTIVENESS OF LARGE LANGUAGE MODELS THAT POWER HEALTH CARE CONVERSATIONS USING GENERATIVE ARTIFICIAL INTELLIGENCE IN ATRIAL FIBRILLATION},
journal = {Heart Rhythm O2},
volume = {6},
number = {9, Supplement },
pages = {S19-S20},
year = {2025},
note = {HRX AbstracX 2025},
issn = {2666-5018},
doi = {https://doi.org/10.1016/j.hroo.2025.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S2666501825003241},
author = {Sainyam Galhotra and Hemang Jiwnani and Audrey Nicholson and Prashanthan Sanders and Ajay Tripuraneni}
}
@article{AHMED20241975,
title = {Generative Artificial Intelligence Tools in Gastroenterology Training},
journal = {Clinical Gastroenterology and Hepatology},
volume = {22},
number = {10},
pages = {1975-1978},
year = {2024},
issn = {1542-3565},
doi = {https://doi.org/10.1016/j.cgh.2024.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S1542356524006001},
author = {Tasnim Ahmed and Loren G. Rabinowitz and Adam Rodman and Tyler M. Berzin}
}
@article{SHLOBIN2024e398,
title = {Opportunities and Considerations for the Incorporation of Artificial Intelligence into Global Neurosurgery: A Generative Pretrained Transformer Chatbot-Based Approach},
journal = {World Neurosurgery},
volume = {186},
pages = {e398-e412},
year = {2024},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2024.03.149},
url = {https://www.sciencedirect.com/science/article/pii/S1878875024005357},
author = {Nathan A. Shlobin and Gail Rosseau},
keywords = {Global health, Global neurosurgery, Global surgery, International development, Public health},
abstract = {Objective
Global neurosurgery is a public health focus in neurosurgery that seeks to ensure safe, timely, and affordable neurosurgical care to all individuals worldwide. Although investigators have begun to explore the promise of artificial intelligence (AI) for neurosurgery, its applicability to global neurosurgery has been largely hypothetical. We characterize opportunities and considerations for the incorporation of AI into global neurosurgery by synthesizing key themes yielded from a series of generative pretrained transformers (GPTs), discuss important limitations of GPTs and cautions when using AI in neurosurgery, and develop a framework for the equitable incorporation of AI into global neurosurgery.
Methods
ChatGPT, Bing Chat/Copilot, You, Perplexity.ai, and Google Bard were queried with the prompt “How can AI be incorporated into global neurosurgery?” A layered ChatGPT-based thematic analysis was performed. The authors synthesized the results into opportunities and considerations for the incorporation of AI in global neurosurgery. A Pareto analysis was conducted to determine common themes.
Results
Eight opportunities and 14 important considerations were synthesized. Six opportunities related to patient care, 1 to education, and another to public health planning. Four of the important considerations were deemed specific to global neurosurgery. The Pareto analysis included all 8 opportunities and 5 considerations.
Conclusions
AI may be incorporated into global neurosurgery in a variety of capacities requiring numerous considerations. The framework presented in this manuscript may facilitate the incorporation of AI into global neurosurgery initiatives while balancing contextual factors and the reality of limited resources.}
}
@article{RODRIGUES202578,
title = {Simulating social dynamics with artificial intelligence: Comment on “LLMs and generative agent-based models for complex systems research” by Yikang Lu et al.},
journal = {Physics of Life Reviews},
volume = {54},
pages = {78-79},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000910},
author = {Francisco A. Rodrigues and Paula Giovanna Rodrigues}
}
@article{SINGH2024100531,
title = {Characterizing generative artificial intelligence applications: Text-mining-enabled technology roadmapping},
journal = {Journal of Innovation & Knowledge},
volume = {9},
number = {3},
pages = {100531},
year = {2024},
issn = {2444-569X},
doi = {https://doi.org/10.1016/j.jik.2024.100531},
url = {https://www.sciencedirect.com/science/article/pii/S2444569X24000702},
author = {Shiwangi Singh and Surabhi Singh and Sascha Kraus and Anuj Sharma and Sanjay Dhir},
keywords = {Generative AI, Technology roadmapping, Patents, Text-mining, Structural topic modeling, Patent data mining},
abstract = {This study aims to identify generative AI (GenAI) applications and develop a roadmap for the near, mid, and far future. Structural topic modeling (STM) is used to discover latent semantic patterns and identify the key application areas from a text corpus comprising 2,398 patents published between 2017 and 2023. The study identifies six latent topics of GenAI application, including object detection and identification; medical applications; intelligent conversational agents; image generation and processing; financial and information security applications; and cyber-physical systems. Emergent topic terms are listed for each topic, and inter-topic correlations are explored to understand the thematic structures and summarize the semantic relationships among GenAI application areas. Finally, a technology roadmap is developed for each identified application area for the near, mid, and far future. This study provides valuable insights into the evolving GenAI landscape and helps practitioners make strategic business decisions based on the GenAI roadmap.}
}
@article{SATURNO2023248,
title = {Generative artificial intelligence fails to provide sufficiently accurate recommendations when compared to established breast reconstruction surgery guidelines},
journal = {Journal of Plastic, Reconstructive & Aesthetic Surgery},
volume = {86},
pages = {248-250},
year = {2023},
issn = {1748-6815},
doi = {https://doi.org/10.1016/j.bjps.2023.09.030},
url = {https://www.sciencedirect.com/science/article/pii/S1748681523005247},
author = {Michael P. Saturno and Mateo Restrepo Mejia and Anya Wang and Daniel Kwon and Olachi Oleru and Nargiz Seyidova and Peter W. Henderson},
keywords = {Large language model, ChatGPT, Artificial intelligence, Reconstructive breast surgery, Plastic and reconstructive surgery, Guidelines}
}
@article{CHAU2024616,
title = {Performance of Generative Artificial Intelligence in Dental Licensing Examinations},
journal = {International Dental Journal},
volume = {74},
number = {3},
pages = {616-621},
year = {2024},
issn = {0020-6539},
doi = {https://doi.org/10.1016/j.identj.2023.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0020653923009899},
author = {Reinhard Chun Wang Chau and Khaing Myat Thu and Ollie Yiru Yu and Richard Tai-Chiu Hsung and Edward Chin Man Lo and Walter Yu Hang Lam},
keywords = {Artificial intelligence, Communication, Dental education, Digital technology, Examination questions, Specialties, Dental},
abstract = {ABSTRACT
Objectives
Generative artificial intelligence (GenAI), including large language models (LLMs), has vast potential applications in health care and education. However, it is unclear how proficient LLMs are in interpreting written input and providing accurate answers in dentistry. This study aims to investigate the accuracy of GenAI in answering questions from dental licensing examinations.
Methods
A total of 1461 multiple-choice questions from question books for the US and the UK dental licensing examinations were input into 2 versions of ChatGPT 3.5 and 4.0. The passing rates of the US and UK dental examinations were 75.0% and 50.0%, respectively. The performance of the 2 versions of GenAI in individual examinations and dental subjects was analysed and compared.
Results
ChatGPT 3.5 correctly answered 68.3% (n = 509) and 43.3% (n = 296) of questions from the US and UK dental licensing examinations, respectively. The scores for ChatGPT 4.0 were 80.7% (n = 601) and 62.7% (n = 429), respectively. ChatGPT 4.0 passed both written dental licensing examinations, whilst ChatGPT 3.5 failed. ChatGPT 4.0 answered 327 more questions correctly and 102 incorrectly compared to ChatGPT 3.5 when comparing the 2 versions.
Conclusions
The newer version of GenAI has shown good proficiency in answering multiple-choice questions from dental licensing examinations. Whilst the more recent version of GenAI generally performed better, this observation may not hold true in all scenarios, and further improvements are necessary. The use of GenAI in dentistry will have significant implications for dentist–patient communication and the training of dental professionals.}
}
@article{BREWER2024525,
title = {Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {525-535},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.04.011},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000569},
author = {Jordan Brewer and Dhru Patel and Dennie Kim and Alex Murray},
keywords = {Blockcain, Generative artificial intelligence (GenAI), ChatGPT, Large language models (LLMs), Chatbots},
abstract = {The transformative impact of generative AI (GenAI), extending beyond traditional AI, raises numerous concerns including the replacement of human roles and AI misuse in an array of industries. This article introduces blockchain technology as a complementary technological safeguard to address some of these challenges. We emphasize blockchain’s role in promoting transparency, verifiability, and decentralization in AI development and usage, thereby offering potential solutions for four distinct challenges: (1) AI toxicity, biases, hallucinations, (2) AI interest misalignment, (3) AI as a black box, and (4) AI misuse. This article proposes ways to ensure responsible and transparent AI usage through the integration of blockchain. We position the convergence of AI and blockchain as a means to manage AI’s societal impact and unlock its benefits—contingent upon collaborative efforts among various stakeholders such as businesses, developers, and regulatory bodies. We contribute to the discourse on ethical AI usage and the potential of blockchain to enhance AI’s reliability and accountability for organizations.}
}
@article{WANG2023100516,
title = {Large-scale generative simulation artificial intelligence: The next hotspot},
journal = {The Innovation},
volume = {4},
number = {6},
pages = {100516},
year = {2023},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2023.100516},
url = {https://www.sciencedirect.com/science/article/pii/S2666675823001443},
author = {Qi Wang and Yanghe Feng and Jincai Huang and Yiqin Lv and Zheng Xie and Xiaoshan Gao}
}
@article{ABOGUNRIN2024S482,
title = {MSR224 Generative Artificial Intelligence: An Effective Alternative for Screening Titles and Abstracts in Systematic Literature Reviews},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S482},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2457},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524053208},
author = {S Abogunrin and RR Sieiro and M Lane}
}
@article{SHAPIRO2024492,
title = {Revolutionizing teledermatology: Exploring the integration of artificial intelligence, including Generative Pre-trained Transformer chatbots for artificial intelligence-driven anamnesis, diagnosis, and treatment plans},
journal = {Clinics in Dermatology},
volume = {42},
number = {5},
pages = {492-497},
year = {2024},
note = {Artificial Intelligence II},
issn = {0738-081X},
doi = {https://doi.org/10.1016/j.clindermatol.2024.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0738081X24001044},
author = {Jonathan Shapiro and Anna Lyakhovitsky},
abstract = {The integration of teledermatology and artificial intelligence (AI) marks a significant advancement in dermatologic care. This study examines the synergistic interplay between these two domains, highlighting their collective impact on enhancing the accuracy, accessibility, and efficiency of teledermatologic services. Teledermatology expands dermatologic care to remote and underserved areas, and AI technologies show considerable potential in analyzing dermatologic images and performing various tasks involved in teledermatology consultations. Such integration facilitates rapid, precise diagnoses, personalized treatment plans, and data-driven insights. Our explorative study involved designing a GPT-based chatbot named “Dr. DermBot” and exploring its performance in a teledermatologic consultation process. The design phase focused on the chatbot's ability to conduct consultations autonomously. The subsequent testing phase assessed its performance against the backdrop of current teledermatologic practices, exploring the potential of AI and chatbots to simulate and potentially enhance teledermatologic health care. Our study demonstrates the promising future of combining teledermatology with AI. It also brings to light ethical and legal concerns, including the protection of patient data privacy and adherence to regulatory standards. The union of teledermatology and AI not only aims to enhance the precision of teledermatologic diagnoses but also broadens the accessibility of dermatologic services to previously underserved populations, benefiting patients, health care providers, and the overall health care system.}
}
@article{ZHAO2024191,
title = {Employees’ perception of generative artificial intelligence and the dark side of work outcomes},
journal = {Journal of Hospitality and Tourism Management},
volume = {61},
pages = {191-199},
year = {2024},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2024.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S1447677024001207},
author = {Hairong Zhao and Bocong Yuan and Yang Song},
keywords = {, , },
abstract = {Artificial intelligence (as well as generative AI) has been increasingly applied in the tourism and hospitality industry and has an important impact on the work behavior of practitioners. Drawing from the transactional theory of stress and coping, this study is to clarify the mechanism of potential negative impact of AI on the work outcomes of tourism and hospitality practitioners who use generative AI (GenAI) to assist their work. This study conducts in-depth interviews and thematic analysis to explore how the use of GenAI affects negative work behaviors among tourism and hospitality practitioners. The results show that employees’ technical fear towards AI is negatively associated with their sense of realism, self-investment, and habitual perception, but positively associated with the perceived threat of job intelligence to employment. Moreover, the technical fear towards AI can be positively associated with their transgression behavior. The findings of this study can be illuminating for helping tourism and hospitality organizations develop sustainable and healthy workplace guidelines.}
}
@article{ZHUANG2024102122,
title = {From hearing to seeing: Linking auditory and visual place perceptions with soundscape-to-image generative artificial intelligence},
journal = {Computers, Environment and Urban Systems},
volume = {110},
pages = {102122},
year = {2024},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2024.102122},
url = {https://www.sciencedirect.com/science/article/pii/S0198971524000516},
author = {Yonggai Zhuang and Yuhao Kang and Teng Fei and Meng Bian and Yunyan Du},
keywords = {Soundscape, Street view images, Sense of place, Stable diffusion, Generative AI, LLMs},
abstract = {People experience the world through multiple senses simultaneously, contributing to our sense of place. Prior quantitative geography studies have mostly emphasized human visual perceptions, neglecting human auditory perceptions at place due to the challenges in characterizing the acoustic environment vividly. Also, few studies have synthesized the two-dimensional (auditory and visual) perceptions in understanding human sense of place. To bridge these gaps, we propose a Soundscape-to-Image Diffusion model, a generative Artificial Intelligence (AI) model supported by Large Language Models (LLMs), aiming to visualize soundscapes through the generation of street view images. By creating audio-image pairs, acoustic environments are first represented as high-dimensional semantic audio vectors. Our proposed Soundscape-to-Image Diffusion model, which contains a Low-Resolution Diffusion Model and a Super-Resolution Diffusion Model, can then translate those semantic audio vectors into visual representations of place effectively. We evaluated our proposed model by using both machine-based and human-centered approaches. We proved that the generated street view images align with our common perceptions, and accurately create several key street elements of the original soundscapes. It also demonstrates that soundscapes provide sufficient visual information places. This study stands at the forefront of the intersection between generative AI and human geography, demonstrating how human multi-sensory experiences can be linked. We aim to enrich geospatial data science and AI studies with human experiences. It has the potential to inform multiple domains such as human geography, environmental psychology, and urban design and planning, as well as advancing our knowledge of human-environment relationships.}
}
@article{JEHA20232105,
title = {ChatGPT and Generative Artificial Intelligence in Mohs Surgery: A New Frontier of Innovation},
journal = {Journal of Investigative Dermatology},
volume = {143},
number = {11},
pages = {2105-2107},
year = {2023},
issn = {0022-202X},
doi = {https://doi.org/10.1016/j.jid.2023.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0022202X23021425},
author = {George M. Jeha and Sultan Qiblawi and Neil Jairath and Kimberly Sable and Keith LeBlanc and Juliet Aylward and Yaohui Gloria Xu}
}
@article{BRAGAZZI2024,
title = {Assessing the Accuracy of Generative Conversational Artificial Intelligence in Debunking Sleep Health Myths: Mixed Methods Comparative Study With Expert Analysis},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/55762},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24002178},
author = {Nicola Luigi Bragazzi and Sergio Garbarino},
keywords = {sleep, sleep health, sleep-related disbeliefs, generative conversational artificial intelligence, chatbot, ChatGPT, misinformation, artificial intelligence, comparative study, expert analysis, adequate sleep, well-being, sleep trackers, sleep health education, sleep-related, chronic disease, healthcare cost, sleep timing, sleep duration, presleep behaviors, sleep experts, healthy behavior, public health, conversational agents},
abstract = {Background
Adequate sleep is essential for maintaining individual and public health, positively affecting cognition and well-being, and reducing chronic disease risks. It plays a significant role in driving the economy, public safety, and managing health care costs. Digital tools, including websites, sleep trackers, and apps, are key in promoting sleep health education. Conversational artificial intelligence (AI) such as ChatGPT (OpenAI, Microsoft Corp) offers accessible, personalized advice on sleep health but raises concerns about potential misinformation. This underscores the importance of ensuring that AI-driven sleep health information is accurate, given its significant impact on individual and public health, and the spread of sleep-related myths.
Objective
This study aims to examine ChatGPT’s capability to debunk sleep-related disbeliefs.
Methods
A mixed methods design was leveraged. ChatGPT categorized 20 sleep-related myths identified by 10 sleep experts and rated them in terms of falseness and public health significance, on a 5-point Likert scale. Sensitivity, positive predictive value, and interrater agreement were also calculated. A qualitative comparative analysis was also conducted.
Results
ChatGPT labeled a significant portion (n=17, 85%) of the statements as “false” (n=9, 45%) or “generally false” (n=8, 40%), with varying accuracy across different domains. For instance, it correctly identified most myths about “sleep timing,” “sleep duration,” and “behaviors during sleep,” while it had varying degrees of success with other categories such as “pre-sleep behaviors” and “brain function and sleep.” ChatGPT’s assessment of the degree of falseness and public health significance, on the 5-point Likert scale, revealed an average score of 3.45 (SD 0.87) and 3.15 (SD 0.99), respectively, indicating a good level of accuracy in identifying the falseness of statements and a good understanding of their impact on public health. The AI-based tool showed a sensitivity of 85% and a positive predictive value of 100%. Overall, this indicates that when ChatGPT labels a statement as false, it is highly reliable, but it may miss identifying some false statements. When comparing with expert ratings, high intraclass correlation coefficients (ICCs) between ChatGPT’s appraisals and expert opinions could be found, suggesting that the AI’s ratings were generally aligned with expert views on falseness (ICC=.83, P<.001) and public health significance (ICC=.79, P=.001) of sleep-related myths. Qualitatively, both ChatGPT and sleep experts refuted sleep-related misconceptions. However, ChatGPT adopted a more accessible style and provided a more generalized view, focusing on broad concepts, while experts sometimes used technical jargon, providing evidence-based explanations.
Conclusions
ChatGPT-4 can accurately address sleep-related queries and debunk sleep-related myths, with a performance comparable to sleep experts, even if, given its limitations, the AI cannot completely replace expert opinions, especially in nuanced and complex fields such as sleep health, but can be a valuable complement in the dissemination of updated information and promotion of healthy behaviors.}
}
@article{COSCI2025112113,
title = {Generative artificial intelligence: A hot topic to face with},
journal = {Journal of Psychosomatic Research},
volume = {192},
pages = {112113},
year = {2025},
issn = {0022-3999},
doi = {https://doi.org/10.1016/j.jpsychores.2025.112113},
url = {https://www.sciencedirect.com/science/article/pii/S0022399925000777},
author = {Fiammetta Cosci and Antonina Mikocka-Walus}
}
@article{ASHRAF2024,
title = {Search Engines and Generative Artificial Intelligence Integration: Public Health Risks and Recommendations to Safeguard Consumers Online},
journal = {JMIR Public Health and Surveillance},
volume = {10},
year = {2024},
issn = {2369-2960},
doi = {https://doi.org/10.2196/53086},
url = {https://www.sciencedirect.com/science/article/pii/S2369296024000504},
author = {Amir Reza Ashraf and Tim Ken Mackey and András Fittler},
keywords = {generative artificial intelligence, artificial intelligence, comparative assessment, search engines, online pharmacies, patient safety, generative, safety, search engine, search, searches, searching, website, websites, Google, Bing, retrieval, information seeking, illegal, pharmacy, pharmacies, risk, risks, consumer, consumers, customer, customers, recommendation, recommendations, vendor, vendors, substance use, substance abuse, controlled substances, controlled substance, drug, drugs, pharmaceutic, pharmaceutics, pharmaceuticals, pharmaceutical, medication, medications},
abstract = {Background
The online pharmacy market is growing, with legitimate online pharmacies offering advantages such as convenience and accessibility. However, this increased demand has attracted malicious actors into this space, leading to the proliferation of illegal vendors that use deceptive techniques to rank higher in search results and pose serious public health risks by dispensing substandard or falsified medicines. Search engine providers have started integrating generative artificial intelligence (AI) into search engine interfaces, which could revolutionize search by delivering more personalized results through a user-friendly experience. However, improper integration of these new technologies carries potential risks and could further exacerbate the risks posed by illicit online pharmacies by inadvertently directing users to illegal vendors.
Objective
The role of generative AI integration in reshaping search engine results, particularly related to online pharmacies, has not yet been studied. Our objective was to identify, determine the prevalence of, and characterize illegal online pharmacy recommendations within the AI-generated search results and recommendations.
Methods
We conducted a comparative assessment of AI-generated recommendations from Google’s Search Generative Experience (SGE) and Microsoft Bing’s Chat, focusing on popular and well-known medicines representing multiple therapeutic categories including controlled substances. Websites were individually examined to determine legitimacy, and known illegal vendors were identified by cross-referencing with the National Association of Boards of Pharmacy and LegitScript databases.
Results
Of the 262 websites recommended in the AI-generated search results, 47.33% (124/262) belonged to active online pharmacies, with 31.29% (82/262) leading to legitimate ones. However, 19.04% (24/126) of Bing Chat’s and 13.23% (18/136) of Google SGE’s recommendations directed users to illegal vendors, including for controlled substances. The proportion of illegal pharmacies varied by drug and search engine. A significant difference was observed in the distribution of illegal websites between search engines. The prevalence of links leading to illegal online pharmacies selling prescription medications was significantly higher (P=.001) in Bing Chat (21/86, 24%) compared to Google SGE (6/92, 6%). Regarding the suggestions for controlled substances, suggestions generated by Google led to a significantly higher number of rogue sellers (12/44, 27%; P=.02) compared to Bing (3/40, 7%).
Conclusions
While the integration of generative AI into search engines offers promising potential, it also poses significant risks. This is the first study to shed light on the vulnerabilities within these platforms while highlighting the potential public health implications associated with their inadvertent promotion of illegal pharmacies. We found a concerning proportion of AI-generated recommendations that led to illegal online pharmacies, which could not only potentially increase their traffic but also further exacerbate existing public health risks. Rigorous oversight and proper safeguards are urgently needed in generative search to mitigate consumer risks, making sure to actively guide users to verified pharmacies and prioritize legitimate sources while excluding illegal vendors from recommendations.}
}
@article{BONNET2024,
title = {Unfolding the Potential of Generative Artificial Intelligence:},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2024},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.368223},
url = {https://www.sciencedirect.com/science/article/pii/S154806662500013X},
author = {Severin Bonnet and Frank Teuteberg},
keywords = {Generative AI Chatbots, Artificial Intelligence, AI Based Chatbots, Academic Research, ChatGPT},
abstract = {ABSTRACT
Scholars are increasingly using generative artificial intelligence (AI) chatbots, like ChatGPT, in research, though concerns remain about ethics, data privacy, bias, and intellectual property. This study adopts a design science research approach to explore how generative AI chatbots can support academic teaching and research, bridging theory and practice. A literature review and expert interviews identified key requirements and design principles that support virtues such as uniqueness, generalizability, and reproducibility. We also introduce a prototype, “AcademiaBot,” to demonstrate these principles in action. Our findings suggest that AI chatbots can significantly aid scholarly work if users are informed and ethical concerns are addressed. Responsible usage can help AI augment human research efforts without compromising integrity. This study provides valuable design knowledge, ensuring AI-based chatbots remain a beneficial tool for scholars.}
}
@article{ESMAEILI2024127676,
title = {Enhancing digital rock analysis through generative artificial intelligence: Diffusion models},
journal = {Neurocomputing},
volume = {587},
pages = {127676},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127676},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224004478},
author = {Mohammad Esmaeili},
keywords = {Diffusion Models, Generative Artificial Intelligence, Computer Vision, Digital Rock Analysis, Single Image Super-Resolution},
abstract = {Within the realm of computer vision, the landscape has been significantly reshaped by the abundance of extensive and diverse datasets, leading to remarkable breakthroughs in image processing. These advancements have reverberated across a wide spectrum of applications, catalyzing transformative outcomes. However, in stark contrast, the field of digital rock analysis finds itself grappling with a conspicuous dearth of data, a challenge that casts a formidable shadow over the effective deployment of computer vision techniques for rock image analysis. In response to this pressing issue, this paper presents a pioneering methodology designed to surmount the hurdles posed by data limitation in the realm of digital rock analysis. At the core of this innovative approach lies the fusion of artificially generated digital rock images, created using a state-of-the-art diffusion model, with their authentic counterparts. This fusion is guided by the overarching objective of augmenting the efficacy of various digital rock analysis applications. This integration endeavors to bridge the gap between the limited available data and the substantial demands of the digital rock analysis domain. The practical significance and potential of this integrated approach are vividly demonstrated through a series of concrete implementations. These include, but are by no means limited to, enhancing image quality to facilitate clearer visualization of intricate rock structures and refining the estimation of petrophysical properties with increased accuracy.}
}
@article{PELLEGRINO2025S126,
title = {OC.02.7 CONVERSATIONAL LARGE LANGUAGE MODEL GENERATIVE ARTIFICIAL INTELLIGENCE CHATBOT CHATGPT-4 FOR COLONOSCOPY BOSTON BOWEL PREPARATION SCORING: AN AI-TO-HEAD HUMAN-BLINDED CONCORDANCE ANALYSIS ON A LARGE VOLUME OF ENDOSCOPIC FRAMES},
journal = {Digestive and Liver Disease},
volume = {57},
pages = {S126-S127},
year = {2025},
note = {Abstracts of the 31st National Congress of Digestive Diseases, FISMAD},
issn = {1590-8658},
doi = {https://doi.org/10.1016/S1590-8658(25)00382-2},
url = {https://www.sciencedirect.com/science/article/pii/S1590865825003822},
author = {R. Pellegrino and G. Palladino and G. Imperio and A. Federico and A.G. Gravina}
}
@article{AMACHER2024100587,
title = {Prediction of outcomes after cardiac arrest by a generative artificial intelligence model},
journal = {Resuscitation Plus},
volume = {18},
pages = {100587},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100587},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000389},
author = {Simon A. Amacher and Armon Arpagaus and Christian Sahmer and Christoph Becker and Sebastian Gross and Tabita Urben and Kai Tisljar and Raoul Sutter and Stephan Marsch and Sabina Hunziker},
keywords = {Artificial intelligence, Cardiac arrest, Cardiopulmonary resuscitation, Mortality prediction, Neurological outcome},
abstract = {Aims
To investigate the prognostic accuracy of a non-medical generative artificial intelligence model (Chat Generative Pre-Trained Transformer 4 - ChatGPT-4) as a novel aspect in predicting death and poor neurological outcome at hospital discharge based on real-life data from cardiac arrest patients.
Methods
This prospective cohort study investigates the prognostic performance of ChatGPT-4 to predict outcomes at hospital discharge of adult cardiac arrest patients admitted to intensive care at a large Swiss tertiary academic medical center (COMMUNICATE/PROPHETIC cohort study). We prompted ChatGPT-4 with sixteen prognostic parameters derived from established post-cardiac arrest scores for each patient. We compared the prognostic performance of ChatGPT-4 regarding the area under the curve (AUC), sensitivity, specificity, positive and negative predictive values, and likelihood ratios of three cardiac arrest scores (Out-of-Hospital Cardiac Arrest [OHCA], Cardiac Arrest Hospital Prognosis [CAHP], and PROgnostication using LOGistic regression model for Unselected adult cardiac arrest patients in the Early stages [PROLOGUE score]) for in-hospital mortality and poor neurological outcome.
Results
Mortality at hospital discharge was 43% (n = 309/713), 54% of patients (n = 387/713) had a poor neurological outcome. ChatGPT-4 showed good discrimination regarding in-hospital mortality with an AUC of 0.85, similar to the OHCA, CAHP, and PROLOGUE (AUCs of 0.82, 0.83, and 0.84, respectively) scores. For poor neurological outcome, ChatGPT-4 showed a similar prediction to the post-cardiac arrest scores (AUC 0.83).
Conclusions
ChatGPT-4 showed a similar performance in predicting mortality and poor neurological outcome compared to validated post-cardiac arrest scores. However, more research is needed regarding illogical answers for potential incorporation of an LLM in the multimodal outcome prognostication after cardiac arrest.}
}
@article{RAMAN2024e24727,
title = {Fake news research trends, linkages to generative artificial intelligence and sustainable development goals},
journal = {Heliyon},
volume = {10},
number = {3},
pages = {e24727},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e24727},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024007588},
author = {Raghu Raman and Vinith {Kumar Nair} and Prema Nedungadi and Aditya {Kumar Sahu} and Robin Kowalski and Sasangan Ramanathan and Krishnashree Achuthan},
keywords = {Deep fake, Ethics, Fake news, Generative AI, Prominence percentile, Sustainable development goal},
abstract = {In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013–2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.}
}
@article{SAJJADIMOHAMMADABADI2024267,
title = {Generative artificial intelligence for distributed learning to enhance smart grid communication},
journal = {International Journal of Intelligent Networks},
volume = {5},
pages = {267-274},
year = {2024},
issn = {2666-6030},
doi = {https://doi.org/10.1016/j.ijin.2024.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2666603024000265},
author = {Seyed Mahmoud {Sajjadi Mohammadabadi} and Mahmoudreza Entezami and Aidin {Karimi Moghaddam} and Mansour Orangian and Shayan Nejadshamsi},
keywords = {Energy forecasting, Generative AI, Smart grid, Communication efficiency, Distributed training, LSTM},
abstract = {Machine learning models are the backbone of smart grid optimization, but their effectiveness hinges on access to vast amounts of training data. However, smart grids face critical communication bottlenecks due to the ever-increasing volume of data from distributed sensors. This paper introduces a novel approach leveraging Generative Artificial Intelligence (GenAI), specifically a type of pre-trained Foundation Model (FM) architecture suitable for time series data due to its efficiency and privacy-preserving properties. These GenAI models are distributed to agents, or data holders, empowering them to fine-tune the foundation model with their local datasets. By fine-tuning the foundation model, the updated model can produce synthetic data that mirrors real-world grid conditions. The server aggregates fine-tuned model from all agents and then generates synthetic data which considers all data collected in the grid. This synthetic data can be used to train global machine learning models for specific tasks like anomaly detection and energy optimization. Then, the trained task models are distributed to agents in the grid to leverage them. The paper highlights the advantages of GenAI for smart grid communication, including reduced communication burden, enhanced privacy through anonymized data transmission, and improved efficiency and scalability. By enabling a distributed and intelligent communication architecture, GenAI introduces a novel way for a more secure, efficient, and sustainable energy future.}
}
@article{MESSER2024100056,
title = {Co-creating art with generative artificial intelligence: Implications for artworks and artists},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100056},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100056},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000161},
author = {Uwe Messer},
keywords = {Art, Authenticity, Generative AI, Human-AI-Collaboration},
abstract = {Synthetic visual art is becoming a commodity due to generative artificial intelligence (AI). The trend of using AI for co-creation will not spare artists’ creative processes, and it is important to understand how the use of generative AI at different stages of the creative process affects both the evaluation of the artist and the result of the human-machine collaboration (i.e., the visual artifact). In three experiments (N = 560), this research explores how the evaluation of artworks is transformed by the revelation that the artist collaborated with AI at different stages of the creative process. The results show that co-created art is less liked and recognized, especially when AI was used in the implementation stage. While co-created art is perceived as more novel, it lacks creative authenticity, which exerts a dominant influence. The results also show that artists’ perceptions suffer from the co-creation process, and that artists who co-create are less admired because they are perceived as less authentic. Two boundary conditions are identified. The negative effect can be mitigated by disclosing the level of artist involvement in co-creation with AI (e.g., by training the algorithm on a curated set of images vs. simply prompting an off-the-shelf AI image generator). In the context of art that is perceived as commercially motivated (e.g., stock images), the effect is also diminished. This research has important implications for the literature on human-AI-collaboration, research on authenticity, and the ongoing policy debate regarding the transparency of algorithmic presence.}
}
@article{ODRI2023103706,
title = {Detecting generative artificial intelligence in scientific articles: Evasion techniques and implications for scientific integrity},
journal = {Orthopaedics & Traumatology: Surgery & Research},
volume = {109},
number = {8},
pages = {103706},
year = {2023},
issn = {1877-0568},
doi = {https://doi.org/10.1016/j.otsr.2023.103706},
url = {https://www.sciencedirect.com/science/article/pii/S1877056823002244},
author = {Guillaume-Anthony Odri and Diane {Ji Yun Yoon}},
keywords = {Generative artificial intelligence, Academic writing, Scientific fraud},
abstract = {Background
Artificial intelligence (AI) tools, although beneficial for data collection and analysis, can also facilitate scientific fraud. AI detectors can help resolve this problem, but their effectiveness depends on their ability to track AI progress. In addition, many methods of evading AI detection exist and their constantly evolving sophistication can make the task more difficult. Thus, from an AI-generated text, we wanted to: (1) evaluate the AI detection sites on a text generated entirely by the AI, (2) test the methods described for evading AI detection, and (3) evaluate the effectiveness of these methods to evade AI detection on the sites tested previously.
Hypothesis
Not all AI detection tools are equally effective in detecting AI-generated text and some techniques used to evade AI detection can make an AI-produced text almost undetectable.
Materials and methods
We created a text with ChatGPT-4 (Chat Generative Pre-trained Transformer) and submitted it to 11 AI detection web tools (Originality, ZeroGPT, Writer, Copyleaks, Crossplag, GPTZero, Sapling, Content at scale, Corrector, Writefull et Quill), before and after applying strategies to minimise AI detection. The strategies used to minimize AI detection were the improvement of command messages in ChatPGT, the introduction of minor grammatical errors such as comma deletion, paraphrasing, and the substitution of Latin letters with similar Cyrillic letters (а and о) which is also a method used elsewhere to evade the detection of plagiarism. We have also tested the effectiveness of these tools in correctly identifying a scientific text written by a human in 1960.
Results
From the initial text generated by the AI, 7 of the 11 detectors concluded that the text was mainly written by humans. Subsequently, the introduction of simple modifications, such as the removal of commas or paraphrasing can effectively reduce AI detection and make the text appear human for all detectors. In addition, replacing certain Latin letters with Cyrillic letters can make an AI text completely undetectable. Finally, we observe that in a paradoxical way, certain sites detect a significant proportion of AI in a text written by a human in 1960.
Discussion
AI detectors have low efficiency, and simple modifications can allow even the most robust detectors to be easily bypassed. The rapid development of generative AI raises questions about the future of scientific writing but also about the detection of scientific fraud, such as data fabrication.
Level of evidence
III Control case study.}
}
@article{INAM2024102387,
title = {A review of top cardiology and cardiovascular medicine journal guidelines regarding the use of generative artificial intelligence tools in scientific writing},
journal = {Current Problems in Cardiology},
volume = {49},
number = {3},
pages = {102387},
year = {2024},
issn = {0146-2806},
doi = {https://doi.org/10.1016/j.cpcardiol.2024.102387},
url = {https://www.sciencedirect.com/science/article/pii/S0146280624000264},
author = {Maha Inam and Sana Sheikh and Abdul Mannan Khan Minhas and Elizabeth M. Vaughan and Chayakrit Krittanawong and Zainab Samad and Carl J. Lavie and Adeel Khoja and Melaine D'Cruze and Leandro Slipczuk and Farhana Alarakhiya and Azra Naseem and Adil H. Haider and Salim S. Virani},
keywords = {Artificial Intelligence, Editorial Policies, ChatGPT, Large Language Models, Machine Learning, Scientific Writing, Cardiology, SCImago},
abstract = {Background
Generative Artificial Intelligence (AI) tools have experienced rapid development over the last decade and are gaining increasing popularity as assistive models in academic writing. However, the ability of AI to generate reliable and accurate research articles is a topic of debate. Major scientific journals have issued policies regarding the contribution of AI tools in scientific writing.
Methods
We conducted a review of the author and peer reviewer guidelines of the top 25 Cardiology and Cardiovascular Medicine journals as per the 2023 SCImago rankings. Data were obtained though reviewing journal websites and directly emailing the editorial office. Descriptive data regarding journal characteristics were coded on SPSS. Subgroup analyses of the journal guidelines were conducted based on the publishing company policies.
Results
Our analysis revealed that all scientific journals in our study permitted the documented use of AI in scientific writing with certain limitations as per ICMJE recommendations. We found that AI tools cannot be included in the authorship or be used for image generation, and that all authors are required to assume full responsibility of their submitted and published work. The use of generative AI tools in the peer review process is strictly prohibited.
Conclusion
Guidelines regarding the use of generative AI in scientific writing are standardized, detailed, and unanimously followed by all journals in our study according to the recommendations set forth by international forums. It is imperative to ensure that these policies are carefully followed and updated to maintain scientific integrity.}
}
@article{STERPETTI2025388,
title = {Letter Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {388-389},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.02.046},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001325},
author = {Antonio V. Sterpetti}
}
@article{SACHDEVA2024S445,
title = {MSR40 Leveraging Artificial Intelligence (AI) and Generative AI (GenAI) for Transforming Real-World Evidence ( RWE) Across the Product Value Chain and Industry Functions},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S445},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2274},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524051374},
author = {S Sachdeva and J Kaneria and R Malik and A Prasad and J Gopalakrishna and RS Shah and S Nandiraju}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@article{MESKO2023,
title = {The ChatGPT (Generative Artificial Intelligence) Revolution Has Made Artificial Intelligence Approachable for Medical Professionals},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48392},
url = {https://www.sciencedirect.com/science/article/pii/S143888712300465X},
author = {Bertalan Mesko},
keywords = {artificial intelligence, digital health, future, technology, ChatGPT, medical practice, large language model, language model, generative, conversational agent, conversation agents, chatbot, generated text, computer generated, medical education, continuing education, professional development, curriculum, curricula},
abstract = {In November 2022, OpenAI publicly launched its large language model (LLM), ChatGPT, and reached the milestone of having over 100 million users in only 2 months. LLMs have been shown to be useful in a myriad of health care–related tasks and processes. In this paper, I argue that attention to, public access to, and debate about LLMs have initiated a wave of products and services using generative artificial intelligence (AI), which had previously found it hard to attract physicians. This paper describes what AI tools have become available since the beginning of the ChatGPT revolution and contemplates how it they might change physicians’ perceptions about this breakthrough technology.}
}
@article{HABIB2024100072,
title = {How does generative artificial intelligence impact student creativity?},
journal = {Journal of Creativity},
volume = {34},
number = {1},
pages = {100072},
year = {2024},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100072},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000316},
author = {Sabrina Habib and Thomas Vogel and Xiao Anli and Evelyn Thorne},
keywords = {Creative process, Artificial intelligence (AI), Alternative uses Task (AUT), Mixed methods, Creative thinking, Higher education, Creative confidence},
abstract = {This study aimed to learn about the impact of generative artificial intelligence (AI) on student creative thinking skills and subsequently provide instructors with information on how to guide the use of AI for creative growth within classroom instruction. This mixed methods study used qualitative and quantitative data collected through an AUT test conducted in a college-level creativity course. The authors measured flexibility, fluency, elaboration, and originality of the data to assess the impact of ChatGPT-3 on students’ divergent thinking. The results advocate for a careful approach in integrating AI into creative education. While AI has the potential to significantly support creative thinking, there are also negative impacts on creativity and creative confidence. The authors of this study believe that creativity is central to learning, developing students’ ability to respond to challenges and find solutions within any field; thus the results of this study can be applicable to any classroom faced with the impact and/or integrating the use of AI on idea generation.}
}
@article{NA2025103614,
title = {1376 Virtual H&E Staining Using Generative Artificial Intelligence: A Novel Technique for Digital Transformation of Unstained Pathology Slides},
journal = {Laboratory Investigation},
volume = {105},
number = {3, Supplement },
pages = {103614},
year = {2025},
note = {USCAP 114th Annual Meeting: See the Light},
issn = {0023-6837},
doi = {https://doi.org/10.1016/j.labinv.2024.103614},
url = {https://www.sciencedirect.com/science/article/pii/S0023683724032926},
author = {Sei Na and Dawoon Na and Kyoungsook Park and SangYong Song and Byullee Park and Hyung Kyung Kim}
}
@article{M2025530,
title = {Debunking myths about Enhanced Recovery After Surgery (ERAS) using Generative Artificial Intelligence},
journal = {Clinical Nutrition ESPEN},
volume = {65},
pages = {530-531},
year = {2025},
issn = {2405-4577},
doi = {https://doi.org/10.1016/j.clnesp.2024.10.104},
url = {https://www.sciencedirect.com/science/article/pii/S2405457724014414},
author = {Aravind M}
}
@article{CONTE2024110893,
title = {Statistical analysis and generative Artificial Intelligence (AI) for assessing pain experience, pain-induced disability, and quality of life in Parkinson's disease patients},
journal = {Brain Research Bulletin},
volume = {208},
pages = {110893},
year = {2024},
issn = {0361-9230},
doi = {https://doi.org/10.1016/j.brainresbull.2024.110893},
url = {https://www.sciencedirect.com/science/article/pii/S0361923024000261},
author = {Luana Conte and Roberto Lupo and Pierluigi Lezzi and Alessio Pedone and Ivan Rubbi and Alessia Lezzi and Elsa Vitale and Antonio Fasano and Giorgio {De Nunzio}},
keywords = {Parkinson's disease, Pain, King's Parkinson's Disease Pain Questionnaire (KPPQ), Parkinson's Disease Questionnaire (PDQ), Generative Artificial Intelligence (AI)},
abstract = {The Parkinson's Disease (PD) is a chronic neurodegenerative condition characterized by motor symptoms such as tremors, rigidity, and bradykinesia, which can significantly impact various aspects of daily life. Among these aspects, pain is a prominent element. Despite the widespread use of therapies aimed at improving symptoms and quality of life, effective pain management is essential to enhance the quality of life of individuals affected by this disease. However, a detailed understanding of the factors associated with pain in PD is still evolving. In this study, we examined the disability caused by pain and the pain experienced by PD patients using two validated questionnaires, namely the Parkinson's Disease Questionnaire (PDQ) and the King's Parkinson's Disease Pain Questionnaire (KPPQ). Customized questions were also included to further explore the pain experience and management strategies adopted by PD patients. Through statistical analysis, we explored the relationships between questionnaire scores, socio-demographic data, and other relevant variables. Additionally, generative Artificial Intelligence (AI) was employed to gain a deeper understanding of patient responses. The results indicate the extent and impact of pain in PD and provide valuable insights for more targeted and personalized management. This study lays the foundation for future research and the development of interventions aimed at improving the quality of life for individuals affected by this condition.}
}
@article{CAO2024e147,
title = {GENERATIVE ARTIFICIAL INTELLIGENCE SUBSTANTIALLY ENHANCES THE ACCURACY OF EMBRYO SELECTION MODELS},
journal = {Fertility and Sterility},
volume = {122},
number = {4, Supplement },
pages = {e147},
year = {2024},
note = {80th Scientific Congress of the American Society for Reproductive Medicine},
issn = {0015-0282},
doi = {https://doi.org/10.1016/j.fertnstert.2024.07.533},
url = {https://www.sciencedirect.com/science/article/pii/S0015028224011506},
author = {Ping Cao and Ganesh Acharya and Andres Salumets and Masoud Zamani Esteki}
}
@article{FIJACKO2024100584,
title = {Using generative artificial intelligence in bibliometric analysis: 10 years of research trends from the European Resuscitation Congresses},
journal = {Resuscitation Plus},
volume = {18},
pages = {100584},
year = {2024},
issn = {2666-5204},
doi = {https://doi.org/10.1016/j.resplu.2024.100584},
url = {https://www.sciencedirect.com/science/article/pii/S2666520424000353},
author = {Nino Fijačko and Ruth Masterson Creber and Benjamin S. Abella and Primož Kocbek and Špela Metličar and Robert Greif and Gregor Štiglic},
keywords = {Emergency medicine, European Resuscitation Council, Congress, Bibliometrics analysis, Generative artificial intelligence},
abstract = {Aims
The aim of this study is to use generative artificial intelligence to perform bibliometric analysis on abstracts published at European Resuscitation Council (ERC) annual scientific congress and define trends in ERC guidelines topics over the last decade.
Methods
In this bibliometric analysis, the WebHarvy software (SysNucleus, India) was used to download data from the Resuscitation journal's website through the technique of web scraping. Next, the Chat Generative Pre-trained Transformer 4 (ChatGPT-4) application programming interface (Open AI, USA) was used to implement the multinomial classification of abstract titles following the ERC 2021 guidelines topics.
Results
From 2012 to 2022 a total of 2491 abstracts have been published at ERC congresses. Published abstracts ranged from 88 (in 2020) to 368 (in 2015). On average, the most common ERC guidelines topics were Adult basic life support (50.1%), followed by Adult advanced life support (41.5%), while Newborn resuscitation and support of transition of infants at birth (2.1%) was the least common topic. The findings also highlight that the Basic Life Support and Adult Advanced Life Support ERC guidelines topics have the strongest co-occurrence to all ERC guidelines topics, where the Newborn resuscitation and support of transition of infants at birth (2.1%; 52/2491) ERC guidelines topic has the weakest co-occurrence.
Conclusion
This study demonstrates the capabilities of generative artificial intelligence in the bibliometric analysis of abstract titles using the example of resuscitation medicine research over the last decade at ERC conferences using large language models.}
}
@incollection{BEHESHTI2025333,
title = {Chapter 13 - Exploring the convergence of Internet of things and big data technologies in the age of generative artificial intelligence},
editor = {Mohamed Adel Serhani and Yang Xu and Zakaria Maamar},
booktitle = {Empowering IoT with Big Data Analytics},
publisher = {Academic Press},
pages = {333-354},
year = {2025},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-443-21640-4},
doi = {https://doi.org/10.1016/B978-0-443-21640-4.00004-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780443216404000041},
author = {Amin Beheshti and Wathiq Mansoor},
keywords = {Internet of things (IoT), Big data analytics, Generative artificial intelligence (AI), Data curation},
abstract = {The Internet of things (IoT) has transformed the way we interact with the physical world, generating an unprecedented volume of data. In modern enterprises, the convergence of IoT, big data, and generative artificial intelligence (GAI) is reshaping the landscape of digital solutions. This chapter explores this convergence, shedding light on emerging solutions, software architectures, and challenges and opportunities in the age of GAI. We explore the complexities of effectively using IoT-generated data, emphasizing the challenges of gathering, organizing, curating, and processing these data for meaningful insights. We highlight the importance of linking analytical, cognitive, and GAI to enable the development of self-evolving systems capable of learning from extensive data streams and making instant data-driven decisions and predictions. This synergy between IoT, big data, and AI can transform various industries by enhancing automation, augmentation, and improvement of their processes.}
}
@article{AZIZOGLU2025162359,
title = {Generative Artificial Intelligence Accuracy in Interpreting Forest Plots in Pediatric Surgery Meta-analyses: A Perspective From Pediatric Surgery Meta-analysis Study Group (PESMA)},
journal = {Journal of Pediatric Surgery},
volume = {60},
number = {7},
pages = {162359},
year = {2025},
issn = {0022-3468},
doi = {https://doi.org/10.1016/j.jpedsurg.2025.162359},
url = {https://www.sciencedirect.com/science/article/pii/S0022346825002040},
author = {Mustafa Azizoglu and Maria Escolino and Tahsin Onat Kamci and Sergey Klyuev and Sonia {Perez Bertolez} and Toni Risteski and Ismael Elhalaby and Nitinkumar Borkar and Ciro Esposito and Mehmet Hanifi Okur and Martin Lacher and Annika Mutanen and Sameh Shehata and Fabio Chiarenza and Mark Davenport}
}
@article{BYRNE2023519,
title = {Generative Artificial Intelligence and ChatGPT},
journal = {Journal of PeriAnesthesia Nursing},
volume = {38},
number = {3},
pages = {519-522},
year = {2023},
issn = {1089-9472},
doi = {https://doi.org/10.1016/j.jopan.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1089947223001405},
author = {Matthew D. Byrne}
}
@article{WONG2024100278,
title = {The sudden disruptive rise of generative artificial intelligence? An evaluation of their impact on higher education and the global workplace},
journal = {Journal of Open Innovation: Technology, Market, and Complexity},
volume = {10},
number = {2},
pages = {100278},
year = {2024},
issn = {2199-8531},
doi = {https://doi.org/10.1016/j.joitmc.2024.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2199853124000726},
author = {Wilson Kia Onn Wong},
keywords = {GAI, Disruptive, GPT, LLMs, “AI-optimists”, “AI-sceptics”},
abstract = {This paper evaluates the rise of “Generative Artificial Intelligence” (GAI) in its myriad forms, with the highest profile being the “Large Language Models” (LLMs). More importantly, it analyses the potentially disruptive impact of this ascendant technology on higher education and the global workplace. The findings of this paper indicate that students pursuing higher education tend to perceive GAI favourably, as it frees them from the toil of rote-learning. However, the view is rather mixed in the case of educators, who are still coming to grips with this seemingly disruptive technology. In the case of the global labour market, GAI has the potential to decimate legions of white-collar jobs once it eliminates inherent issues of biases, security and misinformation. Despite the media’s constant labelling of GAI as a disruptive technology that has suddenly burst onto the technological scene, it is evidenced in this paper that the technology has taken nearly eight decades to reach today’s level of technological advancement. Further, it is far from reaching its full potential, as it is still incorporating advances in pattern recognition, planning and problem solving, and quantum computing technologies. This study also warns of concentrating the power of this game-changing technology in the hands of a few major corporate titans.}
}
@article{PIERCE2024S444,
title = {MSR33 Utilizing Generative Artificial Intelligence in Network Meta-Analysis: Assessing the Effectiveness of GenAI as a Tool in Feasibility Assessments},
journal = {Value in Health},
volume = {27},
number = {12, Supplement },
pages = {S444},
year = {2024},
note = {ISPOR Europe 2024},
issn = {1098-3015},
doi = {https://doi.org/10.1016/j.jval.2024.10.2267},
url = {https://www.sciencedirect.com/science/article/pii/S1098301524051301},
author = {P Pierce and C Kraan and C Bennison and S Petersohn and S Kroep and K Nickel}
}
@article{BRITOZERON2025570,
title = {POS0311 SARCOIDOSIS AS A SYSTEMIC DISEASE: IDENTIFYING PATTERNS OF MULTIORGAN-SPECIFIC INVOLVEMENT AND EPIDEMIOLOGICAL PROFILING THROUGH GENERATIVE ARTIFICIAL INTELLIGENCE-DRIVEN CLUSTERING},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {570-571},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.05.698},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725017315},
author = {P. Brito-Zerón and A. Flores-Chávez and C. Feijoo-Masso and G. Policarpo-Torres and R. {Gómez de la Torre} and B. Escalante and J.M. Lopez-Dupla and C. Soler-i-Ferrer and E. Fonseca-Aizpuru and A. González-García and J.C. Herranz-Pérez and S. {GARCÍA MORILLO} and A. Alguacil and Á. {Robles Marhuenda} and M. Bonet and M.V. Villalba-García and A.J. Chamorro and B. {De Miguel-Campo} and M.G. {CRUZ CAPARROS} and M. {Akasbi Montalvo} and A. Mayer-Fuentes and M. Ramos-Casals},
keywords = {Registries, Artificial Intelligence, Prognostic factors, Epidemiology, Comorbidities},
abstract = {Background:
Sarcoidosis is a heterogeneous granulomatous disease characterized by a wide range of clinical manifestations stemming from multiple organ involvement. While clustering techniques offer a robust method for uncovering these patterns, traditional approaches may fail to fully capture the complexity of multisystem diseases like sarcoidosis. Leveraging generative artificial intelligence (AI) offers a unique opportunity to improve data analysis and interpretation in complex systemic settings, providing novel insights into multifaceted disease patterns and guiding both hypothesis generation and clinical decision-making.
Objectives:
This study aimed to identify distinct clusters of organ involvement in patients with sarcoidosis, assess their corresponding epidemiological characteristics, and highlight the benefits of AI-driven methodologies in handling complex multisystem data—underscoring the feasibility and advantages of advanced AI-based approaches for systemic phenotypes in this heterogeneous disease.
Methods:
We conducted an AI-assisted analysis to identify organ-involvement clusters in a dataset of 2,187 anonymized sarcoidosis patients (Spanish National Registry SarcoGEAS, all fulfilling the 1999 ATS/ERS/WASOG criteria). Organ involvement was retrospectively determined in each patient at the time of diagnosis using the 2014 WASOG organ assessment instrument. Clustering was carried out via the k-means algorithm in Python's scikit-learn library (version 1.0.2). The optimal number of clusters was determined using the elbow method, supported by silhouette scores to evaluate cluster quality. Statistical comparisons (ANOVA, Kruskal-Wallis, and Chi-square tests—using exact tests for low-frequency data) were applied to characterize cluster differences. Significance was set at p < 0.05, ensuring rigorous evaluation of epidemiological and clinical distinctions. The analysis was conducted in a secure computational environment using generative AI (via OpenAI's GPT-4 model) using Python (version 3.9) with essential libraries including pandas (1.4.3) for data manipulation, numpy (1.21.5) for numerical computations, and matplotlib (3.5.1) and seaborn (0.11.2) for visualizations. Data processing and analysis workflows adhered to GDPR standards to ensure patient privacy. All patient data were anonymized prior to analysis, and no identifiable information was accessed at any point. Code modularity and reproducibility were prioritized, with all scripts managed in version control systems (e.g., Git) to enable transparency.
Results:
The cohort comprised 2,187 patients, with a female predominance (61.4%), a mean age at diagnosis of 48.6 years (range: 5-95), and a majority identifying as White (88%). Cluster quality analysis identified 5 as the optimal number of clusters potential; an additional clinically significant cluster (hepatic-splenic) was manually identified and confirmed post hoc through statistical validation. Ultimately, we defined six distinct clusters of systemic involvement: the lymphadenopathic cluster (Cluster 1, characterized by 100% lymphadenopathy), the pulmonary cluster (Cluster 2, characterized by 100% lung involvement and co-occurring 100% lymphadenopathy), the cutaneous cluster (Cluster 3, 100% of cutaneous involvement), the ocular cluster (Cluster 4, 100% ocular involvement), the hepato-splenic cluster (Cluster 5, defined by 100% hepatic and splenic involvement), and the multisystemic cluster (Cluster 6, exhibiting generalized, but not predominant, organ involvement). Each cluster demonstrated statistically significant epidemiological differences (Figure 1). For age, the lymphadenopathic cluster had the highest mean (51.7 years), whereas the cutaneous cluster had the lowest (42.9 years) (p = 0.00056). For sex, the proportion of females ranged from 49.0% in the hepato-splenic cluster to 65.9% in the ocular cluster (p = 0.000017). For ethnicity, the proportion of White patients ranged from 81.4% in the ocular cluster to 94.6% in the lymphadenopathic cluster (p = 0.00135).
Conclusion:
This generative AI-driven clustering study successfully identified six distinct patterns of systemic involvement in sarcoidosis, offering a deeper understanding of the disease's heterogeneity. Each cluster exhibited specific epidemiological profiles: cutaneous cluster was associated with the youngest age at sarcoidosis diagnosis, lymphadenopathic cluster with the oldest age and the highest frequency of White patients, ocular cluster with the highest frequency of women and highest frequency of non-White patients, and the hepato-splenic cluster with the highest rate of men. The significant epidemiological disparities among clusters underscore the disease's variability and offer a framework for refined patient stratification.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{ROBINSON2025390,
title = {Response Regarding: Generative Artificial Intelligence in Academic Surgery: Ethical Implications and Transformative Potential},
journal = {Journal of Surgical Research},
volume = {310},
pages = {390-391},
year = {2025},
issn = {0022-4804},
doi = {https://doi.org/10.1016/j.jss.2025.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022480425001337},
author = {Jamie R. Robinson and Anne Stey and David F. Schneider and Anai N. Kothari and Brenessa Lindeman and Haytham M. Kaafarani and Krista L. Haines}
}
@article{BURNS2024100166,
title = {Practical implementation of generative artificial intelligence systems in healthcare: A United States perspective},
journal = {Future Healthcare Journal},
volume = {11},
number = {3},
pages = {100166},
year = {2024},
issn = {2514-6645},
doi = {https://doi.org/10.1016/j.fhj.2024.100166},
url = {https://www.sciencedirect.com/science/article/pii/S251466452401556X},
author = {Barclay Burns and Bo Nemelka and Anmol Arora}
}
@article{BRITOZERON20252097,
title = {ABS0885 COMPLEMENT CONSUMPTION PATTERNS AS AN EARLY PREDICTOR OF SYSTEMIC SJÖGREN DISEASE: GENERATIVE ARTIFICIAL INTELLIGENCE-ASSISTED ANALYSIS USING STRATIFIED CROSS-VALIDATION GENERALIZABILITY MODELS},
journal = {Annals of the Rheumatic Diseases},
volume = {84},
pages = {2097-2098},
year = {2025},
note = {EULAR 2025: European Congress of Rheumatology},
issn = {0003-4967},
doi = {https://doi.org/10.1016/j.ard.2025.06.1702},
url = {https://www.sciencedirect.com/science/article/pii/S0003496725037550},
author = {P. Brito-Zerón and A. Flores-Chávez and L.T. {Delgado Garcia} and I.F. Horváth and R. Priori and H. Bootsma and B. Armagan and V. Manfrè and S. Praprotnik and G. Hernandez-Molina and R. {Pereira da Costa} and R. Gerli and M. Rischmueller and Y. Suzuki and R. Solans-Laqué and S. Pasoto and E. Skoglund and I. Sanchez-Berna and A. Alunno and V. {Fernandes Moça Trevisani} and V. Valim and S. {Melchor Díaz} and B. {Maure Noia} and E. Fonseca-Aizpuru and H. Nakamura and L.D. Miguel and M. Vázquez and M. {Akasbi Montalvo} and G. Policarpo-Torres and B. {De Miguel-Campo} and A. Szántó and A. Gattamelata and A. Vissink and L. Quartuccio and L. Kiliç and K. Perdan-Pirkmajer and V.C. Romão and E. Bartoloni and S. Downie-Doyle and Y. Fujisawa and M. Ramos-Casals},
keywords = {Validation, Artificial Intelligence},
abstract = {Background:
Complement consumption, characterized by decreased C3 and/or C4 levels, is a hallmark of immune complex-mediated inflammation and vascular involvement in patients with systemic autoimmune diseases. In patients with Sjögren Disease (SjD), hypocomplementemia at diagnosis has been mainly linked to an increased risk of lymphoma. By analysing the relationship between complement consumption profiles and systemic activity in the largest international cohort, we aim to refine early prognostic paradigms and inform tailored clinical surveillance strategies in SjD, thereby addressing a critical gap in precision medicine for this complex autoimmune disease.
Objectives:
The objectives of this study were to identify and classify complement consumption patterns, investigate their association with an early phenotype consisting of systemic activity across ESSDAI domains while adjusting for age and gender, and explore how cross-validation techniques may validate the predictive accuracy and generalizability of developed models.
Methods:
This study analyzed data from the International Sjögren Big Data Registry. Patients were categorized into four distinct groups according to their complement consumption patterns (isolated low C3, isolated low C4, combined low C3 and C4, and normal C3 and C4 levels). We used Chi-square tests to evaluate univariate associations, and Kruskal-Wallis H-test and Mann-Whitney U test to investigate significant differences with respect to systemic activity (mean ESSDAI score and DAS categories). Multivariable logistic regression models were developed to analyze associations between complement patterns and ESSDAI domains, adjusting for age and gender. Odds ratios (ORs) and 95% confidence intervals (CIs) were calculated. A five-fold stratified cross-validation was carried out to rigorously evaluate the models' generalizability, with the Area Under the Curve (AUC) serving as the primary performance metric. Generative Artificial Intelligence (AI) (ChatGPT-4o model) was used within a secure offline environment to automate anonymized data recoding and statistical scripting. Python libraries, including pandas, statsmodels, and scikit-learn, were integral for data processing, model development, and cross-validation.
Results:
Complement values determined at diagnosis were available in 13,710 patients. Stratification according to the 4 complement consumption patterns identified that 79.58% of patients had normal levels of C3 and C4, 7.42% exhibited isolated low C3, 6.90% showed isolated low C4, and 6.09% presented combined low C3 and C4 levels. Combined low C3-C4 levels exhibited the highest mean ESSDAI score (11.41), follwed by isolated low C3, isolated low C4 and normocomplementemia (mean ESSDAI score of 9.26, 7.39, and 5.66, respectively) (Figure 1); Kruskal-Wallis H-test revealed a highly significant difference between the groups (p<0.001), as well as pairwise comparisons using the Mann-Whitney U test (p<0.001). The Chi-square test revealed significant differences in the distribution of DAS categories across the C3-C4 combined groups (χ2=476.41, p<0.001) (Figure 2). However, multivariate logistic regression confirmed significant associations in only three domains. For the pulmonary domain, combined low C3 and C4 levels were associated with the highest odds of activity (OR: 3.12, 95% CI: 2.50–3.91, p < 0.001; AUC: 0.591). In the biological domain, isolated low C3 strongly correlated with activity (OR: 2.45, 95% CI: 1.98–3.03, p < 0.001; AUC: 0.580). For constitutional symptoms, isolated low C3 was associated with the highest activity frequency (18.54%), whereas normal complement levels showed the lowest frequency (11.06%, OR: 0.56, 95% CI: 0.48–0.67, p < 0.001; AUC: 0.563). After adjusting for epidemiological factors, sex and age emerged as influential variables: men had higher odds of constitutional activity (OR 1.24, 95% CI: 1.02–1.52, p = 0.03), while older age had a protective effect, reducing systemic activity by about 1% per year (OR: 0.99, 95% CI: 0.99–1.00, p = 0.0003). The AUC values obtained after running the five-fold stratified cross-validation generalizability models ranged between 0.56 and 0.59, indicating modest ability to discriminate between active and inactive states.
Conclusion:
This study demonstrates that complement consumption patterns are strongly associated with baseline systemic activity in SjD, highlighting their potential as early prognostic markers. While complement patterns provide valuable insights for risk stratification, the current predictive models exhibit modest discriminatory ability (AUC values between 0.5 and 0.6), suggesting that complement patterns are relevant but insufficient alone as predictors to improve clinical applicability. The nuanced influence of epidemiological factors—such as the protective effect of age and the increased susceptibility of men to systemic disease—adds complexity to our understanding of early systemic Sjögren.
REFERENCES:
NIL. 
Acknowledgements:
NIL.
Disclosure of Interests:
None declared. © The Authors 2025. This abstract is an open access article published in Annals of Rheumatic Diseases under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/). Neither EULAR nor the publisher make any representation as to the accuracy of the content. The authors are solely responsible for the content in their abstract including accuracy of the facts, statements, results, conclusion, citing resources etc.}
}
@article{THELANCET20241,
title = {Rethinking research and generative artificial intelligence},
journal = {The Lancet},
volume = {404},
number = {10447},
pages = {1},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01394-1},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624013941},
author = { {The Lancet}}
}
@article{MARTIN2024100265,
title = {Navigating the data frontier in science assessment: Advancing data augmentation strategies for machine learning applications with generative artificial intelligence},
journal = {Computers and Education: Artificial Intelligence},
volume = {7},
pages = {100265},
year = {2024},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100265},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24000687},
author = {Paul P. Martin and Nicole Graulich},
keywords = {Assessment, Large language models (LLMs), Machine learning (ML), Data augmentation, Science education},
abstract = {Machine learning (ML) techniques are commonly seen as an inductive learning procedure, typically involving the identification of patterns in a specific training dataset to make predictions in novel contexts. By doing so, the performance and generalizability of these techniques often rely on the quality and quantity of the available training data. However, gathering a diverse training dataset that captures multiple nuances of students’ reasoning poses challenges in educational settings due to resource constraints. We compared three data augmentation strategies to address this issue: collecting additional student data, utilizing chatbots to paraphrase existing responses, and prompting chatbots to generate synthetic responses. We found that leveraging data augmentation significantly improved ML model performance. In detail, combining authentic and/or paraphrased responses with chatbot responses yielded the best machine-human score agreements across various validation conditions. This data augmentation allowed us to expand our applied scoring rubric by introducing a more detailed categorization that better captured the level of causality in undergraduate chemistry students’ reasoning about reaction mechanisms. Together, these findings highlight effective possibilities for augmenting the size and heterogeneity of the training data to improve ML model performance and generalizability, introduce a more fine-grained categorization, and reduce human effort in data collection. In the future, these benefits may enhance the scalability of formative assessments that adaptively support students’ reasoning in postsecondary chemistry classes.}
}
@article{KHOSRAVI2024101503,
title = {Analyzing Racial Differences in Imaging Joint Replacement Registries Using Generative Artificial Intelligence: Advancing Orthopaedic Data Equity},
journal = {Arthroplasty Today},
volume = {29},
pages = {101503},
year = {2024},
issn = {2352-3441},
doi = {https://doi.org/10.1016/j.artd.2024.101503},
url = {https://www.sciencedirect.com/science/article/pii/S2352344124001882},
author = {Bardia Khosravi and Pouria Rouzrokh and Bradley J. Erickson and Hillary W. Garner and Doris E. Wenger and Michael J. Taunton and Cody C. Wyles},
keywords = {Generative AI, Explainability, Dataset curation, Equity, Bias},
abstract = {Background
Discrepancies in medical data sets can perpetuate bias, especially when training deep learning models, potentially leading to biased outcomes in clinical applications. Understanding these biases is crucial for the development of equitable healthcare technologies. This study employs generative deep learning technology to explore and understand radiographic differences based on race among patients undergoing total hip arthroplasty.
Methods
Utilizing a large institutional registry, we retrospectively analyzed pelvic radiographs from total hip arthroplasty patients, characterized by demographics and image features. Denoising diffusion probabilistic models generated radiographs conditioned on demographic and imaging characteristics. Fréchet Inception Distance assessed the generated image quality, showing the diversity and realism of the generated images. Sixty transition videos were generated that showed transforming White pelvises to their closest African American counterparts and vice versa while controlling for patients’ sex, age, and body mass index. Two expert surgeons and 2 radiologists carefully studied these videos to understand the systematic differences that are present in the 2 races’ radiographs.
Results
Our data set included 480,407 pelvic radiographs, with a predominance of White patients over African Americans. The generative denoising diffusion probabilistic model created high-quality images and reached an Fréchet Inception Distance of 6.8. Experts identified 6 characteristics differentiating races, including interacetabular distance, osteoarthritis degree, obturator foramina shape, femoral neck-shaft angle, pelvic ring shape, and femoral cortical thickness.
Conclusions
This study demonstrates the potential of generative models for understanding disparities in medical imaging data sets. By visualizing race-based differences, this method aids in identifying bias in downstream tasks, fostering the development of fairer healthcare practices.}
}
@article{DAUNGSUPAWONG2024105498,
title = {Correspondence: Generative artificial intelligence in healthcare},
journal = {International Journal of Medical Informatics},
volume = {189},
pages = {105498},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105498},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001618},
author = {Hineptch Daungsupawong and Viroj Wiwanitkit},
keywords = {Generative, Artificial intelligence, Healthcare}
}
@article{HYUNBAEK2023102030,
title = {Is ChatGPT scary good? How user motivations affect creepiness and trust in generative artificial intelligence},
journal = {Telematics and Informatics},
volume = {83},
pages = {102030},
year = {2023},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2023.102030},
url = {https://www.sciencedirect.com/science/article/pii/S0736585323000941},
author = {Tae {Hyun Baek} and Minseong Kim},
keywords = {ChatGPT, Generative artificial intelligence (AI), Uses and gratifications theory, Creepiness, Trust, Continuance intention},
abstract = {Few studies have examined user motivations to use generative artificial intelligence (AI). This research aims to address this gap by examining how user motivations for ChatGPT usage affect perceived creepiness, trust, and the intention to continue using AI chatbot technology. The findings of an online survey (N = 421) reveal a negative relationship between personalization and creepiness, while task efficiency and social interaction are positively associated with creepiness. Increased levels of creepiness, in turn, result in decreased continuance intention. Furthermore, task efficiency and personalization have a positive impact on trust, leading to increased continuance intention. The results contribute to the field of human–computer interaction by investigating the motivations for utilizing generative AI chatbots and advancing our comprehension of AI creepiness, trust, and continuance intention. The practical ramifications of this research can inform the design of user interfaces and the development of features for generative AI chatbots.}
}
@article{PATEL2024105791,
title = {Generative artificial intelligence versus clinicians: Who diagnoses multiple sclerosis faster and with greater accuracy?},
journal = {Multiple Sclerosis and Related Disorders},
volume = {90},
pages = {105791},
year = {2024},
issn = {2211-0348},
doi = {https://doi.org/10.1016/j.msard.2024.105791},
url = {https://www.sciencedirect.com/science/article/pii/S2211034824003687},
author = {Mahi A. Patel and Francisco Villalobos and Kevin Shan and Lauren M. Tardo and Lindsay A. Horton and Peter V. Sguigna and Kyle M. Blackburn and Shanan B. Munoz and Tatum M. Moog and Alexander D. Smith and Katy W. Burgess and Morgan McCreary and Darin T. Okuda},
keywords = {Multiple sclerosis, Artificial intelligence, ChatGPT, Diagnosis, Generative AI},
abstract = {Background
Those receiving the diagnosis of multiple sclerosis (MS) over the next ten years will predominantly be part of Generation Z (Gen Z). Recent observations within our clinic suggest that younger people with MS utilize online generative artificial intelligence (AI) platforms for personalized medical advice prior to their first visit with a specialist in neuroimmunology. The use of such platforms is anticipated to increase given the technology driven nature, desire for instant communication, and cost-conscious nature of Gen Z. Our objective was to determine if ChatGPT (Generative Pre-trained Transformer) could diagnose MS in individuals earlier than their clinical timeline, and to assess if the accuracy differed based on age, sex, and race/ethnicity.
Methods
People with MS between 18 and 59 years of age were studied. The clinical timeline for people diagnosed with MS was retrospectively identified and simulated using ChatGPT-3.5 (GPT-3.5). Chats were conducted using both actual and derivatives of their age, sex, and race/ethnicity to test diagnostic accuracy. A Kaplan-Meier survival curve was estimated for time to diagnosis, clustered by subject. The p-value testing for differences in time to diagnosis was accomplished using a general Wilcoxon test. Logistic regression (subject-specific intercept) was used to capture intra-subject correlation to test the accuracy prior to and after the inclusion of MRI data.
Results
The study cohort included 100 unique people with MS. Of those, 50 were members of Gen Z (38 female; 22 White; mean age at first symptom was 20.6 years (y) (standard deviation (SD)=2.2y)), and 50 were non-Gen Z (34 female; 27 White; mean age at first symptom was 37.0y (SD=10.4y)). In addition, a total of 529 people that represented digital simulations of the original cohort of 100 people (333 female; 166 White; 136 Black/African American; 107 Asian; 120 Hispanic, mean age at first symptom was 31.6y (SD=12.4y)) were generated allowing for 629 scripted conversations to be analyzed. The estimated median time to diagnosis in clinic was significantly longer at 0.35y (95% CI=[0.28, 0.48]) versus that by ChatGPT at 0.08y (95% CI=[0.04, 0.24]) (p<0.0001). There was no difference in the diagnostic accuracy between ages and by race/ethnicity prior to the inclusion of MRI data. However, prior to including the MRI data, males had a 47% less likely chance of a correct diagnosis relative to females (p=0.05). Post-MRI data inclusion within GPT-3.5, the odds of an accurate diagnosis was 4.0-fold greater for Gen Z participants, relative to non-Gen Z participants (p=0.01) with the diagnostic accuracy being 68% less in males relative to females (p=0.009), and 75% less for White subjects, relative to non-White subjects (p=0.0004).
Conclusion
Although generative AI platforms enable rapid information access and are not principally designed for use in healthcare, an increase in use by Gen Z is anticipated. However, the obtained responses may not be generalizable to all users and bias may exist in select groups.}
}
@article{LAW2024100174,
title = {Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review},
journal = {Computers and Education Open},
volume = {6},
pages = {100174},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100174},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000156},
author = {Locky Law},
keywords = {Generative AI, AI, Language education, Scoping review, Content generation, ChatGPT},
abstract = {This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.}
}
@article{WINNIFRITH2024102794,
title = {Generative artificial intelligence for de novo protein design},
journal = {Current Opinion in Structural Biology},
volume = {86},
pages = {102794},
year = {2024},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2024.102794},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X24000216},
author = {Adam Winnifrith and Carlos Outeiral and Brian L. Hie},
abstract = {Engineering new molecules with desirable functions and properties has the potential to extend our ability to engineer proteins beyond what nature has so far evolved. Advances in the so-called ‘de novo’ design problem have recently been brought forward by developments in artificial intelligence. Generative architectures, such as language models and diffusion processes, seem adept at generating novel, yet realistic proteins that display desirable properties and perform specified functions. State-of-the-art design protocols now achieve experimental success rates nearing 20%, thus widening the access to de novo designed proteins. Despite extensive progress, there are clear field-wide challenges, for example, in determining the best in silico metrics to prioritise designs for experimental testing, and in designing proteins that can undergo large conformational changes or be regulated by post-translational modifications. With an increase in the number of models being developed, this review provides a framework to understand how these tools fit into the overall process of de novo protein design. Throughout, we highlight the power of incorporating biochemical knowledge to improve performance and interpretability.}
}
@article{CHAUHAN20242234,
title = {The Impact of Generative Artificial Intelligence on Research Integrity in Scholarly Publishing},
journal = {The American Journal of Pathology},
volume = {194},
number = {12},
pages = {2234-2238},
year = {2024},
issn = {0002-9440},
doi = {https://doi.org/10.1016/j.ajpath.2024.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0002944024003651},
author = {Chhavi Chauhan and George Currie}
}
@article{HASAN2024,
title = {Governance of Generative Artificial Intelligence:},
journal = {International Journal of Knowledge Management},
volume = {21},
number = {1},
year = {2024},
issn = {1548-0666},
doi = {https://doi.org/10.4018/IJKM.383061},
url = {https://www.sciencedirect.com/science/article/pii/S1548066625000359},
author = {A K M Kamrul Hasan},
keywords = {Knowledge Management, Knowledge Management System, Generative Artificial Intelligence (GenAI), Governance Structure, Institutional Economics},
abstract = {ABSTRACT
The field of knowledge management and knowledge management systems is evolving and dynamic. In the era of developed information technology systems, the dynamics of knowledge creation and dissemination have also changed. Generative artificial intelligence (GenAI)—an embedded entity in the knowledge management system—has become a prominent area of research nowadays, while accountability, transparency, and ethics are common research agendas in institutional economics related to GenAI. The research in this paper has investigated the convictions behind GenAI adoption and how to develop a GenAI governance framework. The research adopts a qualitative approach to investigate the problem and surveys undergraduate students to explore their motive for using GenAI. The study sheds analytical light on institutional economists’ view on the governance of GenAI. The study has found a positive relationship between perceived benefits and the adoption of GenAI in education by students. The theoretical model will have a considerable impact on the ongoing debate on the governance of GenAI and knowledge management systems.}
}
@article{HE20241210,
title = {Generative Artificial Intelligence: A New Frontier of Scientific Misconduct?},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {120},
number = {5},
pages = {1210-1213},
year = {2024},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2024.03.026},
url = {https://www.sciencedirect.com/science/article/pii/S0360301624004413},
author = {Ling He and Hannah Hausman and Frank Pajonk}
}
@article{KSHETRI2024102760,
title = {The academic industry’s response to generative artificial intelligence: An institutional analysis of large language models},
journal = {Telecommunications Policy},
volume = {48},
number = {5},
pages = {102760},
year = {2024},
issn = {0308-5961},
doi = {https://doi.org/10.1016/j.telpol.2024.102760},
url = {https://www.sciencedirect.com/science/article/pii/S0308596124000570},
author = {Nir Kshetri},
keywords = {Academic industry, ChatGPT, Generative artificial intelligence, Institutional theory, Large language models, Theorization},
abstract = {This paper examines academic institutions' heterogeneous initial responses to generative AI (GAI) tools like ChatGPT and factors influencing increased acceptance over time. GAI's disruptive nature coupled with uncertainty about impacts poses adoption challenges. However, external pressures from stakeholders seeking GAI integration contribute to changing attitudes. Actions of institutional change agents also drive growing acceptance by increasing awareness of GAI advantages. They challenge prevailing logics emphasizing assessments, proposing new values around employability and job performance. Additionally, academic institutions reevaluating GAI's value creation potential through applications and evolving business models contributes to favorable responses. The paper proposes an institutional theory framework explaining dynamics underpinning academic institutions' assimilation of GAI. It highlights how various mechanisms like external pressures, institutional entrepreneurs' theorization efforts justifying technology use, and internal sensemaking shape institutional norms and values, enabling academic systems' adaptation. The study informs policy and practice while directing future research toward validating propositions empirically and examining contextual dimensions including industry characteristics affecting GAI adoption.}
}
@article{YANG20241184,
title = {Chat Generative Pretrained Transformer (ChatGPT) and Bard: Artificial Intelligence Does not yet Provide Clinically Supported Answers for Hip and Knee Osteoarthritis},
journal = {The Journal of Arthroplasty},
volume = {39},
number = {5},
pages = {1184-1190},
year = {2024},
issn = {0883-5403},
doi = {https://doi.org/10.1016/j.arth.2024.01.029},
url = {https://www.sciencedirect.com/science/article/pii/S0883540324000275},
author = {JaeWon Yang and Kyle S. Ardavanis and Katherine E. Slack and Navin D. Fernando and Craig J. {Della Valle} and Nicholas M. Hernandez},
keywords = {ChatGPT, bard, machine learning, artificial intelligence, large language models},
abstract = {Background
Advancements in artificial intelligence (AI) have led to the creation of large language models (LLMs), such as Chat Generative Pretrained Transformer (ChatGPT) and Bard, that analyze online resources to synthesize responses to user queries. Despite their popularity, the accuracy of LLM responses to medical questions remains unknown. This study aimed to compare the responses of ChatGPT and Bard regarding treatments for hip and knee osteoarthritis with the American Academy of Orthopaedic Surgeons (AAOS) Evidence-Based Clinical Practice Guidelines (CPGs) recommendations.
Methods
Both ChatGPT (Open AI) and Bard (Google) were queried regarding 20 treatments (10 for hip and 10 for knee osteoarthritis) from the AAOS CPGs. Responses were classified by 2 reviewers as being in “Concordance,” “Discordance,” or “No Concordance” with AAOS CPGs. A Cohen’s Kappa coefficient was used to assess inter-rater reliability, and Chi-squared analyses were used to compare responses between LLMs.
Results
Overall, ChatGPT and Bard provided responses that were concordant with the AAOS CPGs for 16 (80%) and 12 (60%) treatments, respectively. Notably, ChatGPT and Bard encouraged the use of non-recommended treatments in 30% and 60% of queries, respectively. There were no differences in performance when evaluating by joint or by recommended versus non-recommended treatments. Studies were referenced in 6 (30%) of the Bard responses and none (0%) of the ChatGPT responses. Of the 6 Bard responses, studies could only be identified for 1 (16.7%). Of the remaining, 2 (33.3%) responses cited studies in journals that did not exist, 2 (33.3%) cited studies that could not be found with the information given, and 1 (16.7%) provided links to unrelated studies.
Conclusions
Both ChatGPT and Bard do not consistently provide responses that align with the AAOS CPGs. Consequently, physicians and patients should temper expectations on the guidance AI platforms can currently provide.}
}
@article{HOSSEINI2025100520,
title = {A social-environmental impact perspective of generative artificial intelligence},
journal = {Environmental Science and Ecotechnology},
volume = {23},
pages = {100520},
year = {2025},
issn = {2666-4984},
doi = {https://doi.org/10.1016/j.ese.2024.100520},
url = {https://www.sciencedirect.com/science/article/pii/S2666498424001340},
author = {Mohammad Hosseini and Peng Gao and Carolina Vivas-Valencia}
}
@article{WAELALKHATIB2023102403,
title = {Drivers of generative artificial intelligence to fostering exploitative and exploratory innovation: A TOE framework},
journal = {Technology in Society},
volume = {75},
pages = {102403},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102403},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23002087},
author = {Ayman {wael AL-khatib}},
keywords = {Generative artificial intelligence, TOE framework, Exploratory innovation, Exploitative innovation},
abstract = {This research work aims to investigate the antecedents of generative artificial intelligence (GEN-AI) adoption, and exploratory and exploitative innovation. A conceptual model based on the technology-organization-environment (TOE) framework is proposed and tested empirically using online survey-based data collected from 260 managers and administrative employees located in the Jordanian retailing industry. To achieve the objectives of this work a covariance-based- structural equation modelling (CB-SEM) was employed. The results indicate that relative advantage, top management support, organizational readiness, and customer pressures positively influence GEN-AI adoption. The empirical results demonstrated that the influence of compatibility and competitive pressures on GEN-AI adoption are insignificant. It was found that complexity negatively influence of GEN-AI adoption, also the findings confirm the positive impact of GEN-AI on both exploratory and exploitative innovation. The findings of the existing research would be valuable for GEN-AI technology providers, managers and top management in the retail firms sector in terms of building effective procedures to promote the successful adoption of GEN-AI technologies and innovation.}
}
@incollection{LEEFRANCISS2025237,
title = {Chapter 13 - Generative artificial intelligence in genetics: A comprehensive review},
editor = {Khalid Raza},
booktitle = {Deep Learning in Genetics and Genomics},
publisher = {Academic Press},
pages = {237-247},
year = {2025},
isbn = {978-0-443-27523-4},
doi = {https://doi.org/10.1016/B978-0-443-27523-4.00005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443275234000056},
author = {Nicholas {Lee Franciss}},
keywords = {Generative artificial intelligence, Generative pretrained transformers, Large language models, Model architecture, Transformers},
abstract = {Generative artificial intelligence (GenAI) is revolutionizing genetics by applying the computational capabilities of predictive algorithms to unveil the genome's intricate complexities. From protein prediction to gene discovery and motif detection, GenAI techniques are transforming our understanding of genetic processes that were not previously possible. Here we explore how Markov chains, long-standing predecessors of more modern technologies like large language models (LLMs) and generative pretrained transformers (GPTs), have been complemented by these advanced methods, empowering researchers to extract unprecedented levels of information from DNA sequences, including regulatory networks that govern gene expression. We dive deep into how the individual model architectures enable their capability to implicitly understand and generate biological data. The cultural and intellectual implications of DeepMind's AlphaFold on the prediction of three-dimensional protein structures and, with it, its cultural impact on generative approaches in protein design and is also explored.}
}
@article{HUESO2023309,
title = {Is Generative Artificial Intelligence the Next Step Toward a Personalized Hemodialysis?},
journal = {Revista de Investigación Clínica},
volume = {75},
number = {6},
pages = {309-317},
year = {2023},
issn = {0034-8376},
doi = {https://doi.org/10.24875/RIC.23000162},
url = {https://www.sciencedirect.com/science/article/pii/S0034837625001597},
author = {Miguel Hueso and Rafael Álvarez and David Marí and Vicent Ribas-Ripoll and Karim Lekadir and Alfredo Vellido},
keywords = {Personalized hemodialysis, Artificial intelligence, Natural language processing, Large Language Models},
abstract = {ABSTRACT
Artificial intelligence (AI) generative models driven by the integration of AI and natural language processing technologies, such as OpenAI’s chatbot generative pre-trained transformer large language model (LLM), are receiving much public attention and have the potential to transform personalized medicine. Dialysis patients are highly dependent on technology and their treatment generates a challenging large volume of data that has to be analyzed for knowledge extraction. We argue that, by integrating the data acquired from hemodialysis treatments with the powerful conversational capabilities of LLMs, nephrologists could personalize treatments adapted to patients’ lifestyles and preferences. We also argue that this new conversational AI integrated with a personalized patient-computer interface will enhance patients’ engagement and self-care by providing them with a more personalized experience. However, generative AI models require continuous and accurate updates of data, and expert supervision and must address potential biases and limitations. Dialysis patients can also benefit from other new emerging technologies such as Digital Twins with which patients’ care can also be addressed from a personalized medicine perspective. In this paper, we will revise LLMs potential strengths in terms of their contribution to personalized medicine, and, in particular, their potential impact, and limitations in nephrology. Nephrologists’ collaboration with AI academia and companies, to develop algorithms and models that are more transparent, understandable, and trustworthy, will be crucial for the next generation of dialysis patients. The combination of technology, patient-specific data, and AI should contribute to create a more personalized and interactive dialysis process, improving patients’ quality of life. (REV INVEST CLIN. 2023;75(6):309-17)}
}
@article{QIN2024109996,
title = {Intelligent design and optimization system for shear wall structures based on large language models and generative artificial intelligence},
journal = {Journal of Building Engineering},
volume = {95},
pages = {109996},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.109996},
url = {https://www.sciencedirect.com/science/article/pii/S235271022401564X},
author = {Sizhong Qin and Hong Guan and Wenjie Liao and Yi Gu and Zhe Zheng and Hongjing Xue and Xinzheng Lu},
keywords = {Intelligent design, Structural optimization, Shear wall structure, Large language model, Generative artificial intelligence},
abstract = {Intelligent design technology for shear wall structures has great potential for enhancing design efficiency and addressing the challenges of tedious and repetitive design tasks. Recently, there has been a surge in the development of this technology. However, existing deep learning-based design methods for shear wall structures suffer from poor quality and usability issues. To address these challenges, this study proposes an intelligent design and optimization system for shear wall structures based on large language models (LLMs) and generative artificial intelligence (AI). The system employs an LLM as the core controller, which interacts with engineers to interpret their language descriptions and translate them into executable computer code. Subsequently, the system utilizes the corresponding structural generation and optimization methods to accomplish intelligent design tasks automatically. Furthermore, the system incorporates such critical factors as the empirical rules, mechanical performance, and material consumption into the structural optimization process. A unique three-level, two-stage optimization method is constructed based on topology, pattern, and size to enhance the overall design quality. Being able to complete the entire workflow of architectural drawing processing, structural scheme generation, and analysis model establishment, the proposed system enables automated and efficient design of shear wall structures. Through the analysis and validation of multiple cases, it was demonstrated that this system can significantly speed up the design by approximately 30 times compared to that of traditional methods whilst ensuring the safety and cost-effectiveness of the design schemes. Consequently, this study provides valuable insights for the advancement of automated structural design undertakings.}
}
@article{CHENG2024899,
title = {Principles and challenges of generative artificial intelligence detection},
journal = {British Journal of Anaesthesia},
volume = {133},
number = {4},
pages = {899-901},
year = {2024},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2024.06.037},
url = {https://www.sciencedirect.com/science/article/pii/S000709122400415X},
author = {Kunming Cheng and Wanqing Li and Nan Zhang and Xiaojun Liu and Haiyang Wu},
keywords = {academic publishing, artificial intelligence, ChatGPT, detection, generative AI, peer review}
}
@article{XU2024e32364,
title = {Generative artificial intelligence in healthcare from the perspective of digital media: Applications, opportunities and challenges},
journal = {Heliyon},
volume = {10},
number = {12},
pages = {e32364},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32364},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024083956},
author = {Rui Xu and Zhong Wang},
keywords = {ChatGPT, Healthcare, Digital media, Applications, Opportunities, Challenges, Digital health, Generative artificial intelligence, Large language models, Artificial intelligence generated content},
abstract = {Introduction
The emergence and application of generative artificial intelligence/large language models (hereafter GenAI LLMs) have the potential for significant impact on the healthcare industry. However, there is currently a lack of systematic research on GenAI LLMs in healthcare based on reliable data. This article aims to conduct an exploratory study of the application of GenAI LLMs (i.e., ChatGPT) in healthcare from the perspective of digital media (i.e., online news), including the application scenarios, potential opportunities, and challenges.
Methods
This research used thematic qualitative text analysis in five steps: firstly, developing main topical categories based on relevant articles; secondly, encoding the search keywords using these categories; thirdly, conducting searches for news articles via Google ; fourthly, encoding the sub-categories using the elaborate category system; and finally, conducting category-based analysis and presenting the results. Natural language processing techniques, including the TermRaider and AntConc tool, were applied in the aforementioned steps to assist in text qualitative analysis. Additionally, this study built a framework, using for analyzing the above three topics, from the perspective of five different stakeholders, including healthcare demanders and providers.
Results
This study summarizes 26 applications (e.g., provide medical advice, provide diagnosis and triage recommendations, provide mental health support, etc.), 21 opportunities (e.g., make healthcare more accessible, reduce healthcare costs, improve patients care, etc.), and 17 challenges (e.g., generate inaccurate/misleading/wrong answers, raise privacy concerns, lack of transparency, etc.), and analyzes the reasons for the formation of these key items and the links between the three research topics.
Conclusions
The application of GenAI LLMs in healthcare is primarily focused on transforming the way healthcare demanders access medical services (i.e., making it more intelligent, refined, and humane) and optimizing the processes through which healthcare providers offer medical services (i.e., simplifying, ensuring timeliness, and reducing errors). As the application becomes more widespread and deepens, GenAI LLMs is expected to have a revolutionary impact on traditional healthcare service models, but it also inevitably raises ethical and security concerns. Furthermore, GenAI LLMs applied in healthcare is still in the initial stage, which can be accelerated from a specific healthcare field (e.g., mental health) or a specific mechanism (e.g., GenAI LLMs’ economic benefits allocation mechanism applied to healthcare) with empirical or clinical research.}
}
@article{KUMAR2025102078,
title = {Evaluating Generative Artificial Intelligence Query of Pelvic Congestion Syndrome Management},
journal = {Journal of Vascular Surgery: Venous and Lymphatic Disorders},
volume = {13},
number = {2},
pages = {102078},
year = {2025},
issn = {2213-333X},
doi = {https://doi.org/10.1016/j.jvsv.2024.102078},
url = {https://www.sciencedirect.com/science/article/pii/S2213333X24004980},
author = {Arjun Kumar and Besher Tolaymat and Katherine McMackin and Patrick Conroy and Laurel Hastings and Bruce Tjaden and Philip Batista and Joseph Lombardi}
}
@article{NIKOLOPOULOS2024104693,
title = {P.6.4 DEVELOPMENT OF A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR THE REGENERATION OF VIRTUAL VOLUNTEERS IN BIOEQUIVALENCE STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104693},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104693},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012912},
author = {A. Nikolopoulos and V. Karalis}
}
@article{TRAN2024104079,
title = {Visual narratives in nursing education: A generative artificial intelligence approach},
journal = {Nurse Education in Practice},
volume = {79},
pages = {104079},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.104079},
url = {https://www.sciencedirect.com/science/article/pii/S1471595324002087},
author = {Linh Duc Tran and Neo Tung and Eugene Tordecilla Macalinga and Arthur Tang and Brigitte Woo and Wilson Tam},
keywords = {Nursing education, Visual narrative, Generative artificial intelligence, DALL-E},
abstract = {Aim
The aim of this paper is to investigate the incorporation of visual narratives, such as comics and graphics, into nursing education using Generative Artificial Intelligence (GAI) models like DALL-E.
Background
Visual narratives serve as a powerful method for communicating intricate concepts in nursing education. Despite their advantages, challenges in creating effective educational comics persist due to the need for expertise in graphic design and the associated time and resource constraints.
Design
This study examines existing literature that highlights the efficacy of visual narratives in education and demonstrates the potential of GAI models, specifically DALL-E, in creating visual narratives for nursing education.
Methods
We analyze the potential of GAI models, specifically DALL-E, to create visual narratives for educational purposes. This was demonstrated through illustrative examples addressing sensitive topics, illustrating research methodology and designing recruitment posters for clinical trials. Additionally, we discussed the necessity of reviewing and editing the text generated by DALL-E to ensure its accuracy and relevance in educational contexts. The method also considered legal concerns related to copyright and ownership of the generated content, highlighting the evolving legal landscape in this domain.
Results
The study found that GAI, specifically DALL-E, has significant potential to bridge the gap in creating visual narratives for nursing education. While offering cost-effectiveness and accessibility, GAI tools require careful consideration of challenges such as text-related errors, misinterpretation of user prompts and legal concerns.
Conclusions
GAI models like DALL-E offer promising solutions for enhancing visual storytelling in nursing education. However, their effective integration requires a collaborative approach, where educators engage with these tools as co-pilots, leveraging their capabilities while mitigating potential drawbacks. By doing so, educators can harness the full potential of GAI to enrich the educational experience for learners through compelling visual narratives.}
}
@article{OCHIENG2024102710,
title = {Potential application of generative artificial intelligence and machine learning algorithm in oil and gas sector: Benefits and future prospects},
journal = {Technology in Society},
volume = {79},
pages = {102710},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102710},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002586},
author = {Edward G. Ochieng and Diana Ominde and Tarila Zuofa},
keywords = {Generative artificial intelligence, Machine learning algorithm, Value chain operations, Oil and gas, Productivity performance, Risk management},
abstract = {With the rapid advancement of technology and societies, the global energy sector now acknowledges that by integrating contemporary digital technologies into their operations and capabilities, can improve their competitive advantage and innovation performance and processes. Moreover, energy operators are also facing a significant undertaking: how to best use and secure large amounts of data that promote sustainable productivity performance and minimise potential threats in the oil and gas value chain and project operations. In view of the foregoing, various facets like Generative Artificial Intelligence (GAI) and Machine Learning Algorithms (MLA) are increasingly gaining popularity within oil and gas sector operations. Thus, we explored how GAI and ML algorithms can enhance oil and gas value chain productivity performance. The Principal Component Analysis (PCA) was employed to identify significant GAI and MLA variables influencing performance in the oil and gas value chain, while Structural Equation Modelling (SEM) was used to test regression equations related to their application. The study found that risk portfolios and profiles can be appraised throughout the value chain by effectively utilising GAI and ML algorithms in upstream, midstream and downstream undertakings. While these findings are noteworthy and have significant implications for current practice, the paper advocates that an array of digital technologies beyond GAI and ML can still be examined during future studies to demonstrate a holistic perspective on how digital transformation can be achieved across the energy sector value and project operations.}
}
@article{BARKER2024A43,
title = {Generative Artificial Intelligence as a Tool for Teaching Communication in Nutrition and Dietetics Education – an Novel Education Innovation},
journal = {Journal of the Academy of Nutrition and Dietetics},
volume = {124},
number = {10, Supplement },
pages = {A43},
year = {2024},
note = {2024 Food & Nutrition Conference & Expo},
issn = {2212-2672},
doi = {https://doi.org/10.1016/j.jand.2024.06.093},
url = {https://www.sciencedirect.com/science/article/pii/S2212267224003873},
author = {L. Barker and J. Moore and H. Cook}
}
@article{RATTEN2023100857,
title = {Generative artificial intelligence (ChatGPT): Implications for management educators},
journal = {The International Journal of Management Education},
volume = {21},
number = {3},
pages = {100857},
year = {2023},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2023.100857},
url = {https://www.sciencedirect.com/science/article/pii/S1472811723000952},
author = {Vanessa Ratten and Paul Jones},
keywords = {Academic research, Teaching, Learning, Digital transformation, Management education, Artificial intelligence, ChatGPT},
abstract = {ChatGPT has been one of the most talked about computer programs amongst management educators in recent weeks due to its transformative ability to change how assessments are undertaken and graded. Unlike other educational technologies that can be tracked when used, ChatGPT has superior abilities that make it virtually untraceable when used. This creates a dilemma for management educators wanting to utilise the technology whilst staying relevant but also interested in authentic learning. Thus, it is critical for management educators to quickly implement policies regarding ChatGPT and subsequent new generative artificial intelligence because of its ease of use and affordability. This article is conceptual in nature and discusses ChatGPT as a generative form of artificial intelligence that presents challenges for management educators that need to be addressed through appropriate strategies. Thereby contributing to the literature on how technological innovations can be included in curriculum design and management learning practices. Practical and managerial implications are stated that highlight the critical need to re-examine existing education practices as a way of incorporating new technological innovation that can be utilised in a beneficial way.}
}
@article{NIKOLOPOULOS2024104690,
title = {P.6.1 CREATING VIRTUAL PATIENTS WITH A GENERATIVE ARTIFICIAL INTELLIGENCE ALGORITHM FOR CLINICAL STUDIES},
journal = {Physica Medica},
volume = {127},
pages = {104690},
year = {2024},
note = {Abstracts of the 2nd Panhellenic Congress of Medical Physics},
issn = {1120-1797},
doi = {https://doi.org/10.1016/j.ejmp.2024.104690},
url = {https://www.sciencedirect.com/science/article/pii/S1120179724012882},
author = {A. Nikolopoulos and V. Karalis}
}
@article{KOHNKE2023100156,
title = {Exploring generative artificial intelligence preparedness among university language instructors: A case study},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100156},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000358},
author = {Lucas Kohnke and Benjamin Luke Moorhouse and Di Zou},
keywords = {Artificial intelligence, AI, Generative AI, University language instructors, Higher education, English},
abstract = {The integration of generative artificial intelligence (AI) in English language teaching presents opportunities and challenges for instructors. This study explores the attitudes of higher education English language instructors towards generative AI tools, their intentions to use them and the institutional support and professional development necessary to teach and learn with them. As the field continues to evolve rapidly, it is essential to comprehend the readiness of front-line language instructors. This qualitative interpretive study seeks to identify the digital competencies and pedagogical knowledge required to implement generative AI in education and provide guidance for the design of professional development programmes that address the challenges and concerns associated with adopting AI. Drawing on semi-structured interviews with twelve instructors at a higher education institution in Hong Kong, the findings reveal the significance of familiarity and confidence with using AI-driven teaching tools, the challenges and concerns language instructors face and the need for tailored support and professional development. The study offers ten practical implications to cultivate language instructors’ digital competencies, pedagogical knowledge and positive attitudes towards integrating AI to enhance their students’ learning experiences.}
}
@article{SONG2024100069,
title = {Developing an immersive game-based learning platform with generative artificial intelligence and virtual reality technologies – “LearningverseVR”},
journal = {Computers & Education: X Reality},
volume = {4},
pages = {100069},
year = {2024},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2024.100069},
url = {https://www.sciencedirect.com/science/article/pii/S2949678024000199},
author = {Yanjie Song and Kaiyi Wu and Jiaoyang Ding},
keywords = {Generative AI, Virtual reality (VR), Game-based learning, Immersion, Interaction},
abstract = {The rapid evolution of generative artificial intelligence (AI) and virtual reality (VR) technologies are revolutionising various fields, including education and gaming industries. However, studies on how to enhance immersive game-based learning with AI and VR technologies remain scant. Given this, the article presents the creation of “LearningverseVR,” an immersive game-based learning platform developed using generative AI and VR technologies, which is based on “Learningverse,” a metaverse platform developed by the lead author and her research team. The “LearningverseVR” platform uses Unity as the client and Python, Flask and MySQL as the backend. Unity's multiplayer service provides multiplayer online functionality, supporting learners to engage in immersive and interactive learning activities. The design framework of the platform consists of two main components: Game-based learning with generative AI and immersion with VR technologies. First, generative AI is used to create NPCs with diverse personalities and life backgrounds, and enable learners to interact with NPCs without scripted dialogues, creating an interactive and immersive game-based learning environment. Secondly, such a learning experience is enhanced by leveraging the Large Language Model (LLM) ecosystem with VR technology. The creation of the “LearningverseVR” platform provides novel perspectives on digital game-based learning.}
}